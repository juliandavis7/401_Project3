{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs import *\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data to Test Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, layers=None, nodes=None, nnodes=None, \n",
    "                 activations=[], activationFn=\"\", batchSize=50, \n",
    "                 lr=.01, max_epoch=100, momentum=.9,tol=0.0001):\n",
    "        \n",
    "        if layers != None:\n",
    "            self.layers = layers # total number of hidden layers\n",
    "        else:\n",
    "            self.layers = len(nodes)\n",
    "            \n",
    "        self.tol = tol\n",
    "\n",
    "        # an int array of size [0, ..., Layers + 1]\n",
    "        # Nodes[0] shall represent the input size (typically 50)\n",
    "        # Nodes[Layers + 1] shall represent the output size (typically 1)\n",
    "        # all other Nodes represent the number of nodes (or width) in the hidden layer i\n",
    "        self.nodes = nodes\n",
    "        if nodes != None:\n",
    "            self.nodes.insert(0, batchSize)\n",
    "            self.nodes.append(1)\n",
    "        \n",
    "        # alternative to nodes where each hidden layer of the nueral network is the same size\n",
    "        self.nnodes = nnodes\n",
    "        if nnodes != None:\n",
    "            self.nodes = []\n",
    "            self.nodes.append(batchSize)\n",
    "            for i in range(layers):\n",
    "                self.nodes.append(nnodes)\n",
    "            self.nodes.append(1)\n",
    "        \n",
    "        # activations[i] values are labels indicating the activation function used in layer i\n",
    "        self.activations = activations\n",
    "        self.activationFn = activationFn\n",
    "        if activationFn != \"\":\n",
    "            self.activations = [activationFn] * layers\n",
    "        \n",
    "        self.batchSize = batchSize\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "        self.max_epoch = max_epoch\n",
    "        \n",
    "        self.mu = momentum\n",
    "        \n",
    "        self.layer_values = [None] * (self.layers + 2)\n",
    "        self.iters = 0\n",
    "        self.epochs = 0\n",
    "                \n",
    "    def validateHyperParams(self):\n",
    "        \n",
    "        if self.layers != (len(self.nodes) - 2):\n",
    "            raise ValueError(\"layers must be equal to the number of hidden layers, got %s.\" % self.layers)\n",
    "        if self.nnodes != None and self.nnodes <= 0:\n",
    "            raise ValueError(\"nnodes must be > 0, got %s.\" % self.nnodes)\n",
    "        if self.lr <= 0 or self.lr > 1:\n",
    "            raise ValueError(\"lr must be in (0, 1], got %s.\" % self.lr)\n",
    "            \n",
    "        if self.max_epoch <= 0:\n",
    "            raise ValueError(\"max_iter must be > 0, got %s.\" % self.max_epoch)\n",
    "               \n",
    "        activation_functions = list(ACTIVATIONS.keys())\n",
    "        if self.activationFn != \"\":\n",
    "            if self.activationFn not in activation_functions:\n",
    "                raise ValueError(\"%s is not an activation function\" % self.activationFn\n",
    "                                + \"\\nAvailable activation functions: relu, leaky_relu, sigmoid, tanh\")\n",
    "    \n",
    "    def initialize_weights(self, M):\n",
    "        weights = []\n",
    "        \n",
    "        for i in range(self.layers + 1):\n",
    "            if i == 0:\n",
    "                input_size = M # special case for w1\n",
    "            else:\n",
    "                input_size = self.nodes[i]\n",
    "            output_size = self.nodes[i + 1]\n",
    "            \n",
    "            # Xavier (Glorot) Initialization\n",
    "            if self.activationFn == \"tanh\":\n",
    "                target_variance = 2 / (input_size + output_size)\n",
    "                w_i = np.random.normal(loc= 0, scale = np.sqrt(target_variance), size=(input_size, output_size))\n",
    "            # He Initialization\n",
    "            elif self.activationFn == \"relu\":\n",
    "                target_variance = 2 / input_size\n",
    "                w_i = np.random.normal(loc= 0, scale = np.sqrt(target_variance), size=(input_size, output_size))\n",
    "            # Random Uniform\n",
    "            else:\n",
    "                w_i = np.random.uniform(-1/np.sqrt(input_size), 1/np.sqrt(input_size))\n",
    "                #w_i = np.random.normal(size=(input_size, output_size))\n",
    "            w_i = np.round(w_i, 2)\n",
    "            w_i[input_size - 1:] = 0 # initialize bias to 0\n",
    "            weights.append(w_i)\n",
    "        return weights\n",
    "       \n",
    "        \n",
    "    def forward_pass(self, X_batch, y_batch):\n",
    "        \n",
    "        self.layer_values[0] = X_batch\n",
    "        \n",
    "        # calculate hidden layers\n",
    "        for i in range(self.layers):\n",
    "            X = self.layer_values[i]\n",
    "            weights = self.weights[i]\n",
    "            h_layer = X.dot(weights)\n",
    "            \n",
    "            # apply activation function\n",
    "            activation_fn = ACTIVATIONS[self.activations[i]]\n",
    "            activation_fn(h_layer)\n",
    "            self.layer_values[i + 1] = h_layer\n",
    "            \n",
    "        \n",
    "        # calculate predictions\n",
    "        X = self.layer_values[self.layers] # values in last hidden layer\n",
    "        weights = self.weights[self.layers]\n",
    "        y_pred = X.dot(weights)\n",
    "        y_pred = y_pred.flatten()\n",
    "        \n",
    "        # calculate the l2 loss\n",
    "        l2_loss = 0\n",
    "        # only need predictions once we have fit the data\n",
    "        if isinstance(y_batch, np.ndarray): \n",
    "            l2_loss = squared_loss(y_pred, y_batch)\n",
    "            self.layer_values[self.layers + 1] = l2_loss\n",
    "        \n",
    "        return l2_loss, y_pred\n",
    "    \n",
    "    \n",
    "    def backward_pass(self, y_pred, y_batch):\n",
    "        \n",
    "        # loss layer\n",
    "        J = squared_loss_derivative(y_pred, y_batch, self.batchSize)\n",
    "        J = np.reshape(J, (len(J), 1))\n",
    "        \n",
    "        J_weights = [None] * (self.layers + 1)\n",
    "        \n",
    "        # output layer\n",
    "        # jacobian w.r.t. weights\n",
    "        x_t = self.layer_values[self.layers].T\n",
    "        J_wi = x_t.dot(J)\n",
    "        J_weights[self.layers] = J_wi\n",
    "        \n",
    "        # update jacobian at output layer\n",
    "        w_t = self.weights[self.layers].T\n",
    "        w_t = np.delete(w_t, w_t.shape[1] - 1, 1) # take out the bias\n",
    "        J = np.dot(J, w_t)\n",
    "        zeros = [0] * len(J)\n",
    "        zeros = np.reshape(zeros, (len(J), 1))\n",
    "        J = np.append(J, zeros, axis=1)\n",
    "        \n",
    "        # iterate through hidden layers backwards\n",
    "        for i in range(self.layers, 0 , -1):\n",
    "            # update jacobian at activation layer\n",
    "            d_activation_fn = DERIVATIVES[self.activations[i - 1]]\n",
    "            d_activation_fn(self.layer_values[i], J)\n",
    "            \n",
    "            # hidden layer\n",
    "            # jacobian w.r.t. weights\n",
    "            x_t = self.layer_values[i - 1].T\n",
    "            J_wi = x_t.dot(J)\n",
    "            J_weights[i - 1] = J_wi\n",
    "            \n",
    "        # initialize velocity to 0\n",
    "        if self.epochs == 0 and self.iters == 0:\n",
    "            self.velocity = []\n",
    "            for i in range(len(J_weights)):\n",
    "                n_rows = J_weights[i].shape[0]\n",
    "                n_cols = J_weights[i].shape[1]\n",
    "                vel_i = np.zeros((n_rows, n_cols))\n",
    "                self.velocity.append(vel_i)\n",
    "        \n",
    "        for i in range(len(J_weights)):\n",
    "            self.velocity[i] = self.mu * self.velocity[i] - self.lr * J_weights[i]\n",
    "            self.weights[i] += self.velocity[i]\n",
    "      \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        self.validateHyperParams()\n",
    "        # convert to numpy arrays\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            X_train = X_train.to_numpy()\n",
    "            \n",
    "        if isinstance(y_train, pd.Series):\n",
    "            y_train = y_train.to_numpy()\n",
    "            \n",
    "        # add ones for bias\n",
    "        ones = [1] * len(X_train)\n",
    "        ones = np.reshape(ones, (len(X_train), 1))\n",
    "        X_train = np.append(X_train, ones, axis=1)\n",
    "        \n",
    "        # save 10% for validation\n",
    "        val_rows = round(len(X_train) * .1)\n",
    "        X_val = X_train[:val_rows, :]\n",
    "        y_val = y_train[:val_rows]\n",
    "        \n",
    "        X_train = X_train[val_rows:, :]\n",
    "        y_train = y_train[val_rows:]\n",
    "        \n",
    "        # initalize weights on first iteration\n",
    "        M = X_train.shape[1] # M = number of features\n",
    "        self.weights = self.initialize_weights(M)\n",
    "        \n",
    "        previous_loss = np.inf\n",
    "        didnt_improve_loss_count = 0\n",
    "            \n",
    "        while (self.epochs < self.max_epoch):\n",
    "            # ONE EPOCH \n",
    "            last_idx = 0\n",
    "            while (last_idx < len(X_train)):\n",
    "                first_idx = self.iters * self.batchSize\n",
    "                remaining_rows = len(X_train) - first_idx\n",
    "                last_idx = first_idx + min(self.batchSize, remaining_rows)\n",
    "                X_batch = X_train[first_idx: last_idx, :]\n",
    "                y_batch = y_train[first_idx: last_idx]\n",
    "\n",
    "                loss, y_pred = self.forward_pass(X_batch, y_batch)\n",
    "                self.backward_pass(y_pred, y_batch)\n",
    "                self.iters += 1\n",
    "            \n",
    "            # trainig and validation loss after one epoch\n",
    "            t_loss, y_pred = self.forward_pass(X_train, y_train)\n",
    "            v_loss, y_pred = self.forward_pass(X_val, y_val)\n",
    "            print(\"epoch:\", self.epochs)\n",
    "            print(\"training loss:\", t_loss)\n",
    "            print(\"validation loss:\", v_loss)\n",
    "            \n",
    "            self.iters = 0 # start over, next epoch\n",
    "            self.epochs += 1\n",
    "            \n",
    "            # Currently stops based on training loss, but could easily be modified to\n",
    "            # stop on validation loss by substituting t_loss with v_loss\n",
    "            print(\"loss difference:\")\n",
    "            print(previous_loss - t_loss)\n",
    "            if previous_loss - t_loss < self.tol:\n",
    "                didnt_improve_loss_count += 1\n",
    "                print(\"that didn't improve loss: \", didnt_improve_loss_count)\n",
    "            else:\n",
    "                didnt_improve_loss_count = 0\n",
    "            \n",
    "            previous_loss = t_loss\n",
    "            \n",
    "            if(didnt_improve_loss_count >= 10):\n",
    "                print(\"Training loss did not improve more than tol=\" + str(self.tol) + \" for 10 consecutive epochs. Stopping.\")\n",
    "                return\n",
    "            \n",
    "       \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        # convert to numpy array\n",
    "        if isinstance(X_test, pd.DataFrame):\n",
    "            X_test = X_test.to_numpy()\n",
    "        \n",
    "        # add ones for bias\n",
    "        ones = [1] * len(X_test)\n",
    "        ones = np.reshape(ones, (len(X_test), 1))\n",
    "        X_test = np.append(X_test, ones, axis=1)\n",
    "        \n",
    "        loss, y_pred = self.forward_pass(X_test, None)\n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Nueral Network on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF EPOCHS\n",
      "0\n",
      "epoch: 0\n",
      "training loss: 266.80589436059756\n",
      "validation loss: 240.65890118480905\n",
      "loss difference:\n",
      "inf\n",
      "epoch: 1\n",
      "training loss: 130.39131134802912\n",
      "validation loss: 136.20026443025083\n",
      "loss difference:\n",
      "136.41458301256844\n",
      "epoch: 2\n",
      "training loss: 21.421191936938673\n",
      "validation loss: 11.431962545738552\n",
      "loss difference:\n",
      "108.97011941109045\n",
      "epoch: 3\n",
      "training loss: 15.343051470104028\n",
      "validation loss: 6.309723167503217\n",
      "loss difference:\n",
      "6.078140466834645\n",
      "epoch: 4\n",
      "training loss: 14.23994515523222\n",
      "validation loss: 6.094842778439463\n",
      "loss difference:\n",
      "1.1031063148718072\n",
      "epoch: 5\n",
      "training loss: 13.606287602081999\n",
      "validation loss: 6.238426593683492\n",
      "loss difference:\n",
      "0.633657553150222\n",
      "epoch: 6\n",
      "training loss: 13.0889426897538\n",
      "validation loss: 6.375127834396407\n",
      "loss difference:\n",
      "0.5173449123281983\n",
      "epoch: 7\n",
      "training loss: 12.6330849755594\n",
      "validation loss: 6.479710631812698\n",
      "loss difference:\n",
      "0.4558577141943996\n",
      "epoch: 8\n",
      "training loss: 12.223300968422953\n",
      "validation loss: 6.55363528032022\n",
      "loss difference:\n",
      "0.409784007136448\n",
      "epoch: 9\n",
      "training loss: 11.853876251072853\n",
      "validation loss: 6.60598107819496\n",
      "loss difference:\n",
      "0.36942471735009974\n",
      "epoch: 10\n",
      "training loss: 11.52108033715671\n",
      "validation loss: 6.646317116359347\n",
      "loss difference:\n",
      "0.3327959139161436\n",
      "epoch: 11\n",
      "training loss: 11.221311365295566\n",
      "validation loss: 6.681351773063571\n",
      "loss difference:\n",
      "0.29976897186114293\n",
      "epoch: 12\n",
      "training loss: 10.950598463072291\n",
      "validation loss: 6.714268168378564\n",
      "loss difference:\n",
      "0.27071290222327526\n",
      "epoch: 13\n",
      "training loss: 10.704841611230743\n",
      "validation loss: 6.7457978597856165\n",
      "loss difference:\n",
      "0.2457568518415485\n",
      "epoch: 14\n",
      "training loss: 10.480370878233167\n",
      "validation loss: 6.775833848244412\n",
      "loss difference:\n",
      "0.2244707329975757\n",
      "epoch: 15\n",
      "training loss: 10.274271516832707\n",
      "validation loss: 6.804396594863014\n",
      "loss difference:\n",
      "0.2060993614004598\n",
      "epoch: 16\n",
      "training loss: 10.084365970401915\n",
      "validation loss: 6.831776318245803\n",
      "loss difference:\n",
      "0.18990554643079172\n",
      "epoch: 17\n",
      "training loss: 9.909007017877293\n",
      "validation loss: 6.858345470237435\n",
      "loss difference:\n",
      "0.17535895252462197\n",
      "epoch: 18\n",
      "training loss: 9.74684917324085\n",
      "validation loss: 6.884403703237987\n",
      "loss difference:\n",
      "0.16215784463644312\n",
      "epoch: 19\n",
      "training loss: 9.596689051823937\n",
      "validation loss: 6.91013000237097\n",
      "loss difference:\n",
      "0.15016012141691348\n",
      "epoch: 20\n",
      "training loss: 9.457388323335545\n",
      "validation loss: 6.9356005957719775\n",
      "loss difference:\n",
      "0.1393007284883918\n",
      "epoch: 21\n",
      "training loss: 9.327853413164021\n",
      "validation loss: 6.960825622973605\n",
      "loss difference:\n",
      "0.12953491017152352\n",
      "epoch: 22\n",
      "training loss: 9.207041493527427\n",
      "validation loss: 6.985778922716127\n",
      "loss difference:\n",
      "0.12081191963659421\n",
      "epoch: 23\n",
      "training loss: 9.09397264401288\n",
      "validation loss: 7.010413629457307\n",
      "loss difference:\n",
      "0.11306884951454776\n",
      "epoch: 24\n",
      "training loss: 8.987739084476805\n",
      "validation loss: 7.034666246094411\n",
      "loss difference:\n",
      "0.10623355953607394\n",
      "epoch: 25\n",
      "training loss: 8.88750925119028\n",
      "validation loss: 7.058454912339345\n",
      "loss difference:\n",
      "0.1002298332865248\n",
      "epoch: 26\n",
      "training loss: 8.792527483039345\n",
      "validation loss: 7.081676704457229\n",
      "loss difference:\n",
      "0.09498176815093551\n",
      "epoch: 27\n",
      "training loss: 8.70211083272183\n",
      "validation loss: 7.104206663693175\n",
      "loss difference:\n",
      "0.09041665031751478\n",
      "epoch: 28\n",
      "training loss: 8.615644333712124\n",
      "validation loss: 7.12589938106981\n",
      "loss difference:\n",
      "0.08646649900970615\n",
      "epoch: 29\n",
      "training loss: 8.532575646682982\n",
      "validation loss: 7.146592844138515\n",
      "loss difference:\n",
      "0.08306868702914194\n",
      "epoch: 30\n",
      "training loss: 8.452409656324226\n",
      "validation loss: 7.166113797517093\n",
      "loss difference:\n",
      "0.08016599035875593\n",
      "epoch: 31\n",
      "training loss: 8.374703349587591\n",
      "validation loss: 7.184283834748093\n",
      "loss difference:\n",
      "0.07770630673663526\n",
      "epoch: 32\n",
      "training loss: 8.299061156621397\n",
      "validation loss: 7.200925595574513\n",
      "loss difference:\n",
      "0.07564219296619434\n",
      "epoch: 33\n",
      "training loss: 8.225130839131914\n",
      "validation loss: 7.215868639341544\n",
      "loss difference:\n",
      "0.07393031748948253\n",
      "epoch: 34\n",
      "training loss: 8.152599941165013\n",
      "validation loss: 7.228954726697095\n",
      "loss difference:\n",
      "0.07253089796690126\n",
      "epoch: 35\n",
      "training loss: 8.081192762432591\n",
      "validation loss: 7.240042347224328\n",
      "loss difference:\n",
      "0.07140717873242153\n",
      "epoch: 36\n",
      "training loss: 8.010667772823208\n",
      "validation loss: 7.249010390092021\n",
      "loss difference:\n",
      "0.07052498960938358\n",
      "epoch: 37\n",
      "training loss: 7.940815361439564\n",
      "validation loss: 7.255760889545391\n",
      "loss difference:\n",
      "0.06985241138364362\n",
      "epoch: 38\n",
      "training loss: 7.871455806473568\n",
      "validation loss: 7.260220806432917\n",
      "loss difference:\n",
      "0.06935955496599622\n",
      "epoch: 39\n",
      "training loss: 7.80243736225952\n",
      "validation loss: 7.262342842021864\n",
      "loss difference:\n",
      "0.06901844421404846\n",
      "epoch: 40\n",
      "training loss: 7.73363438241981\n",
      "validation loss: 7.262105323249238\n",
      "loss difference:\n",
      "0.06880297983970962\n",
      "epoch: 41\n",
      "training loss: 7.664945426873005\n",
      "validation loss: 7.259511245318061\n",
      "loss difference:\n",
      "0.0686889555468051\n",
      "epoch: 42\n",
      "training loss: 7.596291329520664\n",
      "validation loss: 7.254586601618091\n",
      "loss difference:\n",
      "0.06865409735234085\n",
      "epoch: 43\n",
      "training loss: 7.527613228095179\n",
      "validation loss: 7.247378165781771\n",
      "loss difference:\n",
      "0.06867810142548514\n",
      "epoch: 44\n",
      "training loss: 7.458870575362965\n",
      "validation loss: 7.237950911147818\n",
      "loss difference:\n",
      "0.06874265273221347\n",
      "epoch: 45\n",
      "training loss: 7.3900391609097085\n",
      "validation loss: 7.226385255974869\n",
      "loss difference:\n",
      "0.06883141445325691\n",
      "epoch: 46\n",
      "training loss: 7.321109175757835\n",
      "validation loss: 7.212774308025362\n",
      "loss difference:\n",
      "0.06892998515187365\n",
      "epoch: 47\n",
      "training loss: 7.252083349647715\n",
      "validation loss: 7.1972212521364325\n",
      "loss difference:\n",
      "0.06902582611011976\n",
      "epoch: 48\n",
      "training loss: 7.182975184931215\n",
      "validation loss: 7.179836984237665\n",
      "loss difference:\n",
      "0.06910816471649994\n",
      "epoch: 49\n",
      "training loss: 7.113807303635852\n",
      "validation loss: 7.16073805162454\n",
      "loss difference:\n",
      "0.06916788129536311\n",
      "epoch: 50\n",
      "training loss: 7.044609916956386\n",
      "validation loss: 7.140044918746905\n",
      "loss difference:\n",
      "0.06919738667946618\n",
      "epoch: 51\n",
      "training loss: 6.9754194202671025\n",
      "validation loss: 7.1178805453477\n",
      "loss difference:\n",
      "0.06919049668928334\n",
      "epoch: 52\n",
      "training loss: 6.906277112197464\n",
      "validation loss: 7.0943692420618865\n",
      "loss difference:\n",
      "0.0691423080696385\n",
      "epoch: 53\n",
      "training loss: 6.837228033384269\n",
      "validation loss: 7.069635757626329\n",
      "loss difference:\n",
      "0.06904907881319478\n",
      "epoch: 54\n",
      "training loss: 6.768319918913466\n",
      "validation loss: 7.043804549811145\n",
      "loss difference:\n",
      "0.06890811447080303\n",
      "epoch: 55\n",
      "training loss: 6.699602257785227\n",
      "validation loss: 7.016999196216528\n",
      "loss difference:\n",
      "0.06871766112823874\n",
      "epoch: 56\n",
      "training loss: 6.631125452592453\n",
      "validation loss: 6.989341908224416\n",
      "loss difference:\n",
      "0.06847680519277421\n",
      "epoch: 57\n",
      "training loss: 6.562940072731168\n",
      "validation loss: 6.9609531192250325\n",
      "loss difference:\n",
      "0.06818537986128526\n",
      "epoch: 58\n",
      "training loss: 6.4950961947472114\n",
      "validation loss: 6.9319511251872425\n",
      "loss difference:\n",
      "0.06784387798395652\n",
      "epoch: 59\n",
      "training loss: 6.427642823881477\n",
      "validation loss: 6.9024517610336655\n",
      "loss difference:\n",
      "0.06745337086573411\n",
      "epoch: 60\n",
      "training loss: 6.360627391587784\n",
      "validation loss: 6.872568100157532\n",
      "loss difference:\n",
      "0.06701543229369378\n",
      "epoch: 61\n",
      "training loss: 6.294095324835699\n",
      "validation loss: 6.842410167259381\n",
      "loss difference:\n",
      "0.06653206675208434\n",
      "epoch: 62\n",
      "training loss: 6.228089684369633\n",
      "validation loss: 6.812084657118055\n",
      "loss difference:\n",
      "0.0660056404660665\n",
      "epoch: 63\n",
      "training loss: 6.162650870646941\n",
      "validation loss: 6.78169465448849\n",
      "loss difference:\n",
      "0.06543881372269134\n",
      "epoch: 64\n",
      "training loss: 6.097816397668692\n",
      "validation loss: 6.751339353338968\n",
      "loss difference:\n",
      "0.06483447297824974\n",
      "epoch: 65\n",
      "training loss: 6.033620736004699\n",
      "validation loss: 6.721113777092923\n",
      "loss difference:\n",
      "0.06419566166399271\n",
      "epoch: 66\n",
      "training loss: 5.970095226642042\n",
      "validation loss: 6.691108505115787\n",
      "loss difference:\n",
      "0.06352550936265722\n",
      "epoch: 67\n",
      "training loss: 5.9072680665744555\n",
      "validation loss: 6.661409413865336\n",
      "loss difference:\n",
      "0.06282716006758626\n",
      "epoch: 68\n",
      "training loss: 5.84516436518402\n",
      "validation loss: 6.63209744330384\n",
      "loss difference:\n",
      "0.062103701390435084\n",
      "epoch: 69\n",
      "training loss: 5.7838062675580355\n",
      "validation loss: 6.603248399837329\n",
      "loss difference:\n",
      "0.061358097625984875\n",
      "epoch: 70\n",
      "training loss: 5.723213137274231\n",
      "validation loss: 6.574932805912147\n",
      "loss difference:\n",
      "0.060593130283804086\n",
      "epoch: 71\n",
      "training loss: 5.663401787401141\n",
      "validation loss: 6.547215803503803\n",
      "loss difference:\n",
      "0.059811349873090336\n",
      "epoch: 72\n",
      "training loss: 5.604386745104181\n",
      "validation loss: 6.520157114465759\n",
      "loss difference:\n",
      "0.059015042296960196\n",
      "epoch: 73\n",
      "training loss: 5.546180532893737\n",
      "validation loss: 6.493811055739478\n",
      "loss difference:\n",
      "0.058206212210444086\n",
      "epoch: 74\n",
      "training loss: 5.488793948625451\n",
      "validation loss: 6.468226602584325\n",
      "loss difference:\n",
      "0.05738658426828547\n",
      "epoch: 75\n",
      "training loss: 5.432236327072308\n",
      "validation loss: 6.44344748907152\n",
      "loss difference:\n",
      "0.05655762155314292\n",
      "epoch: 76\n",
      "training loss: 5.376515768194338\n",
      "validation loss: 6.419512332728134\n",
      "loss difference:\n",
      "0.05572055887797056\n",
      "epoch: 77\n",
      "training loss: 5.3216393208730155\n",
      "validation loss: 6.396454769758917\n",
      "loss difference:\n",
      "0.05487644732132235\n",
      "epoch: 78\n",
      "training loss: 5.267613115419119\n",
      "validation loss: 6.3743035887243185\n",
      "loss difference:\n",
      "0.054026205453896914\n",
      "epoch: 79\n",
      "training loss: 5.214442443074892\n",
      "validation loss: 6.353082853616899\n",
      "loss difference:\n",
      "0.05317067234422623\n",
      "epoch: 80\n",
      "training loss: 5.162131785461807\n",
      "validation loss: 6.3328120114243545\n",
      "loss difference:\n",
      "0.052310657613085176\n",
      "epoch: 81\n",
      "training loss: 5.110684800976374\n",
      "validation loss: 6.313505983838304\n",
      "loss difference:\n",
      "0.051446984485433056\n",
      "epoch: 82\n",
      "training loss: 5.060104278124773\n",
      "validation loss: 6.295175247093334\n",
      "loss difference:\n",
      "0.050580522851601195\n",
      "epoch: 83\n",
      "training loss: 5.01039206748663\n",
      "validation loss: 6.2778259074166884\n",
      "loss difference:\n",
      "0.049712210638142906\n",
      "epoch: 84\n",
      "training loss: 4.961549004360507\n",
      "validation loss: 6.261459781817771\n",
      "loss difference:\n",
      "0.04884306312612274\n",
      "epoch: 85\n",
      "training loss: 4.91357483328994\n",
      "validation loss: 6.246074494739329\n",
      "loss difference:\n",
      "0.04797417107056745\n",
      "epoch: 86\n",
      "training loss: 4.86646814385696\n",
      "validation loss: 6.2316636004365735\n",
      "loss difference:\n",
      "0.047106689432979465\n",
      "epoch: 87\n",
      "training loss: 4.820226324703072\n",
      "validation loss: 6.218216739049804\n",
      "loss difference:\n",
      "0.04624181915388803\n",
      "epoch: 88\n",
      "training loss: 4.774845540062097\n",
      "validation loss: 6.205719831532987\n",
      "loss difference:\n",
      "0.04538078464097506\n",
      "epoch: 89\n",
      "training loss: 4.73032073049949\n",
      "validation loss: 6.194155315318046\n",
      "loss difference:\n",
      "0.04452480956260718\n",
      "epoch: 90\n",
      "training loss: 4.686645637307799\n",
      "validation loss: 6.183502419258291\n",
      "loss difference:\n",
      "0.04367509319169116\n",
      "epoch: 91\n",
      "training loss: 4.643812848270185\n",
      "validation loss: 6.173737473381435\n",
      "loss difference:\n",
      "0.04283278903761367\n",
      "epoch: 92\n",
      "training loss: 4.601813861336888\n",
      "validation loss: 6.164834246571818\n",
      "loss difference:\n",
      "0.04199898693329729\n",
      "epoch: 93\n",
      "training loss: 4.560639162143362\n",
      "validation loss: 6.156764303657248\n",
      "loss difference:\n",
      "0.04117469919352601\n",
      "epoch: 94\n",
      "training loss: 4.520278311154543\n",
      "validation loss: 6.149497372547969\n",
      "loss difference:\n",
      "0.0403608509888187\n",
      "epoch: 95\n",
      "training loss: 4.480720036436768\n",
      "validation loss: 6.143001712015146\n",
      "loss difference:\n",
      "0.03955827471777518\n",
      "epoch: 96\n",
      "training loss: 4.44195232851843\n",
      "validation loss: 6.1372444712858325\n",
      "loss difference:\n",
      "0.03876770791833817\n",
      "epoch: 97\n",
      "training loss: 4.40396253439422\n",
      "validation loss: 6.132192033711939\n",
      "loss difference:\n",
      "0.03798979412420955\n",
      "epoch: 98\n",
      "training loss: 4.366737448367175\n",
      "validation loss: 6.127810338171911\n",
      "loss difference:\n",
      "0.03722508602704533\n",
      "epoch: 99\n",
      "training loss: 4.330263398043511\n",
      "validation loss: 6.124065173422951\n",
      "loss difference:\n",
      "0.036474050323664464\n",
      "epoch: 100\n",
      "training loss: 4.294526324356341\n",
      "validation loss: 6.120922442201557\n",
      "loss difference:\n",
      "0.035737073687169385\n",
      "epoch: 101\n",
      "training loss: 4.259511854974216\n",
      "validation loss: 6.118348393362393\n",
      "loss difference:\n",
      "0.03501446938212549\n",
      "epoch: 102\n",
      "training loss: 4.225205370841761\n",
      "validation loss: 6.1163098216765475\n",
      "loss difference:\n",
      "0.03430648413245496\n",
      "epoch: 103\n",
      "training loss: 4.191592065905602\n",
      "validation loss: 6.114774236033475\n",
      "loss difference:\n",
      "0.03361330493615888\n",
      "epoch: 104\n",
      "training loss: 4.158657000307452\n",
      "validation loss: 6.113709997687929\n",
      "loss difference:\n",
      "0.03293506559815018\n",
      "epoch: 105\n",
      "training loss: 4.126385147488606\n",
      "validation loss: 6.113086430862863\n",
      "loss difference:\n",
      "0.03227185281884548\n",
      "epoch: 106\n",
      "training loss: 4.094761435758678\n",
      "validation loss: 6.112873908475978\n",
      "loss difference:\n",
      "0.03162371172992806\n",
      "epoch: 107\n",
      "training loss: 4.063770784945396\n",
      "validation loss: 6.113043916022177\n",
      "loss difference:\n",
      "0.03099065081328245\n",
      "epoch: 108\n",
      "training loss: 4.03339813877331\n",
      "validation loss: 6.113569096745397\n",
      "loss difference:\n",
      "0.03037264617208546\n",
      "epoch: 109\n",
      "training loss: 4.003628493623087\n",
      "validation loss: 6.114423281197608\n",
      "loss difference:\n",
      "0.029769645150222956\n",
      "epoch: 110\n",
      "training loss: 3.974446924307403\n",
      "validation loss: 6.115581504138729\n",
      "loss difference:\n",
      "0.029181569315684275\n",
      "epoch: 111\n",
      "training loss: 3.9458386074682172\n",
      "validation loss: 6.117020011503791\n",
      "loss difference:\n",
      "0.028608316839185743\n",
      "epoch: 112\n",
      "training loss: 3.917788843157094\n",
      "validation loss: 6.118716259874782\n",
      "loss difference:\n",
      "0.02804976431112305\n",
      "epoch: 113\n",
      "training loss: 3.8902830751076976\n",
      "validation loss: 6.120648910563494\n",
      "loss difference:\n",
      "0.02750576804939664\n",
      "epoch: 114\n",
      "training loss: 3.8633069101488564\n",
      "validation loss: 6.12279782005362\n",
      "loss difference:\n",
      "0.026976164958841142\n",
      "epoch: 115\n",
      "training loss: 3.836846137139092\n",
      "validation loss: 6.125144028178257\n",
      "loss difference:\n",
      "0.02646077300976435\n",
      "epoch: 116\n",
      "training loss: 3.810886745728867\n",
      "validation loss: 6.127669745033381\n",
      "loss difference:\n",
      "0.025959391410224963\n",
      "epoch: 117\n",
      "training loss: 3.7854149451763157\n",
      "validation loss: 6.130358337257749\n",
      "loss difference:\n",
      "0.025471800552551382\n",
      "epoch: 118\n",
      "training loss: 3.760417183355016\n",
      "validation loss: 6.133194313953513\n",
      "loss difference:\n",
      "0.024997761821299758\n",
      "epoch: 119\n",
      "training loss: 3.735880165999868\n",
      "validation loss: 6.136163312187478\n",
      "loss difference:\n",
      "0.024537017355148016\n",
      "epoch: 120\n",
      "training loss: 3.711790876140065\n",
      "validation loss: 6.139252081710635\n",
      "loss difference:\n",
      "0.024089289859802854\n",
      "epoch: 121\n",
      "training loss: 3.6881365935683363\n",
      "validation loss: 6.142448468271759\n",
      "loss difference:\n",
      "0.023654282571728746\n",
      "epoch: 122\n",
      "training loss: 3.6649049140965473\n",
      "validation loss: 6.145741394692021\n",
      "loss difference:\n",
      "0.023231679471789057\n",
      "epoch: 123\n",
      "training loss: 3.6420837682530545\n",
      "validation loss: 6.149120838721986\n",
      "loss difference:\n",
      "0.02282114584349282\n",
      "epoch: 124\n",
      "training loss: 3.6196614389928916\n",
      "validation loss: 6.152577806632329\n",
      "loss difference:\n",
      "0.022422329260162854\n",
      "epoch: 125\n",
      "training loss: 3.5976265779233403\n",
      "validation loss: 6.15610430150255\n",
      "loss difference:\n",
      "0.022034861069551326\n",
      "epoch: 126\n",
      "training loss: 3.5759682195025286\n",
      "validation loss: 6.159693285275249\n",
      "loss difference:\n",
      "0.021658358420811652\n",
      "epoch: 127\n",
      "training loss: 3.554675792652388\n",
      "validation loss: 6.163338633835691\n",
      "loss difference:\n",
      "0.021292426850140433\n",
      "epoch: 128\n",
      "training loss: 3.533739129246179\n",
      "validation loss: 6.167035084652145\n",
      "loss difference:\n",
      "0.020936663406209366\n",
      "epoch: 129\n",
      "training loss: 3.5131484689868047\n",
      "validation loss: 6.170778176857377\n",
      "loss difference:\n",
      "0.02059066025937417\n",
      "epoch: 130\n",
      "training loss: 3.492894460286364\n",
      "validation loss: 6.17456418404387\n",
      "loss difference:\n",
      "0.020254008700440806\n",
      "epoch: 131\n",
      "training loss: 3.4729681568860262\n",
      "validation loss: 6.17839004045876\n",
      "loss difference:\n",
      "0.01992630340033763\n",
      "epoch: 132\n",
      "training loss: 3.4533610101121988\n",
      "validation loss: 6.182253261686039\n",
      "loss difference:\n",
      "0.019607146773827466\n",
      "epoch: 133\n",
      "training loss: 3.4340648568394747\n",
      "validation loss: 6.186151861262772\n",
      "loss difference:\n",
      "0.019296153272724048\n",
      "epoch: 134\n",
      "training loss: 3.415071903411668\n",
      "validation loss: 6.190084264962671\n",
      "loss difference:\n",
      "0.018992953427806825\n",
      "epoch: 135\n",
      "training loss: 3.3963747059450093\n",
      "validation loss: 6.194049224671232\n",
      "loss difference:\n",
      "0.018697197466658544\n",
      "epoch: 136\n",
      "training loss: 3.377966147590463\n",
      "validation loss: 6.198045733857489\n",
      "loss difference:\n",
      "0.018408558354546134\n",
      "epoch: 137\n",
      "training loss: 3.359839413452809\n",
      "validation loss: 6.202072946612591\n",
      "loss difference:\n",
      "0.01812673413765431\n",
      "epoch: 138\n",
      "training loss: 3.34198796394546\n",
      "validation loss: 6.206130102081966\n",
      "loss difference:\n",
      "0.01785144950734896\n",
      "epoch: 139\n",
      "training loss: 3.324405507396496\n",
      "validation loss: 6.210216455878679\n",
      "loss difference:\n",
      "0.017582456548963954\n",
      "epoch: 140\n",
      "training loss: 3.3070859727132147\n",
      "validation loss: 6.21433121975409\n",
      "loss difference:\n",
      "0.01731953468328129\n",
      "epoch: 141\n",
      "training loss: 3.290023482862501\n",
      "validation loss: 6.218473510442471\n",
      "loss difference:\n",
      "0.017062489850713902\n",
      "epoch: 142\n",
      "training loss: 3.2732123298387696\n",
      "validation loss: 6.222642308216439\n",
      "loss difference:\n",
      "0.01681115302373115\n",
      "epoch: 143\n",
      "training loss: 3.2566469516789147\n",
      "validation loss: 6.226836425315725\n",
      "loss difference:\n",
      "0.016565378159854927\n",
      "epoch: 144\n",
      "training loss: 3.2403219119538753\n",
      "validation loss: 6.231054484064014\n",
      "loss difference:\n",
      "0.016325039725039403\n",
      "epoch: 145\n",
      "training loss: 3.2242318820292466\n",
      "validation loss: 6.2352949041855075\n",
      "loss difference:\n",
      "0.016090029924628713\n",
      "epoch: 146\n",
      "training loss: 3.208371626251415\n",
      "validation loss: 6.239555898584674\n",
      "loss difference:\n",
      "0.01586025577783179\n",
      "epoch: 147\n",
      "training loss: 3.19273599008932\n",
      "validation loss: 6.2438354766667565\n",
      "loss difference:\n",
      "0.015635636162094624\n",
      "epoch: 148\n",
      "training loss: 3.177319891150042\n",
      "validation loss: 6.248131454152181\n",
      "loss difference:\n",
      "0.0154160989392782\n",
      "epoch: 149\n",
      "training loss: 3.1621183128942794\n",
      "validation loss: 6.252441468273787\n",
      "loss difference:\n",
      "0.015201578255762627\n",
      "epoch: 150\n",
      "training loss: 3.1471263008056405\n",
      "validation loss: 6.256762997233142\n",
      "loss difference:\n",
      "0.014992012088638873\n",
      "epoch: 151\n",
      "training loss: 3.1323389607184184\n",
      "validation loss: 6.261093382826159\n",
      "loss difference:\n",
      "0.014787340087222045\n",
      "epoch: 152\n",
      "training loss: 3.117751458977777\n",
      "validation loss: 6.265429855214995\n",
      "loss difference:\n",
      "0.014587501740641606\n",
      "epoch: 153\n",
      "training loss: 3.103359024096165\n",
      "validation loss: 6.269769558919183\n",
      "loss difference:\n",
      "0.014392434881612015\n",
      "epoch: 154\n",
      "training loss: 3.089156949572586\n",
      "validation loss: 6.274109579208113\n",
      "loss difference:\n",
      "0.014202074523578911\n",
      "epoch: 155\n",
      "training loss: 3.075140597559748\n",
      "validation loss: 6.278446968199322\n",
      "loss difference:\n",
      "0.014016352012837796\n",
      "epoch: 156\n",
      "training loss: 3.0613054030883187\n",
      "validation loss: 6.282778770087112\n",
      "loss difference:\n",
      "0.013835194471429446\n",
      "epoch: 157\n",
      "training loss: 3.0476468785919835\n",
      "validation loss: 6.287102045047217\n",
      "loss difference:\n",
      "0.0136585244963352\n",
      "epoch: 158\n",
      "training loss: 3.0341606185105534\n",
      "validation loss: 6.291413891472113\n",
      "loss difference:\n",
      "0.013486260081430057\n",
      "epoch: 159\n",
      "training loss: 3.0208423037882506\n",
      "validation loss: 6.2957114662954545\n",
      "loss difference:\n",
      "0.013318314722302826\n",
      "epoch: 160\n",
      "training loss: 3.007687706117742\n",
      "validation loss: 6.299992003249717\n",
      "loss difference:\n",
      "0.01315459767050875\n",
      "epoch: 161\n",
      "training loss: 2.9946926918184507\n",
      "validation loss: 6.304252828980876\n",
      "loss difference:\n",
      "0.012995014299291174\n",
      "epoch: 162\n",
      "training loss: 2.9818532252651737\n",
      "validation loss: 6.308491377002729\n",
      "loss difference:\n",
      "0.012839466553276946\n",
      "epoch: 163\n",
      "training loss: 2.9691653718149817\n",
      "validation loss: 6.312705199528975\n",
      "loss difference:\n",
      "0.012687853450191966\n",
      "epoch: 164\n",
      "training loss: 2.956625300199569\n",
      "validation loss: 6.316891977255405\n",
      "loss difference:\n",
      "0.012540071615412707\n",
      "epoch: 165\n",
      "training loss: 2.944229284374822\n",
      "validation loss: 6.321049527199104\n",
      "loss difference:\n",
      "0.012396015824747142\n",
      "epoch: 166\n",
      "training loss: 2.9319737048298404\n",
      "validation loss: 6.32517580871632\n",
      "loss difference:\n",
      "0.012255579544981465\n",
      "epoch: 167\n",
      "training loss: 2.9198550493760083\n",
      "validation loss: 6.329268927840003\n",
      "loss difference:\n",
      "0.012118655453832172\n",
      "epoch: 168\n",
      "training loss: 2.9078699134388724\n",
      "validation loss: 6.333327140077618\n",
      "loss difference:\n",
      "0.011985135937135905\n",
      "epoch: 169\n",
      "training loss: 2.8960149998899993\n",
      "validation loss: 6.337348851820579\n",
      "loss difference:\n",
      "0.011854913548873025\n",
      "epoch: 170\n",
      "training loss: 2.884287118450669\n",
      "validation loss: 6.341332620504963\n",
      "loss difference:\n",
      "0.011727881439330456\n",
      "epoch: 171\n",
      "training loss: 2.8726831847123773\n",
      "validation loss: 6.345277153670535\n",
      "loss difference:\n",
      "0.011603933738291605\n",
      "epoch: 172\n",
      "training loss: 2.861200218807051\n",
      "validation loss: 6.349181307045003\n",
      "loss difference:\n",
      "0.011482965905326381\n",
      "epoch: 173\n",
      "training loss: 2.8498353437743593\n",
      "validation loss: 6.353044081788917\n",
      "loss difference:\n",
      "0.011364875032691568\n",
      "epoch: 174\n",
      "training loss: 2.8385857836547626\n",
      "validation loss: 6.356864621009234\n",
      "loss difference:\n",
      "0.011249560119596769\n",
      "epoch: 175\n",
      "training loss: 2.82744886135568\n",
      "validation loss: 6.360642205663086\n",
      "loss difference:\n",
      "0.011136922299082475\n",
      "epoch: 176\n",
      "training loss: 2.816421996311709\n",
      "validation loss: 6.364376249938053\n",
      "loss difference:\n",
      "0.01102686504397088\n",
      "epoch: 177\n",
      "training loss: 2.805502701986202\n",
      "validation loss: 6.36806629621801\n",
      "loss difference:\n",
      "0.010919294325506979\n",
      "epoch: 178\n",
      "training loss: 2.794688583224813\n",
      "validation loss: 6.371712009697528\n",
      "loss difference:\n",
      "0.010814118761389047\n",
      "epoch: 179\n",
      "training loss: 2.783977333510281\n",
      "validation loss: 6.375313172745459\n",
      "loss difference:\n",
      "0.0107112497145323\n",
      "epoch: 180\n",
      "training loss: 2.7733667321159556\n",
      "validation loss: 6.37886967905572\n",
      "loss difference:\n",
      "0.010610601394325236\n",
      "epoch: 181\n",
      "training loss: 2.7628546412130257\n",
      "validation loss: 6.382381527683295\n",
      "loss difference:\n",
      "0.010512090902929927\n",
      "epoch: 182\n",
      "training loss: 2.7524390029122414\n",
      "validation loss: 6.3858488169758765\n",
      "loss difference:\n",
      "0.010415638300784291\n",
      "epoch: 183\n",
      "training loss: 2.742117836306497\n",
      "validation loss: 6.389271738504426\n",
      "loss difference:\n",
      "0.010321166605744558\n",
      "epoch: 184\n",
      "training loss: 2.7318892344725936\n",
      "validation loss: 6.392650570970083\n",
      "loss difference:\n",
      "0.010228601833903284\n",
      "epoch: 185\n",
      "training loss: 2.721751361518518\n",
      "validation loss: 6.395985674207294\n",
      "loss difference:\n",
      "0.010137872954075533\n",
      "epoch: 186\n",
      "training loss: 2.7117024496027575\n",
      "validation loss: 6.399277483217487\n",
      "loss difference:\n",
      "0.010048911915760517\n",
      "epoch: 187\n",
      "training loss: 2.7017407960449527\n",
      "validation loss: 6.40252650238624\n",
      "loss difference:\n",
      "0.009961653557804873\n",
      "epoch: 188\n",
      "training loss: 2.691864760407445\n",
      "validation loss: 6.405733299758079\n",
      "loss difference:\n",
      "0.00987603563750783\n",
      "epoch: 189\n",
      "training loss: 2.6820727617200424\n",
      "validation loss: 6.4088985015795945\n",
      "loss difference:\n",
      "0.009791998687402437\n",
      "epoch: 190\n",
      "training loss: 2.6723632756561617\n",
      "validation loss: 6.412022786896305\n",
      "loss difference:\n",
      "0.009709486063880668\n",
      "epoch: 191\n",
      "training loss: 2.6627348319173407\n",
      "validation loss: 6.415106882510647\n",
      "loss difference:\n",
      "0.009628443738820991\n",
      "epoch: 192\n",
      "training loss: 2.6531860115233252\n",
      "validation loss: 6.418151557950365\n",
      "loss difference:\n",
      "0.0095488203940155\n",
      "epoch: 193\n",
      "training loss: 2.6437154444000472\n",
      "validation loss: 6.421157620913641\n",
      "loss difference:\n",
      "0.009470567123277984\n",
      "epoch: 194\n",
      "training loss: 2.634321806787759\n",
      "validation loss: 6.424125912626556\n",
      "loss difference:\n",
      "0.009393637612288064\n",
      "epoch: 195\n",
      "training loss: 2.62500381907874\n",
      "validation loss: 6.427057303838786\n",
      "loss difference:\n",
      "0.00931798770901926\n",
      "epoch: 196\n",
      "training loss: 2.6157602433276943\n",
      "validation loss: 6.429952690551824\n",
      "loss difference:\n",
      "0.009243575751045618\n",
      "epoch: 197\n",
      "training loss: 2.6065898813949464\n",
      "validation loss: 6.432812990630484\n",
      "loss difference:\n",
      "0.009170361932747895\n",
      "epoch: 198\n",
      "training loss: 2.5974915725152377\n",
      "validation loss: 6.435639139838993\n",
      "loss difference:\n",
      "0.00909830887970875\n",
      "epoch: 199\n",
      "training loss: 2.5884641918230407\n",
      "validation loss: 6.438432089151696\n",
      "loss difference:\n",
      "0.009027380692196996\n",
      "epoch: 200\n",
      "training loss: 2.5795066478936857\n",
      "validation loss: 6.441192800972952\n",
      "loss difference:\n",
      "0.008957543929354994\n",
      "epoch: 201\n",
      "training loss: 2.570617881767567\n",
      "validation loss: 6.443922247274895\n",
      "loss difference:\n",
      "0.008888766126118774\n",
      "epoch: 202\n",
      "training loss: 2.5617968643108875\n",
      "validation loss: 6.446621405785864\n",
      "loss difference:\n",
      "0.008821017456679403\n",
      "epoch: 203\n",
      "training loss: 2.5530425959288303\n",
      "validation loss: 6.449291259172264\n",
      "loss difference:\n",
      "0.008754268382057173\n",
      "epoch: 204\n",
      "training loss: 2.5443541034841974\n",
      "validation loss: 6.451932790835184\n",
      "loss difference:\n",
      "0.008688492444632878\n",
      "epoch: 205\n",
      "training loss: 2.5357304410200014\n",
      "validation loss: 6.45454698551885\n",
      "loss difference:\n",
      "0.008623662464195991\n",
      "epoch: 206\n",
      "training loss: 2.527170685791602\n",
      "validation loss: 6.457134824114603\n",
      "loss difference:\n",
      "0.008559755228399357\n",
      "epoch: 207\n",
      "training loss: 2.5186739405488217\n",
      "validation loss: 6.4596972863768825\n",
      "loss difference:\n",
      "0.008496745242780435\n",
      "epoch: 208\n",
      "training loss: 2.5102393279248956\n",
      "validation loss: 6.462235343722578\n",
      "loss difference:\n",
      "0.008434612623926085\n",
      "epoch: 209\n",
      "training loss: 2.5018659952320466\n",
      "validation loss: 6.464749965267787\n",
      "loss difference:\n",
      "0.008373332692849011\n",
      "epoch: 210\n",
      "training loss: 2.4935531059091383\n",
      "validation loss: 6.46724210689448\n",
      "loss difference:\n",
      "0.008312889322908301\n",
      "epoch: 211\n",
      "training loss: 2.4852998484960254\n",
      "validation loss: 6.469712722768438\n",
      "loss difference:\n",
      "0.008253257413112891\n",
      "epoch: 212\n",
      "training loss: 2.4771054228926452\n",
      "validation loss: 6.472162747680468\n",
      "loss difference:\n",
      "0.008194425603380129\n",
      "epoch: 213\n",
      "training loss: 2.4689690564362836\n",
      "validation loss: 6.474593117896951\n",
      "loss difference:\n",
      "0.008136366456361621\n",
      "epoch: 214\n",
      "training loss: 2.4608899810454563\n",
      "validation loss: 6.477004741525718\n",
      "loss difference:\n",
      "0.008079075390827306\n",
      "epoch: 215\n",
      "training loss: 2.4528674615649586\n",
      "validation loss: 6.4793985355853545\n",
      "loss difference:\n",
      "0.008022519480497703\n",
      "epoch: 216\n",
      "training loss: 2.4449007568719345\n",
      "validation loss: 6.481775375083264\n",
      "loss difference:\n",
      "0.007966704693024074\n",
      "epoch: 217\n",
      "training loss: 2.436989169668443\n",
      "validation loss: 6.484136158671211\n",
      "loss difference:\n",
      "0.00791158720349161\n",
      "epoch: 218\n",
      "training loss: 2.4291319792420483\n",
      "validation loss: 6.486481719754893\n",
      "loss difference:\n",
      "0.007857190426394656\n",
      "epoch: 219\n",
      "training loss: 2.421328529128698\n",
      "validation loss: 6.4888129430728405\n",
      "loss difference:\n",
      "0.007803450113350152\n",
      "epoch: 220\n",
      "training loss: 2.4135781094704845\n",
      "validation loss: 6.491130607696615\n",
      "loss difference:\n",
      "0.007750419658213659\n",
      "epoch: 221\n",
      "training loss: 2.4058801121307254\n",
      "validation loss: 6.493435595133752\n",
      "loss difference:\n",
      "0.007697997339759066\n",
      "epoch: 222\n",
      "training loss: 2.398233822813708\n",
      "validation loss: 6.495728609315153\n",
      "loss difference:\n",
      "0.007646289317017274\n",
      "epoch: 223\n",
      "training loss: 2.3906386972895293\n",
      "validation loss: 6.498010550520672\n",
      "loss difference:\n",
      "0.007595125524178847\n",
      "epoch: 224\n",
      "training loss: 2.38309399079703\n",
      "validation loss: 6.500282011578046\n",
      "loss difference:\n",
      "0.007544706492499387\n",
      "epoch: 225\n",
      "training loss: 2.3755992533926555\n",
      "validation loss: 6.502543954528771\n",
      "loss difference:\n",
      "0.007494737404374341\n",
      "epoch: 226\n",
      "training loss: 2.368153663801217\n",
      "validation loss: 6.504796796697803\n",
      "loss difference:\n",
      "0.007445589591438484\n",
      "epoch: 227\n",
      "training loss: 2.360756924193934\n",
      "validation loss: 6.507041644199187\n",
      "loss difference:\n",
      "0.007396739607282932\n",
      "epoch: 228\n",
      "training loss: 2.353408053284849\n",
      "validation loss: 6.509278620831367\n",
      "loss difference:\n",
      "0.007348870909085203\n",
      "epoch: 229\n",
      "training loss: 2.346107014563513\n",
      "validation loss: 6.51150913334027\n",
      "loss difference:\n",
      "0.007301038721335917\n",
      "epoch: 230\n",
      "training loss: 2.338852512806808\n",
      "validation loss: 6.513732792195602\n",
      "loss difference:\n",
      "0.007254501756705167\n",
      "epoch: 231\n",
      "training loss: 2.331644978908034\n",
      "validation loss: 6.5159516025121285\n",
      "loss difference:\n",
      "0.007207533898773821\n",
      "epoch: 232\n",
      "training loss: 2.324482516472867\n",
      "validation loss: 6.5181642471517\n",
      "loss difference:\n",
      "0.007162462435167161\n",
      "epoch: 233\n",
      "training loss: 2.317366413846285\n",
      "validation loss: 6.520373897620263\n",
      "loss difference:\n",
      "0.0071161026265817995\n",
      "epoch: 234\n",
      "training loss: 2.3102936322249903\n",
      "validation loss: 6.522577520817947\n",
      "loss difference:\n",
      "0.007072781621294766\n",
      "epoch: 235\n",
      "training loss: 2.303267059114254\n",
      "validation loss: 6.524780543690059\n",
      "loss difference:\n",
      "0.0070265731107364005\n",
      "epoch: 236\n",
      "training loss: 2.296281484851548\n",
      "validation loss: 6.5269767045747225\n",
      "loss difference:\n",
      "0.0069855742627060735\n",
      "epoch: 237\n",
      "training loss: 2.289342814507098\n",
      "validation loss: 6.529175786162698\n",
      "loss difference:\n",
      "0.006938670344449616\n",
      "epoch: 238\n",
      "training loss: 2.28244169837313\n",
      "validation loss: 6.5313653742916316\n",
      "loss difference:\n",
      "0.006901116133968266\n",
      "epoch: 239\n",
      "training loss: 2.2755897882420983\n",
      "validation loss: 6.533563683760003\n",
      "loss difference:\n",
      "0.006851910131031591\n",
      "epoch: 240\n",
      "training loss: 2.2687697968201728\n",
      "validation loss: 6.535746455849797\n",
      "loss difference:\n",
      "0.006819991421925575\n",
      "epoch: 241\n",
      "training loss: 2.26200440734432\n",
      "validation loss: 6.537948300991287\n",
      "loss difference:\n",
      "0.00676538947585259\n",
      "epoch: 242\n",
      "training loss: 2.2552610207853263\n",
      "validation loss: 6.540121959471506\n",
      "loss difference:\n",
      "0.006743386558993869\n",
      "epoch: 243\n",
      "training loss: 2.2485836515539805\n",
      "validation loss: 6.5423340979186\n",
      "loss difference:\n",
      "0.006677369231345764\n",
      "epoch: 244\n",
      "training loss: 2.241909973042459\n",
      "validation loss: 6.5444924425887265\n",
      "loss difference:\n",
      "0.0066736785115213415\n",
      "epoch: 245\n",
      "training loss: 2.2353255355092982\n",
      "validation loss: 6.546726717349381\n",
      "loss difference:\n",
      "0.006584437533160958\n",
      "epoch: 246\n",
      "training loss: 2.228709916321653\n",
      "validation loss: 6.548855912891563\n",
      "loss difference:\n",
      "0.006615619187645194\n",
      "epoch: 247\n",
      "training loss: 2.222230094444237\n",
      "validation loss: 6.551134582806769\n",
      "loss difference:\n",
      "0.0064798218774160254\n",
      "epoch: 248\n",
      "training loss: 2.2156513611319864\n",
      "validation loss: 6.5532055755684\n",
      "loss difference:\n",
      "0.006578733312250673\n",
      "epoch: 249\n",
      "training loss: 2.2093014000930777\n",
      "validation loss: 6.5555721660507205\n",
      "loss difference:\n",
      "0.006349961038908614\n",
      "epoch: 250\n",
      "training loss: 2.2027192006183247\n",
      "validation loss: 6.557525185871795\n",
      "loss difference:\n",
      "0.0065821994747530255\n",
      "epoch: 251\n",
      "training loss: 2.1965517044514233\n",
      "validation loss: 6.560066719103979\n",
      "loss difference:\n",
      "0.006167496166901376\n",
      "epoch: 252\n",
      "training loss: 2.1898868679787467\n",
      "validation loss: 6.561779417813327\n",
      "loss difference:\n",
      "0.006664836472676683\n",
      "epoch: 253\n",
      "training loss: 2.184010029761476\n",
      "validation loss: 6.5646722468203675\n",
      "loss difference:\n",
      "0.005876838217270475\n",
      "epoch: 254\n",
      "training loss: 2.1771044075577652\n",
      "validation loss: 6.565893812349688\n",
      "loss difference:\n",
      "0.006905622203710937\n",
      "epoch: 255\n",
      "training loss: 2.171740203376805\n",
      "validation loss: 6.5694987227914226\n",
      "loss difference:\n",
      "0.005364204180960286\n",
      "epoch: 256\n",
      "training loss: 2.1642742430176574\n",
      "validation loss: 6.569712852875423\n",
      "loss difference:\n",
      "0.007465960359147594\n",
      "epoch: 257\n",
      "training loss: 2.1598794915994217\n",
      "validation loss: 6.574773667488516\n",
      "loss difference:\n",
      "0.004394751418235643\n",
      "epoch: 258\n",
      "training loss: 2.1512028510471217\n",
      "validation loss: 6.572912036644961\n",
      "loss difference:\n",
      "0.008676640552299997\n",
      "epoch: 259\n",
      "training loss: 2.148724203654596\n",
      "validation loss: 6.5809731844722705\n",
      "loss difference:\n",
      "0.00247864739252579\n",
      "epoch: 260\n",
      "training loss: 2.1375091248614244\n",
      "validation loss: 6.574813387563004\n",
      "loss difference:\n",
      "0.011215078793171518\n",
      "epoch: 261\n",
      "training loss: 2.1389305774342118\n",
      "validation loss: 6.589104466934577\n",
      "loss difference:\n",
      "-0.0014214525727873628\n",
      "that didn't improve loss:  1\n",
      "epoch: 262\n",
      "training loss: 2.122474135667821\n",
      "validation loss: 6.57400054636169\n",
      "loss difference:\n",
      "0.016456441766390828\n",
      "epoch: 263\n",
      "training loss: 2.1320314616040488\n",
      "validation loss: 6.601327209405279\n",
      "loss difference:\n",
      "-0.009557325936227823\n",
      "that didn't improve loss:  1\n",
      "epoch: 264\n",
      "training loss: 2.104914562946205\n",
      "validation loss: 6.567531211726397\n",
      "loss difference:\n",
      "0.027116898657843613\n",
      "epoch: 265\n",
      "training loss: 2.131944786580483\n",
      "validation loss: 6.622366418440925\n",
      "loss difference:\n",
      "-0.02703022363427765\n",
      "that didn't improve loss:  1\n",
      "epoch: 266\n",
      "training loss: 2.083776085536173\n",
      "validation loss: 6.549411566394551\n",
      "loss difference:\n",
      "0.0481687010443097\n",
      "epoch: 267\n",
      "training loss: 2.150040910045028\n",
      "validation loss: 6.662901733348652\n",
      "loss difference:\n",
      "-0.06626482450885485\n",
      "that didn't improve loss:  1\n",
      "epoch: 268\n",
      "training loss: 2.063279078245185\n",
      "validation loss: 6.508095264785967\n",
      "loss difference:\n",
      "0.08676183179984287\n",
      "epoch: 269\n",
      "training loss: 2.224217149686797\n",
      "validation loss: 6.748329984076962\n",
      "loss difference:\n",
      "-0.16093807144161199\n",
      "that didn't improve loss:  1\n",
      "epoch: 270\n",
      "training loss: 2.080638283944486\n",
      "validation loss: 6.424849485982453\n",
      "loss difference:\n",
      "0.14357886574231093\n",
      "epoch: 271\n",
      "training loss: 2.492778422578335\n",
      "validation loss: 6.942644263624825\n",
      "loss difference:\n",
      "-0.4121401386338488\n",
      "that didn't improve loss:  1\n",
      "epoch: 272\n",
      "training loss: 2.3208825311512578\n",
      "validation loss: 6.287110766295688\n",
      "loss difference:\n",
      "0.17189589142707717\n",
      "epoch: 273\n",
      "training loss: 3.4122217028284187\n",
      "validation loss: 7.3998595115935695\n",
      "loss difference:\n",
      "-1.091339171677161\n",
      "that didn't improve loss:  1\n",
      "epoch: 274\n",
      "training loss: 3.30215980650421\n",
      "validation loss: 6.164371197076577\n",
      "loss difference:\n",
      "0.1100618963242086\n",
      "epoch: 275\n",
      "training loss: 5.4820940263572675\n",
      "validation loss: 8.250673444654558\n",
      "loss difference:\n",
      "-2.1799342198530574\n",
      "that didn't improve loss:  1\n",
      "epoch: 276\n",
      "training loss: 4.566412352658353\n",
      "validation loss: 6.26664459567568\n",
      "loss difference:\n",
      "0.9156816736989146\n",
      "epoch: 277\n",
      "training loss: 5.951774920077335\n",
      "validation loss: 8.55120977050945\n",
      "loss difference:\n",
      "-1.3853625674189818\n",
      "that didn't improve loss:  1\n",
      "epoch: 278\n",
      "training loss: 3.7086742123631704\n",
      "validation loss: 6.488692069826268\n",
      "loss difference:\n",
      "2.2431007077141643\n",
      "epoch: 279\n",
      "training loss: 3.7615418271320085\n",
      "validation loss: 7.728700741221221\n",
      "loss difference:\n",
      "-0.052867614768838056\n",
      "that didn't improve loss:  1\n",
      "epoch: 280\n",
      "training loss: 2.5221821705726173\n",
      "validation loss: 6.565013860745609\n",
      "loss difference:\n",
      "1.2393596565593912\n",
      "epoch: 281\n",
      "training loss: 2.5549913290634394\n",
      "validation loss: 7.154039016468495\n",
      "loss difference:\n",
      "-0.03280915849082211\n",
      "that didn't improve loss:  1\n",
      "epoch: 282\n",
      "training loss: 2.1216342331555844\n",
      "validation loss: 6.615145259386282\n",
      "loss difference:\n",
      "0.433357095907855\n",
      "epoch: 283\n",
      "training loss: 2.1952115192154302\n",
      "validation loss: 6.9155431812925\n",
      "loss difference:\n",
      "-0.07357728605984581\n",
      "that didn't improve loss:  1\n",
      "epoch: 284\n",
      "training loss: 2.021390274483321\n",
      "validation loss: 6.646091276935586\n",
      "loss difference:\n",
      "0.17382124473210903\n",
      "epoch: 285\n",
      "training loss: 2.0792898937334763\n",
      "validation loss: 6.810555896198589\n",
      "loss difference:\n",
      "-0.05789961925015508\n",
      "that didn't improve loss:  1\n",
      "epoch: 286\n",
      "training loss: 1.9911473445188297\n",
      "validation loss: 6.660980003157049\n",
      "loss difference:\n",
      "0.08814254921464659\n",
      "epoch: 287\n",
      "training loss: 2.029609444210989\n",
      "validation loss: 6.758136253703358\n",
      "loss difference:\n",
      "-0.03846209969215941\n",
      "that didn't improve loss:  1\n",
      "epoch: 288\n",
      "training loss: 1.9769669171776383\n",
      "validation loss: 6.667976926349825\n",
      "loss difference:\n",
      "0.05264252703335082\n",
      "epoch: 289\n",
      "training loss: 2.0016691473207997\n",
      "validation loss: 6.729589368807233\n",
      "loss difference:\n",
      "-0.02470223014316142\n",
      "that didn't improve loss:  1\n",
      "epoch: 290\n",
      "training loss: 1.966668394338565\n",
      "validation loss: 6.671723164593832\n",
      "loss difference:\n",
      "0.035000752982234706\n",
      "epoch: 291\n",
      "training loss: 1.9824296121306282\n",
      "validation loss: 6.713350581313705\n",
      "loss difference:\n",
      "-0.015761217792063187\n",
      "that didn't improve loss:  1\n",
      "epoch: 292\n",
      "training loss: 1.9572781078886416\n",
      "validation loss: 6.674356486437123\n",
      "loss difference:\n",
      "0.025151504241986533\n",
      "epoch: 293\n",
      "training loss: 1.967251795879475\n",
      "validation loss: 6.704115517039147\n",
      "loss difference:\n",
      "-0.009973687990833424\n",
      "that didn't improve loss:  1\n",
      "epoch: 294\n",
      "training loss: 1.9480343956597226\n",
      "validation loss: 6.676797843718892\n",
      "loss difference:\n",
      "0.01921740021975249\n",
      "epoch: 295\n",
      "training loss: 1.9541932538541211\n",
      "validation loss: 6.699168434865443\n",
      "loss difference:\n",
      "-0.006158858194398542\n",
      "that didn't improve loss:  1\n",
      "epoch: 296\n",
      "training loss: 1.9387505664310996\n",
      "validation loss: 6.679408538063417\n",
      "loss difference:\n",
      "0.015442687423021573\n",
      "epoch: 297\n",
      "training loss: 1.9423345876947733\n",
      "validation loss: 6.696986299166946\n",
      "loss difference:\n",
      "-0.0035840212636737423\n",
      "that didn't improve loss:  1\n",
      "epoch: 298\n",
      "training loss: 1.9293954529562636\n",
      "validation loss: 6.682296781877466\n",
      "loss difference:\n",
      "0.012939134738509717\n",
      "epoch: 299\n",
      "training loss: 1.9312002256842593\n",
      "validation loss: 6.696651024810754\n",
      "loss difference:\n",
      "-0.0018047727279957293\n",
      "that didn't improve loss:  1\n",
      "epoch: 300\n",
      "training loss: 1.9199787630771021\n",
      "validation loss: 6.68546154072577\n",
      "loss difference:\n",
      "0.011221462607157173\n",
      "epoch: 301\n",
      "training loss: 1.9205279478721027\n",
      "validation loss: 6.697578727057523\n",
      "loss difference:\n",
      "-0.0005491847950005457\n",
      "that didn't improve loss:  1\n",
      "epoch: 302\n",
      "training loss: 1.9105187539088861\n",
      "validation loss: 6.688860535026249\n",
      "loss difference:\n",
      "0.010009193963216534\n",
      "epoch: 303\n",
      "training loss: 1.910166348554346\n",
      "validation loss: 6.6993840552484665\n",
      "loss difference:\n",
      "0.00035240535454006405\n",
      "epoch: 304\n",
      "training loss: 1.9010333171087281\n",
      "validation loss: 6.692441722553086\n",
      "loss difference:\n",
      "0.009133031445617945\n",
      "epoch: 305\n",
      "training loss: 1.900025037658301\n",
      "validation loss: 6.701806576259356\n",
      "loss difference:\n",
      "0.0010082794504271408\n",
      "epoch: 306\n",
      "training loss: 1.8915378636844697\n",
      "validation loss: 6.696156860399592\n",
      "loss difference:\n",
      "0.008487173973831252\n",
      "epoch: 307\n",
      "training loss: 1.8900487368374486\n",
      "validation loss: 6.7046678532525155\n",
      "loss difference:\n",
      "0.0014891268470211827\n",
      "epoch: 308\n",
      "training loss: 1.8820451354317205\n",
      "validation loss: 6.69996633234809\n",
      "loss difference:\n",
      "0.008003601405728089\n",
      "epoch: 309\n",
      "training loss: 1.880203063002589\n",
      "validation loss: 6.707844875856627\n",
      "loss difference:\n",
      "0.0018420724291314805\n",
      "epoch: 310\n",
      "training loss: 1.8725654989305083\n",
      "validation loss: 6.703839880406266\n",
      "loss difference:\n",
      "0.007637564072080716\n",
      "epoch: 311\n",
      "training loss: 1.8704663954828478\n",
      "validation loss: 6.711252835466738\n",
      "loss difference:\n",
      "0.002099103447660511\n",
      "epoch: 312\n",
      "training loss: 1.8631073073229334\n",
      "validation loss: 6.707755582976561\n",
      "loss difference:\n",
      "0.007359088159914373\n",
      "epoch: 313\n",
      "training loss: 1.8608250739906826\n",
      "validation loss: 6.714833584104283\n",
      "loss difference:\n",
      "0.0022822333322507493\n",
      "epoch: 314\n",
      "training loss: 1.8536772233963965\n",
      "validation loss: 6.711698237159887\n",
      "loss difference:\n",
      "0.0071478505942861315\n",
      "epoch: 315\n",
      "training loss: 1.8512704964894622\n",
      "validation loss: 6.718547731793825\n",
      "loss difference:\n",
      "0.002406726906934331\n",
      "epoch: 316\n",
      "training loss: 1.8442804858279407\n",
      "validation loss: 6.71565768838786\n",
      "loss difference:\n",
      "0.006990010661521495\n",
      "epoch: 317\n",
      "training loss: 1.8417973377243355\n",
      "validation loss: 6.722369168281575\n",
      "loss difference:\n",
      "0.0024831481036051706\n",
      "epoch: 318\n",
      "training loss: 1.8349211225705804\n",
      "validation loss: 6.719627334897938\n",
      "loss difference:\n",
      "0.006876215153755139\n",
      "epoch: 319\n",
      "training loss: 1.8324024477729477\n",
      "validation loss: 6.7262812496710955\n",
      "loss difference:\n",
      "0.0025186747976326807\n",
      "epoch: 320\n",
      "training loss: 1.8256021186452394\n",
      "validation loss: 6.723602876170302\n",
      "loss difference:\n",
      "0.006800329127708338\n",
      "epoch: 321\n",
      "training loss: 1.8230841740259953\n",
      "validation loss: 6.730274155294885\n",
      "loss difference:\n",
      "0.002517944619244039\n",
      "epoch: 322\n",
      "training loss: 1.8163255442571724\n",
      "validation loss: 6.727581298577853\n",
      "loss difference:\n",
      "0.00675862976882291\n",
      "epoch: 323\n",
      "training loss: 1.8138419540738673\n",
      "validation loss: 6.734343083498673\n",
      "loss difference:\n",
      "0.002483590183305129\n",
      "epoch: 324\n",
      "training loss: 1.8070926471398572\n",
      "validation loss: 6.731560058181458\n",
      "loss difference:\n",
      "0.006749306934010102\n",
      "epoch: 325\n",
      "training loss: 1.8046760879989452\n",
      "validation loss: 6.738487061318791\n",
      "loss difference:\n",
      "0.002416559140911989\n",
      "epoch: 326\n",
      "training loss: 1.797903911240201\n",
      "validation loss: 6.735536408299844\n",
      "loss difference:\n",
      "0.006772176758744086\n",
      "epoch: 327\n",
      "training loss: 1.7955876357539282\n",
      "validation loss: 6.742708215687056\n",
      "loss difference:\n",
      "0.0023162754862728896\n",
      "epoch: 328\n",
      "training loss: 1.7887590823708979\n",
      "validation loss: 6.739506816554852\n",
      "loss difference:\n",
      "0.006828553383030345\n",
      "epoch: 329\n",
      "training loss: 1.7865784090957046\n",
      "validation loss: 6.747011405949841\n",
      "loss difference:\n",
      "0.0021806732751932234\n",
      "epoch: 330\n",
      "training loss: 1.77965716019126\n",
      "validation loss: 6.7434664162060995\n",
      "loss difference:\n",
      "0.006921248904444566\n",
      "epoch: 331\n",
      "training loss: 1.7776510439403759\n",
      "validation loss: 6.751404157105573\n",
      "loss difference:\n",
      "0.0020061162508842045\n",
      "epoch: 332\n",
      "training loss: 1.7705963548024377\n",
      "validation loss: 6.747408436216767\n",
      "loss difference:\n",
      "0.007054689137938164\n",
      "epoch: 333\n",
      "training loss: 1.7688091517249975\n",
      "validation loss: 6.755896865541654\n",
      "loss difference:\n",
      "0.0017872030774401804\n",
      "epoch: 334\n",
      "training loss: 1.761574005441379\n",
      "validation loss: 6.75132355150852\n",
      "loss difference:\n",
      "0.007235146283618432\n",
      "epoch: 335\n",
      "training loss: 1.7600575600319983\n",
      "validation loss: 6.760503278160681\n",
      "loss difference:\n",
      "0.0015164454093807844\n",
      "epoch: 336\n",
      "training loss: 1.752586458512269\n",
      "validation loss: 6.755199087721979\n",
      "loss difference:\n",
      "0.007471101519729295\n",
      "epoch: 337\n",
      "training loss: 1.7514026656383201\n",
      "validation loss: 6.765241275069459\n",
      "loss difference:\n",
      "0.0011837928739488746\n",
      "epoch: 338\n",
      "training loss: 1.7436289031276508\n",
      "validation loss: 6.759018002033137\n",
      "loss difference:\n",
      "0.007773762510669302\n",
      "epoch: 339\n",
      "training loss: 1.7428529398480126\n",
      "validation loss: 6.7701340189680135\n",
      "loss difference:\n",
      "0.0007759632796382476\n",
      "epoch: 340\n",
      "training loss: 1.7346951656897216\n",
      "validation loss: 6.762757541450013\n",
      "loss difference:\n",
      "0.008157774158290998\n",
      "epoch: 341\n",
      "training loss: 1.734419649963127\n",
      "validation loss: 6.775211575128378\n",
      "loss difference:\n",
      "0.00027551572659456625\n",
      "epoch: 342\n",
      "training loss: 1.725777473227187\n",
      "validation loss: 6.7663874502688195\n",
      "loss difference:\n",
      "0.008642176735939922\n",
      "epoch: 343\n",
      "training loss: 1.7261178975024853\n",
      "validation loss: 6.78051315975722\n",
      "loss difference:\n",
      "-0.0003404242752982345\n",
      "that didn't improve loss:  1\n",
      "epoch: 344\n",
      "training loss: 1.7168662127807568\n",
      "validation loss: 6.769867556023107\n",
      "loss difference:\n",
      "0.009251684721728548\n",
      "epoch: 345\n",
      "training loss: 1.717968132353861\n",
      "validation loss: 6.786090249087799\n",
      "loss difference:\n",
      "-0.0011019195731041265\n",
      "that didn't improve loss:  1\n",
      "epoch: 346\n",
      "training loss: 1.707949749730735\n",
      "validation loss: 6.773144504501382\n",
      "loss difference:\n",
      "0.010018382623125932\n",
      "epoch: 347\n",
      "training loss: 1.709998398025359\n",
      "validation loss: 6.792010887666627\n",
      "loss difference:\n",
      "-0.0020486482946240336\n",
      "that didn't improve loss:  1\n",
      "epoch: 348\n",
      "training loss: 1.6990144378652405\n",
      "validation loss: 6.776147334746029\n",
      "loss difference:\n",
      "0.010983960160118489\n",
      "epoch: 349\n",
      "training loss: 1.7022477239248925\n",
      "validation loss: 6.798365688300708\n",
      "loss difference:\n",
      "-0.0032332860596520074\n",
      "that didn't improve loss:  1\n",
      "epoch: 350\n",
      "training loss: 1.6900450889241636\n",
      "validation loss: 6.778781479959247\n",
      "loss difference:\n",
      "0.012202635000728934\n",
      "epoch: 351\n",
      "training loss: 1.6947713549830459\n",
      "validation loss: 6.805276242702002\n",
      "loss difference:\n",
      "-0.004726266058882267\n",
      "that didn't improve loss:  1\n",
      "epoch: 352\n",
      "training loss: 1.6810264273717952\n",
      "validation loss: 6.780920647821695\n",
      "loss difference:\n",
      "0.013744927611250679\n",
      "epoch: 353\n",
      "training loss: 1.687648985034178\n",
      "validation loss: 6.812906998550561\n",
      "loss difference:\n",
      "-0.006622557662382844\n",
      "that didn't improve loss:  1\n",
      "epoch: 354\n",
      "training loss: 1.6719465469816395\n",
      "validation loss: 6.782395879710596\n",
      "loss difference:\n",
      "0.01570243805253857\n",
      "epoch: 355\n",
      "training loss: 1.6809979981503842\n",
      "validation loss: 6.821482162205085\n",
      "loss difference:\n",
      "-0.009051451168744729\n",
      "that didn't improve loss:  1\n",
      "epoch: 356\n",
      "training loss: 1.662804316555153\n",
      "validation loss: 6.782980939712643\n",
      "loss difference:\n",
      "0.01819368159523127\n",
      "epoch: 357\n",
      "training loss: 1.674995212355574\n",
      "validation loss: 6.831309940075653\n",
      "loss difference:\n",
      "-0.012190895800421098\n",
      "that didn't improve loss:  1\n",
      "epoch: 358\n",
      "training loss: 1.653624441080674\n",
      "validation loss: 6.782373119419153\n",
      "loss difference:\n",
      "0.021370771274900058\n",
      "epoch: 359\n",
      "training loss: 1.6699132868025948\n",
      "validation loss: 6.8428175505501185\n",
      "loss difference:\n",
      "-0.016288845721920797\n",
      "that didn't improve loss:  1\n",
      "epoch: 360\n",
      "training loss: 1.6444871883933294\n",
      "validation loss: 6.7801687591775135\n",
      "loss difference:\n",
      "0.025426098409265352\n",
      "epoch: 361\n",
      "training loss: 1.6661827160305074\n",
      "validation loss: 6.85660205336821\n",
      "loss difference:\n",
      "-0.02169552763717797\n",
      "that didn't improve loss:  1\n",
      "epoch: 362\n",
      "training loss: 1.6355859151553835\n",
      "validation loss: 6.775833737666932\n",
      "loss difference:\n",
      "0.030596800875123842\n",
      "epoch: 363\n",
      "training loss: 1.6644987057758294\n",
      "validation loss: 6.873504211081038\n",
      "loss difference:\n",
      "-0.028912790620445827\n",
      "that didn't improve loss:  1\n",
      "epoch: 364\n",
      "training loss: 1.6273365617684754\n",
      "validation loss: 6.7686718857446735\n",
      "loss difference:\n",
      "0.03716214400735396\n",
      "epoch: 365\n",
      "training loss: 1.6660063062618355\n",
      "validation loss: 6.894714961112753\n",
      "loss difference:\n",
      "-0.038669744493360136\n",
      "that didn't improve loss:  1\n",
      "epoch: 366\n",
      "training loss: 1.6205819969100625\n",
      "validation loss: 6.757800893581072\n",
      "loss difference:\n",
      "0.045424309351772996\n",
      "epoch: 367\n",
      "training loss: 1.672618393902518\n",
      "validation loss: 6.921924772371011\n",
      "loss difference:\n",
      "-0.05203639699245555\n",
      "that didn't improve loss:  1\n",
      "epoch: 368\n",
      "training loss: 1.6169614946469018\n",
      "validation loss: 6.742160059642153\n",
      "loss difference:\n",
      "0.05565689925561634\n",
      "epoch: 369\n",
      "training loss: 1.6875437439452416\n",
      "validation loss: 6.957518557265094\n",
      "loss difference:\n",
      "-0.0705822492983399\n",
      "that didn't improve loss:  1\n",
      "epoch: 370\n",
      "training loss: 1.619539691812366\n",
      "validation loss: 6.720604433809682\n",
      "loss difference:\n",
      "0.06800405213287575\n",
      "epoch: 371\n",
      "training loss: 1.716089791614795\n",
      "validation loss: 7.004782618054726\n",
      "loss difference:\n",
      "-0.09655009980242912\n",
      "that didn't improve loss:  1\n",
      "epoch: 372\n",
      "training loss: 1.6337455171109336\n",
      "validation loss: 6.692193464768227\n",
      "loss difference:\n",
      "0.08234427450386139\n",
      "epoch: 373\n",
      "training loss: 1.7666169448788627\n",
      "validation loss: 7.067970602492905\n",
      "loss difference:\n",
      "-0.13287142776792904\n",
      "that didn't improve loss:  1\n",
      "epoch: 374\n",
      "training loss: 1.6683362356435942\n",
      "validation loss: 6.656849688254068\n",
      "loss difference:\n",
      "0.09828070923526844\n",
      "epoch: 375\n",
      "training loss: 1.850761963880239\n",
      "validation loss: 7.151753028851191\n",
      "loss difference:\n",
      "-0.18242572823664482\n",
      "that didn't improve loss:  1\n",
      "epoch: 376\n",
      "training loss: 1.7349367475762376\n",
      "validation loss: 6.616551529076494\n",
      "loss difference:\n",
      "0.11582521630400144\n",
      "epoch: 377\n",
      "training loss: 1.980037347843884\n",
      "validation loss: 7.258915794409818\n",
      "loss difference:\n",
      "-0.24510060026764635\n",
      "that didn't improve loss:  1\n",
      "epoch: 378\n",
      "training loss: 1.8422531984776684\n",
      "validation loss: 6.576829017907129\n",
      "loss difference:\n",
      "0.13778414936621552\n",
      "epoch: 379\n",
      "training loss: 2.153282310895967\n",
      "validation loss: 7.384610486692088\n",
      "loss difference:\n",
      "-0.31102911241829867\n",
      "that didn't improve loss:  1\n",
      "epoch: 380\n",
      "training loss: 1.9802686001847194\n",
      "validation loss: 6.547137340093282\n",
      "loss difference:\n",
      "0.17301371071124771\n",
      "epoch: 381\n",
      "training loss: 2.3342854748476483\n",
      "validation loss: 7.507806541576386\n",
      "loss difference:\n",
      "-0.35401687466292886\n",
      "that didn't improve loss:  1\n",
      "epoch: 382\n",
      "training loss: 2.102703076484941\n",
      "validation loss: 6.53754124122562\n",
      "loss difference:\n",
      "0.23158239836270722\n",
      "epoch: 383\n",
      "training loss: 2.44585087017377\n",
      "validation loss: 7.590290069414096\n",
      "loss difference:\n",
      "-0.343147793688829\n",
      "that didn't improve loss:  1\n",
      "epoch: 384\n",
      "training loss: 2.14351822034621\n",
      "validation loss: 6.55192031616683\n",
      "loss difference:\n",
      "0.30233264982756003\n",
      "epoch: 385\n",
      "training loss: 2.4226808446660426\n",
      "validation loss: 7.599108903392167\n",
      "loss difference:\n",
      "-0.27916262431983263\n",
      "that didn't improve loss:  1\n",
      "epoch: 386\n",
      "training loss: 2.0781657848019863\n",
      "validation loss: 6.584713818015412\n",
      "loss difference:\n",
      "0.3445150598640563\n",
      "epoch: 387\n",
      "training loss: 2.2806742061954863\n",
      "validation loss: 7.537368852747118\n",
      "loss difference:\n",
      "-0.2025084213935\n",
      "that didn't improve loss:  1\n",
      "epoch: 388\n",
      "training loss: 1.9492617844733826\n",
      "validation loss: 6.626014375125132\n",
      "loss difference:\n",
      "0.3314124217221037\n",
      "epoch: 389\n",
      "training loss: 2.096309695488021\n",
      "validation loss: 7.439784395000267\n",
      "loss difference:\n",
      "-0.14704791101463854\n",
      "that didn't improve loss:  1\n",
      "epoch: 390\n",
      "training loss: 1.816471008387387\n",
      "validation loss: 6.668011699717356\n",
      "loss difference:\n",
      "0.2798386871006342\n",
      "epoch: 391\n",
      "training loss: 1.931696466544593\n",
      "validation loss: 7.340616634968581\n",
      "loss difference:\n",
      "-0.11522545815720608\n",
      "that didn't improve loss:  1\n",
      "epoch: 392\n",
      "training loss: 1.7111876976427898\n",
      "validation loss: 6.706582476927601\n",
      "loss difference:\n",
      "0.22050876890180326\n",
      "epoch: 393\n",
      "training loss: 1.80765332900543\n",
      "validation loss: 7.256997346147097\n",
      "loss difference:\n",
      "-0.09646563136264019\n",
      "that didn't improve loss:  1\n",
      "epoch: 394\n",
      "training loss: 1.6373137201918067\n",
      "validation loss: 6.740217118800117\n",
      "loss difference:\n",
      "0.1703396088136233\n",
      "epoch: 395\n",
      "training loss: 1.7204771809063497\n",
      "validation loss: 7.192547678382991\n",
      "loss difference:\n",
      "-0.08316346071454306\n",
      "that didn't improve loss:  1\n",
      "epoch: 396\n",
      "training loss: 1.5877556947789948\n",
      "validation loss: 6.768854375076049\n",
      "loss difference:\n",
      "0.1327214861273549\n",
      "epoch: 397\n",
      "training loss: 1.6600570639587813\n",
      "validation loss: 7.145022947465152\n",
      "loss difference:\n",
      "-0.07230136917978647\n",
      "that didn't improve loss:  1\n",
      "epoch: 398\n",
      "training loss: 1.5544490438224199\n",
      "validation loss: 6.793081773714701\n",
      "loss difference:\n",
      "0.10560802013636139\n",
      "epoch: 399\n",
      "training loss: 1.6174793590709153\n",
      "validation loss: 7.110807848882727\n",
      "loss difference:\n",
      "-0.06303031524849545\n",
      "that didn't improve loss:  1\n",
      "epoch: 400\n",
      "training loss: 1.5313604742619826\n",
      "validation loss: 6.813665630374247\n",
      "loss difference:\n",
      "0.0861188848089327\n",
      "epoch: 401\n",
      "training loss: 1.5864959551132738\n",
      "validation loss: 7.086614074163865\n",
      "loss difference:\n",
      "-0.05513548085129116\n",
      "that didn't improve loss:  1\n",
      "epoch: 402\n",
      "training loss: 1.5145595584170453\n",
      "validation loss: 6.831327896210273\n",
      "loss difference:\n",
      "0.07193639669622853\n",
      "epoch: 403\n",
      "training loss: 1.5630619566094937\n",
      "validation loss: 7.069874928161977\n",
      "loss difference:\n",
      "-0.04850239819244839\n",
      "that didn't improve loss:  1\n",
      "epoch: 404\n",
      "training loss: 1.5016203437754154\n",
      "validation loss: 6.846669135018208\n",
      "loss difference:\n",
      "0.06144161283407823\n",
      "epoch: 405\n",
      "training loss: 1.5446215312539593\n",
      "validation loss: 7.058697269141887\n",
      "loss difference:\n",
      "-0.04300118747854387\n",
      "that didn't improve loss:  1\n",
      "epoch: 406\n",
      "training loss: 1.4910729744105278\n",
      "validation loss: 6.860160424282344\n",
      "loss difference:\n",
      "0.053548556843431516\n",
      "epoch: 407\n",
      "training loss: 1.5295598532404486\n",
      "validation loss: 7.051713319235173\n",
      "loss difference:\n",
      "-0.038486878829920856\n",
      "that didn't improve loss:  1\n",
      "epoch: 408\n",
      "training loss: 1.4820290444290458\n",
      "validation loss: 6.872160654692301\n",
      "loss difference:\n",
      "0.047530808811402814\n",
      "epoch: 409\n",
      "training loss: 1.5168458530045783\n",
      "validation loss: 7.047940504240077\n",
      "loss difference:\n",
      "-0.03481680857553249\n",
      "that didn't improve loss:  1\n",
      "epoch: 410\n",
      "training loss: 1.473949275580808\n",
      "validation loss: 6.882939194398247\n",
      "loss difference:\n",
      "0.0428965774237704\n",
      "epoch: 411\n",
      "training loss: 1.5058117513558884\n",
      "validation loss: 7.046673083928397\n",
      "loss difference:\n",
      "-0.0318624757750805\n",
      "that didn't improve loss:  1\n",
      "epoch: 412\n",
      "training loss: 1.46650451009999\n",
      "validation loss: 6.892696304248085\n",
      "loss difference:\n",
      "0.03930724125589835\n",
      "epoch: 413\n",
      "training loss: 1.4960190361254895\n",
      "validation loss: 7.047404003040188\n",
      "loss difference:\n",
      "-0.02951452602549942\n",
      "that didn't improve loss:  1\n",
      "epoch: 414\n",
      "training loss: 1.4594934146341312\n",
      "validation loss: 6.9015792656286\n",
      "loss difference:\n",
      "0.036525621491358296\n",
      "epoch: 415\n",
      "training loss: 1.4871768473748375\n",
      "validation loss: 7.0497700124459035\n",
      "loss difference:\n",
      "-0.027683432740706282\n",
      "that didn't improve loss:  1\n",
      "epoch: 416\n",
      "training loss: 1.4527937679543457\n",
      "validation loss: 6.909694334676165\n",
      "loss difference:\n",
      "0.03438307942049179\n",
      "epoch: 417\n",
      "training loss: 1.4790918792246248\n",
      "validation loss: 7.053513507137431\n",
      "loss difference:\n",
      "-0.026298111270279145\n",
      "that didn't improve loss:  1\n",
      "epoch: 418\n",
      "training loss: 1.446333575408553\n",
      "validation loss: 6.917115281690113\n",
      "loss difference:\n",
      "0.03275830381607192\n",
      "epoch: 419\n",
      "training loss: 1.4716373910508243\n",
      "validation loss: 7.058456109119653\n",
      "loss difference:\n",
      "-0.025303815642271354\n",
      "that didn't improve loss:  1\n",
      "epoch: 420\n",
      "training loss: 1.4400740090768103\n",
      "validation loss: 6.923889331842189\n",
      "loss difference:\n",
      "0.03156338197401398\n",
      "epoch: 421\n",
      "training loss: 1.464734023127675\n",
      "validation loss: 7.064480493920026\n",
      "loss difference:\n",
      "-0.02466001405086482\n",
      "that didn't improve loss:  1\n",
      "epoch: 422\n",
      "training loss: 1.4339995576731226\n",
      "validation loss: 6.930041193249947\n",
      "loss difference:\n",
      "0.030734465454552495\n",
      "epoch: 423\n",
      "training loss: 1.4583381162262063\n",
      "validation loss: 7.071518064660183\n",
      "loss difference:\n",
      "-0.024338558553083756\n",
      "that didn't improve loss:  1\n",
      "epoch: 424\n",
      "training loss: 1.4281127407065894\n",
      "validation loss: 6.935575700916833\n",
      "loss difference:\n",
      "0.030225375519616904\n",
      "epoch: 425\n",
      "training loss: 1.45243500758916\n",
      "validation loss: 7.079540848824671\n",
      "loss difference:\n",
      "-0.024322266882570664\n",
      "that didn't improve loss:  1\n",
      "epoch: 426\n",
      "training loss: 1.4224318984686726\n",
      "validation loss: 6.940479476427297\n",
      "loss difference:\n",
      "0.030003109120487537\n",
      "epoch: 427\n",
      "training loss: 1.447035838852828\n",
      "validation loss: 7.088556513346304\n",
      "loss difference:\n",
      "-0.024603940384155365\n",
      "that didn't improve loss:  1\n",
      "epoch: 428\n",
      "training loss: 1.4169912649650676\n",
      "validation loss: 6.944721919731523\n",
      "loss difference:\n",
      "0.030044573887760384\n",
      "epoch: 429\n",
      "training loss: 1.4421770655836526\n",
      "validation loss: 7.098605734777564\n",
      "loss difference:\n",
      "-0.025185800618584997\n",
      "that didn't improve loss:  1\n",
      "epoch: 430\n",
      "training loss: 1.4118429640476164\n",
      "validation loss: 6.948255814040295\n",
      "loss difference:\n",
      "0.030334101536036107\n",
      "epoch: 431\n",
      "training loss: 1.4379222712825388\n",
      "validation loss: 7.1097613702019995\n",
      "loss difference:\n",
      "-0.026079307234922355\n",
      "that didn't improve loss:  1\n",
      "epoch: 432\n",
      "training loss: 1.4070608473065256\n",
      "validation loss: 6.9510178395609366\n",
      "loss difference:\n",
      "0.030861423976013214\n",
      "epoch: 433\n",
      "training loss: 1.4343661479173004\n",
      "validation loss: 7.122128974465462\n",
      "loss difference:\n",
      "-0.027305300610774852\n",
      "that didn't improve loss:  1\n",
      "epoch: 434\n",
      "training loss: 1.402746264345546\n",
      "validation loss: 6.952929361467506\n",
      "loss difference:\n",
      "0.03161988357175449\n",
      "epoch: 435\n",
      "training loss: 1.4316406404119508\n",
      "validation loss: 7.135848201268523\n",
      "loss difference:\n",
      "-0.02889437606640488\n",
      "that didn't improve loss:  1\n",
      "epoch: 436\n",
      "training loss: 1.3990359232074372\n",
      "validation loss: 6.953897991215631\n",
      "loss difference:\n",
      "0.032604717204513634\n",
      "epoch: 437\n",
      "training loss: 1.4299232421029786\n",
      "validation loss: 7.1510944874220606\n",
      "loss difference:\n",
      "-0.030887318895541416\n",
      "that didn't improve loss:  1\n",
      "epoch: 438\n",
      "training loss: 1.3961119102052044\n",
      "validation loss: 6.953820629467131\n",
      "loss difference:\n",
      "0.03381133189777419\n",
      "epoch: 439\n",
      "training loss: 1.429447186058217\n",
      "validation loss: 7.168080102208702\n",
      "loss difference:\n",
      "-0.03333527585301255\n",
      "that didn't improve loss:  1\n",
      "epoch: 440\n",
      "training loss: 1.3942135714874226\n",
      "validation loss: 6.9525889905670155\n",
      "loss difference:\n",
      "0.035233614570794325\n",
      "epoch: 441\n",
      "training loss: 1.430512626593547\n",
      "validation loss: 7.1870530680292495\n",
      "loss difference:\n",
      "-0.03629905510612441\n",
      "that didn't improve loss:  1\n",
      "epoch: 442\n",
      "training loss: 1.393650085951674\n",
      "validation loss: 6.950098970056523\n",
      "loss difference:\n",
      "0.036862540641873\n",
      "epoch: 443\n",
      "training loss: 1.4334965435848441\n",
      "validation loss: 7.208291517977023\n",
      "loss difference:\n",
      "-0.039846457633170074\n",
      "that didn't improve loss:  1\n",
      "epoch: 444\n",
      "training loss: 1.3948108170366664\n",
      "validation loss: 6.946265584314037\n",
      "loss difference:\n",
      "0.0386857265481777\n",
      "epoch: 445\n",
      "training loss: 1.438856584938795\n",
      "validation loss: 7.232089645546816\n",
      "loss difference:\n",
      "-0.04404576790212866\n",
      "that didn't improve loss:  1\n",
      "epoch: 446\n",
      "training loss: 1.3981674365030823\n",
      "validation loss: 6.941045414547955\n",
      "loss difference:\n",
      "0.04068914843571281\n",
      "epoch: 447\n",
      "training loss: 1.447119890501434\n",
      "validation loss: 7.258729510239932\n",
      "loss difference:\n",
      "-0.048952453998351686\n",
      "that didn't improve loss:  1\n",
      "epoch: 448\n",
      "training loss: 1.4042569535102507\n",
      "validation loss: 6.934468167299642\n",
      "loss difference:\n",
      "0.042862936991183265\n",
      "epoch: 449\n",
      "training loss: 1.4588419408010447\n",
      "validation loss: 7.288430902045357\n",
      "loss difference:\n",
      "-0.054584987290793974\n",
      "that didn't improve loss:  1\n",
      "epoch: 450\n",
      "training loss: 1.4136284288975756\n",
      "validation loss: 6.9266774950982075\n",
      "loss difference:\n",
      "0.04521351190346912\n",
      "epoch: 451\n",
      "training loss: 1.4745138174089698\n",
      "validation loss: 7.321270329106531\n",
      "loss difference:\n",
      "-0.060885388511394245\n",
      "that didn't improve loss:  1\n",
      "epoch: 452\n",
      "training loss: 1.4267306582202\n",
      "validation loss: 6.917977745183643\n",
      "loss difference:\n",
      "0.04778315918876985\n",
      "epoch: 453\n",
      "training loss: 1.4943934468360336\n",
      "validation loss: 7.357062540667243\n",
      "loss difference:\n",
      "-0.06766278861583364\n",
      "that didn't improve loss:  1\n",
      "epoch: 454\n",
      "training loss: 1.4437201201998675\n",
      "validation loss: 6.908877119715822\n",
      "loss difference:\n",
      "0.05067332663616608\n",
      "epoch: 455\n",
      "training loss: 1.5182476974390104\n",
      "validation loss: 7.395208383166294\n",
      "loss difference:\n",
      "-0.07452757723914294\n",
      "that didn't improve loss:  1\n",
      "epoch: 456\n",
      "training loss: 1.4641904589867054\n",
      "validation loss: 6.900109381352295\n",
      "loss difference:\n",
      "0.054057238452305034\n",
      "epoch: 457\n",
      "training loss: 1.5450332217604537\n",
      "validation loss: 7.434536606341305\n",
      "loss difference:\n",
      "-0.08084276277374824\n",
      "that didn't improve loss:  1\n",
      "epoch: 458\n",
      "training loss: 1.4868804327126286\n",
      "validation loss: 6.892609297612567\n",
      "loss difference:\n",
      "0.05815278904782506\n",
      "epoch: 459\n",
      "training loss: 1.5726243151933224\n",
      "validation loss: 7.473205113027593\n",
      "loss difference:\n",
      "-0.08574388248069376\n",
      "that didn't improve loss:  1\n",
      "epoch: 460\n",
      "training loss: 1.5095028572185274\n",
      "validation loss: 6.887419179676989\n",
      "loss difference:\n",
      "0.06312145797479496\n",
      "epoch: 461\n",
      "training loss: 1.5977901277527171\n",
      "validation loss: 7.508763399316646\n",
      "loss difference:\n",
      "-0.08828727053418972\n",
      "that didn't improve loss:  1\n",
      "epoch: 462\n",
      "training loss: 1.528900364897958\n",
      "validation loss: 6.885523834430666\n",
      "loss difference:\n",
      "0.06888976285475912\n",
      "epoch: 463\n",
      "training loss: 1.6166409186907043\n",
      "validation loss: 7.538471746273749\n",
      "loss difference:\n",
      "-0.08774055379274626\n",
      "that didn't improve loss:  1\n",
      "epoch: 464\n",
      "training loss: 1.5416703168445336\n",
      "validation loss: 6.88764871836806\n",
      "loss difference:\n",
      "0.07497060184617066\n",
      "epoch: 465\n",
      "training loss: 1.6255859279959377\n",
      "validation loss: 7.559877578354933\n",
      "loss difference:\n",
      "-0.08391561115140411\n",
      "that didn't improve loss:  1\n",
      "epoch: 466\n",
      "training loss: 1.5451451177862048\n",
      "validation loss: 6.894091423395142\n",
      "loss difference:\n",
      "0.08044081020973293\n",
      "epoch: 467\n",
      "training loss: 1.6224845925836844\n",
      "validation loss: 7.571477188876936\n",
      "loss difference:\n",
      "-0.0773394747974796\n",
      "that didn't improve loss:  1\n",
      "epoch: 468\n",
      "training loss: 1.5382943966881322\n",
      "validation loss: 6.90465814409359\n",
      "loss difference:\n",
      "0.08419019589555221\n",
      "epoch: 469\n",
      "training loss: 1.6073984714906735\n",
      "validation loss: 7.573162591823067\n",
      "loss difference:\n",
      "-0.06910407480254133\n",
      "that didn't improve loss:  1\n",
      "epoch: 470\n",
      "training loss: 1.522042402149438\n",
      "validation loss: 6.918731782292442\n",
      "loss difference:\n",
      "0.08535606934123541\n",
      "epoch: 471\n",
      "training loss: 1.5824982135961005\n",
      "validation loss: 7.566217640483548\n",
      "loss difference:\n",
      "-0.060455811446662455\n",
      "that didn't improve loss:  1\n",
      "epoch: 472\n",
      "training loss: 1.4988265364143054\n",
      "validation loss: 6.93543538128049\n",
      "loss difference:\n",
      "0.08367167718179513\n",
      "epoch: 473\n",
      "training loss: 1.5512073256560155\n",
      "validation loss: 7.552876782190556\n",
      "loss difference:\n",
      "-0.05238078924171008\n",
      "that didn't improve loss:  1\n",
      "epoch: 474\n",
      "training loss: 1.4716979051276786\n",
      "validation loss: 6.95381946252072\n",
      "loss difference:\n",
      "0.07950942052833687\n",
      "epoch: 475\n",
      "training loss: 1.5171063412588655\n",
      "validation loss: 7.535692442149071\n",
      "loss difference:\n",
      "-0.045408436131186836\n",
      "that didn't improve loss:  1\n",
      "epoch: 476\n",
      "training loss: 1.443462949497309\n",
      "validation loss: 6.973011889373075\n",
      "loss difference:\n",
      "0.07364339176155643\n",
      "epoch: 477\n",
      "training loss: 1.4831202779231916\n",
      "validation loss: 7.516993945005988\n",
      "loss difference:\n",
      "-0.03965732842588254\n",
      "that didn't improve loss:  1\n",
      "epoch: 478\n",
      "training loss: 1.4161906591100928\n",
      "validation loss: 6.992303692527943\n",
      "loss difference:\n",
      "0.06692961881309878\n",
      "epoch: 479\n",
      "training loss: 1.4511905166132941\n",
      "validation loss: 7.49858661033887\n",
      "loss difference:\n",
      "-0.03499985750320134\n",
      "that didn't improve loss:  1\n",
      "epoch: 480\n",
      "training loss: 1.3911127578639073\n",
      "validation loss: 7.011175422557649\n",
      "loss difference:\n",
      "0.06007775874938681\n",
      "epoch: 481\n",
      "training loss: 1.4223323504980516\n",
      "validation loss: 7.481683029482189\n",
      "loss difference:\n",
      "-0.03121959263414431\n",
      "that didn't improve loss:  1\n",
      "epoch: 482\n",
      "training loss: 1.3687681756909238\n",
      "validation loss: 7.029283456799239\n",
      "loss difference:\n",
      "0.05356417480712783\n",
      "epoch: 483\n",
      "training loss: 1.3968749279478074\n",
      "validation loss: 7.466979190692101\n",
      "loss difference:\n",
      "-0.028106752256883638\n",
      "that didn't improve loss:  1\n",
      "epoch: 484\n",
      "training loss: 1.3492279809710668\n",
      "validation loss: 7.0464267577037845\n",
      "loss difference:\n",
      "0.047646946976740656\n",
      "epoch: 485\n",
      "training loss: 1.3747236717502176\n",
      "validation loss: 7.454786250821923\n",
      "loss difference:\n",
      "-0.025495690779150815\n",
      "that didn't improve loss:  1\n",
      "epoch: 486\n",
      "training loss: 1.3322997657273434\n",
      "validation loss: 7.0625090503542465\n",
      "loss difference:\n",
      "0.04242390602287416\n",
      "epoch: 487\n",
      "training loss: 1.355568202431107\n",
      "validation loss: 7.445160935064718\n",
      "loss difference:\n",
      "-0.023268436703763662\n",
      "that didn't improve loss:  1\n",
      "epoch: 488\n",
      "training loss: 1.3176746560042314\n",
      "validation loss: 7.077504790319412\n",
      "loss difference:\n",
      "0.0378935464268757\n",
      "epoch: 489\n",
      "training loss: 1.3390195400168807\n",
      "validation loss: 7.438009823047081\n",
      "loss difference:\n",
      "-0.021344884012649334\n",
      "that didn't improve loss:  1\n",
      "epoch: 490\n",
      "training loss: 1.305017592543548\n",
      "validation loss: 7.09143222349989\n",
      "loss difference:\n",
      "0.03400194747333263\n",
      "epoch: 491\n",
      "training loss: 1.3246885697957322\n",
      "validation loss: 7.433163009926572\n",
      "loss difference:\n",
      "-0.01967097725218414\n",
      "that didn't improve loss:  1\n",
      "epoch: 492\n",
      "training loss: 1.294015287437981\n",
      "validation loss: 7.104333823152344\n",
      "loss difference:\n",
      "0.03067328235775113\n",
      "epoch: 493\n",
      "training loss: 1.3122245074971348\n",
      "validation loss: 7.430421696781802\n",
      "loss difference:\n",
      "-0.018209220059153708\n",
      "that didn't improve loss:  1\n",
      "epoch: 494\n",
      "training loss: 1.284397207067744\n",
      "validation loss: 7.116263003572465\n",
      "loss difference:\n",
      "0.027827300429390744\n",
      "epoch: 495\n",
      "training loss: 1.301329453255928\n",
      "validation loss: 7.429586628325158\n",
      "loss difference:\n",
      "-0.016932246188184008\n",
      "that didn't improve loss:  1\n",
      "epoch: 496\n",
      "training loss: 1.2759413072352594\n",
      "validation loss: 7.127275625445882\n",
      "loss difference:\n",
      "0.025388146020668634\n",
      "epoch: 497\n",
      "training loss: 1.2917601835509893\n",
      "validation loss: 7.430473660715805\n",
      "loss difference:\n",
      "-0.01581887631572987\n",
      "that didn't improve loss:  1\n",
      "epoch: 498\n",
      "training loss: 1.2684721510233212\n",
      "validation loss: 7.137424916814652\n",
      "loss difference:\n",
      "0.02328803252766809\n",
      "epoch: 499\n",
      "training loss: 1.2833240028262902\n",
      "validation loss: 7.43292121401438\n",
      "loss difference:\n",
      "-0.014851851802968996\n",
      "that didn't improve loss:  1\n",
      "epoch: 500\n",
      "training loss: 1.261855869364742\n",
      "validation loss: 7.146758720647765\n",
      "loss difference:\n",
      "0.0214681334615483\n",
      "epoch: 501\n",
      "training loss: 1.2758724532337415\n",
      "validation loss: 7.43679286913426\n",
      "loss difference:\n",
      "-0.014016583868999621\n",
      "that didn't improve loss:  1\n",
      "epoch: 502\n",
      "training loss: 1.2559943362926074\n",
      "validation loss: 7.155318284786421\n",
      "loss difference:\n",
      "0.019878116941134172\n",
      "epoch: 503\n",
      "training loss: 1.2692948056128486\n",
      "validation loss: 7.441977199883136\n",
      "loss difference:\n",
      "-0.013300469320241204\n",
      "that didn't improve loss:  1\n",
      "epoch: 504\n",
      "training loss: 1.250819681966183\n",
      "validation loss: 7.163138068224795\n",
      "loss difference:\n",
      "0.018475123646665592\n",
      "epoch: 505\n",
      "training loss: 1.2635121787622827\n",
      "validation loss: 7.448386105480914\n",
      "loss difference:\n",
      "-0.01269249679609974\n",
      "that didn't improve loss:  1\n",
      "epoch: 506\n",
      "training loss: 1.246289568490452\n",
      "validation loss: 7.170246234381176\n",
      "loss difference:\n",
      "0.017222610271830696\n",
      "epoch: 507\n",
      "training loss: 1.2584725511880295\n",
      "validation loss: 7.455952357742137\n",
      "loss difference:\n",
      "-0.012182982697577449\n",
      "that didn't improve loss:  1\n",
      "epoch: 508\n",
      "training loss: 1.2423832822119862\n",
      "validation loss: 7.176665643064553\n",
      "loss difference:\n",
      "0.016089268976043236\n",
      "epoch: 509\n",
      "training loss: 1.2541466261682215\n",
      "validation loss: 7.464626718986057\n",
      "loss difference:\n",
      "-0.01176334395623524\n",
      "that didn't improve loss:  1\n",
      "epoch: 510\n",
      "training loss: 1.2390985029072097\n",
      "validation loss: 7.182415249868558\n",
      "loss difference:\n",
      "0.015048123261011792\n",
      "epoch: 511\n",
      "training loss: 1.2505243533511066\n",
      "validation loss: 7.474374755671695\n",
      "loss difference:\n",
      "-0.011425850443896879\n",
      "that didn't improve loss:  1\n",
      "epoch: 512\n",
      "training loss: 1.2364485045498979\n",
      "validation loss: 7.187511885379089\n",
      "loss difference:\n",
      "0.014075848801208712\n",
      "epoch: 513\n",
      "training loss: 1.2476118198627884\n",
      "validation loss: 7.485173322280173\n",
      "loss difference:\n",
      "-0.011163315312890498\n",
      "that didn't improve loss:  1\n",
      "epoch: 514\n",
      "training loss: 1.2344594725756541\n",
      "validation loss: 7.191972424032843\n",
      "loss difference:\n",
      "0.013152347287134214\n",
      "epoch: 515\n",
      "training loss: 1.2454281582184503\n",
      "validation loss: 7.497006590965606\n",
      "loss difference:\n",
      "-0.010968685642796183\n",
      "that didn't improve loss:  1\n",
      "epoch: 516\n",
      "training loss: 1.2331675624701568\n",
      "validation loss: 7.195816366808375\n",
      "loss difference:\n",
      "0.012260595748293523\n",
      "epoch: 517\n",
      "training loss: 1.2440020574920214\n",
      "validation loss: 7.509861440091822\n",
      "loss difference:\n",
      "-0.01083449502186462\n",
      "that didn't improve loss:  1\n",
      "epoch: 518\n",
      "training loss: 1.2326152657333203\n",
      "validation loss: 7.199068852400804\n",
      "loss difference:\n",
      "0.011386791758701165\n",
      "epoch: 519\n",
      "training loss: 1.2433674059303297\n",
      "validation loss: 7.523721986198846\n",
      "loss difference:\n",
      "-0.01075214019700943\n",
      "that didn't improve loss:  1\n",
      "epoch: 520\n",
      "training loss: 1.2328465992009334\n",
      "validation loss: 7.201764074209144\n",
      "loss difference:\n",
      "0.01052080672939626\n",
      "epoch: 521\n",
      "training loss: 1.2435575520821502\n",
      "validation loss: 7.538563057594336\n",
      "loss difference:\n",
      "-0.010710952881216818\n",
      "that didn't improve loss:  1\n",
      "epoch: 522\n",
      "training loss: 1.2339006169741924\n",
      "validation loss: 7.203949009684492\n",
      "loss difference:\n",
      "0.009656935107957842\n",
      "epoch: 523\n",
      "training loss: 1.2445976815751716\n",
      "validation loss: 7.554342482667186\n",
      "loss difference:\n",
      "-0.01069706460097919\n",
      "that didn't improve loss:  1\n",
      "epoch: 524\n",
      "training loss: 1.235802805658507\n",
      "validation loss: 7.205687259528627\n",
      "loss difference:\n",
      "0.008794875916664502\n",
      "epoch: 525\n",
      "training loss: 1.2464949241914987\n",
      "validation loss: 7.570992230107235\n",
      "loss difference:\n",
      "-0.010692118532991568\n",
      "that didn't improve loss:  1\n",
      "epoch: 526\n",
      "training loss: 1.2385541288753978\n",
      "validation loss: 7.207062647295651\n",
      "loss difference:\n",
      "0.007940795316100813\n",
      "epoch: 527\n",
      "training loss: 1.2492261072426547\n",
      "validation loss: 7.58840872276721\n",
      "loss difference:\n",
      "-0.010671978367256862\n",
      "that didn't improve loss:  1\n",
      "epoch: 528\n",
      "training loss: 1.2421179141930963\n",
      "validation loss: 7.2081820571152875\n",
      "loss difference:\n",
      "0.007108193049558453\n",
      "epoch: 529\n",
      "training loss: 1.2527236375155693\n",
      "validation loss: 7.6064430736585456\n",
      "loss difference:\n",
      "-0.010605723322473004\n",
      "that didn't improve loss:  1\n",
      "epoch: 530\n",
      "training loss: 1.2464054890634428\n",
      "validation loss: 7.209176819515572\n",
      "loss difference:\n",
      "0.006318148452126415\n",
      "epoch: 531\n",
      "training loss: 1.256860872286119\n",
      "validation loss: 7.624892550408123\n",
      "loss difference:\n",
      "-0.01045538322267614\n",
      "that didn't improve loss:  1\n",
      "epoch: 532\n",
      "training loss: 1.251262470387842\n",
      "validation loss: 7.210201848079708\n",
      "loss difference:\n",
      "0.005598401898276872\n",
      "epoch: 533\n",
      "training loss: 1.2614394752070057\n",
      "validation loss: 7.643495186377811\n",
      "loss difference:\n",
      "-0.010177004819163615\n",
      "that didn't improve loss:  1\n",
      "epoch: 534\n",
      "training loss: 1.2564587515813554\n",
      "validation loss: 7.211431760304143\n",
      "loss difference:\n",
      "0.004980723625650274\n",
      "epoch: 535\n",
      "training loss: 1.2661824037291354\n",
      "validation loss: 7.661929947012671\n",
      "loss difference:\n",
      "-0.009723652147779926\n",
      "that didn't improve loss:  1\n",
      "epoch: 536\n",
      "training loss: 1.2616861555993277\n",
      "validation loss: 7.21305346620575\n",
      "loss difference:\n",
      "0.004496248129807645\n",
      "epoch: 537\n",
      "training loss: 1.2707368583679786\n",
      "validation loss: 7.679824947850111\n",
      "loss difference:\n",
      "-0.009050702768650831\n",
      "that didn't improve loss:  1\n",
      "epoch: 538\n",
      "training loss: 1.2665678638401865\n",
      "validation loss: 7.215255226785032\n",
      "loss difference:\n",
      "0.004168994527792069\n",
      "epoch: 539\n",
      "training loss: 1.2746910782917045\n",
      "validation loss: 7.696775576152333\n",
      "loss difference:\n",
      "-0.00812321445151798\n",
      "that didn't improve loss:  1\n",
      "epoch: 540\n",
      "training loss: 1.2706824654255504\n",
      "validation loss: 7.218212937641201\n",
      "loss difference:\n",
      "0.00400861286615406\n",
      "epoch: 541\n",
      "training loss: 1.2776067136255242\n",
      "validation loss: 7.712372761698973\n",
      "loss difference:\n",
      "-0.006924248199973837\n",
      "that didn't improve loss:  1\n",
      "epoch: 542\n",
      "training loss: 1.2736024750579698\n",
      "validation loss: 7.222075226700111\n",
      "loss difference:\n",
      "0.004004238567554497\n",
      "epoch: 543\n",
      "training loss: 1.2790645971687824\n",
      "validation loss: 7.726239162848583\n",
      "loss difference:\n",
      "-0.0054621221108126505\n",
      "that didn't improve loss:  1\n",
      "epoch: 544\n",
      "training loss: 1.2749428552922617\n",
      "validation loss: 7.2269496056378\n",
      "loss difference:\n",
      "0.0041217418765207015\n",
      "epoch: 545\n",
      "training loss: 1.2787169804191103\n",
      "validation loss: 7.738068262287684\n",
      "loss difference:\n",
      "-0.0037741251268486042\n",
      "that didn't improve loss:  1\n",
      "epoch: 546\n",
      "training loss: 1.2744108155778975\n",
      "validation loss: 7.232892094482131\n",
      "loss difference:\n",
      "0.004306164841212823\n",
      "epoch: 547\n",
      "training loss: 1.2763355268683547\n",
      "validation loss: 7.7476593230978175\n",
      "loss difference:\n",
      "-0.0019247112904572372\n",
      "that didn't improve loss:  1\n",
      "epoch: 548\n",
      "training loss: 1.2718458899519518\n",
      "validation loss: 7.23990227593321\n",
      "loss difference:\n",
      "0.004489636916402917\n",
      "epoch: 549\n",
      "training loss: 1.2718436041414616\n",
      "validation loss: 7.7549409075788365\n",
      "loss difference:\n",
      "2.2858104902212517e-06\n",
      "that didn't improve loss:  1\n",
      "epoch: 550\n",
      "training loss: 1.2672405510229676\n",
      "validation loss: 7.2479246930012255\n",
      "loss difference:\n",
      "0.0046030531184939605\n",
      "epoch: 551\n",
      "training loss: 1.2653246994366625\n",
      "validation loss: 7.7599777171534345\n",
      "loss difference:\n",
      "0.0019158515863051395\n",
      "epoch: 552\n",
      "training loss: 1.2607364482891428\n",
      "validation loss: 7.2568561887663225\n",
      "loss difference:\n",
      "0.004588251147519706\n",
      "epoch: 553\n",
      "training loss: 1.2570052019500118\n",
      "validation loss: 7.762959382813391\n",
      "loss difference:\n",
      "0.0037312463391310224\n",
      "epoch: 554\n",
      "training loss: 1.2525980113561994\n",
      "validation loss: 7.266557626278244\n",
      "loss difference:\n",
      "0.004407190593812338\n",
      "epoch: 555\n",
      "training loss: 1.2472167932666025\n",
      "validation loss: 7.764174148437397\n",
      "loss difference:\n",
      "0.005381218089596906\n",
      "epoch: 556\n",
      "training loss: 1.243170931533149\n",
      "validation loss: 7.276867767024149\n",
      "loss difference:\n",
      "0.00404586173345356\n",
      "epoch: 557\n",
      "training loss: 1.2363484315428275\n",
      "validation loss: 7.763973563819058\n",
      "loss difference:\n",
      "0.006822499990321473\n",
      "epoch: 558\n",
      "training loss: 1.2328357766830609\n",
      "validation loss: 7.287617052056328\n",
      "loss difference:\n",
      "0.003512654859766595\n",
      "epoch: 559\n",
      "training loss: 1.2247988635899878\n",
      "validation loss: 7.76273536108248\n",
      "loss difference:\n",
      "0.008036913093073084\n",
      "epoch: 560\n",
      "training loss: 1.2219661780961857\n",
      "validation loss: 7.298639507307055\n",
      "loss difference:\n",
      "0.0028326854938021118\n",
      "epoch: 561\n",
      "training loss: 1.2129381212132238\n",
      "validation loss: 7.760830646826941\n",
      "loss difference:\n",
      "0.009028056882961932\n",
      "epoch: 562\n",
      "training loss: 1.210897728359997\n",
      "validation loss: 7.309781731811002\n",
      "loss difference:\n",
      "0.002040392853226658\n",
      "epoch: 563\n",
      "training loss: 1.2010822562223962\n",
      "validation loss: 7.758599215867547\n",
      "loss difference:\n",
      "0.009815472137600922\n",
      "epoch: 564\n",
      "training loss: 1.1999097195423079\n",
      "validation loss: 7.320908666033357\n",
      "loss difference:\n",
      "0.0011725366800883208\n",
      "epoch: 565\n",
      "training loss: 1.1894815211177794\n",
      "validation loss: 7.756334230100476\n",
      "loss difference:\n",
      "0.010428198424528468\n",
      "epoch: 566\n",
      "training loss: 1.1892186044238917\n",
      "validation loss: 7.331906403450616\n",
      "loss difference:\n",
      "0.00026291669388767147\n",
      "epoch: 567\n",
      "training loss: 1.1783194889473654\n",
      "validation loss: 7.754275494123778\n",
      "loss difference:\n",
      "0.010899115476526333\n",
      "epoch: 568\n",
      "training loss: 1.1789802472260307\n",
      "validation loss: 7.342682637505864\n",
      "loss difference:\n",
      "-0.0006607582786652966\n",
      "that didn't improve loss:  1\n",
      "epoch: 569\n",
      "training loss: 1.1677194918336382\n",
      "validation loss: 7.752609419656319\n",
      "loss difference:\n",
      "0.011260755392392463\n",
      "epoch: 570\n",
      "training loss: 1.1692975706458857\n",
      "validation loss: 7.353165448570975\n",
      "loss difference:\n",
      "-0.0015780788122474743\n",
      "that didn't improve loss:  1\n",
      "epoch: 571\n",
      "training loss: 1.1577548800368846\n",
      "validation loss: 7.75147343621633\n",
      "loss difference:\n",
      "0.011542690609001038\n",
      "epoch: 572\n",
      "training loss: 1.1602306423090778\n",
      "validation loss: 7.363301095060557\n",
      "loss difference:\n",
      "-0.0024757622721931494\n",
      "that didn't improve loss:  1\n",
      "epoch: 573\n",
      "training loss: 1.1484603882476476\n",
      "validation loss: 7.750962813994375\n",
      "loss difference:\n",
      "0.011770254061430174\n",
      "epoch: 574\n",
      "training loss: 1.15180706887661\n",
      "validation loss: 7.3730513497395505\n",
      "loss difference:\n",
      "-0.003346680628962373\n",
      "that didn't improve loss:  1\n",
      "epoch: 575\n",
      "training loss: 1.1398428536802112\n",
      "validation loss: 7.7511383328909425\n",
      "loss difference:\n",
      "0.011964215196398786\n",
      "epoch: 576\n",
      "training loss: 1.144031412642275\n",
      "validation loss: 7.38239077304516\n",
      "loss difference:\n",
      "-0.004188558962063826\n",
      "that didn't improve loss:  1\n",
      "epoch: 577\n",
      "training loss: 1.131890367760134\n",
      "validation loss: 7.752033747547171\n",
      "loss difference:\n",
      "0.012141044882141072\n",
      "epoch: 578\n",
      "training loss: 1.1368930244420665\n",
      "validation loss: 7.391304175784677\n",
      "loss difference:\n",
      "-0.00500265668193256\n",
      "that didn't improve loss:  1\n",
      "epoch: 579\n",
      "training loss: 1.1245795454604246\n",
      "validation loss: 7.7536624431157835\n",
      "loss difference:\n",
      "0.012313478981641923\n",
      "epoch: 580\n",
      "training loss: 1.130372145841105\n",
      "validation loss: 7.399784411165556\n",
      "loss difference:\n",
      "-0.005792600380680302\n",
      "that didn't improve loss:  1\n",
      "epoch: 581\n",
      "training loss: 1.1178809635111944\n",
      "validation loss: 7.7560230064216755\n",
      "loss difference:\n",
      "0.012491182329910533\n",
      "epoch: 582\n",
      "training loss: 1.1244443969399596\n",
      "validation loss: 7.407830555001948\n",
      "loss difference:\n",
      "-0.006563433428765197\n",
      "that didn't improve loss:  1\n",
      "epoch: 583\n",
      "training loss: 1.1117630020635318\n",
      "validation loss: 7.759103653402124\n",
      "loss difference:\n",
      "0.01268139487642772\n",
      "epoch: 584\n",
      "training loss: 1.1190838860462833\n",
      "validation loss: 7.415446480002402\n",
      "loss difference:\n",
      "-0.007320883982751436\n",
      "that didn't improve loss:  1\n",
      "epoch: 585\n",
      "training loss: 1.1061943855114316\n",
      "validation loss: 7.7628855782746085\n",
      "loss difference:\n",
      "0.012889500534851717\n",
      "epoch: 586\n",
      "training loss: 1.1142652065162817\n",
      "validation loss: 7.422639799082434\n",
      "loss difference:\n",
      "-0.008070821004850126\n",
      "that didn't improve loss:  1\n",
      "epoch: 587\n",
      "training loss: 1.101145709144272\n",
      "validation loss: 7.7673453495672184\n",
      "loss difference:\n",
      "0.01311949737200968\n",
      "epoch: 588\n",
      "training loss: 1.1099645656069177\n",
      "validation loss: 7.429421137054167\n",
      "loss difference:\n",
      "-0.008818856462645686\n",
      "that didn't improve loss:  1\n",
      "epoch: 589\n",
      "training loss: 1.0965901959653228\n",
      "validation loss: 7.772456496751249\n",
      "loss difference:\n",
      "0.013374369641594885\n",
      "epoch: 590\n",
      "training loss: 1.1061602481793815\n",
      "validation loss: 7.435803684095748\n",
      "loss difference:\n",
      "-0.00957005221405871\n",
      "that didn't improve loss:  1\n",
      "epoch: 591\n",
      "training loss: 1.0925038752907055\n",
      "validation loss: 7.778190426854121\n",
      "loss difference:\n",
      "0.01365637288867605\n",
      "epoch: 592\n",
      "training loss: 1.1028325714446294\n",
      "validation loss: 7.441802983696211\n",
      "loss difference:\n",
      "-0.010328696153923955\n",
      "that didn't improve loss:  1\n",
      "epoch: 593\n",
      "training loss: 1.0888653243156545\n",
      "validation loss: 7.7845167955939765\n",
      "loss difference:\n",
      "0.013967247128974902\n",
      "epoch: 594\n",
      "training loss: 1.0999634447778377\n",
      "validation loss: 7.4474369092072195\n",
      "loss difference:\n",
      "-0.01109812046218317\n",
      "that didn't improve loss:  1\n",
      "epoch: 595\n",
      "training loss: 1.0856550718496345\n",
      "validation loss: 7.791403440264074\n",
      "loss difference:\n",
      "0.014308372928203195\n",
      "epoch: 596\n",
      "training loss: 1.0975356153275837\n",
      "validation loss: 7.452725784703641\n",
      "loss difference:\n",
      "-0.011880543477949201\n",
      "that didn't improve loss:  1\n",
      "epoch: 597\n",
      "training loss: 1.0828547323637936\n",
      "validation loss: 7.798815966597567\n",
      "loss difference:\n",
      "0.01468088296379011\n",
      "epoch: 598\n",
      "training loss: 1.0955316575000162\n",
      "validation loss: 7.45769260640491\n",
      "loss difference:\n",
      "-0.01267692513622265\n",
      "that didn't improve loss:  1\n",
      "epoch: 599\n",
      "training loss: 1.0804459190728881\n",
      "validation loss: 7.806717071827611\n",
      "loss difference:\n",
      "0.015085738427128126\n",
      "epoch: 600\n",
      "training loss: 1.093932752971469\n",
      "validation loss: 7.462363319949684\n",
      "loss difference:\n",
      "-0.013486833898580963\n",
      "that didn't improve loss:  1\n",
      "epoch: 601\n",
      "training loss: 1.0784089769811405\n",
      "validation loss: 7.8150656823940965\n",
      "loss difference:\n",
      "0.015523775990328614\n",
      "epoch: 602\n",
      "training loss: 1.09271730768442\n",
      "validation loss: 7.466767106404491\n",
      "loss difference:\n",
      "-0.014308330703279637\n",
      "that didn't improve loss:  1\n",
      "epoch: 603\n",
      "training loss: 1.0767215803577406\n",
      "validation loss: 7.823815987518742\n",
      "loss difference:\n",
      "0.015995727326679532\n",
      "epoch: 604\n",
      "training loss: 1.0918594629305536\n",
      "validation loss: 7.470936626568532\n",
      "loss difference:\n",
      "-0.01513788257281301\n",
      "that didn't improve loss:  1\n",
      "epoch: 605\n",
      "training loss: 1.075357253339644\n",
      "validation loss: 7.832916458586869\n",
      "loss difference:\n",
      "0.016502209590909533\n",
      "epoch: 606\n",
      "training loss: 1.0913275781216238\n",
      "validation loss: 7.474908169917782\n",
      "loss difference:\n",
      "-0.015970324781979794\n",
      "that didn't improve loss:  1\n",
      "epoch: 607\n",
      "training loss: 1.0742838959372956\n",
      "validation loss: 7.8423089574158045\n",
      "loss difference:\n",
      "0.01704368218432828\n",
      "epoch: 608\n",
      "training loss: 1.0910827910821925\n",
      "validation loss: 7.478721652839556\n",
      "loss difference:\n",
      "-0.016798895144896964\n",
      "that didn't improve loss:  1\n",
      "epoch: 609\n",
      "training loss: 1.0734624279751692\n",
      "validation loss: 7.851928051412765\n",
      "loss difference:\n",
      "0.017620363107023307\n",
      "epoch: 610\n",
      "training loss: 1.0910777938274256\n",
      "validation loss: 7.482420412397113\n",
      "loss difference:\n",
      "-0.017615365852256426\n",
      "that didn't improve loss:  1\n",
      "epoch: 611\n",
      "training loss: 1.072845695802484\n",
      "validation loss: 7.8617006664197175\n",
      "loss difference:\n",
      "0.018232098024941745\n",
      "epoch: 612\n",
      "training loss: 1.0912559917263742\n",
      "validation loss: 7.486050748597314\n",
      "loss difference:\n",
      "-0.01841029592389032\n",
      "that didn't improve loss:  1\n",
      "epoch: 613\n",
      "training loss: 1.072377813933157\n",
      "validation loss: 7.8715462135609355\n",
      "loss difference:\n",
      "0.01887817779321721\n",
      "epoch: 614\n",
      "training loss: 1.091551233252814\n",
      "validation loss: 7.489661181648811\n",
      "loss difference:\n",
      "-0.01917341931965688\n",
      "that didn't improve loss:  1\n",
      "epoch: 615\n",
      "training loss: 1.0719941268319158\n",
      "validation loss: 7.881377318677546\n",
      "loss difference:\n",
      "0.01955710642089814\n",
      "epoch: 616\n",
      "training loss: 1.0918882960643512\n",
      "validation loss: 7.493301411913688\n",
      "loss difference:\n",
      "-0.019894169232435477\n",
      "that didn't improve loss:  1\n",
      "epoch: 617\n",
      "training loss: 1.0716219643954314\n",
      "validation loss: 7.891101256100671\n",
      "loss difference:\n",
      "0.02026633166891978\n",
      "epoch: 618\n",
      "training loss: 1.0921842828803257\n",
      "validation loss: 7.497020998837497\n",
      "loss difference:\n",
      "-0.020562318484894204\n",
      "that didn't improve loss:  1\n",
      "epoch: 619\n",
      "training loss: 1.071182318931028\n",
      "validation loss: 7.900622138382242\n",
      "loss difference:\n",
      "0.021001963949297542\n",
      "epoch: 620\n",
      "training loss: 1.0923510104968417\n",
      "validation loss: 7.500867809041952\n",
      "loss difference:\n",
      "-0.02116869156581358\n",
      "that didn't improve loss:  1\n",
      "epoch: 621\n",
      "training loss: 1.0705924867170582\n",
      "validation loss: 7.909843839571713\n",
      "loss difference:\n",
      "0.02175852377978349\n",
      "epoch: 622\n",
      "training loss: 1.092298366828774\n",
      "validation loss: 7.504886319042005\n",
      "loss difference:\n",
      "-0.021705880111715814\n",
      "that didn't improve loss:  1\n",
      "epoch: 623\n",
      "training loss: 1.0697695967964376\n",
      "validation loss: 7.918673536559157\n",
      "loss difference:\n",
      "0.022528770032336443\n",
      "epoch: 624\n",
      "training loss: 1.0919384734696471\n",
      "validation loss: 7.509115889184827\n",
      "loss difference:\n",
      "-0.022168876673209548\n",
      "that didn't improve loss:  1\n",
      "epoch: 625\n",
      "training loss: 1.0686348075837964\n",
      "validation loss: 7.927025652246307\n",
      "loss difference:\n",
      "0.023303665885850755\n",
      "epoch: 626\n",
      "training loss: 1.0911903453562715\n",
      "validation loss: 7.51358914619849\n",
      "loss difference:\n",
      "-0.0225555377724751\n",
      "that didn't improve loss:  1\n",
      "epoch: 627\n",
      "training loss: 1.0671178129948227\n",
      "validation loss: 7.934825893011691\n",
      "loss difference:\n",
      "0.024072532361448795\n",
      "epoch: 628\n",
      "training loss: 1.089984614033407\n",
      "validation loss: 7.518330616689666\n",
      "loss difference:\n",
      "-0.022866801038584406\n",
      "that didn't improve loss:  1\n",
      "epoch: 629\n",
      "training loss: 1.0651611956929872\n",
      "validation loss: 7.942015011178163\n",
      "loss difference:\n",
      "0.0248234183404199\n",
      "epoch: 630\n",
      "training loss: 1.0882678086607844\n",
      "validation loss: 7.523355739826851\n",
      "loss difference:\n",
      "-0.023106612967797258\n",
      "that didn't improve loss:  1\n",
      "epoch: 631\n",
      "training loss: 1.0627241260284064\n",
      "validation loss: 7.948551909074667\n",
      "loss difference:\n",
      "0.02554368263237805\n",
      "epoch: 632\n",
      "training loss: 1.086005694623003\n",
      "validation loss: 7.528670354584397\n",
      "loss difference:\n",
      "-0.023281568594596624\n",
      "that didn't improve loss:  1\n",
      "epoch: 633\n",
      "training loss: 1.0597849505934471\n",
      "validation loss: 7.954415745294988\n",
      "loss difference:\n",
      "0.026220744029555876\n",
      "epoch: 634\n",
      "training loss: 1.0831852629087815\n",
      "validation loss: 7.5342707095211745\n",
      "loss difference:\n",
      "-0.02340031231533435\n",
      "that didn't improve loss:  1\n",
      "epoch: 635\n",
      "training loss: 1.0563423441335935\n",
      "validation loss: 7.959606804299369\n",
      "loss difference:\n",
      "0.026842918775187963\n",
      "epoch: 636\n",
      "training loss: 1.0798151325757455\n",
      "validation loss: 7.540143988569543\n",
      "loss difference:\n",
      "-0.02347278844215195\n",
      "that didn't improve loss:  1\n",
      "epoch: 637\n",
      "training loss: 1.0524148910701265\n",
      "validation loss: 7.964146032645355\n",
      "loss difference:\n",
      "0.027400241505618927\n",
      "epoch: 638\n",
      "training loss: 1.0759243418375317\n",
      "validation loss: 7.5462692937205835\n",
      "loss difference:\n",
      "-0.023509450767405182\n",
      "that didn't improve loss:  1\n",
      "epoch: 639\n",
      "training loss: 1.0480391792226593\n",
      "validation loss: 7.9680733034910105\n",
      "loss difference:\n",
      "0.027885162614872394\n",
      "epoch: 640\n",
      "training loss: 1.0715597170355613\n",
      "validation loss: 7.552618983230078\n",
      "loss difference:\n",
      "-0.023520537812901976\n",
      "that didn't improve loss:  1\n",
      "epoch: 641\n",
      "training loss: 1.0432666833824815\n",
      "validation loss: 7.971444616202502\n",
      "loss difference:\n",
      "0.02829303365307978\n",
      "epoch: 642\n",
      "training loss: 1.0667821800984432\n",
      "validation loss: 7.5591602379496186\n",
      "loss difference:\n",
      "-0.023515496715961648\n",
      "that didn't improve loss:  1\n",
      "epoch: 643\n",
      "training loss: 1.0381598520218374\n",
      "validation loss: 7.974328544304424\n",
      "loss difference:\n",
      "0.028622328076605807\n",
      "epoch: 644\n",
      "training loss: 1.0616624538251092\n",
      "validation loss: 7.565856720895069\n",
      "loss difference:\n",
      "-0.023502601803271794\n",
      "that didn't improve loss:  1\n",
      "epoch: 645\n",
      "training loss: 1.032787865660165\n",
      "validation loss: 7.976802297172966\n",
      "loss difference:\n",
      "0.028874588164944148\n",
      "epoch: 646\n",
      "training loss: 1.056276640011893\n",
      "validation loss: 7.572670204813027\n",
      "loss difference:\n",
      "-0.023488774351728026\n",
      "that didn't improve loss:  1\n",
      "epoch: 647\n",
      "training loss: 1.0272225103084311\n",
      "validation loss: 7.978947756339242\n",
      "loss difference:\n",
      "0.029054129703461884\n",
      "epoch: 648\n",
      "training loss: 1.0507020875832782\n",
      "validation loss: 7.579562065107286\n",
      "loss difference:\n",
      "-0.023479577274847063\n",
      "that didn't improve loss:  1\n",
      "epoch: 649\n",
      "training loss: 1.021534521895157\n",
      "validation loss: 7.98084779539633\n",
      "loss difference:\n",
      "0.029167565688121178\n",
      "epoch: 650\n",
      "training loss: 1.0450138601100825\n",
      "validation loss: 7.5864945654462375\n",
      "loss difference:\n",
      "-0.023479338214925427\n",
      "that didn't improve loss:  1\n",
      "epoch: 651\n",
      "training loss: 1.015790635487905\n",
      "validation loss: 7.982583110188956\n",
      "loss difference:\n",
      "0.029223224622177524\n",
      "epoch: 652\n",
      "training loss: 1.0392819834236757\n",
      "validation loss: 7.593431895094726\n",
      "loss difference:\n",
      "-0.02349134793577079\n",
      "that didn't improve loss:  1\n",
      "epoch: 653\n",
      "training loss: 1.0100514451813005\n",
      "validation loss: 7.984229692262129\n",
      "loss difference:\n",
      "0.029230538242375204\n",
      "epoch: 654\n",
      "training loss: 1.033569530692896\n",
      "validation loss: 7.600340945969794\n",
      "loss difference:\n",
      "-0.02351808551159551\n",
      "that didn't improve loss:  1\n",
      "epoch: 655\n",
      "training loss: 1.0043700693131774\n",
      "validation loss: 7.985856990015943\n",
      "loss difference:\n",
      "0.029199461379718628\n",
      "epoch: 656\n",
      "training loss: 1.0279315025371194\n",
      "validation loss: 7.607191840679964\n",
      "loss difference:\n",
      "-0.023561433223941997\n",
      "that didn't improve loss:  1\n",
      "epoch: 657\n",
      "training loss: 0.9987915342611321\n",
      "validation loss: 7.987526729947554\n",
      "loss difference:\n",
      "0.029139968275987305\n",
      "epoch: 658\n",
      "training loss: 1.022414392088454\n",
      "validation loss: 7.613958239095058\n",
      "loss difference:\n",
      "-0.023622857827321986\n",
      "that didn't improve loss:  1\n",
      "epoch: 659\n",
      "training loss: 0.993352742108393\n",
      "validation loss: 7.98929232007857\n",
      "loss difference:\n",
      "0.02906164998006111\n",
      "epoch: 660\n",
      "training loss: 1.0170562896199948\n",
      "validation loss: 7.620617460386677\n",
      "loss difference:\n",
      "-0.023703547511601863\n",
      "that didn't improve loss:  1\n",
      "epoch: 661\n",
      "training loss: 0.9880828695397857\n",
      "validation loss: 7.991198729385096\n",
      "loss difference:\n",
      "0.02897342008020909\n",
      "epoch: 662\n",
      "training loss: 1.0118873731042395\n",
      "validation loss: 7.627150460960646\n",
      "loss difference:\n",
      "-0.02380450356445374\n",
      "that didn't improve loss:  1\n",
      "epoch: 663\n",
      "training loss: 0.9830040501324965\n",
      "validation loss: 7.993282727562362\n",
      "loss difference:\n",
      "0.02888332297174301\n",
      "epoch: 664\n",
      "training loss: 1.0069306420037576\n",
      "validation loss: 7.633541707696969\n",
      "loss difference:\n",
      "-0.023926591871261116\n",
      "that didn't improve loss:  1\n",
      "epoch: 665\n",
      "training loss: 0.9781322113805581\n",
      "validation loss: 7.995573373907455\n",
      "loss difference:\n",
      "0.028798430623199534\n",
      "epoch: 666\n",
      "training loss: 1.0022027737387436\n",
      "validation loss: 7.639778981922876\n",
      "loss difference:\n",
      "-0.0240705623581855\n",
      "that didn't improve loss:  1\n",
      "epoch: 667\n",
      "training loss: 0.9734779638549015\n",
      "validation loss: 7.99809265740236\n",
      "loss difference:\n",
      "0.028724809883842073\n",
      "epoch: 668\n",
      "training loss: 0.9977150089649828\n",
      "validation loss: 7.645853143902858\n",
      "loss difference:\n",
      "-0.02423704511008129\n",
      "that didn't improve loss:  1\n",
      "epoch: 669\n",
      "training loss: 0.969047467211564\n",
      "validation loss: 8.00085620780666\n",
      "loss difference:\n",
      "0.02866754175341879\n",
      "epoch: 670\n",
      "training loss: 0.9934739982938042\n",
      "validation loss: 7.651757881384317\n",
      "loss difference:\n",
      "-0.024426531082240244\n",
      "that didn't improve loss:  1\n",
      "epoch: 671\n",
      "training loss: 0.9648432227166532\n",
      "validation loss: 8.003874016396507\n",
      "loss difference:\n",
      "0.02863077557715099\n",
      "epoch: 672\n",
      "training loss: 0.9894825665548022\n",
      "validation loss: 7.657489459617525\n",
      "loss difference:\n",
      "-0.02463934383814892\n",
      "that didn't improve loss:  1\n",
      "epoch: 673\n",
      "training loss: 0.9608647627220854\n",
      "validation loss: 8.007151122720522\n",
      "loss difference:\n",
      "0.028617803832716726\n",
      "epoch: 674\n",
      "training loss: 0.9857403698498853\n",
      "validation loss: 7.663046484720307\n",
      "loss difference:\n",
      "-0.024875607127799904\n",
      "that didn't improve loss:  1\n",
      "epoch: 675\n",
      "training loss: 0.957109223568597\n",
      "validation loss: 8.010688239177794\n",
      "loss difference:\n",
      "0.028631146281288378\n",
      "epoch: 676\n",
      "training loss: 0.9822444352632826\n",
      "validation loss: 7.668429687501006\n",
      "loss difference:\n",
      "-0.02513521169468569\n",
      "that didn't improve loss:  1\n",
      "epoch: 677\n",
      "training loss: 0.953571800001732\n",
      "validation loss: 8.014482297887158\n",
      "loss difference:\n",
      "0.028672635261550616\n",
      "epoch: 678\n",
      "training loss: 0.9789895836149164\n",
      "validation loss: 7.673641730949107\n",
      "loss difference:\n",
      "-0.025417783613184364\n",
      "that didn't improve loss:  1\n",
      "epoch: 679\n",
      "training loss: 0.950246087080394\n",
      "validation loss: 8.018526914228353\n",
      "loss difference:\n",
      "0.02874349653452235\n",
      "epoch: 680\n",
      "training loss: 0.9759687428205195\n",
      "validation loss: 7.678687041514673\n",
      "loss difference:\n",
      "-0.025722655740125444\n",
      "that didn't improve loss:  1\n",
      "epoch: 681\n",
      "training loss: 0.9471243205967519\n",
      "validation loss: 8.022812768890804\n",
      "loss difference:\n",
      "0.028844422223767596\n",
      "epoch: 682\n",
      "training loss: 0.9731731640715745\n",
      "validation loss: 7.683571661939167\n",
      "loss difference:\n",
      "-0.026048843474822614\n",
      "that didn't improve loss:  1\n",
      "epoch: 683\n",
      "training loss: 0.9441975300382397\n",
      "validation loss: 8.027327915675816\n",
      "loss difference:\n",
      "0.028975634033334807\n",
      "epoch: 684\n",
      "training loss: 0.9705925559248382\n",
      "validation loss: 7.688303121669423\n",
      "loss difference:\n",
      "-0.026395025886598478\n",
      "that didn't improve loss:  1\n",
      "epoch: 685\n",
      "training loss: 0.9414556198062243\n",
      "validation loss: 8.032058026091189\n",
      "loss difference:\n",
      "0.0291369361186139\n",
      "epoch: 686\n",
      "training loss: 0.9682151531079861\n",
      "validation loss: 7.692890319690028\n",
      "loss difference:\n",
      "-0.02675953330176184\n",
      "that didn't improve loss:  1\n",
      "epoch: 687\n",
      "training loss: 0.9388873952918405\n",
      "validation loss: 8.036986584323614\n",
      "loss difference:\n",
      "0.029327757816145605\n",
      "epoch: 688\n",
      "training loss: 0.9660277378503936\n",
      "validation loss: 7.697343413872467\n",
      "loss difference:\n",
      "-0.027140342558553132\n",
      "that didn't improve loss:  1\n",
      "epoch: 689\n",
      "training loss: 0.9364805508546797\n",
      "validation loss: 8.042095047763887\n",
      "loss difference:\n",
      "0.029547186995713903\n",
      "epoch: 690\n",
      "training loss: 0.9640156321140981\n",
      "validation loss: 7.701673710612601\n",
      "loss difference:\n",
      "-0.027535081259418392\n",
      "that didn't improve loss:  1\n",
      "epoch: 691\n",
      "training loss: 0.934221636949019\n",
      "validation loss: 8.047362989084208\n",
      "loss difference:\n",
      "0.02979399516507908\n",
      "epoch: 692\n",
      "training loss: 0.962162679353804\n",
      "validation loss: 7.705893548583551\n",
      "loss difference:\n",
      "-0.0279410424047849\n",
      "that didn't improve loss:  1\n",
      "epoch: 693\n",
      "training loss: 0.93209602364846\n",
      "validation loss: 8.052768236025287\n",
      "loss difference:\n",
      "0.030066655705343948\n",
      "epoch: 694\n",
      "training loss: 0.9604512343690619\n",
      "validation loss: 7.710016170858568\n",
      "loss difference:\n",
      "-0.028355210720601876\n",
      "that didn't improve loss:  1\n",
      "epoch: 695\n",
      "training loss: 0.9300878775706874\n",
      "validation loss: 8.05828702456624\n",
      "loss difference:\n",
      "0.03036335679837443\n",
      "epoch: 696\n",
      "training loss: 0.95886217931573\n",
      "validation loss: 7.714055580456652\n",
      "loss difference:\n",
      "-0.028774301745042585\n",
      "that didn't improve loss:  1\n",
      "epoch: 697\n",
      "training loss: 0.9281801685499254\n",
      "validation loss: 8.063894179986153\n",
      "loss difference:\n",
      "0.03068201076580468\n",
      "epoch: 698\n",
      "training loss: 0.9573749828366827\n",
      "validation loss: 7.7180263755259215\n",
      "loss difference:\n",
      "-0.029194814286757298\n",
      "that didn't improve loss:  1\n",
      "epoch: 699\n",
      "training loss: 0.9263547211440831\n",
      "validation loss: 8.06956333841719\n",
      "loss difference:\n",
      "0.031020261692599527\n",
      "epoch: 700\n",
      "training loss: 0.9559678173424215\n",
      "validation loss: 7.721943561890105\n",
      "loss difference:\n",
      "-0.029613096198338407\n",
      "that didn't improve loss:  1\n",
      "epoch: 701\n",
      "training loss: 0.9245923239832728\n",
      "validation loss: 8.07526721877236\n",
      "loss difference:\n",
      "0.03137549335914869\n",
      "epoch: 702\n",
      "training loss: 0.9546177465267665\n",
      "validation loss: 7.725822342496345\n",
      "loss difference:\n",
      "-0.030025422543493607\n",
      "that didn't improve loss:  1\n",
      "epoch: 703\n",
      "training loss: 0.9228729068889228\n",
      "validation loss: 8.080977951377852\n",
      "loss difference:\n",
      "0.03174483963784369\n",
      "epoch: 704\n",
      "training loss: 0.9533009911155165\n",
      "validation loss: 7.729677885343378\n",
      "loss difference:\n",
      "-0.03042808422659371\n",
      "that didn't improve loss:  1\n",
      "epoch: 705\n",
      "training loss: 0.9211757915268688\n",
      "validation loss: 8.086667465293932\n",
      "loss difference:\n",
      "0.03212519958864768\n",
      "epoch: 706\n",
      "training loss: 0.9519932756118399\n",
      "validation loss: 7.7335250736241585\n",
      "loss difference:\n",
      "-0.030817484084971092\n",
      "that didn't improve loss:  1\n",
      "epoch: 707\n",
      "training loss: 0.9194800161467158\n",
      "validation loss: 8.09230793130987\n",
      "loss difference:\n",
      "0.03251325946512407\n",
      "epoch: 708\n",
      "training loss: 0.9506702525808526\n",
      "validation loss: 7.737378243938151\n",
      "loss difference:\n",
      "-0.031190236434136764\n",
      "that didn't improve loss:  1\n",
      "epoch: 709\n",
      "training loss: 0.9177647289184518\n",
      "validation loss: 8.097872252207011\n",
      "loss difference:\n",
      "0.03290552366240074\n",
      "epoch: 710\n",
      "training loss: 0.9493079941576074\n",
      "validation loss: 7.7412509203412005\n",
      "loss difference:\n",
      "-0.031543265239155516\n",
      "that didn't improve loss:  1\n",
      "epoch: 711\n",
      "training loss: 0.9160096379070158\n",
      "validation loss: 8.103334586473387\n",
      "loss difference:\n",
      "0.03329835625059152\n",
      "epoch: 712\n",
      "training loss: 0.9478835335054949\n",
      "validation loss: 7.745155553519616\n",
      "loss difference:\n",
      "-0.031873895598479085\n",
      "that didn't improve loss:  1\n",
      "epoch: 713\n",
      "training loss: 0.9141954993990767\n",
      "validation loss: 8.10867088669493\n",
      "loss difference:\n",
      "0.033688034106418185\n",
      "epoch: 714\n",
      "training loss: 0.9463754325830985\n",
      "validation loss: 7.749103275326896\n",
      "loss difference:\n",
      "-0.03217993318402179\n",
      "that didn't improve loss:  1\n",
      "epoch: 715\n",
      "training loss: 0.9123046208029484\n",
      "validation loss: 8.113859429864727\n",
      "loss difference:\n",
      "0.034070811780150145\n",
      "epoch: 716\n",
      "training loss: 0.9447643475543243\n",
      "validation loss: 7.753103679165972\n",
      "loss difference:\n",
      "-0.03245972675137587\n",
      "that didn't improve loss:  1\n",
      "epoch: 717\n",
      "training loss: 0.910321350400674\n",
      "validation loss: 8.118881314348418\n",
      "loss difference:\n",
      "0.03444299715365029\n",
      "epoch: 718\n",
      "training loss: 0.9430335602191018\n",
      "validation loss: 7.757164636159324\n",
      "loss difference:\n",
      "-0.03271220981842782\n",
      "that didn't improve loss:  1\n",
      "epoch: 719\n",
      "training loss: 0.9082325244732204\n",
      "validation loss: 8.123720897636005\n",
      "loss difference:\n",
      "0.03480103574588134\n",
      "epoch: 720\n",
      "training loss: 0.9411694435084608\n",
      "validation loss: 7.761292155718924\n",
      "loss difference:\n",
      "-0.03293691903524032\n",
      "that didn't improve loss:  1\n",
      "epoch: 721\n",
      "training loss: 0.9060278431737375\n",
      "validation loss: 8.128366150542675\n",
      "loss difference:\n",
      "0.035141600334723244\n",
      "epoch: 722\n",
      "training loss: 0.9391618316590797\n",
      "validation loss: 7.7654902970891015\n",
      "loss difference:\n",
      "-0.033133988485342214\n",
      "that didn't improve loss:  1\n",
      "epoch: 723\n",
      "training loss: 0.9037001501145341\n",
      "validation loss: 8.13280890720795\n",
      "loss difference:\n",
      "0.03546168154454565\n",
      "epoch: 724\n",
      "training loss: 0.9370042710838683\n",
      "validation loss: 7.769761135849516\n",
      "loss difference:\n",
      "-0.03330412096933422\n",
      "that didn't improve loss:  1\n",
      "epoch: 725\n",
      "training loss: 0.9012455967281837\n",
      "validation loss: 8.13704499584428\n",
      "loss difference:\n",
      "0.03575867435568458\n",
      "epoch: 726\n",
      "training loss: 0.9346941357336401\n",
      "validation loss: 7.774104786455436\n",
      "loss difference:\n",
      "-0.03344853900545641\n",
      "that didn't improve loss:  1\n",
      "epoch: 727\n",
      "training loss: 0.8986636804793063\n",
      "validation loss: 8.141074242214959\n",
      "loss difference:\n",
      "0.03603045525433379\n",
      "epoch: 728\n",
      "training loss: 0.9322326001145107\n",
      "validation loss: 7.778519478918358\n",
      "loss difference:\n",
      "-0.033568919635204364\n",
      "that didn't improve loss:  1\n",
      "epoch: 729\n",
      "training loss: 0.8959571550830643\n",
      "validation loss: 8.144900345606338\n",
      "loss difference:\n",
      "0.03627544503144642\n",
      "epoch: 730\n",
      "training loss: 0.9296244730782122\n",
      "validation loss: 7.783001684953542\n",
      "loss difference:\n",
      "-0.03366731799514788\n",
      "that didn't improve loss:  1\n",
      "epoch: 731\n",
      "training loss: 0.8931318200223299\n",
      "validation loss: 8.148530634828308\n",
      "loss difference:\n",
      "0.03649265305588223\n",
      "epoch: 732\n",
      "training loss: 0.9268779049585524\n",
      "validation loss: 7.787546286574906\n",
      "loss difference:\n",
      "-0.03374608493622244\n",
      "that didn't improve loss:  1\n",
      "epoch: 733\n",
      "training loss: 0.8901962048505306\n",
      "validation loss: 8.151975718771459\n",
      "loss difference:\n",
      "0.03668170010802174\n",
      "epoch: 734\n",
      "training loss: 0.9240039886017839\n",
      "validation loss: 7.792146778375974\n",
      "loss difference:\n",
      "-0.03380778375125326\n",
      "that didn't improve loss:  1\n",
      "epoch: 735\n",
      "training loss: 0.8871611701836571\n",
      "validation loss: 8.155249051625265\n",
      "loss difference:\n",
      "0.036842818418126755\n",
      "epoch: 736\n",
      "training loss: 0.9210162805834604\n",
      "validation loss: 7.7967954936989425\n",
      "loss difference:\n",
      "-0.03385511039980327\n",
      "that didn't improve loss:  1\n",
      "epoch: 737\n",
      "training loss: 0.8840394513643955\n",
      "validation loss: 8.158366436574495\n",
      "loss difference:\n",
      "0.036976829219064866\n",
      "epoch: 738\n",
      "training loss: 0.917930272002613\n",
      "validation loss: 7.801483844582838\n",
      "loss difference:\n",
      "-0.03389082063821747\n",
      "that didn't improve loss:  1\n",
      "epoch: 739\n",
      "training loss: 0.8808451723041447\n",
      "validation loss: 8.161345493441004\n",
      "loss difference:\n",
      "0.03708509969846829\n",
      "epoch: 740\n",
      "training loss: 0.9147628386401238\n",
      "validation loss: 7.806202565743105\n",
      "loss difference:\n",
      "-0.033917666335979035\n",
      "that didn't improve loss:  1\n",
      "epoch: 741\n",
      "training loss: 0.8775933560919051\n",
      "validation loss: 8.164205115374218\n",
      "loss difference:\n",
      "0.03716948254821861\n",
      "epoch: 742\n",
      "training loss: 0.9115316982346836\n",
      "validation loss: 7.810941953757524\n",
      "loss difference:\n",
      "-0.033938342142778466\n",
      "that didn't improve loss:  1\n",
      "epoch: 743\n",
      "training loss: 0.8742994559981003\n",
      "validation loss: 8.166964937576834\n",
      "loss difference:\n",
      "0.03723224223658328\n",
      "epoch: 744\n",
      "training loss: 0.9082548986864504\n",
      "validation loss: 7.81569209397012\n",
      "loss difference:\n",
      "-0.033955442688350046\n",
      "that didn't improve loss:  1\n",
      "epoch: 745\n",
      "training loss: 0.8709789260750349\n",
      "validation loss: 8.169644837598497\n",
      "loss difference:\n",
      "0.037275972611415464\n",
      "epoch: 746\n",
      "training loss: 0.9049503558029636\n",
      "validation loss: 7.82044306921229\n",
      "loss difference:\n",
      "-0.03397142972792866\n",
      "that didn't improve loss:  1\n",
      "epoch: 747\n",
      "training loss: 0.8676468453164916\n",
      "validation loss: 8.172264482427527\n",
      "loss difference:\n",
      "0.03730351048647196\n",
      "epoch: 748\n",
      "training loss: 0.9016354534394774\n",
      "validation loss: 7.825185146121548\n",
      "loss difference:\n",
      "-0.033988608122985764\n",
      "that didn't improve loss:  1\n",
      "epoch: 749\n",
      "training loss: 0.8643176039142049\n",
      "validation loss: 8.174842932955901\n",
      "loss difference:\n",
      "0.037317849525272506\n",
      "epoch: 750\n",
      "training loss: 0.8983267131761187\n",
      "validation loss: 7.829908936476704\n",
      "loss difference:\n",
      "-0.034009109261913806\n",
      "that didn't improve loss:  1\n",
      "epoch: 751\n",
      "training loss: 0.8610046550639391\n",
      "validation loss: 8.177398311824925\n",
      "loss difference:\n",
      "0.03732205811217959\n",
      "epoch: 752\n",
      "training loss: 0.8950395355066001\n",
      "validation loss: 7.834605532457381\n",
      "loss difference:\n",
      "-0.03403488044266101\n",
      "that didn't improve loss:  1\n",
      "epoch: 753\n",
      "training loss: 0.8577203314084509\n",
      "validation loss: 8.17994753652359\n",
      "loss difference:\n",
      "0.03731920409814915\n",
      "epoch: 754\n",
      "training loss: 0.8917880102170799\n",
      "validation loss: 7.839266616002691\n",
      "loss difference:\n",
      "-0.03406767880862893\n",
      "that didn't improve loss:  1\n",
      "epoch: 755\n",
      "training loss: 0.8544757217802254\n",
      "validation loss: 8.182506116142566\n",
      "loss difference:\n",
      "0.037312288436854524\n",
      "epoch: 756\n",
      "training loss: 0.8885847903767226\n",
      "validation loss: 7.843884543451027\n",
      "loss difference:\n",
      "-0.034109068596497205\n",
      "that didn't improve loss:  1\n",
      "epoch: 757\n",
      "training loss: 0.8512806014993104\n",
      "validation loss: 8.185088007505557\n",
      "loss difference:\n",
      "0.03730418887741216\n",
      "epoch: 758\n",
      "training loss: 0.8854410221714618\n",
      "validation loss: 7.848452407378507\n",
      "loss difference:\n",
      "-0.034160420672151415\n",
      "that didn't improve loss:  1\n",
      "epoch: 759\n",
      "training loss: 0.8481434080496989\n",
      "validation loss: 8.187705524532044\n",
      "loss difference:\n",
      "0.03729761412176291\n",
      "epoch: 760\n",
      "training loss: 0.8823663216107651\n",
      "validation loss: 7.85296407803172\n",
      "loss difference:\n",
      "-0.034222913561066215\n",
      "that didn't improve loss:  1\n",
      "epoch: 761\n",
      "training loss: 0.8450712533798881\n",
      "validation loss: 8.19036929357917\n",
      "loss difference:\n",
      "0.037295068230877026\n",
      "epoch: 762\n",
      "training loss: 0.8793687887759912\n",
      "validation loss: 7.857414226998114\n",
      "loss difference:\n",
      "-0.03429753539610314\n",
      "that didn't improve loss:  1\n",
      "epoch: 763\n",
      "training loss: 0.8420699641827091\n",
      "validation loss: 8.193088247068626\n",
      "loss difference:\n",
      "0.037298824593282154\n",
      "epoch: 764\n",
      "training loss: 0.8764550505776338\n",
      "validation loss: 7.86179833581317\n",
      "loss difference:\n",
      "-0.03438508639492477\n",
      "that didn't improve loss:  1\n",
      "epoch: 765\n",
      "training loss: 0.839144142125579\n",
      "validation loss: 8.195869647796357\n",
      "loss difference:\n",
      "0.03731090845205487\n",
      "epoch: 766\n",
      "training loss: 0.8736303237600658\n",
      "validation loss: 7.866112692107907\n",
      "loss difference:\n",
      "-0.0344861816344868\n",
      "that didn't improve loss:  1\n",
      "epoch: 767\n",
      "training loss: 0.8362972369523483\n",
      "validation loss: 8.198719136817257\n",
      "loss difference:\n",
      "0.03733308680771752\n",
      "epoch: 768\n",
      "training loss: 0.8708984909646186\n",
      "validation loss: 7.870354375694208\n",
      "loss difference:\n",
      "-0.03460125401227032\n",
      "that didn't improve loss:  1\n",
      "epoch: 769\n",
      "training loss: 0.8335316265120869\n",
      "validation loss: 8.201640798563307\n",
      "loss difference:\n",
      "0.03736686445253168\n",
      "epoch: 770\n",
      "training loss: 0.8682621838888507\n",
      "validation loss: 7.874521236706343\n",
      "loss difference:\n",
      "-0.03473055737676378\n",
      "that didn't improve loss:  1\n",
      "epoch: 771\n",
      "training loss: 0.8308486989687076\n",
      "validation loss: 8.204637237781204\n",
      "loss difference:\n",
      "0.03741348492014307\n",
      "epoch: 772\n",
      "training loss: 0.8657228688471738\n",
      "validation loss: 7.878611867597299\n",
      "loss difference:\n",
      "-0.034874169878466144\n",
      "that didn't improve loss:  1\n",
      "epoch: 773\n",
      "training loss: 0.8282489336192511\n",
      "validation loss: 8.207709663870267\n",
      "loss difference:\n",
      "0.03747393522792264\n",
      "epoch: 774\n",
      "training loss: 0.86328093126231\n",
      "validation loss: 7.882625570454202\n",
      "loss difference:\n",
      "-0.035031997643058865\n",
      "that didn't improve loss:  1\n",
      "epoch: 775\n",
      "training loss: 0.8257319778380454\n",
      "validation loss: 8.210857979192863\n",
      "loss difference:\n",
      "0.037548953424264564\n",
      "epoch: 776\n",
      "training loss: 0.8609357567424506\n",
      "validation loss: 7.886562320770153\n",
      "loss difference:\n",
      "-0.03520377890440518\n",
      "that didn't improve loss:  1\n",
      "epoch: 777\n",
      "training loss: 0.8232967186323488\n",
      "validation loss: 8.214080868864958\n",
      "loss difference:\n",
      "0.03763903811010183\n",
      "epoch: 778\n",
      "training loss: 0.8586858073929425\n",
      "validation loss: 7.890422728504902\n",
      "loss difference:\n",
      "-0.03538908876059377\n",
      "that didn't improve loss:  1\n",
      "epoch: 779\n",
      "training loss: 0.8209413481251644\n",
      "validation loss: 8.217375890379037\n",
      "loss difference:\n",
      "0.03774445926777814\n",
      "epoch: 780\n",
      "training loss: 0.8565286928575158\n",
      "validation loss: 7.894207996996204\n",
      "loss difference:\n",
      "-0.03558734473235137\n",
      "that didn't improve loss:  1\n",
      "epoch: 781\n",
      "training loss: 0.8186634229675119\n",
      "validation loss: 8.22073956214421\n",
      "loss difference:\n",
      "0.03786526989000383\n",
      "epoch: 782\n",
      "training loss: 0.8544612362790014\n",
      "validation loss: 7.89791988005423\n",
      "loss difference:\n",
      "-0.03579781331148946\n",
      "that didn't improve loss:  1\n",
      "epoch: 783\n",
      "training loss: 0.8164599182295885\n",
      "validation loss: 8.224167450636662\n",
      "loss difference:\n",
      "0.03800131804941287\n",
      "epoch: 784\n",
      "training loss: 0.8524795359160365\n",
      "validation loss: 7.9015606373880045\n",
      "loss difference:\n",
      "-0.03601961768644801\n",
      "that didn't improve loss:  1\n",
      "epoch: 785\n",
      "training loss: 0.8143272767354819\n",
      "validation loss: 8.227654256335342\n",
      "loss difference:\n",
      "0.03815225918055465\n",
      "epoch: 786\n",
      "training loss: 0.8505790235577814\n",
      "validation loss: 7.905132988377944\n",
      "loss difference:\n",
      "-0.03625174682229948\n",
      "that didn't improve loss:  1\n",
      "epoch: 787\n",
      "training loss: 0.8122614550992441\n",
      "validation loss: 8.2311938989726\n",
      "loss difference:\n",
      "0.03831756845853729\n",
      "epoch: 788\n",
      "training loss: 0.8487545211517117\n",
      "validation loss: 7.908640064121819\n",
      "loss difference:\n",
      "-0.036493066052467604\n",
      "that didn't improve loss:  1\n",
      "epoch: 789\n",
      "training loss: 0.8102579679006728\n",
      "validation loss: 8.2347796028622\n",
      "loss difference:\n",
      "0.038496553251038845\n",
      "epoch: 790\n",
      "training loss: 0.8470002972084226\n",
      "validation loss: 7.912085357642602\n",
      "loss difference:\n",
      "-0.03674232930774979\n",
      "that didn't improve loss:  1\n",
      "epoch: 791\n",
      "training loss: 0.8083119315152071\n",
      "validation loss: 8.238403983184\n",
      "loss difference:\n",
      "0.03868836569321554\n",
      "epoch: 792\n",
      "training loss: 0.8453101245801078\n",
      "validation loss: 7.915472672152169\n",
      "loss difference:\n",
      "-0.03699819306490071\n",
      "that didn't improve loss:  1\n",
      "epoch: 793\n",
      "training loss: 0.8064181090916184\n",
      "validation loss: 8.242059134112871\n",
      "loss difference:\n",
      "0.03889201548848942\n",
      "epoch: 794\n",
      "training loss: 0.8436773411331355\n",
      "validation loss: 7.918806067311931\n",
      "loss difference:\n",
      "-0.037259232041517154\n",
      "that didn't improve loss:  1\n",
      "epoch: 795\n",
      "training loss: 0.8045709580597827\n",
      "validation loss: 8.245736719588555\n",
      "loss difference:\n",
      "0.03910638307335279\n",
      "epoch: 796\n",
      "training loss: 0.8420949146573918\n",
      "validation loss: 7.922089803513891\n",
      "loss difference:\n",
      "-0.0375239565976091\n",
      "that didn't improve loss:  1\n",
      "epoch: 797\n",
      "training loss: 0.802764681355288\n",
      "validation loss: 8.249428067342965\n",
      "loss difference:\n",
      "0.039330233302103834\n",
      "epoch: 798\n",
      "training loss: 0.8405555130840864\n",
      "validation loss: 7.92532828431853\n",
      "loss difference:\n",
      "-0.03779083172879838\n",
      "that didn't improve loss:  1\n",
      "epoch: 799\n",
      "training loss: 0.8009932832757358\n",
      "validation loss: 8.253124266544427\n",
      "loss difference:\n",
      "0.03956222980835056\n",
      "epoch: 800\n",
      "training loss: 0.8390515807302513\n",
      "validation loss: 7.928525997320392\n",
      "loss difference:\n",
      "-0.0380582974545155\n",
      "that didn't improve loss:  1\n",
      "epoch: 801\n",
      "training loss: 0.7992506305448013\n",
      "validation loss: 8.25681626909965\n",
      "loss difference:\n",
      "0.039800950185450046\n",
      "epoch: 802\n",
      "training loss: 0.837575420865579\n",
      "validation loss: 7.931687453860962\n",
      "loss difference:\n",
      "-0.038324790320777735\n",
      "that didn't improve loss:  1\n",
      "epoch: 803\n",
      "training loss: 0.7975305187671133\n",
      "validation loss: 8.260494994289035\n",
      "loss difference:\n",
      "0.04004490209846567\n",
      "epoch: 804\n",
      "training loss: 0.836119284423236\n",
      "validation loss: 7.9348171281612645\n",
      "loss difference:\n",
      "-0.03858876565612268\n",
      "that didn't improve loss:  1\n",
      "epoch: 805\n",
      "training loss: 0.7958267440263994\n",
      "validation loss: 8.264151436021272\n",
      "loss difference:\n",
      "0.04029254039683661\n",
      "epoch: 806\n",
      "training loss: 0.8346754641725247\n",
      "validation loss: 7.937919396593645\n",
      "loss difference:\n",
      "-0.03884872014612528\n",
      "that didn't improve loss:  1\n",
      "epoch: 807\n",
      "training loss: 0.7941331789311045\n",
      "validation loss: 8.267776771598587\n",
      "loss difference:\n",
      "0.04054228524142023\n",
      "epoch: 808\n",
      "training loss: 0.8332363931634496\n",
      "validation loss: 7.940998477943939\n",
      "loss difference:\n",
      "-0.039103214232345085\n",
      "that didn't improve loss:  1\n",
      "epoch: 809\n",
      "training loss: 0.7924438519696773\n",
      "validation loss: 8.271362470510113\n",
      "loss difference:\n",
      "0.04079254119377229\n",
      "epoch: 810\n",
      "training loss: 0.8317947457703391\n",
      "validation loss: 7.944058375620951\n",
      "loss difference:\n",
      "-0.03935089380066181\n",
      "that didn't improve loss:  1\n",
      "epoch: 811\n",
      "training loss: 0.7907530286280668\n",
      "validation loss: 8.27490040144031\n",
      "loss difference:\n",
      "0.04104171714227223\n",
      "epoch: 812\n",
      "training loss: 0.8303435392341776\n",
      "validation loss: 7.947102822842612\n",
      "loss difference:\n",
      "-0.03959051060611074\n",
      "that didn't improve loss:  1\n",
      "epoch: 813\n",
      "training loss: 0.7890552923716533\n",
      "validation loss: 8.278382935416671\n",
      "loss difference:\n",
      "0.0412882468625243\n",
      "epoch: 814\n",
      "training loss: 0.8288762332613198\n",
      "validation loss: 7.9501352318584715\n",
      "loss difference:\n",
      "-0.03982094088966648\n",
      "that didn't improve loss:  1\n",
      "epoch: 815\n",
      "training loss: 0.7873456233289228\n",
      "validation loss: 8.281803042847054\n",
      "loss difference:\n",
      "0.04153060993239699\n",
      "epoch: 816\n",
      "training loss: 0.8273868250069747\n",
      "validation loss: 7.953158648253944\n",
      "loss difference:\n",
      "-0.04004120167805192\n",
      "that didn't improve loss:  1\n",
      "epoch: 817\n",
      "training loss: 0.7856194723570439\n",
      "validation loss: 8.285154382128196\n",
      "loss difference:\n",
      "0.04176735264993081\n",
      "epoch: 818\n",
      "training loss: 0.8258699366772877\n",
      "validation loss: 7.956175711318483\n",
      "loss difference:\n",
      "-0.04025046432024382\n",
      "that didn't improve loss:  1\n",
      "epoch: 819\n",
      "training loss: 0.7838728281367452\n",
      "validation loss: 8.288431377555078\n",
      "loss difference:\n",
      "0.041997108540542505\n",
      "epoch: 820\n",
      "training loss: 0.8243208930374402\n",
      "validation loss: 7.959188621349943\n",
      "loss difference:\n",
      "-0.04044806490069497\n",
      "that didn't improve loss:  1\n",
      "epoch: 821\n",
      "training loss: 0.7821022750445109\n",
      "validation loss: 8.291629284429707\n",
      "loss difference:\n",
      "0.04221861799292925\n",
      "epoch: 822\n",
      "training loss: 0.8227357863195338\n",
      "validation loss: 7.962199114614355\n",
      "loss difference:\n",
      "-0.040633511275022904\n",
      "that didn't improve loss:  1\n",
      "epoch: 823\n",
      "training loss: 0.7803050397834226\n",
      "validation loss: 8.294744239552957\n",
      "loss difference:\n",
      "0.04243074653611123\n",
      "epoch: 824\n",
      "training loss: 0.8211115263759832\n",
      "validation loss: 7.965208446490627\n",
      "loss difference:\n",
      "-0.04080648659256059\n",
      "that didn't improve loss:  1\n",
      "epoch: 825\n",
      "training loss: 0.7784790251097352\n",
      "validation loss: 8.297773295672785\n",
      "loss difference:\n",
      "0.04263250126624796\n",
      "epoch: 826\n",
      "training loss: 0.8194458744041639\n",
      "validation loss: 7.968217383112544\n",
      "loss difference:\n",
      "-0.04096684929442873\n",
      "that didn't improve loss:  1\n",
      "epoch: 827\n",
      "training loss: 0.776622829450589\n",
      "validation loss: 8.300714438936671\n",
      "loss difference:\n",
      "0.04282304495357492\n",
      "epoch: 828\n",
      "training loss: 0.8177374591484982\n",
      "validation loss: 7.971226201587265\n",
      "loss difference:\n",
      "-0.04111462969790913\n",
      "that didn't improve loss:  1\n",
      "epoch: 829\n",
      "training loss: 0.7747357517409185\n",
      "validation loss: 8.303566588928813\n",
      "loss difference:\n",
      "0.04300170740757969\n",
      "epoch: 830\n",
      "training loss: 0.8159857751315802\n",
      "validation loss: 7.97423469863121\n",
      "loss difference:\n",
      "-0.04125002339066175\n",
      "that didn't improve loss:  1\n",
      "epoch: 831\n",
      "training loss: 0.7728177813808785\n",
      "validation loss: 8.30632958143431\n",
      "loss difference:\n",
      "0.04316799375070168\n",
      "epoch: 832\n",
      "training loss: 0.8141911631360309\n",
      "validation loss: 7.977242207233714\n",
      "loss difference:\n",
      "-0.04137338175515237\n",
      "that didn't improve loss:  1\n",
      "epoch: 833\n",
      "training loss: 0.7708695737920174\n",
      "validation loss: 8.30900413463006\n",
      "loss difference:\n",
      "0.043321589344013534\n",
      "epoch: 834\n",
      "training loss: 0.8123547738118542\n",
      "validation loss: 7.980247620747177\n",
      "loss difference:\n",
      "-0.0414852000198368\n",
      "that didn't improve loss:  1\n",
      "epoch: 835\n",
      "training loss: 0.7688924125945336\n",
      "validation loss: 8.311591799924708\n",
      "loss difference:\n",
      "0.04346236121732061\n",
      "epoch: 836\n",
      "training loss: 0.8104785158808336\n",
      "validation loss: 7.983249423618655\n",
      "loss difference:\n",
      "-0.04158610328630008\n",
      "that didn't improve loss:  1\n",
      "epoch: 837\n",
      "training loss: 0.7668881599062009\n",
      "validation loss: 8.314094899128417\n",
      "loss difference:\n",
      "0.04359035597463279\n",
      "epoch: 838\n",
      "training loss: 0.8085649909155058\n",
      "validation loss: 7.986245727830704\n",
      "loss difference:\n",
      "-0.04167683100930497\n",
      "that didn't improve loss:  1\n",
      "epoch: 839\n",
      "training loss: 0.7648591966491632\n",
      "validation loss: 8.316516450006265\n",
      "loss difference:\n",
      "0.04370579426634258\n",
      "epoch: 840\n",
      "training loss: 0.8066174170602639\n",
      "validation loss: 7.989234314012795\n",
      "loss difference:\n",
      "-0.041758220411100666\n",
      "that didn't improve loss:  1\n",
      "epoch: 841\n",
      "training loss: 0.7628083550252388\n",
      "validation loss: 8.318860082537793\n",
      "loss difference:\n",
      "0.043809062035025104\n",
      "epoch: 842\n",
      "training loss: 0.8046395443193255\n",
      "validation loss: 7.992212676121775\n",
      "loss difference:\n",
      "-0.04183118929408669\n",
      "that didn't improve loss:  1\n",
      "epoch: 843\n",
      "training loss: 0.7607388454741179\n",
      "validation loss: 8.321129948364154\n",
      "loss difference:\n",
      "0.04390069884520764\n",
      "epoch: 844\n",
      "training loss: 0.8026355641556434\n",
      "validation loss: 7.995178068570105\n",
      "loss difference:\n",
      "-0.04189671868152556\n",
      "that didn't improve loss:  1\n",
      "epoch: 845\n",
      "training loss: 0.758654180462145\n",
      "validation loss: 8.32333062594998\n",
      "loss difference:\n",
      "0.043981383693498466\n",
      "epoch: 846\n",
      "training loss: 0.8006100161302221\n",
      "validation loss: 7.9981275547010435\n",
      "loss difference:\n",
      "-0.041955835668077146\n",
      "that didn't improve loss:  1\n",
      "epoch: 847\n",
      "training loss: 0.7565580973703501\n",
      "validation loss: 8.325467023928146\n",
      "loss difference:\n",
      "0.04405191875987202\n",
      "epoch: 848\n",
      "training loss: 0.7985676941760466\n",
      "validation loss: 8.001058055566537\n",
      "loss difference:\n",
      "-0.04200959680569649\n",
      "that didn't improve loss:  1\n",
      "epoch: 849\n",
      "training loss: 0.7544544825747425\n",
      "validation loss: 8.327544284942956\n",
      "loss difference:\n",
      "0.0441132116013041\n",
      "epoch: 850\n",
      "training loss: 0.7965135548647106\n",
      "validation loss: 8.003966398049341\n",
      "loss difference:\n",
      "-0.04205907228996819\n",
      "that didn't improve loss:  1\n",
      "epoch: 851\n",
      "training loss: 0.7523472985596253\n",
      "validation loss: 8.329567692078975\n",
      "loss difference:\n",
      "0.044166256305085305\n",
      "epoch: 852\n",
      "training loss: 0.7944526297107996\n",
      "validation loss: 8.0068493614798\n",
      "loss difference:\n",
      "-0.04210533115117421\n",
      "that didn't improve loss:  1\n",
      "epoch: 853\n",
      "training loss: 0.7502405155989263\n",
      "validation loss: 8.331542579677294\n",
      "loss difference:\n",
      "0.0442121141118732\n",
      "epoch: 854\n",
      "training loss: 0.7923899431957071\n",
      "validation loss: 8.009703722021266\n",
      "loss difference:\n",
      "-0.04214942759678075\n",
      "that didn't improve loss:  1\n",
      "epoch: 855\n",
      "training loss: 0.7481380492046628\n",
      "validation loss: 8.33347425002074\n",
      "loss difference:\n",
      "0.044251893991044344\n",
      "epoch: 856\n",
      "training loss: 0.7903304378042044\n",
      "validation loss: 8.012526294230758\n",
      "loss difference:\n",
      "-0.042192388599541664\n",
      "that didn't improve loss:  1\n",
      "epoch: 857\n",
      "training loss: 0.7460437041979978\n",
      "validation loss: 8.335367897032087\n",
      "loss difference:\n",
      "0.04428673360620661\n",
      "epoch: 858\n",
      "training loss: 0.7882789069777492\n",
      "validation loss: 8.015313969334462\n",
      "loss difference:\n",
      "-0.042235202779751346\n",
      "that didn't improve loss:  1\n",
      "epoch: 859\n",
      "training loss: 0.7439611259259153\n",
      "validation loss: 8.33722853779556\n",
      "loss difference:\n",
      "0.044317781051833816\n",
      "epoch: 860\n",
      "training loss: 0.7862399365183654\n",
      "validation loss: 8.018063749887911\n",
      "loss difference:\n",
      "-0.04227881059245009\n",
      "that didn't improve loss:  1\n",
      "epoch: 861\n",
      "training loss: 0.7418937588415037\n",
      "validation loss: 8.339060952394545\n",
      "loss difference:\n",
      "0.044346177676861775\n",
      "epoch: 862\n",
      "training loss: 0.7842178546415107\n",
      "validation loss: 8.020772780610713\n",
      "loss difference:\n",
      "-0.04232409580000707\n",
      "that didn't improve loss:  1\n",
      "epoch: 863\n",
      "training loss: 0.739844812399023\n",
      "validation loss: 8.340869632271732\n",
      "loss difference:\n",
      "0.044373042242487726\n",
      "epoch: 864\n",
      "training loss: 0.782216690587089\n",
      "validation loss: 8.023438375294704\n",
      "loss difference:\n",
      "-0.04237187818806598\n",
      "that didn't improve loss:  1\n",
      "epoch: 865\n",
      "training loss: 0.7378172339940365\n",
      "validation loss: 8.342658737068286\n",
      "loss difference:\n",
      "0.044399456593052444\n",
      "epoch: 866\n",
      "training loss: 0.7802401414609048\n",
      "validation loss: 8.026058039777853\n",
      "loss difference:\n",
      "-0.042422907466868276\n",
      "that didn't improve loss:  1\n",
      "epoch: 867\n",
      "training loss: 0.7358136885067539\n",
      "validation loss: 8.344432059692886\n",
      "loss difference:\n",
      "0.04442645295415093\n",
      "epoch: 868\n",
      "training loss: 0.7782915467971249\n",
      "validation loss: 8.028629491054804\n",
      "loss difference:\n",
      "-0.042477858290370984\n",
      "that didn't improve loss:  1\n",
      "epoch: 869\n",
      "training loss: 0.7338365438835973\n",
      "validation loss: 8.346192999209824\n",
      "loss difference:\n",
      "0.04445500291352755\n",
      "epoch: 870\n",
      "training loss: 0.7763738702042037\n",
      "validation loss: 8.031150672656134\n",
      "loss difference:\n",
      "-0.04253732632060636\n",
      "that didn't improve loss:  1\n",
      "epoch: 871\n",
      "training loss: 0.7318878621146853\n",
      "validation loss: 8.347944541018494\n",
      "loss difference:\n",
      "0.044486008089518414\n",
      "epoch: 872\n",
      "training loss: 0.7744896873789242\n",
      "validation loss: 8.033619766475516\n",
      "loss difference:\n",
      "-0.042601825264238946\n",
      "that didn't improve loss:  1\n",
      "epoch: 873\n",
      "training loss: 0.7299693949290643\n",
      "validation loss: 8.349689243720274\n",
      "loss difference:\n",
      "0.04452029244985989\n",
      "epoch: 874\n",
      "training loss: 0.7726411797398087\n",
      "validation loss: 8.036035201255043\n",
      "loss difference:\n",
      "-0.042671784810744406\n",
      "that didn't improve loss:  1\n",
      "epoch: 875\n",
      "training loss: 0.7280825835288521\n",
      "validation loss: 8.351429232029835\n",
      "loss difference:\n",
      "0.04455859621095659\n",
      "epoch: 876\n",
      "training loss: 0.770830132935283\n",
      "validation loss: 8.038395657958334\n",
      "loss difference:\n",
      "-0.042747549406430885\n",
      "that didn't improve loss:  1\n",
      "epoch: 877\n",
      "training loss: 0.7262285617114762\n",
      "validation loss: 8.353166195080137\n",
      "loss difference:\n",
      "0.04460157122380681\n",
      "epoch: 878\n",
      "training loss: 0.7690579395164151\n",
      "validation loss: 8.040700072268551\n",
      "loss difference:\n",
      "-0.042829377804938895\n",
      "that didn't improve loss:  1\n",
      "epoch: 879\n",
      "training loss: 0.7244081617792417\n",
      "validation loss: 8.354901389488361\n",
      "loss difference:\n",
      "0.04464977773717338\n",
      "epoch: 880\n",
      "training loss: 0.7673256051213989\n",
      "validation loss: 8.042947634447438\n",
      "loss difference:\n",
      "-0.04291744334215719\n",
      "that didn't improve loss:  1\n",
      "epoch: 881\n",
      "training loss: 0.722621922701071\n",
      "validation loss: 8.356635646587666\n",
      "loss difference:\n",
      "0.04470368242032796\n",
      "epoch: 882\n",
      "training loss: 0.765633757592074\n",
      "validation loss: 8.04513778678322\n",
      "loss difference:\n",
      "-0.04301183489100302\n",
      "that didn't improve loss:  1\n",
      "epoch: 883\n",
      "training loss: 0.7208701000664952\n",
      "validation loss: 8.358369383281632\n",
      "loss difference:\n",
      "0.04476365752557876\n",
      "epoch: 884\n",
      "training loss: 0.7639826585254847\n",
      "validation loss: 8.047270218842167\n",
      "loss difference:\n",
      "-0.043112558458989536\n",
      "that didn't improve loss:  1\n",
      "epoch: 885\n",
      "training loss: 0.719152677451821\n",
      "validation loss: 8.360102616038015\n",
      "loss difference:\n",
      "0.04482998107366376\n",
      "epoch: 886\n",
      "training loss: 0.7623722168499711\n",
      "validation loss: 8.04934486072241\n",
      "loss difference:\n",
      "-0.04321953939815015\n",
      "that didn't improve loss:  1\n",
      "epoch: 887\n",
      "training loss: 0.717469378898228\n",
      "validation loss: 8.361834977603632\n",
      "loss difference:\n",
      "0.0449028379517431\n",
      "epoch: 888\n",
      "training loss: 0.760802004100936\n",
      "validation loss: 8.051361874491182\n",
      "loss difference:\n",
      "-0.043332625202707975\n",
      "that didn't improve loss:  1\n",
      "epoch: 889\n",
      "training loss: 0.7158196822779702\n",
      "validation loss: 8.36356573608578\n",
      "loss difference:\n",
      "0.0449823218229658\n",
      "epoch: 890\n",
      "training loss: 0.7592712711523105\n",
      "validation loss: 8.0533216439691\n",
      "loss difference:\n",
      "-0.04345158887434031\n",
      "that didn't improve loss:  1\n",
      "epoch: 891\n",
      "training loss: 0.7142028333948307\n",
      "validation loss: 8.36529381610679\n",
      "loss difference:\n",
      "0.04506843775747982\n",
      "epoch: 892\n",
      "training loss: 0.7577789662325599\n",
      "validation loss: 8.055224763009186\n",
      "loss difference:\n",
      "-0.04357613283772921\n",
      "that didn't improve loss:  1\n",
      "epoch: 893\n",
      "training loss: 0.7126178607263616\n",
      "validation loss: 8.367017821792796\n",
      "loss difference:\n",
      "0.04516110550619834\n",
      "epoch: 894\n",
      "training loss: 0.7563237541167199\n",
      "validation loss: 8.057072022404629\n",
      "loss difference:\n",
      "-0.04370589339035835\n",
      "that didn't improve loss:  1\n",
      "epoch: 895\n",
      "training loss: 0.7110635907666607\n",
      "validation loss: 8.36873606140387\n",
      "loss difference:\n",
      "0.045260163350059224\n",
      "epoch: 896\n",
      "training loss: 0.7549040364364478\n",
      "validation loss: 8.058864395548712\n",
      "loss difference:\n",
      "-0.043840445669787065\n",
      "that didn't improve loss:  1\n",
      "epoch: 897\n",
      "training loss: 0.7095386639683111\n",
      "validation loss: 8.370446573449605\n",
      "loss difference:\n",
      "0.045365372468136655\n",
      "epoch: 898\n",
      "training loss: 0.7535179730875327\n",
      "validation loss: 8.060603022963358\n",
      "loss difference:\n",
      "-0.043979309119221544\n",
      "that didn't improve loss:  1\n",
      "epoch: 899\n",
      "training loss: 0.7080415513102695\n",
      "validation loss: 8.372147154159915\n",
      "loss difference:\n",
      "0.04547642177726319\n",
      "epoch: 900\n",
      "training loss: 0.7521635047379498\n",
      "validation loss: 8.062289195809665\n",
      "loss difference:\n",
      "-0.04412195342768033\n",
      "that didn't improve loss:  1\n",
      "epoch: 901\n",
      "training loss: 0.7065705715343903\n",
      "validation loss: 8.37383538619559\n",
      "loss difference:\n",
      "0.045592933203559505\n",
      "epoch: 902\n",
      "training loss: 0.7508383764495271\n",
      "validation loss: 8.063924338494568\n",
      "loss difference:\n",
      "-0.04426780491513682\n",
      "that didn't improve loss:  1\n",
      "epoch: 903\n",
      "training loss: 0.7051239090975213\n",
      "validation loss: 8.375508668487793\n",
      "loss difference:\n",
      "0.045714467352005794\n",
      "epoch: 904\n",
      "training loss: 0.7495401624226488\n",
      "validation loss: 8.065509990492082\n",
      "loss difference:\n",
      "-0.04441625332512744\n",
      "that didn't improve loss:  1\n",
      "epoch: 905\n",
      "training loss: 0.7036996328787457\n",
      "validation loss: 8.37716424708868\n",
      "loss difference:\n",
      "0.04584052954390305\n",
      "epoch: 906\n",
      "training loss: 0.7482662918574773\n",
      "validation loss: 8.067047787505624\n",
      "loss difference:\n",
      "-0.04456665897873158\n",
      "that didn't improve loss:  1\n",
      "epoch: 907\n",
      "training loss: 0.7022957156638064\n",
      "validation loss: 8.378799246900469\n",
      "loss difference:\n",
      "0.04597057619367084\n",
      "epoch: 908\n",
      "training loss: 0.7470140758975521\n",
      "validation loss: 8.068539442107923\n",
      "loss difference:\n",
      "-0.044718360233745647\n",
      "that didn't improve loss:  1\n",
      "epoch: 909\n",
      "training loss: 0.7009100544017208\n",
      "validation loss: 8.380410704126259\n",
      "loss difference:\n",
      "0.04610402149583126\n",
      "epoch: 910\n",
      "training loss: 0.7457807355845624\n",
      "validation loss: 8.069986724007743\n",
      "loss difference:\n",
      "-0.04487068118284154\n",
      "that didn't improve loss:  1\n",
      "epoch: 911\n",
      "training loss: 0.6995404911939374\n",
      "validation loss: 8.38199559925639\n",
      "loss difference:\n",
      "0.04624024439062502\n",
      "epoch: 912\n",
      "training loss: 0.7445634307080624\n",
      "validation loss: 8.0713914401062\n",
      "loss difference:\n",
      "-0.04502293951412506\n",
      "that didn't improve loss:  1\n",
      "epoch: 913\n",
      "training loss: 0.6981848349357134\n",
      "validation loss: 8.383550890369797\n",
      "loss difference:\n",
      "0.04637859577234904\n",
      "epoch: 914\n",
      "training loss: 0.7433592893836903\n",
      "validation loss: 8.07275541451894\n",
      "loss difference:\n",
      "-0.045174454447976964\n",
      "that didn't improve loss:  1\n",
      "epoch: 915\n",
      "training loss: 0.6968408834848995\n",
      "validation loss: 8.385073546493484\n",
      "loss difference:\n",
      "0.04651840589879086\n",
      "epoch: 916\n",
      "training loss: 0.742165438140206\n",
      "validation loss: 8.074080468753788\n",
      "loss difference:\n",
      "-0.04532455465530649\n",
      "that didn't improve loss:  1\n",
      "epoch: 917\n",
      "training loss: 0.6955064461871623\n",
      "validation loss: 8.38656058072701\n",
      "loss difference:\n",
      "0.04665899195304368\n",
      "epoch: 918\n",
      "training loss: 0.7409790322427925\n",
      "validation loss: 8.075368402244289\n",
      "loss difference:\n",
      "-0.045472586055630204\n",
      "that didn't improve loss:  1\n",
      "epoch: 919\n",
      "training loss: 0.6941793665414182\n",
      "validation loss: 8.388009082805164\n",
      "loss difference:\n",
      "0.04679966570137428\n",
      "epoch: 920\n",
      "training loss: 0.7397972859297686\n",
      "validation loss: 8.076620973448355\n",
      "loss difference:\n",
      "-0.04561791938835036\n",
      "that didn't improve loss:  1\n",
      "epoch: 921\n",
      "training loss: 0.692857544747162\n",
      "validation loss: 8.389416250743016\n",
      "loss difference:\n",
      "0.046939741182606576\n",
      "epoch: 922\n",
      "training loss: 0.738617502195663\n",
      "validation loss: 8.077839881725945\n",
      "loss difference:\n",
      "-0.04575995744850103\n",
      "that didn't improve loss:  1\n",
      "epoch: 923\n",
      "training loss: 0.6915389598391409\n",
      "validation loss: 8.39077942118556\n",
      "loss difference:\n",
      "0.04707854235652209\n",
      "epoch: 924\n",
      "training loss: 0.7374371017178857\n",
      "validation loss: 8.079026750210312\n",
      "loss difference:\n",
      "-0.04589814187874475\n",
      "that didn't improve loss:  1\n",
      "epoch: 925\n",
      "training loss: 0.6902216910864292\n",
      "validation loss: 8.392096098071251\n",
      "loss difference:\n",
      "0.04721541063145651\n",
      "epoch: 926\n",
      "training loss: 0.7362536504995401\n",
      "validation loss: 8.080183109883082\n",
      "loss difference:\n",
      "-0.04603195941311089\n",
      "that didn't improve loss:  1\n",
      "epoch: 927\n",
      "training loss: 0.6889039383145857\n",
      "validation loss: 8.393363979216149\n",
      "loss difference:\n",
      "0.04734971218495432\n",
      "epoch: 928\n",
      "training loss: 0.7350648857894084\n",
      "validation loss: 8.081310385053914\n",
      "loss difference:\n",
      "-0.04616094747482269\n",
      "that didn't improve loss:  1\n",
      "epoch: 929\n",
      "training loss: 0.6875840408025896\n",
      "validation loss: 8.394580980434567\n",
      "loss difference:\n",
      "0.047480844986818815\n",
      "epoch: 930\n",
      "training loss: 0.7338687398429746\n",
      "validation loss: 8.0824098804306\n",
      "loss difference:\n",
      "-0.04628469904038501\n",
      "that didn't improve loss:  1\n",
      "epoch: 931\n",
      "training loss: 0.6862604944118694\n",
      "validation loss: 8.39574525683351\n",
      "loss difference:\n",
      "0.0476082454311052\n",
      "epoch: 932\n",
      "training loss: 0.7326633611066934\n",
      "validation loss: 8.083482769945318\n",
      "loss difference:\n",
      "-0.04640286669482396\n",
      "that didn't improve loss:  1\n",
      "epoch: 933\n",
      "training loss: 0.6849319666232422\n",
      "validation loss: 8.396855220951837\n",
      "loss difference:\n",
      "0.047731394483451206\n",
      "epoch: 934\n",
      "training loss: 0.7314471324414088\n",
      "validation loss: 8.084530087477715\n",
      "loss difference:\n",
      "-0.046515165818166615\n",
      "that didn't improve loss:  1\n",
      "epoch: 935\n",
      "training loss: 0.6835973091888857\n",
      "validation loss: 8.397909557460782\n",
      "loss difference:\n",
      "0.04784982325252307\n",
      "epoch: 936\n",
      "training loss: 0.730218686049103\n",
      "validation loss: 8.085552719586358\n",
      "loss difference:\n",
      "-0.04662137686021728\n",
      "that didn't improve loss:  1\n",
      "epoch: 937\n",
      "training loss: 0.6822555681496161\n",
      "validation loss: 8.398907234197921\n",
      "loss difference:\n",
      "0.04796311789948693\n",
      "epoch: 938\n",
      "training loss: 0.7289769148287838\n",
      "validation loss: 8.08655140032698\n",
      "loss difference:\n",
      "-0.04672134667916772\n",
      "that didn't improve loss:  1\n",
      "epoch: 939\n",
      "training loss: 0.6809059910213012\n",
      "validation loss: 8.39984750937244\n",
      "loss difference:\n",
      "0.04807092380748257\n",
      "epoch: 940\n",
      "training loss: 0.7277209799599186\n",
      "validation loss: 8.087526708200855\n",
      "loss difference:\n",
      "-0.04681498893861735\n",
      "that didn't improve loss:  1\n",
      "epoch: 941\n",
      "training loss: 0.6795480310161639\n",
      "validation loss: 8.40072993485039\n",
      "loss difference:\n",
      "0.04817294894375468\n",
      "epoch: 942\n",
      "training loss: 0.7264503145927961\n",
      "validation loss: 8.088479065239524\n",
      "loss difference:\n",
      "-0.046902283576632176\n",
      "that didn't improve loss:  1\n",
      "epoch: 943\n",
      "training loss: 0.6781813482324346\n",
      "validation loss: 8.401554355505146\n",
      "loss difference:\n",
      "0.04826896636036149\n",
      "epoch: 944\n",
      "training loss: 0.7251646236112397\n",
      "validation loss: 8.089408738195115\n",
      "loss difference:\n",
      "-0.04698327537880509\n",
      "that didn't improve loss:  1\n",
      "epoch: 945\n",
      "training loss: 0.676805807816673\n",
      "validation loss: 8.402320904695534\n",
      "loss difference:\n",
      "0.04835881579456669\n",
      "epoch: 946\n",
      "training loss: 0.7238638795209931\n",
      "validation loss: 8.090315841768913\n",
      "loss difference:\n",
      "-0.04705807170432008\n",
      "that didn't improve loss:  1\n",
      "epoch: 947\n",
      "training loss: 0.6754214751739273\n",
      "validation loss: 8.403029996010362\n",
      "loss difference:\n",
      "0.048442404347065815\n",
      "epoch: 948\n",
      "training loss: 0.7225483146029748\n",
      "validation loss: 8.091200343776526\n",
      "loss difference:\n",
      "-0.047126839429047496\n",
      "that didn't improve loss:  1\n",
      "epoch: 949\n",
      "training loss: 0.6740286083690532\n",
      "validation loss: 8.403682311490257\n",
      "loss difference:\n",
      "0.048519706233921545\n",
      "epoch: 950\n",
      "training loss: 0.7212184095517161\n",
      "validation loss: 8.092062072116496\n",
      "loss difference:\n",
      "-0.047189801182662916\n",
      "that didn't improve loss:  1\n",
      "epoch: 951\n",
      "training loss: 0.6726276479250956\n",
      "validation loss: 8.4042787866037\n",
      "loss difference:\n",
      "0.04859076162662057\n",
      "epoch: 952\n",
      "training loss: 0.7198748788919207\n",
      "validation loss: 8.092900723381462\n",
      "loss difference:\n",
      "-0.04724723096682515\n",
      "that didn't improve loss:  1\n",
      "epoch: 953\n",
      "training loss: 0.671219204279422\n",
      "validation loss: 8.404820592310918\n",
      "loss difference:\n",
      "0.048655674612498645\n",
      "epoch: 954\n",
      "training loss: 0.7185186535282956\n",
      "validation loss: 8.09371587292783\n",
      "loss difference:\n",
      "-0.047299449248873526\n",
      "that didn't improve loss:  1\n",
      "epoch: 955\n",
      "training loss: 0.6698040432031848\n",
      "validation loss: 8.405309114596417\n",
      "loss difference:\n",
      "0.04871461032511082\n",
      "epoch: 956\n",
      "training loss: 0.7171508608332166\n",
      "validation loss: 8.094506986202003\n",
      "loss difference:\n",
      "-0.04734681763003179\n",
      "that didn't improve loss:  1\n",
      "epoch: 957\n",
      "training loss: 0.6683830695236119\n",
      "validation loss: 8.405745931886011\n",
      "loss difference:\n",
      "0.048767791309604624\n",
      "epoch: 958\n",
      "training loss: 0.7157728027124322\n",
      "validation loss: 8.0952734311081\n",
      "loss difference:\n",
      "-0.04738973318882023\n",
      "that didn't improve loss:  1\n",
      "epoch: 959\n",
      "training loss: 0.6669573095106246\n",
      "validation loss: 8.406132790786982\n",
      "loss difference:\n",
      "0.04881549320180756\n",
      "epoch: 960\n",
      "training loss: 0.7143859321101781\n",
      "validation loss: 8.096014491195017\n",
      "loss difference:\n",
      "-0.047428622599553494\n",
      "that didn't improve loss:  1\n",
      "epoch: 961\n",
      "training loss: 0.6655278922992073\n",
      "validation loss: 8.406471580601016\n",
      "loss difference:\n",
      "0.04885803981097081\n",
      "epoch: 962\n",
      "training loss: 0.7129918284218693\n",
      "validation loss: 8.096729379438218\n",
      "loss difference:\n",
      "-0.047463936122661976\n",
      "that didn't improve loss:  1\n",
      "epoch: 963\n",
      "training loss: 0.6640960307175345\n",
      "validation loss: 8.406764307058003\n",
      "loss difference:\n",
      "0.04889579770433472\n",
      "epoch: 964\n",
      "training loss: 0.7115921722759985\n",
      "validation loss: 8.097417252394784\n",
      "loss difference:\n",
      "-0.047496141558463933\n",
      "that didn't improve loss:  1\n",
      "epoch: 965\n",
      "training loss: 0.6626630018785169\n",
      "validation loss: 8.40701306570671\n",
      "loss difference:\n",
      "0.04892917039748157\n",
      "epoch: 966\n",
      "training loss: 0.7101887201278159\n",
      "validation loss: 8.098077224517297\n",
      "loss difference:\n",
      "-0.047525718249298965\n",
      "that didn't improve loss:  1\n",
      "epoch: 967\n",
      "training loss: 0.6612301278710102\n",
      "validation loss: 8.407220015376108\n",
      "loss difference:\n",
      "0.048958592256805655\n",
      "epoch: 968\n",
      "training loss: 0.7087832790781077\n",
      "validation loss: 8.098708382423334\n",
      "loss difference:\n",
      "-0.047553151207097466\n",
      "that didn't improve loss:  1\n",
      "epoch: 969\n",
      "training loss: 0.6597987568577519\n",
      "validation loss: 8.407387352090804\n",
      "loss difference:\n",
      "0.048984522220355764\n",
      "epoch: 970\n",
      "training loss: 0.7073776822925133\n",
      "validation loss: 8.099309798932138\n",
      "loss difference:\n",
      "-0.04757892543476139\n",
      "that didn't improve loss:  1\n",
      "epoch: 971\n",
      "training loss: 0.6583702448520549\n",
      "validation loss: 8.40751728378761\n",
      "loss difference:\n",
      "0.049007437440458435\n",
      "epoch: 972\n",
      "training loss: 0.7059737653526914\n",
      "validation loss: 8.099880546696408\n",
      "loss difference:\n",
      "-0.04760352050063654\n",
      "that didn't improve loss:  1\n",
      "epoch: 973\n",
      "training loss: 0.6569459384063132\n",
      "validation loss: 8.407612006138038\n",
      "loss difference:\n",
      "0.049027826946378195\n",
      "epoch: 974\n",
      "training loss: 0.7045733438225645\n",
      "validation loss: 8.100419711276576\n",
      "loss difference:\n",
      "-0.04762740541625132\n",
      "that didn't improve loss:  1\n",
      "epoch: 975\n",
      "training loss: 0.6555271584043494\n",
      "validation loss: 8.407673679738055\n",
      "loss difference:\n",
      "0.04904618541821515\n",
      "epoch: 976\n",
      "training loss: 0.703178192262756\n",
      "validation loss: 8.100926403524346\n",
      "loss difference:\n",
      "-0.04765103385840663\n",
      "that didn't improve loss:  1\n",
      "epoch: 977\n",
      "training loss: 0.654115185108085\n",
      "validation loss: 8.407704408879988\n",
      "loss difference:\n",
      "0.049063007154671046\n",
      "epoch: 978\n",
      "training loss: 0.7017900248763211\n",
      "validation loss: 8.101399771162836\n",
      "loss difference:\n",
      "-0.047674839768236166\n",
      "that didn't improve loss:  1\n",
      "epoch: 979\n",
      "training loss: 0.6527112445688107\n",
      "validation loss: 8.407706222077097\n",
      "loss difference:\n",
      "0.04907878030751045\n",
      "epoch: 980\n",
      "training loss: 0.7004104779207349\n",
      "validation loss: 8.101839009470782\n",
      "loss difference:\n",
      "-0.047699233351924164\n",
      "that didn't improve loss:  1\n",
      "epoch: 981\n",
      "training loss: 0.6513164964753877\n",
      "validation loss: 8.40768105446698\n",
      "loss difference:\n",
      "0.04909398144534716\n",
      "epoch: 982\n",
      "training loss: 0.6990410939759518\n",
      "validation loss: 8.102243370997769\n",
      "loss difference:\n",
      "-0.047724597500564125\n",
      "that didn't improve loss:  1\n",
      "epoch: 983\n",
      "training loss: 0.6499320234773672\n",
      "validation loss: 8.407630732180369\n",
      "loss difference:\n",
      "0.049109070498584595\n",
      "epoch: 984\n",
      "training loss: 0.6976833081176173\n",
      "validation loss: 8.102612174256002\n",
      "loss difference:\n",
      "-0.047751284640250025\n",
      "that didn't improve loss:  1\n",
      "epoch: 985\n",
      "training loss: 0.6485588219907453\n",
      "validation loss: 8.407556958723847\n",
      "loss difference:\n",
      "0.049124486126871925\n",
      "epoch: 986\n",
      "training loss: 0.6963384360087503\n",
      "validation loss: 8.102944811351193\n",
      "loss difference:\n",
      "-0.04777961401800501\n",
      "that didn't improve loss:  1\n",
      "epoch: 987\n",
      "training loss: 0.6471977944684899\n",
      "validation loss: 8.407461303392784\n",
      "loss difference:\n",
      "0.04914064154026043\n",
      "epoch: 988\n",
      "training loss: 0.6950076638929729\n",
      "validation loss: 8.103240754530516\n",
      "loss difference:\n",
      "-0.047809869424482954\n",
      "that didn't improve loss:  1\n",
      "epoch: 989\n",
      "training loss: 0.6458497430971992\n",
      "validation loss: 8.407345191702563\n",
      "loss difference:\n",
      "0.049157920795773635\n",
      "epoch: 990\n",
      "training loss: 0.6936920404476468\n",
      "validation loss: 8.103499561639646\n",
      "loss difference:\n",
      "-0.04784229735044754\n",
      "that didn't improve loss:  1\n",
      "epoch: 991\n",
      "training loss: 0.6445153648652584\n",
      "validation loss: 8.407209897802085\n",
      "loss difference:\n",
      "0.04917667558238836\n",
      "epoch: 992\n",
      "training loss: 0.6923924704361782\n",
      "validation loss: 8.103720880492567\n",
      "loss difference:\n",
      "-0.04787710557091984\n",
      "that didn't improve loss:  1\n",
      "epoch: 993\n",
      "training loss: 0.6431952479364109\n",
      "validation loss: 8.407056538814981\n",
      "loss difference:\n",
      "0.049197222499767324\n",
      "epoch: 994\n",
      "training loss: 0.6911097100848039\n",
      "validation loss: 8.103904452168418\n",
      "loss difference:\n",
      "-0.04791446214839301\n",
      "that didn't improve loss:  1\n",
      "epoch: 995\n",
      "training loss: 0.641889869255359\n",
      "validation loss: 8.406886071038755\n",
      "loss difference:\n",
      "0.04921984082944497\n",
      "epoch: 996\n",
      "training loss: 0.6898443640998948\n",
      "validation loss: 8.104050113258161\n",
      "loss difference:\n",
      "-0.047954494844535844\n",
      "that didn't improve loss:  1\n",
      "epoch: 997\n",
      "training loss: 0.6405995933084411\n",
      "validation loss: 8.406699287921297\n",
      "loss difference:\n",
      "0.04924477079145373\n",
      "epoch: 998\n",
      "training loss: 0.6885968842367315\n",
      "validation loss: 8.104157797090888\n",
      "loss difference:\n",
      "-0.047997290928290415\n",
      "that didn't improve loss:  1\n",
      "epoch: 999\n",
      "training loss: 0.639324671961824\n",
      "validation loss: 8.406496819726623\n",
      "loss difference:\n",
      "0.04927221227490752\n",
      "epoch: 1000\n",
      "training loss: 0.6873675693289538\n",
      "validation loss: 8.104227533975786\n",
      "loss difference:\n",
      "-0.048042897367129855\n",
      "that didn't improve loss:  1\n",
      "epoch: 1001\n",
      "training loss: 0.6380652453015809\n",
      "validation loss: 8.406279134796957\n",
      "loss difference:\n",
      "0.04930232402737289\n",
      "epoch: 1002\n",
      "training loss: 0.6861565666888142\n",
      "validation loss: 8.10425945049997\n",
      "loss difference:\n",
      "-0.048091321387233266\n",
      "that didn't improve loss:  1\n",
      "epoch: 1003\n",
      "training loss: 0.636821343403775\n",
      "validation loss: 8.40604654231573\n",
      "loss difference:\n",
      "0.04933522328503914\n",
      "epoch: 1004\n",
      "training loss: 0.6849638747913007\n",
      "validation loss: 8.104253767926805\n",
      "loss difference:\n",
      "-0.04814253138752567\n",
      "that didn't improve loss:  1\n",
      "epoch: 1005\n",
      "training loss: 0.6355928889675122\n",
      "validation loss: 8.405799196475346\n",
      "loss difference:\n",
      "0.049370985823788516\n",
      "epoch: 1006\n",
      "training loss: 0.6837893471592326\n",
      "validation loss: 8.104210799741752\n",
      "loss difference:\n",
      "-0.04819645819172036\n",
      "that didn't improve loss:  1\n",
      "epoch: 1007\n",
      "training loss: 0.6343797007495005\n",
      "validation loss: 8.405537101953753\n",
      "loss difference:\n",
      "0.04940964640973211\n",
      "epoch: 1008\n",
      "training loss: 0.6826326973711675\n",
      "validation loss: 8.104130948396085\n",
      "loss difference:\n",
      "-0.048252996621667044\n",
      "that didn't improve loss:  1\n",
      "epoch: 1009\n",
      "training loss: 0.6331814977441836\n",
      "validation loss: 8.405260120604893\n",
      "loss difference:\n",
      "0.049451199626983855\n",
      "epoch: 1010\n",
      "training loss: 0.6814935051184361\n",
      "validation loss: 8.10401470130052\n",
      "loss difference:\n",
      "-0.04831200737425245\n",
      "that didn't improve loss:  1\n",
      "epoch: 1011\n",
      "training loss: 0.6319979040586282\n",
      "validation loss: 8.404967979269008\n",
      "loss difference:\n",
      "0.04949560105980788\n",
      "epoch: 1012\n",
      "training loss: 0.6803712232417766\n",
      "validation loss: 8.103862626123362\n",
      "loss difference:\n",
      "-0.048373319183148356\n",
      "that didn't improve loss:  1\n",
      "epoch: 1013\n",
      "training loss: 0.6308284544357323\n",
      "validation loss: 8.404660278609542\n",
      "loss difference:\n",
      "0.049542768806044246\n",
      "epoch: 1014\n",
      "training loss: 0.6792651856808714\n",
      "validation loss: 8.10367536544957\n",
      "loss difference:\n",
      "-0.04843673124513903\n",
      "that didn't improve loss:  1\n",
      "epoch: 1015\n",
      "training loss: 0.6296726003824452\n",
      "validation loss: 8.404336502883814\n",
      "loss difference:\n",
      "0.04959258529842614\n",
      "epoch: 1016\n",
      "training loss: 0.6781746162718642\n",
      "validation loss: 8.103453630859365\n",
      "loss difference:\n",
      "-0.04850201588941894\n",
      "that didn't improve loss:  1\n",
      "epoch: 1017\n",
      "training loss: 0.6285297168614699\n",
      "validation loss: 8.4039960305538\n",
      "loss difference:\n",
      "0.049644899410394294\n",
      "epoch: 1018\n",
      "training loss: 0.6770986383279226\n",
      "validation loss: 8.103198196487526\n",
      "loss difference:\n",
      "-0.04856892146645275\n",
      "that didn't improve loss:  1\n",
      "epoch: 1019\n",
      "training loss: 0.6273991095052964\n",
      "validation loss: 8.403638145642127\n",
      "loss difference:\n",
      "0.04969952882262618\n",
      "epoch: 1020\n",
      "training loss: 0.6760362849363021\n",
      "validation loss: 8.102909892126453\n",
      "loss difference:\n",
      "-0.04863717543100565\n",
      "that didn't improve loss:  1\n",
      "epoch: 1021\n",
      "training loss: 0.6262800223099715\n",
      "validation loss: 8.403262049735842\n",
      "loss difference:\n",
      "0.049756262626330594\n",
      "epoch: 1022\n",
      "training loss: 0.674986509902052\n",
      "validation loss: 8.102589595939076\n",
      "loss difference:\n",
      "-0.048706487592080516\n",
      "that didn't improve loss:  1\n",
      "epoch: 1023\n",
      "training loss: 0.625171645763293\n",
      "validation loss: 8.402866874537352\n",
      "loss difference:\n",
      "0.04981486413875902\n",
      "epoch: 1024\n",
      "training loss: 0.6739481992635163\n",
      "validation loss: 8.102238226850003\n",
      "loss difference:\n",
      "-0.04877655350022336\n",
      "that didn't improve loss:  1\n",
      "epoch: 1025\n",
      "training loss: 0.6240731253577269\n",
      "validation loss: 8.402451694857504\n",
      "loss difference:\n",
      "0.04987507390578949\n",
      "epoch: 1026\n",
      "training loss: 0.672920183298425\n",
      "validation loss: 8.101856736686047\n",
      "loss difference:\n",
      "-0.0488470579406981\n",
      "that didn't improve loss:  1\n",
      "epoch: 1027\n",
      "training loss: 0.6229835704328964\n",
      "validation loss: 8.402015541941502\n",
      "loss difference:\n",
      "0.04993661286552853\n",
      "epoch: 1028\n",
      "training loss: 0.6719012489318089\n",
      "validation loss: 8.101446102139622\n",
      "loss difference:\n",
      "-0.04891767849891249\n",
      "that didn't improve loss:  1\n",
      "epoch: 1029\n",
      "training loss: 0.6219020632859075\n",
      "validation loss: 8.401557417012999\n",
      "loss difference:\n",
      "0.049999185645901445\n",
      "epoch: 1030\n",
      "training loss: 0.6708901524486349\n",
      "validation loss: 8.1010073166309\n",
      "loss difference:\n",
      "-0.048988089162727455\n",
      "that didn't improve loss:  1\n",
      "epoch: 1031\n",
      "training loss: 0.6208276684806419\n",
      "validation loss: 8.401076304916643\n",
      "loss difference:\n",
      "0.050062483967993066\n",
      "epoch: 1032\n",
      "training loss: 0.6698856324053587\n",
      "validation loss: 8.100541382146476\n",
      "loss difference:\n",
      "-0.04905796392471684\n",
      "that didn't improve loss:  1\n",
      "epoch: 1033\n",
      "training loss: 0.6197594422796773\n",
      "validation loss: 8.400571187734789\n",
      "loss difference:\n",
      "0.050126190125681425\n",
      "epoch: 1034\n",
      "training loss: 0.668886422625943\n",
      "validation loss: 8.10004930113346\n",
      "loss difference:\n",
      "-0.049126980346265725\n",
      "that didn't improve loss:  1\n",
      "epoch: 1035\n",
      "training loss: 0.6186964421151144\n",
      "validation loss: 8.400041058249768\n",
      "loss difference:\n",
      "0.05018998051082857\n",
      "epoch: 1036\n",
      "training loss: 0.6678912651598417\n",
      "validation loss: 8.099532068528854\n",
      "loss difference:\n",
      "-0.04919482304472722\n",
      "that didn't improve loss:  1\n",
      "epoch: 1037\n",
      "training loss: 0.6176377360077977\n",
      "validation loss: 8.399484933120181\n",
      "loss difference:\n",
      "0.05025352915204395\n",
      "epoch: 1038\n",
      "training loss: 0.6668989230725082\n",
      "validation loss: 8.098990664003756\n",
      "loss difference:\n",
      "-0.0492611870647105\n",
      "that didn't improve loss:  1\n",
      "epoch: 1039\n",
      "training loss: 0.6165824118385237\n",
      "validation loss: 8.398901865638102\n",
      "loss difference:\n",
      "0.05031651123398451\n",
      "epoch: 1040\n",
      "training loss: 0.6659081929335354\n",
      "validation loss: 8.098426044500886\n",
      "loss difference:\n",
      "-0.049325781095011734\n",
      "that didn't improve loss:  1\n",
      "epoch: 1041\n",
      "training loss: 0.6155295863703201\n",
      "validation loss: 8.398290957934009\n",
      "loss difference:\n",
      "0.050378606563215356\n",
      "epoch: 1042\n",
      "training loss: 0.6649179168642804\n",
      "validation loss: 8.097839137141907\n",
      "loss difference:\n",
      "-0.0493883304939603\n",
      "that didn't improve loss:  1\n",
      "epoch: 1043\n",
      "training loss: 0.6144784139181406\n",
      "validation loss: 8.397651372498476\n",
      "loss difference:\n",
      "0.05043950294613975\n",
      "epoch: 1044\n",
      "training loss: 0.6639269940057408\n",
      "validation loss: 8.097230832577663\n",
      "loss difference:\n",
      "-0.049448580087600225\n",
      "that didn't improve loss:  1\n",
      "epoch: 1045\n",
      "training loss: 0.6134280945614836\n",
      "validation loss: 8.396982342894006\n",
      "loss difference:\n",
      "0.05049889944425723\n",
      "epoch: 1046\n",
      "training loss: 0.6629343912693905\n",
      "validation loss: 8.096601978850236\n",
      "loss difference:\n",
      "-0.04950629670790685\n",
      "that didn't improve loss:  1\n",
      "epoch: 1047\n",
      "training loss: 0.6123778817970545\n",
      "validation loss: 8.396283183537042\n",
      "loss difference:\n",
      "0.05055650947233592\n",
      "epoch: 1048\n",
      "training loss: 0.6619391532383114\n",
      "validation loss: 8.095953375830057\n",
      "loss difference:\n",
      "-0.04956127144125688\n",
      "that didn't improve loss:  1\n",
      "epoch: 1049\n",
      "training loss: 0.6113270895325125\n",
      "validation loss: 8.395553298439383\n",
      "loss difference:\n",
      "0.05061206370579896\n",
      "epoch: 1050\n",
      "training loss: 0.6609404110938862\n",
      "validation loss: 8.095285770284626\n",
      "loss difference:\n",
      "-0.04961332156137377\n",
      "that didn't improve loss:  1\n",
      "epoch: 1051\n",
      "training loss: 0.6102750983288068\n",
      "validation loss: 8.394792188809701\n",
      "loss difference:\n",
      "0.05066531276507946\n",
      "epoch: 1052\n",
      "training loss: 0.659937390454066\n",
      "validation loss: 8.094599851627967\n",
      "loss difference:\n",
      "-0.04966229212525919\n",
      "that didn't improve loss:  1\n",
      "epoch: 1053\n",
      "training loss: 0.6092213608074967\n",
      "validation loss: 8.39399945942985\n",
      "loss difference:\n",
      "0.050716029646569294\n",
      "epoch: 1054\n",
      "training loss: 0.6589294180231516\n",
      "validation loss: 8.093896248390882\n",
      "loss difference:\n",
      "-0.049708057215654966\n",
      "that didn't improve loss:  1\n",
      "epoch: 1055\n",
      "training loss: 0.6081654061507383\n",
      "validation loss: 8.39317482373641\n",
      "loss difference:\n",
      "0.050764011872413306\n",
      "epoch: 1056\n",
      "training loss: 0.6579159269694335\n",
      "validation loss: 8.093175525443039\n",
      "loss difference:\n",
      "-0.04975052081869513\n",
      "that didn't improve loss:  1\n",
      "epoch: 1057\n",
      "training loss: 0.6071068436348482\n",
      "validation loss: 8.392318107555536\n",
      "loss difference:\n",
      "0.050809083334585226\n",
      "epoch: 1058\n",
      "training loss: 0.6568964609657901\n",
      "validation loss: 8.092438181987628\n",
      "loss difference:\n",
      "-0.04978961733094189\n",
      "that didn't improve loss:  1\n",
      "epoch: 1059\n",
      "training loss: 0.6060453651534075\n",
      "validation loss: 8.391429251458387\n",
      "loss difference:\n",
      "0.050851095812382674\n",
      "epoch: 1060\n",
      "training loss: 0.6558706768490472\n",
      "validation loss: 8.09168465033903\n",
      "loss difference:\n",
      "-0.04982531169563975\n",
      "that didn't improve loss:  1\n",
      "epoch: 1061\n",
      "training loss: 0.6049807467023526\n",
      "validation loss: 8.39050831172425\n",
      "loss difference:\n",
      "0.05088993014669463\n",
      "epoch: 1062\n",
      "training loss: 0.6548383458758095\n",
      "validation loss: 8.09091529548308\n",
      "loss difference:\n",
      "-0.04985759917345689\n",
      "that didn't improve loss:  1\n",
      "epoch: 1063\n",
      "training loss: 0.6039128488166169\n",
      "validation loss: 8.389555459918954\n",
      "loss difference:\n",
      "0.05092549705919258\n",
      "epoch: 1064\n",
      "training loss: 0.6537993535750429\n",
      "validation loss: 8.090130415409273\n",
      "loss difference:\n",
      "-0.04988650475842604\n",
      "that didn't improve loss:  1\n",
      "epoch: 1065\n",
      "training loss: 0.6028416159656647\n",
      "validation loss: 8.388570981116628\n",
      "loss difference:\n",
      "0.05095773760937827\n",
      "epoch: 1066\n",
      "training loss: 0.6527536982205442\n",
      "validation loss: 8.089330242193466\n",
      "loss difference:\n",
      "-0.04991208225487953\n",
      "that didn't improve loss:  1\n",
      "epoch: 1067\n",
      "training loss: 0.6017670749326773\n",
      "validation loss: 8.38755527081272\n",
      "loss difference:\n",
      "0.05098662328786685\n",
      "epoch: 1068\n",
      "training loss: 0.6517014879684568\n",
      "validation loss: 8.088514943800085\n",
      "loss difference:\n",
      "-0.0499344130357795\n",
      "that didn't improve loss:  1\n",
      "epoch: 1069\n",
      "training loss: 0.6006893322190754\n",
      "validation loss: 8.386508830594996\n",
      "loss difference:\n",
      "0.05101215574938145\n",
      "epoch: 1070\n",
      "training loss: 0.650642936726135\n",
      "validation loss: 8.08768462656353\n",
      "loss difference:\n",
      "-0.04995360450705966\n",
      "that didn't improve loss:  1\n",
      "epoch: 1071\n",
      "training loss: 0.5996085705317782\n",
      "validation loss: 8.385432262656545\n",
      "loss difference:\n",
      "0.05103436619435686\n",
      "epoch: 1072\n",
      "training loss: 0.649578358837852\n",
      "validation loss: 8.086839338300067\n",
      "loss difference:\n",
      "-0.04996978830607379\n",
      "that didn't improve loss:  1\n",
      "epoch: 1073\n",
      "training loss: 0.5985250444247827\n",
      "validation loss: 8.384326263250408\n",
      "loss difference:\n",
      "0.05105331441306926\n",
      "epoch: 1074\n",
      "training loss: 0.6485081626900062\n",
      "validation loss: 8.085979071994387\n",
      "loss difference:\n",
      "-0.0499831182652235\n",
      "that didn't improve loss:  1\n",
      "epoch: 1075\n",
      "training loss: 0.5974390751789379\n",
      "validation loss: 8.38319161519856\n",
      "loss difference:\n",
      "0.05106908751106831\n",
      "epoch: 1076\n",
      "training loss: 0.6474328433529288\n",
      "validation loss: 8.085103769998705\n",
      "loss difference:\n",
      "-0.04999376817399093\n",
      "that didn't improve loss:  1\n",
      "epoch: 1077\n",
      "training loss: 0.5963510450138734\n",
      "validation loss: 8.382029179578732\n",
      "loss difference:\n",
      "0.05108179833905546\n",
      "epoch: 1078\n",
      "training loss: 0.6463529743880378\n",
      "validation loss: 8.084213328677324\n",
      "loss difference:\n",
      "-0.05000192937416448\n",
      "that didn't improve loss:  1\n",
      "epoch: 1079\n",
      "training loss: 0.595261390733708\n",
      "validation loss: 8.380839886720675\n",
      "loss difference:\n",
      "0.051091583654329864\n",
      "epoch: 1080\n",
      "training loss: 0.6452691989575902\n",
      "validation loss: 8.083307603426025\n",
      "loss difference:\n",
      "-0.05000780822388218\n",
      "that didn't improve loss:  1\n",
      "epoch: 1081\n",
      "training loss: 0.5941705969134302\n",
      "validation loss: 8.379624726648867\n",
      "loss difference:\n",
      "0.051098602044159946\n",
      "epoch: 1082\n",
      "training loss: 0.6441822203796819\n",
      "validation loss: 8.082386413993236\n",
      "loss difference:\n",
      "-0.05001162346625165\n",
      "that didn't improve loss:  1\n",
      "epoch: 1083\n",
      "training loss: 0.5930791887354762\n",
      "validation loss: 8.378384739111311\n",
      "loss difference:\n",
      "0.05110303164420571\n",
      "epoch: 1084\n",
      "training loss: 0.6430927922734215\n",
      "validation loss: 8.081449550028733\n",
      "loss difference:\n",
      "-0.05001360353794537\n",
      "that didn't improve loss:  1\n",
      "epoch: 1085\n",
      "training loss: 0.5919877245863977\n",
      "validation loss: 8.377121003333993\n",
      "loss difference:\n",
      "0.05110506768702383\n",
      "epoch: 1086\n",
      "training loss: 0.6420017084384572\n",
      "validation loss: 8.080496776785985\n",
      "loss difference:\n",
      "-0.05001398385205946\n",
      "that didn't improve loss:  1\n",
      "epoch: 1087\n",
      "training loss: 0.5908967885215038\n",
      "validation loss: 8.375834627638305\n",
      "loss difference:\n",
      "0.05110491991695332\n",
      "epoch: 1088\n",
      "training loss: 0.640909792609732\n",
      "validation loss: 8.079527840905227\n",
      "loss difference:\n",
      "-0.050013004088228175\n",
      "that didn't improve loss:  1\n",
      "epoch: 1089\n",
      "training loss: 0.589806982701373\n",
      "validation loss: 8.374526739053804\n",
      "loss difference:\n",
      "0.051102809908359026\n",
      "epoch: 1090\n",
      "training loss: 0.639817888222318\n",
      "validation loss: 8.078542476206884\n",
      "loss difference:\n",
      "-0.050010905520945004\n",
      "that didn't improve loss:  1\n",
      "epoch: 1091\n",
      "training loss: 0.5887189198983721\n",
      "validation loss: 8.373198473052291\n",
      "loss difference:\n",
      "0.05109896832394589\n",
      "epoch: 1092\n",
      "training loss: 0.6387268483132972\n",
      "validation loss: 8.077540409427886\n",
      "loss difference:\n",
      "-0.050007928414925074\n",
      "that didn't improve loss:  1\n",
      "epoch: 1093\n",
      "training loss: 0.5876332161640513\n",
      "validation loss: 8.37185096352052\n",
      "loss difference:\n",
      "0.05109363214924589\n",
      "epoch: 1094\n",
      "training loss: 0.6376375256779362\n",
      "validation loss: 8.076521365837786\n",
      "loss difference:\n",
      "-0.050004309513884904\n",
      "that didn't improve loss:  1\n",
      "epoch: 1095\n",
      "training loss: 0.586550483739958\n",
      "validation loss: 8.370485333079484\n",
      "loss difference:\n",
      "0.051087041937978195\n",
      "epoch: 1096\n",
      "training loss: 0.6365507633864393\n",
      "validation loss: 8.075485074675704\n",
      "loss difference:\n",
      "-0.05000027964648135\n",
      "that didn't improve loss:  1\n",
      "epoch: 1097\n",
      "training loss: 0.5854713242852371\n",
      "validation loss: 8.369102683847363\n",
      "loss difference:\n",
      "0.05107943910120227\n",
      "epoch: 1098\n",
      "training loss: 0.6354673857556761\n",
      "validation loss: 8.074431274354755\n",
      "loss difference:\n",
      "-0.049996061470439\n",
      "that didn't improve loss:  1\n",
      "epoch: 1099\n",
      "training loss: 0.5843963224847396\n",
      "validation loss: 8.367704088731866\n",
      "loss difference:\n",
      "0.05107106327093647\n",
      "epoch: 1100\n",
      "training loss: 0.6343881898578593\n",
      "validation loss: 8.073359717385637\n",
      "loss difference:\n",
      "-0.04999186737311967\n",
      "that didn't improve loss:  1\n",
      "epoch: 1101\n",
      "training loss: 0.5833260400915583\n",
      "validation loss: 8.36629058332607\n",
      "loss difference:\n",
      "0.05106214976630097\n",
      "epoch: 1102\n",
      "training loss: 0.633313937635659\n",
      "validation loss: 8.07227017497699\n",
      "loss difference:\n",
      "-0.04998789754410071\n",
      "that didn't improve loss:  1\n",
      "epoch: 1103\n",
      "training loss: 0.5822610104481942\n",
      "validation loss: 8.364863158469975\n",
      "loss difference:\n",
      "0.05105292718746479\n",
      "epoch: 1104\n",
      "training loss: 0.6322453486807902\n",
      "validation loss: 8.071162441275854\n",
      "loss difference:\n",
      "-0.04998433823259596\n",
      "that didn't improve loss:  1\n",
      "epoch: 1105\n",
      "training loss: 0.5812017335212014\n",
      "validation loss: 8.363422753528416\n",
      "loss difference:\n",
      "0.05104361515958877\n",
      "epoch: 1106\n",
      "training loss: 0.6311830937212087\n",
      "validation loss: 8.07003633721747\n",
      "loss difference:\n",
      "-0.04998136020000732\n",
      "that didn't improve loss:  1\n",
      "epoch: 1107\n",
      "training loss: 0.580148671475242\n",
      "validation loss: 8.361970250424731\n",
      "loss difference:\n",
      "0.05103442224596677\n",
      "epoch: 1108\n",
      "training loss: 0.6301277888507438\n",
      "validation loss: 8.068891713959049\n",
      "loss difference:\n",
      "-0.04997911737550187\n",
      "that didn't improve loss:  1\n",
      "epoch: 1109\n",
      "training loss: 0.5791022448043839\n",
      "validation loss: 8.36050646845879\n",
      "loss difference:\n",
      "0.05102554404635995\n",
      "epoch: 1110\n",
      "training loss: 0.6290799905244862\n",
      "validation loss: 8.06772845587813\n",
      "loss difference:\n",
      "-0.04997774572010227\n",
      "that didn't improve loss:  1\n",
      "epoch: 1111\n",
      "training loss: 0.5780628290309637\n",
      "validation loss: 8.359032159928141\n",
      "loss difference:\n",
      "0.05101716149352242\n",
      "epoch: 1112\n",
      "training loss: 0.6280401913337438\n",
      "validation loss: 8.066546483120996\n",
      "loss difference:\n",
      "-0.04997736230278005\n",
      "that didn't improve loss:  1\n",
      "epoch: 1113\n",
      "training loss: 0.5770307519758481\n",
      "validation loss: 8.357548006561672\n",
      "loss difference:\n",
      "0.0510094393578957\n",
      "epoch: 1114\n",
      "training loss: 0.6270088165657798\n",
      "validation loss: 8.065345753692085\n",
      "loss difference:\n",
      "-0.0499780645899317\n",
      "that didn't improve loss:  1\n",
      "epoch: 1115\n",
      "training loss: 0.576006291598096\n",
      "validation loss: 8.356054616766823\n",
      "loss difference:\n",
      "0.05100252496768376\n",
      "epoch: 1116\n",
      "training loss: 0.6259862215459692\n",
      "validation loss: 8.064126265079553\n",
      "loss difference:\n",
      "-0.04997992994787315\n",
      "that didn't improve loss:  1\n",
      "epoch: 1117\n",
      "training loss: 0.5749896743971633\n",
      "validation loss: 8.354552523683603\n",
      "loss difference:\n",
      "0.05099654714880586\n",
      "epoch: 1118\n",
      "training loss: 0.6249726897534449\n",
      "validation loss: 8.062888055417295\n",
      "loss difference:\n",
      "-0.04998301535628158\n",
      "that didn't improve loss:  1\n",
      "epoch: 1119\n",
      "training loss: 0.5739810743666408\n",
      "validation loss: 8.353042184032216\n",
      "loss difference:\n",
      "0.05099161538680408\n",
      "epoch: 1120\n",
      "training loss: 0.6239684316955558\n",
      "validation loss: 8.061631204186956\n",
      "loss difference:\n",
      "-0.049987357328915016\n",
      "that didn't improve loss:  1\n",
      "epoch: 1121\n",
      "training loss: 0.5729806124850418\n",
      "validation loss: 8.351523977734763\n",
      "loss difference:\n",
      "0.050987819210513985\n",
      "epoch: 1122\n",
      "training loss: 0.6229735845216641\n",
      "validation loss: 8.060355832468161\n",
      "loss difference:\n",
      "-0.04999297203662223\n",
      "that didn't improve loss:  1\n",
      "epoch: 1123\n",
      "training loss: 0.5719883567264077\n",
      "validation loss: 8.349998208286186\n",
      "loss difference:\n",
      "0.05098522779525638\n",
      "epoch: 1124\n",
      "training loss: 0.6219882123525887\n",
      "validation loss: 8.059062102747914\n",
      "loss difference:\n",
      "-0.04999985562618103\n",
      "that didn't improve loss:  1\n",
      "epoch: 1125\n",
      "training loss: 0.5710043225710915\n",
      "validation loss: 8.348465103845182\n",
      "loss difference:\n",
      "0.05098388978149726\n",
      "epoch: 1126\n",
      "training loss: 0.6210123072984205\n",
      "validation loss: 8.057750218304012\n",
      "loss difference:\n",
      "-0.050007984727329036\n",
      "that didn't improve loss:  1\n",
      "epoch: 1127\n",
      "training loss: 0.5700284739952557\n",
      "validation loss: 8.34692481901147\n",
      "loss difference:\n",
      "0.050983833303164805\n",
      "epoch: 1128\n",
      "training loss: 0.6200457911344982\n",
      "validation loss: 8.056420422179714\n",
      "loss difference:\n",
      "-0.05001731713924251\n",
      "that didn't improve loss:  1\n",
      "epoch: 1129\n",
      "training loss: 0.569060724915955\n",
      "validation loss: 8.345377437252093\n",
      "loss difference:\n",
      "0.05098506621854315\n",
      "epoch: 1130\n",
      "training loss: 0.6190885176023668\n",
      "validation loss: 8.055072995770102\n",
      "loss difference:\n",
      "-0.050027792686411776\n",
      "that didn't improve loss:  1\n",
      "epoch: 1131\n",
      "training loss: 0.5681009410672555\n",
      "validation loss: 8.343822973936312\n",
      "loss difference:\n",
      "0.05098757653511132\n",
      "epoch: 1132\n",
      "training loss: 0.6181402753002593\n",
      "validation loss: 8.05370825704276\n",
      "loss difference:\n",
      "-0.050039334233003774\n",
      "that didn't improve loss:  1\n",
      "epoch: 1133\n",
      "training loss: 0.5671489422815479\n",
      "validation loss: 8.342261379935628\n",
      "loss difference:\n",
      "0.05099133301871139\n",
      "epoch: 1134\n",
      "training loss: 0.617200791125192\n",
      "validation loss: 8.05232655841795\n",
      "loss difference:\n",
      "-0.05005184884364411\n",
      "that didn't improve loss:  1\n",
      "epoch: 1135\n",
      "training loss: 0.5662045051488606\n",
      "validation loss: 8.34069254574271\n",
      "loss difference:\n",
      "0.050996285976331435\n",
      "epoch: 1136\n",
      "training loss: 0.6162697342264671\n",
      "validation loss: 8.050928284335434\n",
      "loss difference:\n",
      "-0.05006522907760658\n",
      "that didn't improve loss:  1\n",
      "epoch: 1137\n",
      "training loss: 0.5652673660256946\n",
      "validation loss: 8.339116306060602\n",
      "loss difference:\n",
      "0.05100236820077253\n",
      "epoch: 1138\n",
      "training loss: 0.6153467204281486\n",
      "validation loss: 8.049513848537199\n",
      "loss difference:\n",
      "-0.050079354402454035\n",
      "that didn't improve loss:  1\n",
      "epoch: 1139\n",
      "training loss: 0.564337224363397\n",
      "validation loss: 8.337532444811076\n",
      "loss difference:\n",
      "0.05100949606475169\n",
      "epoch: 1140\n",
      "training loss: 0.6144313170757297\n",
      "validation loss: 8.048083691096894\n",
      "loss difference:\n",
      "-0.05009409271233278\n",
      "that didn't improve loss:  1\n",
      "epoch: 1141\n",
      "training loss: 0.5634137463246192\n",
      "validation loss: 8.335940700509155\n",
      "loss difference:\n",
      "0.051017570751110575\n",
      "epoch: 1142\n",
      "training loss: 0.613523048259814\n",
      "validation loss: 8.04663827522881\n",
      "loss difference:\n",
      "-0.050109301935194805\n",
      "that didn't improve loss:  1\n",
      "epoch: 1143\n",
      "training loss: 0.5624965686546647\n",
      "validation loss: 8.334340771948439\n",
      "loss difference:\n",
      "0.05102647960514928\n",
      "epoch: 1144\n",
      "training loss: 0.6126214003672649\n",
      "validation loss: 8.045178083910104\n",
      "loss difference:\n",
      "-0.05012483171260018\n",
      "that didn't improve loss:  1\n",
      "epoch: 1145\n",
      "training loss: 0.5615853027728558\n",
      "validation loss: 8.332732324140252\n",
      "loss difference:\n",
      "0.05103609759440908\n",
      "epoch: 1146\n",
      "training loss: 0.611725827907781\n",
      "validation loss: 8.043703616351742\n",
      "loss difference:\n",
      "-0.050140525134925173\n",
      "that didn't improve loss:  1\n",
      "epoch: 1147\n",
      "training loss: 0.560679539047103\n",
      "validation loss: 8.331114994448003\n",
      "loss difference:\n",
      "0.05104628886067797\n",
      "epoch: 1148\n",
      "training loss: 0.6108357595615441\n",
      "validation loss: 8.042215384354174\n",
      "loss difference:\n",
      "-0.05015622051444113\n",
      "that didn't improve loss:  1\n",
      "epoch: 1149\n",
      "training loss: 0.559778851213139\n",
      "validation loss: 8.32948839885662\n",
      "loss difference:\n",
      "0.05105690834840515\n",
      "epoch: 1150\n",
      "training loss: 0.609950604391304\n",
      "validation loss: 8.040713908584873\n",
      "loss difference:\n",
      "-0.050171753178165024\n",
      "that didn't improve loss:  1\n",
      "epoch: 1151\n",
      "training loss: 0.5588828008979921\n",
      "validation loss: 8.327852138316059\n",
      "loss difference:\n",
      "0.05106780349331186\n",
      "epoch: 1152\n",
      "training loss: 0.6090697581601205\n",
      "validation loss: 8.039199714815076\n",
      "loss difference:\n",
      "-0.05018695726212841\n",
      "that didn't improve loss:  1\n",
      "epoch: 1153\n",
      "training loss: 0.5579909422056337\n",
      "validation loss: 8.326205805096931\n",
      "loss difference:\n",
      "0.05107881595448682\n",
      "epoch: 1154\n",
      "training loss: 0.6081926096943572\n",
      "validation loss: 8.037673330153414\n",
      "loss difference:\n",
      "-0.050201667488723456\n",
      "that didn't improve loss:  1\n",
      "epoch: 1155\n",
      "training loss: 0.5571028263213129\n",
      "validation loss: 8.324548989096362\n",
      "loss difference:\n",
      "0.05108978337304426\n",
      "epoch: 1156\n",
      "training loss: 0.6073185472300295\n",
      "validation loss: 8.036135279313925\n",
      "loss difference:\n",
      "-0.05021572090871662\n",
      "that didn't improve loss:  1\n",
      "epoch: 1157\n",
      "training loss: 0.5562180060898871\n",
      "validation loss: 8.322881284032013\n",
      "loss difference:\n",
      "0.0511005411401424\n",
      "epoch: 1158\n",
      "training loss: 0.6064469646798585\n",
      "validation loss: 8.03458608095552\n",
      "loss difference:\n",
      "-0.05022895858997134\n",
      "that didn't improve loss:  1\n",
      "epoch: 1159\n",
      "training loss: 0.5553360405227803\n",
      "validation loss: 8.321202293463436\n",
      "loss difference:\n",
      "0.051110924157078186\n",
      "epoch: 1160\n",
      "training loss: 0.6055772677580835\n",
      "validation loss: 8.033026244128996\n",
      "loss difference:\n",
      "-0.05024122723530322\n",
      "that didn't improve loss:  1\n",
      "epoch: 1161\n",
      "training loss: 0.5544564991878461\n",
      "validation loss: 8.31951163658122\n",
      "loss difference:\n",
      "0.051120768570237396\n",
      "epoch: 1162\n",
      "training loss: 0.604708879900637\n",
      "validation loss: 8.031456264866625\n",
      "loss difference:\n",
      "-0.05025238071279092\n",
      "that didn't improve loss:  1\n",
      "epoch: 1163\n",
      "training loss: 0.5535789664368085\n",
      "validation loss: 8.317808953706242\n",
      "loss difference:\n",
      "0.05112991346382856\n",
      "epoch: 1164\n",
      "training loss: 0.6038412479194378\n",
      "validation loss: 8.029876622947631\n",
      "loss difference:\n",
      "-0.050262281482629345\n",
      "that didn't improve loss:  1\n",
      "epoch: 1165\n",
      "training loss: 0.55270304542575\n",
      "validation loss: 8.316093911444753\n",
      "loss difference:\n",
      "0.051138202493687834\n",
      "epoch: 1166\n",
      "training loss: 0.6029738473317902\n",
      "validation loss: 8.028287778870883\n",
      "loss difference:\n",
      "-0.05027080190604016\n",
      "that didn't improve loss:  1\n",
      "epoch: 1167\n",
      "training loss: 0.551828361885792\n",
      "validation loss: 8.314366207447966\n",
      "loss difference:\n",
      "0.05114548544599817\n",
      "epoch: 1168\n",
      "training loss: 0.6021061873087652\n",
      "validation loss: 8.026690171063743\n",
      "loss difference:\n",
      "-0.05027782542297321\n",
      "that didn't improve loss:  1\n",
      "epoch: 1169\n",
      "training loss: 0.5509545676033408\n",
      "validation loss: 8.312625574729559\n",
      "loss difference:\n",
      "0.05115161970542437\n",
      "epoch: 1170\n",
      "training loss: 0.6012378151904109\n",
      "validation loss: 8.025084213353297\n",
      "loss difference:\n",
      "-0.050283247587070035\n",
      "that didn't improve loss:  1\n",
      "epoch: 1171\n",
      "training loss: 0.5500813435722722\n",
      "validation loss: 8.310871785499131\n",
      "loss difference:\n",
      "0.05115647161813863\n",
      "epoch: 1172\n",
      "training loss: 0.6003683205203245\n",
      "validation loss: 8.023470292722996\n",
      "loss difference:\n",
      "-0.05028697694805229\n",
      "that didn't improve loss:  1\n",
      "epoch: 1173\n",
      "training loss: 0.5492084027840783\n",
      "validation loss: 8.309104654475494\n",
      "loss difference:\n",
      "0.051159917736246174\n",
      "epoch: 1174\n",
      "training loss: 0.5994973385578222\n",
      "validation loss: 8.021848767374541\n",
      "loss difference:\n",
      "-0.050288935773743826\n",
      "that didn't improve loss:  1\n",
      "epoch: 1175\n",
      "training loss: 0.5483354926263676\n",
      "validation loss: 8.307324041649895\n",
      "loss difference:\n",
      "0.051161845931454564\n",
      "epoch: 1176\n",
      "training loss: 0.5986245532322535\n",
      "validation loss: 8.020219965110957\n",
      "loss difference:\n",
      "-0.050289060605885894\n",
      "that didn't improve loss:  1\n",
      "epoch: 1177\n",
      "training loss: 0.5474623968649605\n",
      "validation loss: 8.305529854475704\n",
      "loss difference:\n",
      "0.051162156367293044\n",
      "epoch: 1178\n",
      "training loss: 0.5977496995110744\n",
      "validation loss: 8.018584182053115\n",
      "loss difference:\n",
      "-0.05028730264611392\n",
      "that didn't improve loss:  1\n",
      "epoch: 1179\n",
      "training loss: 0.5465889371902644\n",
      "validation loss: 8.303722049468561\n",
      "loss difference:\n",
      "0.051160762320810016\n",
      "epoch: 1180\n",
      "training loss: 0.5968725651609176\n",
      "validation loss: 8.016941681697807\n",
      "loss difference:\n",
      "-0.05028362797065322\n",
      "that didn't improve loss:  1\n",
      "epoch: 1181\n",
      "training loss: 0.545714974314422\n",
      "validation loss: 8.301900633208\n",
      "loss difference:\n",
      "0.051157590846495626\n",
      "epoch: 1182\n",
      "training loss: 0.5959929918888797\n",
      "validation loss: 8.015292694321568\n",
      "loss difference:\n",
      "-0.05027801757445771\n",
      "that didn't improve loss:  1\n",
      "epoch: 1183\n",
      "training loss: 0.5448404086118204\n",
      "validation loss: 8.300065662739511\n",
      "loss difference:\n",
      "0.051152583277059294\n",
      "epoch: 1184\n",
      "training loss: 0.5951108758594797\n",
      "validation loss: 8.013637416730036\n",
      "loss difference:\n",
      "-0.05027046724765938\n",
      "that didn't improve loss:  1\n",
      "epoch: 1185\n",
      "training loss: 0.5439651803017853\n",
      "validation loss: 8.298217245382993\n",
      "loss difference:\n",
      "0.05114569555769444\n",
      "epoch: 1186\n",
      "training loss: 0.5942261675911507\n",
      "validation loss: 8.011976012348816\n",
      "loss difference:\n",
      "-0.050260987289365344\n",
      "that didn't improve loss:  1\n",
      "epoch: 1187\n",
      "training loss: 0.5430892691786071\n",
      "validation loss: 8.296355537961679\n",
      "loss difference:\n",
      "0.05113689841254354\n",
      "epoch: 1188\n",
      "training loss: 0.5933388712443275\n",
      "validation loss: 8.010308611647611\n",
      "loss difference:\n",
      "-0.05024960206572038\n",
      "that didn't improve loss:  1\n",
      "epoch: 1189\n",
      "training loss: 0.5422126939001688\n",
      "validation loss: 8.294480745471908\n",
      "loss difference:\n",
      "0.051126177344158696\n",
      "epoch: 1190\n",
      "training loss: 0.5924490433212054\n",
      "validation loss: 8.008635312885687\n",
      "loss difference:\n",
      "-0.05023634942103661\n",
      "that didn't improve loss:  1\n",
      "epoch: 1191\n",
      "training loss: 0.5413355108523805\n",
      "validation loss: 8.292593119221815\n",
      "loss difference:\n",
      "0.051113532468824885\n",
      "epoch: 1192\n",
      "training loss: 0.591556790804825\n",
      "validation loss: 8.006956183163199\n",
      "loss difference:\n",
      "-0.05022127995244452\n",
      "that didn't improve loss:  1\n",
      "epoch: 1193\n",
      "training loss: 0.5404578126122094\n",
      "validation loss: 8.290692954472522\n",
      "loss difference:\n",
      "0.05109897819261566\n",
      "epoch: 1194\n",
      "training loss: 0.5906622687721662\n",
      "validation loss: 8.00527125975948\n",
      "loss difference:\n",
      "-0.050204456159956834\n",
      "that didn't improve loss:  1\n",
      "epoch: 1195\n",
      "training loss: 0.5395797260370826\n",
      "validation loss: 8.28878058762139\n",
      "loss difference:\n",
      "0.051082542735083614\n",
      "epoch: 1196\n",
      "training loss: 0.5897656775221943\n",
      "validation loss: 8.003580551736393\n",
      "loss difference:\n",
      "-0.050185951485111735\n",
      "that didn't improve loss:  1\n",
      "epoch: 1197\n",
      "training loss: 0.5387014100130476\n",
      "validation loss: 8.286856392971801\n",
      "loss difference:\n",
      "0.05106426750914672\n",
      "epoch: 1198\n",
      "training loss: 0.5888672592653702\n",
      "validation loss: 8.001884041782523\n",
      "loss difference:\n",
      "-0.05016584925232259\n",
      "that didn't improve loss:  1\n",
      "epoch: 1199\n",
      "training loss: 0.5378230528977586\n",
      "validation loss: 8.284920779137998\n",
      "loss difference:\n",
      "0.051044206367611644\n",
      "epoch: 1200\n",
      "training loss: 0.5879672944256373\n",
      "validation loss: 8.00018168827151\n",
      "loss difference:\n",
      "-0.050144241527878775\n",
      "that didn't improve loss:  1\n",
      "epoch: 1201\n",
      "training loss: 0.5369448696976233\n",
      "validation loss: 8.282974185136773\n",
      "loss difference:\n",
      "0.05102242472801399\n",
      "epoch: 1202\n",
      "training loss: 0.5870660976096488\n",
      "validation loss: 7.99847342750609\n",
      "loss difference:\n",
      "-0.050121227912025446\n",
      "that didn't improve loss:  1\n",
      "epoch: 1203\n",
      "training loss: 0.5360670990206596\n",
      "validation loss: 8.281017076220351\n",
      "loss difference:\n",
      "0.05099899858898915\n",
      "epoch: 1204\n",
      "training loss: 0.5861640133005273\n",
      "validation loss: 7.996759176118264\n",
      "loss difference:\n",
      "-0.05009691427986762\n",
      "that didn't improve loss:  1\n",
      "epoch: 1205\n",
      "training loss: 0.5351899998482892\n",
      "validation loss: 8.279049939506239\n",
      "loss difference:\n",
      "0.050974013452238065\n",
      "epoch: 1206\n",
      "training loss: 0.5852614113351527\n",
      "validation loss: 7.995038833595017\n",
      "loss difference:\n",
      "-0.05007141148686356\n",
      "that didn't improve loss:  1\n",
      "epoch: 1207\n",
      "training loss: 0.5343138481700944\n",
      "validation loss: 8.27707327946052\n",
      "loss difference:\n",
      "0.05094756316505833\n",
      "epoch: 1208\n",
      "training loss: 0.5843586822246892\n",
      "validation loss: 7.993312284898282\n",
      "loss difference:\n",
      "-0.05004483405459481\n",
      "that didn't improve loss:  1\n",
      "epoch: 1209\n",
      "training loss: 0.5334389335256249\n",
      "validation loss: 8.275087613291092\n",
      "loss difference:\n",
      "0.05091974869906435\n",
      "epoch: 1210\n",
      "training loss: 0.5834562323776191\n",
      "validation loss: 7.991579403148417\n",
      "loss difference:\n",
      "-0.05001729885199424\n",
      "that didn't improve loss:  1\n",
      "epoch: 1211\n",
      "training loss: 0.5325655554967553\n",
      "validation loss: 8.273093466305935\n",
      "loss difference:\n",
      "0.050890676880863794\n",
      "epoch: 1212\n",
      "training loss: 0.5825544792836116\n",
      "validation loss: 7.989840052340163\n",
      "loss difference:\n",
      "-0.049988923786856265\n",
      "that didn't improve loss:  1\n",
      "epoch: 1213\n",
      "training loss: 0.5316940201928592\n",
      "validation loss: 8.271091367290575\n",
      "loss difference:\n",
      "0.05086045909075243\n",
      "epoch: 1214\n",
      "training loss: 0.5816538467144455\n",
      "validation loss: 7.988094090061189\n",
      "loss difference:\n",
      "-0.04995982652158637\n",
      "that didn't improve loss:  1\n",
      "epoch: 1215\n",
      "training loss: 0.530824636769211\n",
      "validation loss: 8.26908184395571\n",
      "loss difference:\n",
      "0.050829209945234544\n",
      "epoch: 1216\n",
      "training loss: 0.5807547599956381\n",
      "validation loss: 7.986341370184213\n",
      "loss difference:\n",
      "-0.04993012322642709\n",
      "that didn't improve loss:  1\n",
      "epoch: 1217\n",
      "training loss: 0.5299577140167897\n",
      "validation loss: 8.267065418503886\n",
      "loss difference:\n",
      "0.050797045978848376\n",
      "epoch: 1218\n",
      "training loss: 0.5798576413991607\n",
      "validation loss: 7.984581745505215\n",
      "loss difference:\n",
      "-0.049899927382371034\n",
      "that didn't improve loss:  1\n",
      "epoch: 1219\n",
      "training loss: 0.5290935570588974\n",
      "validation loss: 8.265042603360135\n",
      "loss difference:\n",
      "0.05076408434026336\n",
      "epoch: 1220\n",
      "training loss: 0.5789629057038622\n",
      "validation loss: 7.9828150703016005\n",
      "loss difference:\n",
      "-0.04986934864496484\n",
      "that didn't improve loss:  1\n",
      "epoch: 1221\n",
      "training loss: 0.5282324641870109\n",
      "validation loss: 8.263013897108065\n",
      "loss difference:\n",
      "0.050730441516851354\n",
      "epoch: 1222\n",
      "training loss: 0.578070955966135\n",
      "validation loss: 7.981041202786371\n",
      "loss difference:\n",
      "-0.04983849177912414\n",
      "that didn't improve loss:  1\n",
      "epoch: 1223\n",
      "training loss: 0.5273747238650682\n",
      "validation loss: 8.260979780668599\n",
      "loss difference:\n",
      "0.050696232101066774\n",
      "epoch: 1224\n",
      "training loss: 0.5771821795388894\n",
      "validation loss: 7.979260007436115\n",
      "loss difference:\n",
      "-0.049807455673821166\n",
      "that didn't improve loss:  1\n",
      "epoch: 1225\n",
      "training loss: 0.5265206119279143\n",
      "validation loss: 8.258940713754544\n",
      "loss difference:\n",
      "0.05066156761097507\n",
      "epoch: 1226\n",
      "training loss: 0.5762969443723615\n",
      "validation loss: 7.977471357172973\n",
      "loss difference:\n",
      "-0.049776332444447124\n",
      "that didn't improve loss:  1\n",
      "epoch: 1227\n",
      "training loss: 0.525670388996216\n",
      "validation loss: 8.25689713162934\n",
      "loss difference:\n",
      "0.050626555376145466\n",
      "epoch: 1228\n",
      "training loss: 0.5754155956255829\n",
      "validation loss: 7.975675135382881\n",
      "loss difference:\n",
      "-0.04974520662936688\n",
      "that didn't improve loss:  1\n",
      "epoch: 1229\n",
      "training loss: 0.5248242981266468\n",
      "validation loss: 8.254849442194342\n",
      "loss difference:\n",
      "0.050591297498936094\n",
      "epoch: 1230\n",
      "training loss: 0.5745384526126177\n",
      "validation loss: 7.973871237754927\n",
      "loss difference:\n",
      "-0.04971415448597094\n",
      "that didn't improve loss:  1\n",
      "epoch: 1231\n",
      "training loss: 0.523982562712678\n",
      "validation loss: 8.252798023423978\n",
      "loss difference:\n",
      "0.050555889899939754\n",
      "epoch: 1232\n",
      "training loss: 0.573665806103131\n",
      "validation loss: 7.972059573928848\n",
      "loss difference:\n",
      "-0.04968324339045305\n",
      "that didn't improve loss:  1\n",
      "epoch: 1233\n",
      "training loss: 0.5231453846480197\n",
      "validation loss: 8.250743221164285\n",
      "loss difference:\n",
      "0.050520421455111264\n",
      "epoch: 1234\n",
      "training loss: 0.5727979159922514\n",
      "validation loss: 7.970240068940243\n",
      "loss difference:\n",
      "-0.04965253134423164\n",
      "that didn't improve loss:  1\n",
      "epoch: 1235\n",
      "training loss: 0.5223129427615004\n",
      "validation loss: 8.248685347305527\n",
      "loss difference:\n",
      "0.05048497323075096\n",
      "epoch: 1236\n",
      "training loss: 0.5719350093504691\n",
      "validation loss: 7.96841266445537\n",
      "loss difference:\n",
      "-0.04962206658896873\n",
      "that didn't improve loss:  1\n",
      "epoch: 1237\n",
      "training loss: 0.5214853915291664\n",
      "validation loss: 8.246624678335657\n",
      "loss difference:\n",
      "0.05044961782130275\n",
      "epoch: 1238\n",
      "training loss: 0.5710772788600751\n",
      "validation loss: 7.966577319789779\n",
      "loss difference:\n",
      "-0.04959188733090869\n",
      "that didn't improve loss:  1\n",
      "epoch: 1239\n",
      "training loss: 0.5206628600665205\n",
      "validation loss: 8.24456145427762\n",
      "loss difference:\n",
      "0.05041441879355457\n",
      "epoch: 1240\n",
      "training loss: 0.5702248816408575\n",
      "validation loss: 7.96473401270737\n",
      "loss difference:\n",
      "-0.04956202157433698\n",
      "that didn't improve loss:  1\n",
      "epoch: 1241\n",
      "training loss: 0.5198454514011149\n",
      "validation loss: 8.242495878009315\n",
      "loss difference:\n",
      "0.05037943023974256\n",
      "epoch: 1242\n",
      "training loss: 0.5693779384640143\n",
      "validation loss: 7.962882739998532\n",
      "loss difference:\n",
      "-0.049532487062899366\n",
      "that didn't improve loss:  1\n",
      "epoch: 1243\n",
      "training loss: 0.5190332420233105\n",
      "validation loss: 8.240428114961846\n",
      "loss difference:\n",
      "0.05034469644070383\n",
      "epoch: 1244\n",
      "training loss: 0.5685365333499246\n",
      "validation loss: 7.961023517838301\n",
      "loss difference:\n",
      "-0.04950329132661413\n",
      "that didn't improve loss:  1\n",
      "epoch: 1245\n",
      "training loss: 0.518226281710672\n",
      "validation loss: 8.2383582931883\n",
      "loss difference:\n",
      "0.05031025163925262\n",
      "epoch: 1246\n",
      "training loss: 0.567700713542157\n",
      "validation loss: 7.9591563819274915\n",
      "loss difference:\n",
      "-0.04947443183148503\n",
      "that didn't improve loss:  1\n",
      "epoch: 1247\n",
      "training loss: 0.5174245936194184\n",
      "validation loss: 8.236286503792089\n",
      "loss difference:\n",
      "0.050276119922738616\n",
      "epoch: 1248\n",
      "training loss: 0.5668704898472627\n",
      "validation loss: 7.957281387421403\n",
      "loss difference:\n",
      "-0.049445896227844344\n",
      "that didn't improve loss:  1\n",
      "epoch: 1249\n",
      "training loss: 0.5166281746343905\n",
      "validation loss: 8.23421280170128\n",
      "loss difference:\n",
      "0.05024231521287226\n",
      "epoch: 1250\n",
      "training loss: 0.566045837327101\n",
      "validation loss: 7.955398608653172\n",
      "loss difference:\n",
      "-0.04941766269271053\n",
      "that didn't improve loss:  1\n",
      "epoch: 1251\n",
      "training loss: 0.5158369959672524\n",
      "validation loss: 8.232137206772425\n",
      "loss difference:\n",
      "0.0502088413598486\n",
      "epoch: 1252\n",
      "training loss: 0.5652266963280125\n",
      "validation loss: 7.953508138659652\n",
      "loss difference:\n",
      "-0.04938970036076007\n",
      "that didn't improve loss:  1\n",
      "epoch: 1253\n",
      "training loss: 0.5150510039910128\n",
      "validation loss: 8.230059705205395\n",
      "loss difference:\n",
      "0.0501756923369997\n",
      "epoch: 1254\n",
      "training loss: 0.564412973828826\n",
      "validation loss: 7.951610088520165\n",
      "loss difference:\n",
      "-0.04936196983781327\n",
      "that didn't improve loss:  1\n",
      "epoch: 1255\n",
      "training loss: 0.5142701212974384\n",
      "validation loss: 8.22798025124816\n",
      "loss difference:\n",
      "0.050142852531387616\n",
      "epoch: 1256\n",
      "training loss: 0.5636045450875666\n",
      "validation loss: 7.949704586519308\n",
      "loss difference:\n",
      "-0.0493344237901282\n",
      "that didn't improve loss:  1\n",
      "epoch: 1257\n",
      "training loss: 0.5134942479625615\n",
      "validation loss: 8.225898769168788\n",
      "loss difference:\n",
      "0.05011029712500514\n",
      "epoch: 1258\n",
      "training loss: 0.5628012555648033\n",
      "validation loss: 7.947791777146564\n",
      "loss difference:\n",
      "-0.049307007602241826\n",
      "that didn't improve loss:  1\n",
      "epoch: 1259\n",
      "training loss: 0.5127232630042102\n",
      "validation loss: 8.223815155470007\n",
      "loss difference:\n",
      "0.05007799256059309\n",
      "epoch: 1260\n",
      "training loss: 0.5620029230997738\n",
      "validation loss: 7.945871819946822\n",
      "loss difference:\n",
      "-0.049279660095563615\n",
      "that didn't improve loss:  1\n",
      "epoch: 1261\n",
      "training loss: 0.5119570260142864\n",
      "validation loss: 8.2217292813202\n",
      "loss difference:\n",
      "0.050045897085487456\n",
      "epoch: 1262\n",
      "training loss: 0.5612093403138616\n",
      "validation loss: 7.9439448882366746\n",
      "loss difference:\n",
      "-0.04925231429957522\n",
      "that didn't improve loss:  1\n",
      "epoch: 1263\n",
      "training loss: 0.5111953789474561\n",
      "validation loss: 8.219640995173457\n",
      "loss difference:\n",
      "0.05001396136640546\n",
      "epoch: 1264\n",
      "training loss: 0.5604202772144223\n",
      "validation loss: 7.942011167702506\n",
      "loss difference:\n",
      "-0.04922489826696619\n",
      "that didn't improve loss:  1\n",
      "epoch: 1265\n",
      "training loss: 0.5104381480468985\n",
      "validation loss: 8.21755012554988\n",
      "loss difference:\n",
      "0.04998212916752387\n",
      "epoch: 1266\n",
      "training loss: 0.5596354839708509\n",
      "validation loss: 7.940070854897127\n",
      "loss difference:\n",
      "-0.04919733592395248\n",
      "that didn't improve loss:  1\n",
      "epoch: 1267\n",
      "training loss: 0.5096851458868983\n",
      "validation loss: 8.215456483946804\n",
      "loss difference:\n",
      "0.04995033808395266\n",
      "epoch: 1268\n",
      "training loss: 0.5588546938334708\n",
      "validation loss: 7.938124155652422\n",
      "loss difference:\n",
      "-0.04916954794657247\n",
      "that didn't improve loss:  1\n",
      "epoch: 1269\n",
      "training loss: 0.5089361735112687\n",
      "validation loss: 8.213359867850652\n",
      "loss difference:\n",
      "0.04991852032220201\n",
      "epoch: 1270\n",
      "training loss: 0.5580776261650581\n",
      "validation loss: 7.936171283425736\n",
      "loss difference:\n",
      "-0.04914145265378933\n",
      "that didn't improve loss:  1\n",
      "epoch: 1271\n",
      "training loss: 0.5081910226459385\n",
      "validation loss: 8.211260063818614\n",
      "loss difference:\n",
      "0.049886603519119554\n",
      "epoch: 1272\n",
      "training loss: 0.5573039895539912\n",
      "validation loss: 7.934212457598466\n",
      "loss difference:\n",
      "-0.04911296690805267\n",
      "that didn't improve loss:  1\n",
      "epoch: 1273\n",
      "training loss: 0.5074494779635135\n",
      "validation loss: 8.209156850599461\n",
      "loss difference:\n",
      "0.04985451159047771\n",
      "epoch: 1274\n",
      "training loss: 0.5565334849775626\n",
      "validation loss: 7.932247901745064\n",
      "loss difference:\n",
      "-0.049084007014049136\n",
      "that didn't improve loss:  1\n",
      "epoch: 1275\n",
      "training loss: 0.5067113193772479\n",
      "validation loss: 8.207050002262429\n",
      "loss difference:\n",
      "0.049822165600314716\n",
      "epoch: 1276\n",
      "training loss: 0.5557658089837385\n",
      "validation loss: 7.930277841890958\n",
      "loss difference:\n",
      "-0.049054489606490614\n",
      "that didn't improve loss:  1\n",
      "epoch: 1277\n",
      "training loss: 0.5059763243416924\n",
      "validation loss: 8.204939291303532\n",
      "loss difference:\n",
      "0.04978948464204613\n",
      "epoch: 1278\n",
      "training loss: 0.5550006568596041\n",
      "validation loss: 7.928302504777709\n",
      "loss difference:\n",
      "-0.04902433251791172\n",
      "that didn't improve loss:  1\n",
      "epoch: 1279\n",
      "training loss: 0.5052442701372076\n",
      "validation loss: 8.202824491699392\n",
      "loss difference:\n",
      "0.04975638672239646\n",
      "epoch: 1280\n",
      "training loss: 0.5542377257550916\n",
      "validation loss: 7.926322116153235\n",
      "loss difference:\n",
      "-0.04899345561788393\n",
      "that didn't improve loss:  1\n",
      "epoch: 1281\n",
      "training loss: 0.5045149361158172\n",
      "validation loss: 8.200705381879198\n",
      "loss difference:\n",
      "0.049722789639274345\n",
      "epoch: 1282\n",
      "training loss: 0.5534767177310862\n",
      "validation loss: 7.924336899104579\n",
      "loss difference:\n",
      "-0.048961781615268984\n",
      "that didn't improve loss:  1\n",
      "epoch: 1283\n",
      "training loss: 0.503788105886191\n",
      "validation loss: 8.198581747586683\n",
      "loss difference:\n",
      "0.04968861184489515\n",
      "epoch: 1284\n",
      "training loss: 0.552717342701973\n",
      "validation loss: 7.922347072450027\n",
      "loss difference:\n",
      "-0.048929236815781985\n",
      "that didn't improve loss:  1\n",
      "epoch: 1285\n",
      "training loss: 0.503063569416283\n",
      "validation loss: 8.196453384605334\n",
      "loss difference:\n",
      "0.049653773285689984\n",
      "epoch: 1286\n",
      "training loss: 0.5519593212438383\n",
      "validation loss: 7.920352849206406\n",
      "loss difference:\n",
      "-0.048895751827555234\n",
      "that didn't improve loss:  1\n",
      "epoch: 1287\n",
      "training loss: 0.5023411250329562\n",
      "validation loss: 8.19432010132175\n",
      "loss difference:\n",
      "0.04961819621088204\n",
      "epoch: 1288\n",
      "training loss: 0.5512023872410888\n",
      "validation loss: 7.918354435146572\n",
      "loss difference:\n",
      "-0.04886126220813258\n",
      "that didn't improve loss:  1\n",
      "epoch: 1289\n",
      "training loss: 0.5016205812991024\n",
      "validation loss: 8.192181721103903\n",
      "loss difference:\n",
      "0.04958180594198647\n",
      "epoch: 1290\n",
      "training loss: 0.5504462903461103\n",
      "validation loss: 7.916352027460877\n",
      "loss difference:\n",
      "-0.04882570904700789\n",
      "that didn't improve loss:  1\n",
      "epoch: 1291\n",
      "training loss: 0.5009017587501191\n",
      "validation loss: 8.190038084473292\n",
      "loss difference:\n",
      "0.04954453159599115\n",
      "epoch: 1292\n",
      "training loss: 0.5496907982287197\n",
      "validation loss: 7.9143458135350295\n",
      "loss difference:\n",
      "-0.04878903947860058\n",
      "that didn't improve loss:  1\n",
      "epoch: 1293\n",
      "training loss: 0.500184491473179\n",
      "validation loss: 8.187889051052364\n",
      "loss difference:\n",
      "0.049506306755540685\n",
      "epoch: 1294\n",
      "training loss: 0.5489356985946263\n",
      "validation loss: 7.912335969855466\n",
      "loss difference:\n",
      "-0.048751207121447315\n",
      "that didn't improve loss:  1\n",
      "epoch: 1295\n",
      "training loss: 0.49946862851458806\n",
      "validation loss: 8.18573450127124\n",
      "loss difference:\n",
      "0.049467070080038256\n",
      "epoch: 1296\n",
      "training loss: 0.5481808009548053\n",
      "validation loss: 7.910322661051812\n",
      "loss difference:\n",
      "-0.048712172440217194\n",
      "that didn't improve loss:  1\n",
      "epoch: 1297\n",
      "training loss: 0.49875403510251365\n",
      "validation loss: 8.183574337820373\n",
      "loss difference:\n",
      "0.04942676585229161\n",
      "epoch: 1298\n",
      "training loss: 0.5474259381306592\n",
      "validation loss: 7.908306039084266\n",
      "loss difference:\n",
      "-0.04867190302814556\n",
      "that didn't improve loss:  1\n",
      "epoch: 1299\n",
      "training loss: 0.498040593674548\n",
      "validation loss: 8.181408486839121\n",
      "loss difference:\n",
      "0.0493853444561112\n",
      "epoch: 1300\n",
      "training loss: 0.5466709674829662\n",
      "validation loss: 7.9062862425822145\n",
      "loss difference:\n",
      "-0.04863037380841817\n",
      "that didn't improve loss:  1\n",
      "epoch: 1301\n",
      "training loss: 0.49732820470196765\n",
      "validation loss: 8.179236898832823\n",
      "loss difference:\n",
      "0.04934276278099853\n",
      "epoch: 1302\n",
      "training loss: 0.5459157718558916\n",
      "validation loss: 7.904263396338442\n",
      "loss difference:\n",
      "-0.04858756715392393\n",
      "that didn't improve loss:  1\n",
      "epoch: 1303\n",
      "training loss: 0.49661678730492054\n",
      "validation loss: 8.177059549314425\n",
      "loss difference:\n",
      "0.04929898455097104\n",
      "epoch: 1304\n",
      "training loss: 0.545160260230783\n",
      "validation loss: 7.902237610961769\n",
      "loss difference:\n",
      "-0.048543472925862474\n",
      "that didn't improve loss:  1\n",
      "epoch: 1305\n",
      "training loss: 0.49590627965534334\n",
      "validation loss: 8.174876439169546\n",
      "loss difference:\n",
      "0.04925398057543967\n",
      "epoch: 1306\n",
      "training loss: 0.5444043680878718\n",
      "validation loss: 7.900208982688775\n",
      "loss difference:\n",
      "-0.04849808843252851\n",
      "that didn't improve loss:  1\n",
      "epoch: 1307\n",
      "training loss: 0.4951966391669746\n",
      "validation loss: 8.172687594747424\n",
      "loss difference:\n",
      "0.049207728920897253\n",
      "epoch: 1308\n",
      "training loss: 0.5436480574774619\n",
      "validation loss: 7.898177593353948\n",
      "loss difference:\n",
      "-0.048451418310487326\n",
      "that didn't improve loss:  1\n",
      "epoch: 1309\n",
      "training loss: 0.49448784247431027\n",
      "validation loss: 8.170493067682779\n",
      "loss difference:\n",
      "0.04916021500315165\n",
      "epoch: 1310\n",
      "training loss: 0.5428913168056484\n",
      "validation loss: 7.896143510515509\n",
      "loss difference:\n",
      "-0.048403474331338125\n",
      "that didn't improve loss:  1\n",
      "epoch: 1311\n",
      "training loss: 0.49377988520493765\n",
      "validation loss: 8.168292934456975\n",
      "loss difference:\n",
      "0.04911143160071074\n",
      "epoch: 1312\n",
      "training loss: 0.5421341603427672\n",
      "validation loss: 7.894106787732595\n",
      "loss difference:\n",
      "-0.04835427513782953\n",
      "that didn't improve loss:  1\n",
      "epoch: 1313\n",
      "training loss: 0.4930727815519925\n",
      "validation loss: 8.16608729570937\n",
      "loss difference:\n",
      "0.04906137879077466\n",
      "epoch: 1314\n",
      "training loss: 0.5413766274660491\n",
      "validation loss: 7.892067464987954\n",
      "loss difference:\n",
      "-0.048303845914056565\n",
      "that didn't improve loss:  1\n",
      "epoch: 1315\n",
      "training loss: 0.4923665636558322\n",
      "validation loss: 8.163876275312665\n",
      "loss difference:\n",
      "0.049010063810216886\n",
      "epoch: 1316\n",
      "training loss: 0.5406187816507527\n",
      "validation loss: 7.890025569248767\n",
      "loss difference:\n",
      "-0.04825221799492052\n",
      "that didn't improve loss:  1\n",
      "epoch: 1317\n",
      "training loss: 0.4916612808060749\n",
      "validation loss: 8.161660019228117\n",
      "loss difference:\n",
      "0.048957500844677815\n",
      "epoch: 1318\n",
      "training loss: 0.5398607092268254\n",
      "validation loss: 7.887981115156791\n",
      "loss difference:\n",
      "-0.04819942842075048\n",
      "that didn't improve loss:  1\n",
      "epoch: 1319\n",
      "training loss: 0.4909569984770941\n",
      "validation loss: 8.159438694158979\n",
      "loss difference:\n",
      "0.048903710749731266\n",
      "epoch: 1320\n",
      "training loss: 0.5391025179204074\n",
      "validation loss: 7.88593410583778\n",
      "loss difference:\n",
      "-0.0481455194433133\n",
      "that didn't improve loss:  1\n",
      "epoch: 1321\n",
      "training loss: 0.4902537972117086\n",
      "validation loss: 8.157212486022127\n",
      "loss difference:\n",
      "0.048848720708698834\n",
      "epoch: 1322\n",
      "training loss: 0.5383443352016797\n",
      "validation loss: 7.883884533819329\n",
      "loss difference:\n",
      "-0.048090537989971094\n",
      "that didn't improve loss:  1\n",
      "epoch: 1323\n",
      "training loss: 0.48955177136928735\n",
      "validation loss: 8.15498159825938\n",
      "loss difference:\n",
      "0.04879256383239233\n",
      "epoch: 1324\n",
      "training loss: 0.5375863064621574\n",
      "validation loss: 7.881832382044849\n",
      "loss difference:\n",
      "-0.04803453509287009\n",
      "that didn't improve loss:  1\n",
      "epoch: 1325\n",
      "training loss: 0.4888510277556341\n",
      "validation loss: 8.152746250011578\n",
      "loss difference:\n",
      "0.04873527870652333\n",
      "epoch: 1326\n",
      "training loss: 0.5368285930460467\n",
      "validation loss: 7.879777624971053\n",
      "loss difference:\n",
      "-0.04797756529041258\n",
      "that didn't improve loss:  1\n",
      "epoch: 1327\n",
      "training loss: 0.48815168415291\n",
      "validation loss: 8.15050667417898\n",
      "loss difference:\n",
      "0.048676908893136694\n",
      "epoch: 1328\n",
      "training loss: 0.5360713701610623\n",
      "validation loss: 7.877720229735702\n",
      "loss difference:\n",
      "-0.04791968600815233\n",
      "that didn't improve loss:  1\n",
      "epoch: 1329\n",
      "training loss: 0.4874538677685417\n",
      "validation loss: 8.148263115392442\n",
      "loss difference:\n",
      "0.048617502392520606\n",
      "epoch: 1330\n",
      "training loss: 0.5353148246949833\n",
      "validation loss: 7.875660157381598\n",
      "loss difference:\n",
      "-0.047860956926441545\n",
      "that didn't improve loss:  1\n",
      "epoch: 1331\n",
      "training loss: 0.48675771362231235\n",
      "validation loss: 8.146015827919923\n",
      "loss difference:\n",
      "0.04855711107267091\n",
      "epoch: 1332\n",
      "training loss: 0.53455915296429\n",
      "validation loss: 7.87359736412309\n",
      "loss difference:\n",
      "-0.04780143934197767\n",
      "that didn't improve loss:  1\n",
      "epoch: 1333\n",
      "training loss: 0.4860633628910291\n",
      "validation loss: 8.143765073532984\n",
      "loss difference:\n",
      "0.048495790073260936\n",
      "epoch: 1334\n",
      "training loss: 0.5338045584212449\n",
      "validation loss: 7.871531802640859\n",
      "loss difference:\n",
      "-0.047741195530215774\n",
      "that didn't improve loss:  1\n",
      "epoch: 1335\n",
      "training loss: 0.4853709612299385\n",
      "validation loss: 8.141511119357528\n",
      "loss difference:\n",
      "0.048433597191306355\n",
      "epoch: 1336\n",
      "training loss: 0.5330512493453742\n",
      "validation loss: 7.869463423390965\n",
      "loss difference:\n",
      "-0.047680288115435676\n",
      "that didn't improve loss:  1\n",
      "epoch: 1337\n",
      "training loss: 0.48468065708965863\n",
      "validation loss: 8.139254235732288\n",
      "loss difference:\n",
      "0.04837059225571555\n",
      "epoch: 1338\n",
      "training loss: 0.532299436544543\n",
      "validation loss: 7.86739217591459\n",
      "loss difference:\n",
      "-0.04761877945488441\n",
      "that didn't improve loss:  1\n",
      "epoch: 1339\n",
      "training loss: 0.48399260004677763\n",
      "validation loss: 8.136994694098002\n",
      "loss difference:\n",
      "0.048306836497765404\n",
      "epoch: 1340\n",
      "training loss: 0.5315493310898842\n",
      "validation loss: 7.865318010134992\n",
      "loss difference:\n",
      "-0.04755673104310659\n",
      "that didn't improve loss:  1\n",
      "epoch: 1341\n",
      "training loss: 0.4833069391654972\n",
      "validation loss: 8.134732764938818\n",
      "loss difference:\n",
      "0.04824239192438701\n",
      "epoch: 1342\n",
      "training loss: 0.5308011421075586\n",
      "validation loss: 7.86324087762882\n",
      "loss difference:\n",
      "-0.04749420294206136\n",
      "that didn't improve loss:  1\n",
      "epoch: 1343\n",
      "training loss: 0.48262382140665155\n",
      "validation loss: 8.132468715796373\n",
      "loss difference:\n",
      "0.04817732070090702\n",
      "epoch: 1344\n",
      "training loss: 0.5300550746488842\n",
      "validation loss: 7.861160732859699\n",
      "loss difference:\n",
      "-0.047431253242232685\n",
      "that didn't improve loss:  1\n",
      "epoch: 1345\n",
      "training loss: 0.4819433900993272\n",
      "validation loss: 8.130202809375334\n",
      "loss difference:\n",
      "0.048111684549557054\n",
      "epoch: 1346\n",
      "training loss: 0.529311327658775\n",
      "validation loss: 7.859077534362577\n",
      "loss difference:\n",
      "-0.04736793755944779\n",
      "that didn't improve loss:  1\n",
      "epoch: 1347\n",
      "training loss: 0.48126578348910015\n",
      "validation loss: 8.127935301757686\n",
      "loss difference:\n",
      "0.048045544169674825\n",
      "epoch: 1348\n",
      "training loss: 0.5285700920605794\n",
      "validation loss: 7.856991245868276\n",
      "loss difference:\n",
      "-0.047304308571479214\n",
      "that didn't improve loss:  1\n",
      "epoch: 1349\n",
      "training loss: 0.4805911333754883\n",
      "validation loss: 8.125666440741304\n",
      "loss difference:\n",
      "0.047978958685091055\n",
      "epoch: 1350\n",
      "training loss: 0.5278315489735884\n",
      "validation loss: 7.854901837358504\n",
      "loss difference:\n",
      "-0.047240415598100105\n",
      "that didn't improve loss:  1\n",
      "epoch: 1351\n",
      "training loss: 0.4799195638498767\n",
      "validation loss: 8.12339646431648\n",
      "loss difference:\n",
      "0.0479119851237117\n",
      "epoch: 1352\n",
      "training loss: 0.5270958680774638\n",
      "validation loss: 7.852809286042717\n",
      "loss difference:\n",
      "-0.04717630422758706\n",
      "that didn't improve loss:  1\n",
      "epoch: 1353\n",
      "training loss: 0.47925119014368206\n",
      "validation loss: 8.121125599292077\n",
      "loss difference:\n",
      "0.04784467793378172\n",
      "epoch: 1354\n",
      "training loss: 0.5263632061358084\n",
      "validation loss: 7.850713577249112\n",
      "loss difference:\n",
      "-0.04711201599212639\n",
      "that didn't improve loss:  1\n",
      "epoch: 1355\n",
      "training loss: 0.4785861175950386\n",
      "validation loss: 8.118854060081194\n",
      "loss difference:\n",
      "0.04777708854076984\n",
      "epoch: 1356\n",
      "training loss: 0.5256337056890703\n",
      "validation loss: 7.848614705223272\n",
      "loss difference:\n",
      "-0.0470475880940317\n",
      "that didn't improve loss:  1\n",
      "epoch: 1357\n",
      "training loss: 0.4779244407408228\n",
      "validation loss: 8.116582047654353\n",
      "loss difference:\n",
      "0.04770926494824751\n",
      "epoch: 1358\n",
      "training loss: 0.5249074939249214\n",
      "validation loss: 7.846512673828783\n",
      "loss difference:\n",
      "-0.04698305318409862\n",
      "that didn't improve loss:  1\n",
      "epoch: 1359\n",
      "training loss: 0.47726624253935035\n",
      "validation loss: 8.114309748665884\n",
      "loss difference:\n",
      "0.04764125138557107\n",
      "epoch: 1360\n",
      "training loss: 0.5241846817321799\n",
      "validation loss: 7.844407497145745\n",
      "loss difference:\n",
      "-0.046918439192829564\n",
      "that didn't improve loss:  1\n",
      "epoch: 1361\n",
      "training loss: 0.4766115937276238\n",
      "validation loss: 8.11203733475779\n",
      "loss difference:\n",
      "0.04757308800455612\n",
      "epoch: 1362\n",
      "training loss: 0.5234653629424063\n",
      "validation loss: 7.842299199963627\n",
      "loss difference:\n",
      "-0.046853769214782515\n",
      "that didn't improve loss:  1\n",
      "epoch: 1363\n",
      "training loss: 0.47596055231558204\n",
      "validation loss: 8.10976496204299\n",
      "loss difference:\n",
      "0.04750481062682427\n",
      "epoch: 1364\n",
      "training loss: 0.5227496137612976\n",
      "validation loss: 7.840187818166552\n",
      "loss difference:\n",
      "-0.04678906144571554\n",
      "that didn't improve loss:  1\n",
      "epoch: 1365\n",
      "training loss: 0.47531316321849554\n",
      "validation loss: 8.107492770768557\n",
      "loss difference:\n",
      "0.047436450542802044\n",
      "epoch: 1366\n",
      "training loss: 0.5220374923902211\n",
      "validation loss: 7.838073399009882\n",
      "loss difference:\n",
      "-0.04672432917172559\n",
      "that didn't improve loss:  1\n",
      "epoch: 1367\n",
      "training loss: 0.47466945802725197\n",
      "validation loss: 8.10522088515717\n",
      "loss difference:\n",
      "0.04736803436296916\n",
      "epoch: 1368\n",
      "training loss: 0.5213290388363814\n",
      "validation loss: 7.835956001288034\n",
      "loss difference:\n",
      "-0.04665958080912941\n",
      "that didn't improve loss:  1\n",
      "epoch: 1369\n",
      "training loss: 0.4740294549151174\n",
      "validation loss: 8.102949413424053\n",
      "loss difference:\n",
      "0.04729958392126399\n",
      "epoch: 1370\n",
      "training loss: 0.5206242749083799\n",
      "validation loss: 7.833835695394803\n",
      "loss difference:\n",
      "-0.04659481999326254\n",
      "that didn't improve loss:  1\n",
      "epoch: 1371\n",
      "training loss: 0.47339315867828735\n",
      "validation loss: 8.100678447964379\n",
      "loss difference:\n",
      "0.047231116230092574\n",
      "epoch: 1372\n",
      "training loss: 0.5199232043924358\n",
      "validation loss: 7.83171256327779\n",
      "loss difference:\n",
      "-0.04653004571414843\n",
      "that didn't improve loss:  1\n",
      "epoch: 1373\n",
      "training loss: 0.47276056090651375\n",
      "validation loss: 8.098408065705298\n",
      "loss difference:\n",
      "0.04716264348592203\n",
      "epoch: 1374\n",
      "training loss: 0.5192258134028892\n",
      "validation loss: 7.8295866982905284\n",
      "loss difference:\n",
      "-0.04646525249637545\n",
      "that didn't improve loss:  1\n",
      "epoch: 1375\n",
      "training loss: 0.47213164027894816\n",
      "validation loss: 8.096138328614822\n",
      "loss difference:\n",
      "0.04709417312394104\n",
      "epoch: 1376\n",
      "training loss: 0.5185320708992944\n",
      "validation loss: 7.827458204945526\n",
      "loss difference:\n",
      "-0.04640043062034627\n",
      "that didn't improve loss:  1\n",
      "epoch: 1377\n",
      "training loss: 0.47150636297944865\n",
      "validation loss: 8.093869284358806\n",
      "loss difference:\n",
      "0.04702570791984578\n",
      "epoch: 1378\n",
      "training loss: 0.5178419293610772\n",
      "validation loss: 7.8253271985734\n",
      "loss difference:\n",
      "-0.04633556638162856\n",
      "that didn't improve loss:  1\n",
      "epoch: 1379\n",
      "training loss: 0.470884683224636\n",
      "validation loss: 8.091600967096113\n",
      "loss difference:\n",
      "0.0469572461364412\n",
      "epoch: 1380\n",
      "training loss: 0.5171553256095263\n",
      "validation loss: 7.823193804893285\n",
      "loss difference:\n",
      "-0.04627064238489026\n",
      "that didn't improve loss:  1\n",
      "epoch: 1381\n",
      "training loss: 0.4702665438971923\n",
      "validation loss: 8.08933339840087\n",
      "loss difference:\n",
      "0.04688878171233396\n",
      "epoch: 1382\n",
      "training loss: 0.5164721817658227\n",
      "validation loss: 7.821058159500809\n",
      "loss difference:\n",
      "-0.046205637868630356\n",
      "that didn't improve loss:  1\n",
      "epoch: 1383\n",
      "training loss: 0.46965187727609503\n",
      "validation loss: 8.0870665882998\n",
      "loss difference:\n",
      "0.04682030448972763\n",
      "epoch: 1384\n",
      "training loss: 0.5157924063328343\n",
      "validation loss: 7.818920407280345\n",
      "loss difference:\n",
      "-0.046140529056739266\n",
      "that didn't improve loss:  1\n",
      "epoch: 1385\n",
      "training loss: 0.46904060585485313\n",
      "validation loss: 8.084800536412022\n",
      "loss difference:\n",
      "0.046751800477981165\n",
      "epoch: 1386\n",
      "training loss: 0.5151158953875469\n",
      "validation loss: 7.816780701748999\n",
      "loss difference:\n",
      "-0.04607528953269374\n",
      "that didn't improve loss:  1\n",
      "epoch: 1387\n",
      "training loss: 0.46843264323814704\n",
      "validation loss: 8.082535233177667\n",
      "loss difference:\n",
      "0.046683252149399834\n",
      "epoch: 1388\n",
      "training loss: 0.5144425338702788\n",
      "validation loss: 7.814639204340045\n",
      "loss difference:\n",
      "-0.04600989063213179\n",
      "that didn't improve loss:  1\n",
      "epoch: 1389\n",
      "training loss: 0.46782789510680123\n",
      "validation loss: 8.08027066116139\n",
      "loss difference:\n",
      "0.0466146387634776\n",
      "epoch: 1390\n",
      "training loss: 0.5137721969561722\n",
      "validation loss: 7.8124960836341275\n",
      "loss difference:\n",
      "-0.04594430184937093\n",
      "that didn't improve loss:  1\n",
      "epoch: 1391\n",
      "training loss: 0.4672262602405609\n",
      "validation loss: 8.07800679641637\n",
      "loss difference:\n",
      "0.04654593671561125\n",
      "epoch: 1392\n",
      "training loss: 0.5131047514940213\n",
      "validation loss: 7.81035151454671\n",
      "loss difference:\n",
      "-0.04587849125346044\n",
      "that didn't improve loss:  1\n",
      "epoch: 1393\n",
      "training loss: 0.46662763158775344\n",
      "validation loss: 8.075743609893895\n",
      "loss difference:\n",
      "0.046477119906267905\n",
      "epoch: 1394\n",
      "training loss: 0.5124400574970547\n",
      "validation loss: 7.808205677480685\n",
      "loss difference:\n",
      "-0.045812425909301235\n",
      "that didn't improve loss:  1\n",
      "epoch: 1395\n",
      "training loss: 0.4660318973707167\n",
      "validation loss: 8.073481068883712\n",
      "loss difference:\n",
      "0.04640816012633797\n",
      "epoch: 1396\n",
      "training loss: 0.5117779696701726\n",
      "validation loss: 7.806058757452954\n",
      "loss difference:\n",
      "-0.04574607229945593\n",
      "that didn't improve loss:  1\n",
      "epoch: 1397\n",
      "training loss: 0.4654389422156407\n",
      "validation loss: 8.071219138470235\n",
      "loss difference:\n",
      "0.046339027454531945\n",
      "epoch: 1398\n",
      "training loss: 0.5111183389578697\n",
      "validation loss: 7.803910943204069\n",
      "loss difference:\n",
      "-0.04567939674222904\n",
      "that didn't improve loss:  1\n",
      "epoch: 1399\n",
      "training loss: 0.46484864829539796\n",
      "validation loss: 8.068957782989498\n",
      "loss difference:\n",
      "0.046269690662471774\n",
      "epoch: 1400\n",
      "training loss: 0.5104610140972977\n",
      "validation loss: 7.801762426299965\n",
      "loss difference:\n",
      "-0.04561236580189976\n",
      "that didn't improve loss:  1\n",
      "epoch: 1401\n",
      "training loss: 0.4642608964740217\n",
      "validation loss: 8.066696967472508\n",
      "loss difference:\n",
      "0.04620011762327603\n",
      "epoch: 1402\n",
      "training loss: 0.5098058431609639\n",
      "validation loss: 7.799613400234603\n",
      "loss difference:\n",
      "-0.0455449466869422\n",
      "that didn't improve loss:  1\n",
      "epoch: 1403\n",
      "training loss: 0.4636755674414979\n",
      "validation loss: 8.064436659060556\n",
      "loss difference:\n",
      "0.046130275719465985\n",
      "epoch: 1404\n",
      "training loss: 0.5091526750739204\n",
      "validation loss: 7.797464059542305\n",
      "loss difference:\n",
      "-0.045477107632422464\n",
      "that didn't improve loss:  1\n",
      "epoch: 1405\n",
      "training loss: 0.46309254282785195\n",
      "validation loss: 8.062176828378643\n",
      "loss difference:\n",
      "0.04606013224606842\n",
      "epoch: 1406\n",
      "training loss: 0.5085013610907679\n",
      "validation loss: 7.795314598928197\n",
      "loss difference:\n",
      "-0.045408818262915984\n",
      "that didn't improve loss:  1\n",
      "epoch: 1407\n",
      "training loss: 0.46251170628580124\n",
      "validation loss: 8.059917450854012\n",
      "loss difference:\n",
      "0.045989654804966695\n",
      "epoch: 1408\n",
      "training loss: 0.5078517562183702\n",
      "validation loss: 7.7931652124249675\n",
      "loss difference:\n",
      "-0.04534004993256896\n",
      "that didn't improve loss:  1\n",
      "epoch: 1409\n",
      "training loss: 0.4619329445316624\n",
      "validation loss: 8.057658507967199\n",
      "loss difference:\n",
      "0.045918811686707806\n",
      "epoch: 1410\n",
      "training loss: 0.5072037205708995\n",
      "validation loss: 7.791016092583462\n",
      "loss difference:\n",
      "-0.04527077603923707\n",
      "that didn't improve loss:  1\n",
      "epoch: 1411\n",
      "training loss: 0.4613561483347563\n",
      "validation loss: 8.05539998842421\n",
      "loss difference:\n",
      "0.045847572236143164\n",
      "epoch: 1412\n",
      "training loss: 0.506557120644714\n",
      "validation loss: 7.7888674297044975\n",
      "loss difference:\n",
      "-0.04520097230995773\n",
      "that didn't improve loss:  1\n",
      "epoch: 1413\n",
      "training loss: 0.4607812134461728\n",
      "validation loss: 8.053141889238917\n",
      "loss difference:\n",
      "0.045775907198541244\n",
      "epoch: 1414\n",
      "training loss: 0.5059118305015395\n",
      "validation loss: 7.786719411118367\n",
      "loss difference:\n",
      "-0.04513061705536675\n",
      "that didn't improve loss:  1\n",
      "epoch: 1415\n",
      "training loss: 0.46020804145843947\n",
      "validation loss: 8.05088421671646\n",
      "loss difference:\n",
      "0.045703789043100074\n",
      "epoch: 1416\n",
      "training loss: 0.5052677328494944\n",
      "validation loss: 7.784572220518271\n",
      "loss difference:\n",
      "-0.04505969139105498\n",
      "that didn't improve loss:  1\n",
      "epoch: 1417\n",
      "training loss: 0.4596365405885358\n",
      "validation loss: 8.048626987329072\n",
      "loss difference:\n",
      "0.04563119226095863\n",
      "epoch: 1418\n",
      "training loss: 0.5046247200127374\n",
      "validation loss: 7.782426037352939\n",
      "loss difference:\n",
      "-0.04498817942420158\n",
      "that didn't improve loss:  1\n",
      "epoch: 1419\n",
      "training loss: 0.459066626377476\n",
      "validation loss: 8.046370228477086\n",
      "loss difference:\n",
      "0.04555809363526142\n",
      "epoch: 1420\n",
      "training loss: 0.5039826947818081\n",
      "validation loss: 7.7802810362829495\n",
      "loss difference:\n",
      "-0.044916068404332155\n",
      "that didn't improve loss:  1\n",
      "epoch: 1421\n",
      "training loss: 0.45849822230073267\n",
      "validation loss: 8.044113979129438\n",
      "loss difference:\n",
      "0.045484472481075455\n",
      "epoch: 1422\n",
      "training loss: 0.5033415711380548\n",
      "validation loss: 7.77813738670496\n",
      "loss difference:\n",
      "-0.044843348837322106\n",
      "that didn't improve loss:  1\n",
      "epoch: 1423\n",
      "training loss: 0.45793126028470765\n",
      "validation loss: 8.041858290339063\n",
      "loss difference:\n",
      "0.045410310853347124\n",
      "epoch: 1424\n",
      "training loss: 0.5027012748469954\n",
      "validation loss: 7.775995252346739\n",
      "loss difference:\n",
      "-0.044770014562287797\n",
      "that didn't improve loss:  1\n",
      "epoch: 1425\n",
      "training loss: 0.45736568112560283\n",
      "validation loss: 8.039603225629852\n",
      "loss difference:\n",
      "0.04533559372139262\n",
      "epoch: 1426\n",
      "training loss: 0.5020617439169894\n",
      "validation loss: 7.773854790935322\n",
      "loss difference:\n",
      "-0.044696062791386604\n",
      "that didn't improve loss:  1\n",
      "epoch: 1427\n",
      "training loss: 0.45680143480806873\n",
      "validation loss: 8.037348861253685\n",
      "loss difference:\n",
      "0.045260309108920704\n",
      "epoch: 1428\n",
      "training loss: 0.5014229289209796\n",
      "validation loss: 7.771716153939983\n",
      "loss difference:\n",
      "-0.04462149411291089\n",
      "that didn't improve loss:  1\n",
      "epoch: 1429\n",
      "training loss: 0.45623848072215883\n",
      "validation loss: 8.03509528631691\n",
      "loss difference:\n",
      "0.04518444819882078\n",
      "epoch: 1430\n",
      "training loss: 0.5007847931806626\n",
      "validation loss: 7.769579486390526\n",
      "loss difference:\n",
      "-0.04454631245850377\n",
      "that didn't improve loss:  1\n",
      "epoch: 1431\n",
      "training loss: 0.45567678777825193\n",
      "validation loss: 8.032842602777407\n",
      "loss difference:\n",
      "0.04510800540241067\n",
      "epoch: 1432\n",
      "training loss: 0.5001473128139283\n",
      "validation loss: 7.7674449267707795\n",
      "loss difference:\n",
      "-0.04447052503567639\n",
      "that didn't improve loss:  1\n",
      "epoch: 1433\n",
      "training loss: 0.45511633442066385\n",
      "validation loss: 8.03059092531452\n",
      "loss difference:\n",
      "0.045030978393264476\n",
      "epoch: 1434\n",
      "training loss: 0.49951047664780673\n",
      "validation loss: 7.765312606986656\n",
      "loss difference:\n",
      "-0.044394142227142885\n",
      "that didn't improve loss:  1\n",
      "epoch: 1435\n",
      "training loss: 0.4545571085418336\n",
      "validation loss: 8.028340381075495\n",
      "loss difference:\n",
      "0.04495336810597311\n",
      "epoch: 1436\n",
      "training loss: 0.49887428600067896\n",
      "validation loss: 7.763182652406722\n",
      "loss difference:\n",
      "-0.044317177458845336\n",
      "that didn't improve loss:  1\n",
      "epoch: 1437\n",
      "training loss: 0.45399910729994103\n",
      "validation loss: 8.026091109303355\n",
      "loss difference:\n",
      "0.04487517870073793\n",
      "epoch: 1438\n",
      "training loss: 0.49823875433876447\n",
      "validation loss: 7.761055181973225\n",
      "loss difference:\n",
      "-0.04423964703882344\n",
      "that didn't improve loss:  1\n",
      "epoch: 1439\n",
      "training loss: 0.4534423368438839\n",
      "validation loss: 8.023843260852152\n",
      "loss difference:\n",
      "0.04479641749488056\n",
      "epoch: 1440\n",
      "training loss: 0.4976039068131779\n",
      "validation loss: 7.75893030838027\n",
      "loss difference:\n",
      "-0.04416156996929399\n",
      "that didn't improve loss:  1\n",
      "epoch: 1441\n",
      "training loss: 0.45288681195039526\n",
      "validation loss: 8.021596997596747\n",
      "loss difference:\n",
      "0.044717094862782636\n",
      "epoch: 1442\n",
      "training loss: 0.4969697796850611\n",
      "validation loss: 7.756808138315555\n",
      "loss difference:\n",
      "-0.04408296773466586\n",
      "that didn't improve loss:  1\n",
      "epoch: 1443\n",
      "training loss: 0.45233255557900415\n",
      "validation loss: 8.01935249174516\n",
      "loss difference:\n",
      "0.04463722410605697\n",
      "epoch: 1444\n",
      "training loss: 0.4963364196472988\n",
      "validation loss: 7.754688772761259\n",
      "loss difference:\n",
      "-0.04400386406829465\n",
      "that didn't improve loss:  1\n",
      "epoch: 1445\n",
      "training loss: 0.45177959835130876\n",
      "validation loss: 8.017109925062426\n",
      "loss difference:\n",
      "0.044556821295990034\n",
      "epoch: 1446\n",
      "training loss: 0.4957038830522248\n",
      "validation loss: 7.752572307349364\n",
      "loss difference:\n",
      "-0.04392428470091603\n",
      "that didn't improve loss:  1\n",
      "epoch: 1447\n",
      "training loss: 0.4512279779616468\n",
      "validation loss: 8.014869488015517\n",
      "loss difference:\n",
      "0.04447590509057797\n",
      "epoch: 1448\n",
      "training loss: 0.4950722350556329\n",
      "validation loss: 7.750458832766048\n",
      "loss difference:\n",
      "-0.043844257093986094\n",
      "that didn't improve loss:  1\n",
      "epoch: 1449\n",
      "training loss: 0.45067773852691656\n",
      "validation loss: 8.012631378849719\n",
      "loss difference:\n",
      "0.044394496528716354\n",
      "epoch: 1450\n",
      "training loss: 0.4944415486879296\n",
      "validation loss: 7.748348435199451\n",
      "loss difference:\n",
      "-0.04376381016101305\n",
      "that didn't improve loss:  1\n",
      "epoch: 1451\n",
      "training loss: 0.4501289298836957\n",
      "validation loss: 8.010395802607116\n",
      "loss difference:\n",
      "0.04431261880423393\n",
      "epoch: 1452\n",
      "training loss: 0.4938119038638634\n",
      "validation loss: 7.74624119682491\n",
      "loss difference:\n",
      "-0.04368297398016774\n",
      "that didn't improve loss:  1\n",
      "epoch: 1453\n",
      "training loss: 0.44958160684120085\n",
      "validation loss: 8.008162970098198\n",
      "loss difference:\n",
      "0.04423029702266257\n",
      "epoch: 1454\n",
      "training loss: 0.49318338634259595\n",
      "validation loss: 7.744137196321415\n",
      "loss difference:\n",
      "-0.0436017795013951\n",
      "that didn't improve loss:  1\n",
      "epoch: 1455\n",
      "training loss: 0.44903582839890727\n",
      "validation loss: 8.005933096838005\n",
      "loss difference:\n",
      "0.04414755794368869\n",
      "epoch: 1456\n",
      "training loss: 0.4925560866501252\n",
      "validation loss: 7.742036509412759\n",
      "loss difference:\n",
      "-0.043520258251217914\n",
      "that didn't improve loss:  1\n",
      "epoch: 1457\n",
      "training loss: 0.4484916569377538\n",
      "validation loss: 8.003706401958139\n",
      "loss difference:\n",
      "0.0440644297123714\n",
      "epoch: 1458\n",
      "training loss: 0.4919300989761447\n",
      "validation loss: 7.7399392094270825\n",
      "loss difference:\n",
      "-0.04343844203839092\n",
      "that didn't improve loss:  1\n",
      "epoch: 1459\n",
      "training loss: 0.44794915739391744\n",
      "validation loss: 8.00148310710597\n",
      "loss difference:\n",
      "0.04398094158222726\n",
      "epoch: 1460\n",
      "training loss: 0.49130552005732\n",
      "validation loss: 7.737845367868139\n",
      "loss difference:\n",
      "-0.04335636266340254\n",
      "that didn't improve loss:  1\n",
      "epoch: 1461\n",
      "training loss: 0.44740839642409486\n",
      "validation loss: 7.999263435342194\n",
      "loss difference:\n",
      "0.04389712363322512\n",
      "epoch: 1462\n",
      "training loss: 0.49068244805887756\n",
      "validation loss: 7.735755054991832\n",
      "loss difference:\n",
      "-0.043274051634782706\n",
      "that didn't improve loss:  1\n",
      "epoch: 1463\n",
      "training loss: 0.4468694415710439\n",
      "validation loss: 7.997047610047702\n",
      "loss difference:\n",
      "0.04381300648783365\n",
      "epoch: 1464\n",
      "training loss: 0.4900609814659532\n",
      "validation loss: 7.73366834038176\n",
      "loss difference:\n",
      "-0.043191539894909314\n",
      "that didn't improve loss:  1\n",
      "epoch: 1465\n",
      "training loss: 0.44633236043789826\n",
      "validation loss: 7.994835853850209\n",
      "loss difference:\n",
      "0.04372862102805497\n",
      "epoch: 1466\n",
      "training loss: 0.4894412179958446\n",
      "validation loss: 7.731585293517396\n",
      "loss difference:\n",
      "-0.043108857557946356\n",
      "that didn't improve loss:  1\n",
      "epoch: 1467\n",
      "training loss: 0.44579721987946064\n",
      "validation loss: 7.992628387580699\n",
      "loss difference:\n",
      "0.043643998116383975\n",
      "epoch: 1468\n",
      "training loss: 0.48882325354169565\n",
      "validation loss: 7.7295059843291725\n",
      "loss difference:\n",
      "-0.04302603366223501\n",
      "that didn't improve loss:  1\n",
      "epoch: 1469\n",
      "training loss: 0.4452640852182195\n",
      "validation loss: 7.990425429269146\n",
      "loss difference:\n",
      "0.04355916832347617\n",
      "epoch: 1470\n",
      "training loss: 0.48820718115754913\n",
      "validation loss: 7.727430483734615\n",
      "loss difference:\n",
      "-0.042943095939329656\n",
      "that didn't improve loss:  1\n",
      "epoch: 1471\n",
      "training loss: 0.44473301949242666\n",
      "validation loss: 7.988227193188319\n",
      "loss difference:\n",
      "0.04347416166512247\n",
      "epoch: 1472\n",
      "training loss: 0.4875930900940119\n",
      "validation loss: 7.725358864150305\n",
      "loss difference:\n",
      "-0.042860070601585254\n",
      "that didn't improve loss:  1\n",
      "epoch: 1473\n",
      "training loss: 0.4442040827429719\n",
      "validation loss: 7.986033888953713\n",
      "loss difference:\n",
      "0.04338900735104001\n",
      "epoch: 1474\n",
      "training loss: 0.48698106489293297\n",
      "validation loss: 7.723291199974805\n",
      "loss difference:\n",
      "-0.04277698214996106\n",
      "that didn't improve loss:  1\n",
      "epoch: 1475\n",
      "training loss: 0.44367733134524795\n",
      "validation loss: 7.983845720686907\n",
      "loss difference:\n",
      "0.04330373354768502\n",
      "epoch: 1476\n",
      "training loss: 0.48637118454875494\n",
      "validation loss: 7.721227568037766\n",
      "loss difference:\n",
      "-0.04269385320350699\n",
      "that didn't improve loss:  1\n",
      "epoch: 1477\n",
      "training loss: 0.4431528173915868\n",
      "validation loss: 7.981662886248928\n",
      "loss difference:\n",
      "0.04321836715716815\n",
      "epoch: 1478\n",
      "training loss: 0.485763521743236\n",
      "validation loss: 7.719168048011559\n",
      "loss difference:\n",
      "-0.04261070435164921\n",
      "that didn't improve loss:  1\n",
      "epoch: 1479\n",
      "training loss: 0.4426305881291356\n",
      "validation loss: 7.9794855765490516\n",
      "loss difference:\n",
      "0.04313293361410042\n",
      "epoch: 1480\n",
      "training loss: 0.4851581421593753\n",
      "validation loss: 7.7171127227814145\n",
      "loss difference:\n",
      "-0.04252755403023972\n",
      "that didn't improve loss:  1\n",
      "epoch: 1481\n",
      "training loss: 0.44211068545744864\n",
      "validation loss: 7.977313974933916\n",
      "loss difference:\n",
      "0.04304745670192667\n",
      "epoch: 1482\n",
      "training loss: 0.4845551038793913\n",
      "validation loss: 7.71506167877139\n",
      "loss difference:\n",
      "-0.04244441842194269\n",
      "that didn't improve loss:  1\n",
      "epoch: 1483\n",
      "training loss: 0.441593145489254\n",
      "validation loss: 7.97514825666066\n",
      "loss difference:\n",
      "0.042961958390137334\n",
      "epoch: 1484\n",
      "training loss: 0.4839544568706721\n",
      "validation loss: 7.713015006223341\n",
      "loss difference:\n",
      "-0.04236131138141813\n",
      "that didn't improve loss:  1\n",
      "epoch: 1485\n",
      "training loss: 0.44107799817729354\n",
      "validation loss: 7.972988588456982\n",
      "loss difference:\n",
      "0.04287645869337858\n",
      "epoch: 1486\n",
      "training loss: 0.48335624256264675\n",
      "validation loss: 7.7109727994270365\n",
      "loss difference:\n",
      "-0.042278244385353214\n",
      "that didn't improve loss:  1\n",
      "epoch: 1487\n",
      "training loss: 0.4405652670092776\n",
      "validation loss: 7.970835128170163\n",
      "loss difference:\n",
      "0.04279097555336914\n",
      "epoch: 1488\n",
      "training loss: 0.4827604935166067\n",
      "validation loss: 7.708935156899767\n",
      "loss difference:\n",
      "-0.0421952265073291\n",
      "that didn't improve loss:  1\n",
      "epoch: 1489\n",
      "training loss: 0.44005496877244554\n",
      "validation loss: 7.968688024506049\n",
      "loss difference:\n",
      "0.04270552474416117\n",
      "epoch: 1490\n",
      "training loss: 0.48216723318948007\n",
      "validation loss: 7.706902181514702\n",
      "loss difference:\n",
      "-0.04211226441703453\n",
      "that didn't improve loss:  1\n",
      "epoch: 1491\n",
      "training loss: 0.43954711338837377\n",
      "validation loss: 7.966547416858177\n",
      "loss difference:\n",
      "0.042620119801106304\n",
      "epoch: 1492\n",
      "training loss: 0.4815764757917124\n",
      "validation loss: 7.704873980577415\n",
      "loss difference:\n",
      "-0.042029362403338655\n",
      "that didn't improve loss:  1\n",
      "epoch: 1493\n",
      "training loss: 0.4390417038181259\n",
      "validation loss: 7.964413435226396\n",
      "loss difference:\n",
      "0.042534771973586516\n",
      "epoch: 1494\n",
      "training loss: 0.4809882262385044\n",
      "validation loss: 7.702850665850668\n",
      "loss difference:\n",
      "-0.041946522420378496\n",
      "that didn't improve loss:  1\n",
      "epoch: 1495\n",
      "training loss: 0.43853873603710525\n",
      "validation loss: 7.962286200223442\n",
      "loss difference:\n",
      "0.042449490201399154\n",
      "epoch: 1496\n",
      "training loss: 0.48040248019276455\n",
      "validation loss: 7.700832353528228\n",
      "loss difference:\n",
      "-0.0418637441556593\n",
      "that didn't improve loss:  1\n",
      "epoch: 1497\n",
      "training loss: 0.4380381990783692\n",
      "validation loss: 7.960165823167148\n",
      "loss difference:\n",
      "0.04236428111439533\n",
      "epoch: 1498\n",
      "training loss: 0.47981922419731293\n",
      "validation loss: 7.698819164158535\n",
      "loss difference:\n",
      "-0.041781025118943715\n",
      "that didn't improve loss:  1\n",
      "epoch: 1499\n",
      "training loss: 0.43754007514251503\n",
      "validation loss: 7.9580524062552245\n",
      "loss difference:\n",
      "0.042279149054797904\n",
      "epoch: 1500\n",
      "training loss: 0.4792384358931246\n",
      "validation loss: 7.696811222520042\n",
      "loss difference:\n",
      "-0.041698360750609564\n",
      "that didn't improve loss:  1\n",
      "epoch: 1501\n",
      "training loss: 0.4370443397717592\n",
      "validation loss: 7.955946042818772\n",
      "loss difference:\n",
      "0.042194096121365376\n",
      "epoch: 1502\n",
      "training loss: 0.47866008431964385\n",
      "validation loss: 7.694808657450096\n",
      "loss difference:\n",
      "-0.04161574454788464\n",
      "that didn't improve loss:  1\n",
      "epoch: 1503\n",
      "training loss: 0.43655096208517674\n",
      "validation loss: 7.953846817650206\n",
      "loss difference:\n",
      "0.04210912223446711\n",
      "epoch: 1504\n",
      "training loss: 0.47808413029249763\n",
      "validation loss: 7.69281160162969\n",
      "loss difference:\n",
      "-0.04153316820732089\n",
      "that didn't improve loss:  1\n",
      "epoch: 1505\n",
      "training loss: 0.4360599050716541\n",
      "validation loss: 7.95175480740046\n",
      "loss difference:\n",
      "0.042024225220843536\n",
      "epoch: 1506\n",
      "training loss: 0.47751052685340156\n",
      "validation loss: 7.690820191327083\n",
      "loss difference:\n",
      "-0.041450621781747465\n",
      "that didn't improve loss:  1\n",
      "epoch: 1507\n",
      "training loss: 0.4355711259365992\n",
      "validation loss: 7.949670081039883\n",
      "loss difference:\n",
      "0.04193940091680237\n",
      "epoch: 1508\n",
      "training loss: 0.47693921978635184\n",
      "validation loss: 7.688834566103185\n",
      "loss difference:\n",
      "-0.04136809384975265\n",
      "that didn't improve loss:  1\n",
      "epoch: 1509\n",
      "training loss: 0.43508457649805415\n",
      "validation loss: 7.947592700376809\n",
      "loss difference:\n",
      "0.04185464328829769\n",
      "epoch: 1510\n",
      "training loss: 0.47637014819381934\n",
      "validation loss: 7.686854868482412\n",
      "loss difference:\n",
      "-0.04128557169576519\n",
      "that didn't improve loss:  1\n",
      "epoch: 1511\n",
      "training loss: 0.4346002036274472\n",
      "validation loss: 7.9455227206273635\n",
      "loss difference:\n",
      "0.04176994456637212\n",
      "epoch: 1512\n",
      "training loss: 0.4758032451261498\n",
      "validation loss: 7.6848812435924625\n",
      "loss difference:\n",
      "-0.041203041498702575\n",
      "that didn't improve loss:  1\n",
      "epoch: 1513\n",
      "training loss: 0.4341179497299234\n",
      "validation loss: 7.943460191029493\n",
      "loss difference:\n",
      "0.041685295396226396\n",
      "epoch: 1514\n",
      "training loss: 0.4752384382570244\n",
      "validation loss: 7.682913838777139\n",
      "loss difference:\n",
      "-0.041120488527100985\n",
      "that didn't improve loss:  1\n",
      "epoch: 1515\n",
      "training loss: 0.4336377532589196\n",
      "validation loss: 7.941405155494405\n",
      "loss difference:\n",
      "0.041600684998104764\n",
      "epoch: 1516\n",
      "training loss: 0.47467565059755995\n",
      "validation loss: 7.680952803186323\n",
      "loss difference:\n",
      "-0.04103789733864033\n",
      "that didn't improve loss:  1\n",
      "epoch: 1517\n",
      "training loss: 0.4331595492593426\n",
      "validation loss: 7.939357653287748\n",
      "loss difference:\n",
      "0.04151610133821737\n",
      "epoch: 1518\n",
      "training loss: 0.4741148012413225\n",
      "validation loss: 7.678998287347391\n",
      "loss difference:\n",
      "-0.04095525198197991\n",
      "that didn't improve loss:  1\n",
      "epoch: 1519\n",
      "training loss: 0.43268326993363904\n",
      "validation loss: 7.937317719733385\n",
      "loss difference:\n",
      "0.041431531307683456\n",
      "epoch: 1520\n",
      "training loss: 0.47355580613246884\n",
      "validation loss: 7.677050442722352\n",
      "loss difference:\n",
      "-0.0408725361988298\n",
      "that didn't improve loss:  1\n",
      "epoch: 1521\n",
      "training loss: 0.43220884522484815\n",
      "validation loss: 7.935285386932091\n",
      "loss difference:\n",
      "0.04134696090762069\n",
      "epoch: 1522\n",
      "training loss: 0.47299857884907465\n",
      "validation loss: 7.67510942125537\n",
      "loss difference:\n",
      "-0.0407897336242265\n",
      "that didn't improve loss:  1\n",
      "epoch: 1523\n",
      "training loss: 0.43173620341066726\n",
      "validation loss: 7.933260684487541\n",
      "loss difference:\n",
      "0.041262375438407384\n",
      "epoch: 1524\n",
      "training loss: 0.4724430313937191\n",
      "validation loss: 7.673175374914976\n",
      "loss difference:\n",
      "-0.04070682798305186\n",
      "that didn't improve loss:  1\n",
      "epoch: 1525\n",
      "training loss: 0.43126527170256046\n",
      "validation loss: 7.931243640232348\n",
      "loss difference:\n",
      "0.041177759691158666\n",
      "epoch: 1526\n",
      "training loss: 0.47188907498344324\n",
      "validation loss: 7.671248455235445\n",
      "loss difference:\n",
      "-0.040623803280882775\n",
      "that didn't improve loss:  1\n",
      "epoch: 1527\n",
      "training loss: 0.4307959768439839\n",
      "validation loss: 7.929234280946773\n",
      "loss difference:\n",
      "0.04109309813945933\n",
      "epoch: 1528\n",
      "training loss: 0.47133662083140154\n",
      "validation loss: 7.669328812861856\n",
      "loss difference:\n",
      "-0.040540643987417635\n",
      "that didn't improve loss:  1\n",
      "epoch: 1529\n",
      "training loss: 0.43032824570186545\n",
      "validation loss: 7.9272326330628236\n",
      "loss difference:\n",
      "0.04100837512953609\n",
      "epoch: 1530\n",
      "training loss: 0.4707855809125976\n",
      "validation loss: 7.667416597102746\n",
      "loss difference:\n",
      "-0.04045733521073214\n",
      "that didn't improve loss:  1\n",
      "epoch: 1531\n",
      "training loss: 0.4298620058456668\n",
      "validation loss: 7.925238723347204\n",
      "loss difference:\n",
      "0.040923575066930784\n",
      "epoch: 1532\n",
      "training loss: 0.4702358687065587\n",
      "validation loss: 7.665511955495048\n",
      "loss difference:\n",
      "-0.040373862860891896\n",
      "that didn't improve loss:  1\n",
      "epoch: 1533\n",
      "training loss: 0.42939718610853755\n",
      "validation loss: 7.923252579556402\n",
      "loss difference:\n",
      "0.04083868259802115\n",
      "epoch: 1534\n",
      "training loss: 0.4696873999099516\n",
      "validation loss: 7.663615033384579\n",
      "loss difference:\n",
      "-0.040290213801414065\n",
      "that didn't improve loss:  1\n",
      "epoch: 1535\n",
      "training loss: 0.42893371712532535\n",
      "validation loss: 7.921274231057969\n",
      "loss difference:\n",
      "0.040753682784626266\n",
      "epoch: 1536\n",
      "training loss: 0.46914009311271376\n",
      "validation loss: 7.661725973526345\n",
      "loss difference:\n",
      "-0.04020637598738841\n",
      "that didn't improve loss:  1\n",
      "epoch: 1537\n",
      "training loss: 0.4284715318425277\n",
      "validation loss: 7.919303709412224\n",
      "loss difference:\n",
      "0.04066856127018609\n",
      "epoch: 1538\n",
      "training loss: 0.4685938704316596\n",
      "validation loss: 7.659844915707761\n",
      "loss difference:\n",
      "-0.040122338589131945\n",
      "that didn't improve loss:  1\n",
      "epoch: 1539\n",
      "training loss: 0.4280105659955992\n",
      "validation loss: 7.917341048909406\n",
      "loss difference:\n",
      "0.0405833044360604\n",
      "epoch: 1540\n",
      "training loss: 0.4680486580960504\n",
      "validation loss: 7.657971996398116\n",
      "loss difference:\n",
      "-0.04003809210045117\n",
      "that didn't improve loss:  1\n",
      "epoch: 1541\n",
      "training loss: 0.4275507585494558\n",
      "validation loss: 7.915386287057461\n",
      "loss difference:\n",
      "0.04049789954659461\n",
      "epoch: 1542\n",
      "training loss: 0.4675043869802286\n",
      "validation loss: 7.656107348427034\n",
      "loss difference:\n",
      "-0.039953628430772825\n",
      "that didn't improve loss:  1\n",
      "epoch: 1543\n",
      "training loss: 0.42709205209844586\n",
      "validation loss: 7.913439465016731\n",
      "loss difference:\n",
      "0.04041233488178275\n",
      "epoch: 1544\n",
      "training loss: 0.46696099307902034\n",
      "validation loss: 7.654251100694526\n",
      "loss difference:\n",
      "-0.039868940980574474\n",
      "that didn't improve loss:  1\n",
      "epoch: 1545\n",
      "training loss: 0.4266343932224853\n",
      "validation loss: 7.9115006279780005\n",
      "loss difference:\n",
      "0.04032659985653503\n",
      "epoch: 1546\n",
      "training loss: 0.4664184179222175\n",
      "validation loss: 7.652403377914662\n",
      "loss difference:\n",
      "-0.03978402469973219\n",
      "that didn't improve loss:  1\n",
      "epoch: 1547\n",
      "training loss: 0.42617773279661914\n",
      "validation loss: 7.909569825481072\n",
      "loss difference:\n",
      "0.04024068512559836\n",
      "epoch: 1548\n",
      "training loss: 0.4658766089252373\n",
      "validation loss: 7.650564300394812\n",
      "loss difference:\n",
      "-0.039698876128618166\n",
      "that didn't improve loss:  1\n",
      "epoch: 1549\n",
      "training loss: 0.42572202625174416\n",
      "validation loss: 7.907647111672004\n",
      "loss difference:\n",
      "0.040154582673493144\n",
      "epoch: 1550\n",
      "training loss: 0.46533551967368436\n",
      "validation loss: 7.648733983851584\n",
      "loss difference:\n",
      "-0.039613493421940205\n",
      "that didn't improve loss:  1\n",
      "epoch: 1551\n",
      "training loss: 0.4252672337848201\n",
      "validation loss: 7.905732545497546\n",
      "loss difference:\n",
      "0.04006828588886424\n",
      "epoch: 1552\n",
      "training loss: 0.4647951101402587\n",
      "validation loss: 7.646912539264731\n",
      "loss difference:\n",
      "-0.039527876355438585\n",
      "that didn't improve loss:  1\n",
      "epoch: 1553\n",
      "training loss: 0.4248133205173639\n",
      "validation loss: 7.903826190835853\n",
      "loss difference:\n",
      "0.03998178962289478\n",
      "epoch: 1554\n",
      "training loss: 0.46425534683328445\n",
      "validation loss: 7.645100072769432\n",
      "loss difference:\n",
      "-0.03944202631592053\n",
      "that didn't improve loss:  1\n",
      "epoch: 1555\n",
      "training loss: 0.4243602566016983\n",
      "validation loss: 7.901928116563722\n",
      "loss difference:\n",
      "0.03989509023158616\n",
      "epoch: 1556\n",
      "training loss: 0.4637162028767004\n",
      "validation loss: 7.643296685587175\n",
      "loss difference:\n",
      "-0.03935594627500211\n",
      "that didn't improve loss:  1\n",
      "epoch: 1557\n",
      "training loss: 0.42390801727486044\n",
      "validation loss: 7.900038396560761\n",
      "loss difference:\n",
      "0.03980818560183996\n",
      "epoch: 1558\n",
      "training loss: 0.46317765802221184\n",
      "validation loss: 7.641502473995117\n",
      "loss difference:\n",
      "-0.0392696407473514\n",
      "that didn't improve loss:  1\n",
      "epoch: 1559\n",
      "training loss: 0.42345658286072346\n",
      "validation loss: 7.8981571096517795\n",
      "loss difference:\n",
      "0.03972107516148837\n",
      "epoch: 1560\n",
      "training loss: 0.4626396985949279\n",
      "validation loss: 7.639717529333284\n",
      "loss difference:\n",
      "-0.03918311573420441\n",
      "that didn't improve loss:  1\n",
      "epoch: 1561\n",
      "training loss: 0.42300593872135167\n",
      "validation loss: 7.896284339489358\n",
      "loss difference:\n",
      "0.0396337598735762\n",
      "epoch: 1562\n",
      "training loss: 0.4621023173744535\n",
      "validation loss: 7.637941938048641\n",
      "loss difference:\n",
      "-0.03909637865310184\n",
      "that didn't improve loss:  1\n",
      "epoch: 1563\n",
      "training loss: 0.4225560751591596\n",
      "validation loss: 7.89442017437896\n",
      "loss difference:\n",
      "0.0395462422152939\n",
      "epoch: 1564\n",
      "training loss: 0.4615655134141555\n",
      "validation loss: 7.6361757817748455\n",
      "loss difference:\n",
      "-0.03900943825499592\n",
      "that didn't improve loss:  1\n",
      "epoch: 1565\n",
      "training loss: 0.4221069872719185\n",
      "validation loss: 7.892564707049614\n",
      "loss difference:\n",
      "0.03945852614223705\n",
      "epoch: 1566\n",
      "training loss: 0.46102929180173613\n",
      "validation loss: 7.634419137445945\n",
      "loss difference:\n",
      "-0.03892230452981765\n",
      "that didn't improve loss:  1\n",
      "epoch: 1567\n",
      "training loss: 0.421658674763109\n",
      "validation loss: 7.890718034373786\n",
      "loss difference:\n",
      "0.039370617038627154\n",
      "epoch: 1568\n",
      "training loss: 0.4604936633649788\n",
      "validation loss: 7.632672077442115\n",
      "loss difference:\n",
      "-0.038834988601869846\n",
      "that didn't improve loss:  1\n",
      "epoch: 1569\n",
      "training loss: 0.42121114171055685\n",
      "validation loss: 7.888880257040264\n",
      "loss difference:\n",
      "0.039282521654421976\n",
      "epoch: 1570\n",
      "training loss: 0.45995864432690214\n",
      "validation loss: 7.630934669765263\n",
      "loss difference:\n",
      "-0.0387475026163453\n",
      "that didn't improve loss:  1\n",
      "epoch: 1571\n",
      "training loss: 0.42076439629662243\n",
      "validation loss: 7.88705147918455\n",
      "loss difference:\n",
      "0.03919424803027971\n",
      "epoch: 1572\n",
      "training loss: 0.45942425591500957\n",
      "validation loss: 7.629206978242041\n",
      "loss difference:\n",
      "-0.03865985961838714\n",
      "that didn't improve loss:  1\n",
      "epoch: 1573\n",
      "training loss: 0.42031845050359495\n",
      "validation loss: 7.8852318079814445\n",
      "loss difference:\n",
      "0.03910580541141462\n",
      "epoch: 1574\n",
      "training loss: 0.45889052392974905\n",
      "validation loss: 7.6274890627514615\n",
      "loss difference:\n",
      "-0.038572073426154097\n",
      "that didn't improve loss:  1\n",
      "epoch: 1575\n",
      "training loss: 0.41987331977819836\n",
      "validation loss: 7.8834213532048025\n",
      "loss difference:\n",
      "0.03901720415155069\n",
      "epoch: 1576\n",
      "training loss: 0.45835747827756324\n",
      "validation loss: 7.625780979474448\n",
      "loss difference:\n",
      "-0.03848415849936487\n",
      "that didn't improve loss:  1\n",
      "epoch: 1577\n",
      "training loss: 0.41942902266938903\n",
      "validation loss: 7.881620226759838\n",
      "loss difference:\n",
      "0.038928455608174206\n",
      "epoch: 1578\n",
      "training loss: 0.45782515247416894\n",
      "validation loss: 7.624082781162104\n",
      "loss difference:\n",
      "-0.03839612980477991\n",
      "that didn't improve loss:  1\n",
      "epoch: 1579\n",
      "training loss: 0.4189855804437405\n",
      "validation loss: 7.879828542193207\n",
      "loss difference:\n",
      "0.038839572030428426\n",
      "epoch: 1580\n",
      "training loss: 0.4572935831238413\n",
      "validation loss: 7.622394517419708\n",
      "loss difference:\n",
      "-0.03830800268010076\n",
      "that didn't improve loss:  1\n",
      "epoch: 1581\n",
      "training loss: 0.4185430166829169\n",
      "validation loss: 7.87804641418657\n",
      "loss difference:\n",
      "0.038750566440924394\n",
      "epoch: 1582\n",
      "training loss: 0.45676280938067\n",
      "validation loss: 7.620716235003139\n",
      "loss difference:\n",
      "-0.03821979269775311\n",
      "that didn't improve loss:  1\n",
      "epoch: 1583\n",
      "training loss: 0.4181013568677829\n",
      "validation loss: 7.8762739580390475\n",
      "loss difference:\n",
      "0.03866145251288711\n",
      "epoch: 1584\n",
      "training loss: 0.45623287239769794\n",
      "validation loss: 7.619047978124495\n",
      "loss difference:\n",
      "-0.03813151552991506\n",
      "that didn't improve loss:  1\n",
      "epoch: 1585\n",
      "training loss: 0.41766062795372866\n",
      "validation loss: 7.874511289144237\n",
      "loss difference:\n",
      "0.038572244443969284\n",
      "epoch: 1586\n",
      "training loss: 0.4557038147699258\n",
      "validation loss: 7.6173897887635755\n",
      "loss difference:\n",
      "-0.038043186816197117\n",
      "that didn't improve loss:  1\n",
      "epoch: 1587\n",
      "training loss: 0.417220857941773\n",
      "validation loss: 7.872758522467189\n",
      "loss difference:\n",
      "0.03848295682815278\n",
      "epoch: 1588\n",
      "training loss: 0.4551756799769864\n",
      "validation loss: 7.615741706982075\n",
      "loss difference:\n",
      "-0.03795482203521339\n",
      "that didn't improve loss:  1\n",
      "epoch: 1589\n",
      "training loss: 0.4167820754499284\n",
      "validation loss: 7.871015772026704\n",
      "loss difference:\n",
      "0.03839360452705798\n",
      "epoch: 1590\n",
      "training loss: 0.4546485118312052\n",
      "validation loss: 7.614103771237215\n",
      "loss difference:\n",
      "-0.03786643638127679\n",
      "that didn't improve loss:  1\n",
      "epoch: 1591\n",
      "training loss: 0.4163443092892315\n",
      "validation loss: 7.869283150388096\n",
      "loss difference:\n",
      "0.0383042025419737\n",
      "epoch: 1592\n",
      "training loss: 0.45412235393657446\n",
      "validation loss: 7.6124760186916935\n",
      "loss difference:\n",
      "-0.03777804464734297\n",
      "that didn't improve loss:  1\n",
      "epoch: 1593\n",
      "training loss: 0.41590758804862493\n",
      "validation loss: 7.867560768171437\n",
      "loss difference:\n",
      "0.03821476588794953\n",
      "epoch: 1594\n",
      "training loss: 0.4535972491638234\n",
      "validation loss: 7.610858485517026\n",
      "loss difference:\n",
      "-0.03768966111519845\n",
      "that didn't improve loss:  1\n",
      "epoch: 1595\n",
      "training loss: 0.415471939692739\n",
      "validation loss: 7.865848733579762\n",
      "loss difference:\n",
      "0.03812530947108439\n",
      "epoch: 1596\n",
      "training loss: 0.45307323914660164\n",
      "validation loss: 7.609251207187303\n",
      "loss difference:\n",
      "-0.03760129945386265\n",
      "that didn't improve loss:  1\n",
      "epoch: 1597\n",
      "training loss: 0.41503739117635424\n",
      "validation loss: 7.864147151951736\n",
      "loss difference:\n",
      "0.038035847970247394\n",
      "epoch: 1598\n",
      "training loss: 0.4525503638033115\n",
      "validation loss: 7.607654218760869\n",
      "loss difference:\n",
      "-0.03751297262695724\n",
      "that didn't improve loss:  1\n",
      "epoch: 1599\n",
      "training loss: 0.41460396807907257\n",
      "validation loss: 7.862456125342683\n",
      "loss difference:\n",
      "0.03794639572423891\n",
      "epoch: 1600\n",
      "training loss: 0.45202866088882737\n",
      "validation loss: 7.606067555147244\n",
      "loss difference:\n",
      "-0.0374246928097548\n",
      "that didn't improve loss:  1\n",
      "epoch: 1601\n",
      "training loss: 0.4141716942634014\n",
      "validation loss: 7.860775752137556\n",
      "loss difference:\n",
      "0.03785696662542598\n",
      "epoch: 1602\n",
      "training loss: 0.4515081655799176\n",
      "validation loss: 7.604491251357098\n",
      "loss difference:\n",
      "-0.037336471316516184\n",
      "that didn't improve loss:  1\n",
      "epoch: 1603\n",
      "training loss: 0.4137405915591966\n",
      "validation loss: 7.85910612669904\n",
      "loss difference:\n",
      "0.03776757402072095\n",
      "epoch: 1604\n",
      "training loss: 0.45098891009771364\n",
      "validation loss: 7.602925342733189\n",
      "loss difference:\n",
      "-0.03724831853851701\n",
      "that didn't improve loss:  1\n",
      "epoch: 1605\n",
      "training loss: 0.41331067947701083\n",
      "validation loss: 7.857447339053615\n",
      "loss difference:\n",
      "0.0376782306207028\n",
      "epoch: 1606\n",
      "training loss: 0.4504709233701091\n",
      "validation loss: 7.601369865160584\n",
      "loss difference:\n",
      "-0.037160243893098244\n",
      "that didn't improve loss:  1\n",
      "epoch: 1607\n",
      "training loss: 0.4128819749525609\n",
      "validation loss: 7.855799474617742\n",
      "loss difference:\n",
      "0.037588948417548174\n",
      "epoch: 1608\n",
      "training loss: 0.44995423073657403\n",
      "validation loss: 7.599824855254397\n",
      "loss difference:\n",
      "-0.03707225578401313\n",
      "that didn't improve loss:  1\n",
      "epoch: 1609\n",
      "training loss: 0.41245449212415947\n",
      "validation loss: 7.854162613966139\n",
      "loss difference:\n",
      "0.03749973861241457\n",
      "epoch: 1610\n",
      "training loss: 0.44943885369721404\n",
      "validation loss: 7.598290350523888\n",
      "loss difference:\n",
      "-0.03698436157305457\n",
      "that didn't improve loss:  1\n",
      "epoch: 1611\n",
      "training loss: 0.4120282421446128\n",
      "validation loss: 7.852536832643458\n",
      "loss difference:\n",
      "0.037410611552601225\n",
      "epoch: 1612\n",
      "training loss: 0.4489248097076396\n",
      "validation loss: 7.596766389511891\n",
      "loss difference:\n",
      "-0.03689656756302678\n",
      "that didn't improve loss:  1\n",
      "epoch: 1613\n",
      "training loss: 0.41160323302861357\n",
      "validation loss: 7.850922201020283\n",
      "loss difference:\n",
      "0.037321576679026025\n",
      "epoch: 1614\n",
      "training loss: 0.44841211202047604\n",
      "validation loss: 7.59525301190888\n",
      "loss difference:\n",
      "-0.03680887899186247\n",
      "that didn't improve loss:  1\n",
      "epoch: 1615\n",
      "training loss: 0.41117946953641227\n",
      "validation loss: 7.849318784193938\n",
      "loss difference:\n",
      "0.03723264248406377\n",
      "epoch: 1616\n",
      "training loss: 0.4479007695740571\n",
      "validation loss: 7.5937502586409575\n",
      "loss difference:\n",
      "-0.036721300037644844\n",
      "that didn't improve loss:  1\n",
      "epoch: 1617\n",
      "training loss: 0.410756953094051\n",
      "validation loss: 7.847726641934008\n",
      "loss difference:\n",
      "0.03714381648000609\n",
      "epoch: 1618\n",
      "training loss: 0.4473907869282458\n",
      "validation loss: 7.592258171931921\n",
      "loss difference:\n",
      "-0.03663383383419477\n",
      "that didn't improve loss:  1\n",
      "epoch: 1619\n",
      "training loss: 0.4103356817501423\n",
      "validation loss: 7.84614582867224\n",
      "loss difference:\n",
      "0.03705510517810351\n",
      "epoch: 1620\n",
      "training loss: 0.4468821642469024\n",
      "validation loss: 7.590776795339155\n",
      "loss difference:\n",
      "-0.036546482496760124\n",
      "that didn't improve loss:  1\n",
      "epoch: 1621\n",
      "training loss: 0.4099156501688146\n",
      "validation loss: 7.8445763935358706\n",
      "loss difference:\n",
      "0.03696651407808782\n",
      "epoch: 1622\n",
      "training loss: 0.44637489732606306\n",
      "validation loss: 7.589306173763863\n",
      "loss difference:\n",
      "-0.036459247157248464\n",
      "that didn't improve loss:  1\n",
      "epoch: 1623\n",
      "training loss: 0.40949684965805505\n",
      "validation loss: 7.843018380423078\n",
      "loss difference:\n",
      "0.03687804766800801\n",
      "epoch: 1624\n",
      "training loss: 0.4458689776664464\n",
      "validation loss: 7.587846353436082\n",
      "loss difference:\n",
      "-0.03637212800839135\n",
      "that didn't improve loss:  1\n",
      "epoch: 1625\n",
      "training loss: 0.40907926823238505\n",
      "validation loss: 7.841471828118958\n",
      "loss difference:\n",
      "0.036789709434061346\n",
      "epoch: 1626\n",
      "training loss: 0.4453643925885617\n",
      "validation loss: 7.586397381875403\n",
      "loss difference:\n",
      "-0.036285124356176646\n",
      "that didn't improve loss:  1\n",
      "epoch: 1627\n",
      "training loss: 0.4086628907085169\n",
      "validation loss: 7.839936770449904\n",
      "loss difference:\n",
      "0.036701501880044785\n",
      "epoch: 1628\n",
      "training loss: 0.44486112538822364\n",
      "validation loss: 7.584959307828364\n",
      "loss difference:\n",
      "-0.03619823467970673\n",
      "that didn't improve loss:  1\n",
      "epoch: 1629\n",
      "training loss: 0.40824769883224765\n",
      "validation loss: 7.838413236474108\n",
      "loss difference:\n",
      "0.03661342655597599\n",
      "epoch: 1630\n",
      "training loss: 0.4443591555300116\n",
      "validation loss: 7.583532181183672\n",
      "loss difference:\n",
      "-0.036111456697763944\n",
      "that didn't improve loss:  1\n",
      "epoch: 1631\n",
      "training loss: 0.40783367143471305\n",
      "validation loss: 7.836901250705405\n",
      "loss difference:\n",
      "0.036525484095298544\n",
      "epoch: 1632\n",
      "training loss: 0.4438584588758411\n",
      "validation loss: 7.582116052866879\n",
      "loss difference:\n",
      "-0.036024787441128026\n",
      "that didn't improve loss:  1\n",
      "epoch: 1633\n",
      "training loss: 0.4074207846157485\n",
      "validation loss: 7.835400833367753\n",
      "loss difference:\n",
      "0.03643767426009259\n",
      "epoch: 1634\n",
      "training loss: 0.4433590079455537\n",
      "validation loss: 7.580710974715958\n",
      "loss difference:\n",
      "-0.03593822332980523\n",
      "that didn't improve loss:  1\n",
      "epoch: 1635\n",
      "training loss: 0.4070090119519781\n",
      "validation loss: 7.83391200067675\n",
      "loss difference:\n",
      "0.036349995993575634\n",
      "epoch: 1636\n",
      "training loss: 0.4428607722062187\n",
      "validation loss: 7.579316999339582\n",
      "loss difference:\n",
      "-0.03585176025424064\n",
      "that didn't improve loss:  1\n",
      "epoch: 1637\n",
      "training loss: 0.4065983247270181\n",
      "validation loss: 7.832434765145337\n",
      "loss difference:\n",
      "0.0362624474792006\n",
      "epoch: 1638\n",
      "training loss: 0.4423637183865501\n",
      "validation loss: 7.577934179959979\n",
      "loss difference:\n",
      "-0.03576539365953196\n",
      "that didn't improve loss:  1\n",
      "epoch: 1639\n",
      "training loss: 0.40618869218101417\n",
      "validation loss: 7.830969135909807\n",
      "loss difference:\n",
      "0.03617502620553592\n",
      "epoch: 1640\n",
      "training loss: 0.4418678108127556\n",
      "validation loss: 7.576562570242419\n",
      "loss difference:\n",
      "-0.03567911863174145\n",
      "that didn't improve loss:  1\n",
      "epoch: 1641\n",
      "training loss: 0.40578008177662234\n",
      "validation loss: 7.82951511907248\n",
      "loss difference:\n",
      "0.036087729036133276\n",
      "epoch: 1642\n",
      "training loss: 0.4413730117619776\n",
      "validation loss: 7.575202224113316\n",
      "loss difference:\n",
      "-0.03559292998535524\n",
      "that didn't improve loss:  1\n",
      "epoch: 1643\n",
      "training loss: 0.40537245947844003\n",
      "validation loss: 7.828072718057549\n",
      "loss difference:\n",
      "0.036000552283537546\n",
      "epoch: 1644\n",
      "training loss: 0.4408792818293574\n",
      "validation loss: 7.573853195569238\n",
      "loss difference:\n",
      "-0.035506822350917344\n",
      "that didn't improve loss:  1\n",
      "epoch: 1645\n",
      "training loss: 0.40496579004276184\n",
      "validation loss: 7.826641933976007\n",
      "loss difference:\n",
      "0.03591349178659553\n",
      "epoch: 1646\n",
      "training loss: 0.4403865803047473\n",
      "validation loss: 7.572515538478886\n",
      "loss difference:\n",
      "-0.03542079026198547\n",
      "that didn't improve loss:  1\n",
      "epoch: 1647\n",
      "training loss: 0.40456003731459844\n",
      "validation loss: 7.825222765996033\n",
      "loss difference:\n",
      "0.03582654299014887\n",
      "epoch: 1648\n",
      "training loss: 0.43989486555508805\n",
      "validation loss: 7.571189306380303\n",
      "loss difference:\n",
      "-0.03533482824048961\n",
      "that didn't improve loss:  1\n",
      "epoch: 1649\n",
      "training loss: 0.4041551645287926\n",
      "validation loss: 7.82381521171506\n",
      "loss difference:\n",
      "0.03573970102629548\n",
      "epoch: 1650\n",
      "training loss: 0.43940409540847236\n",
      "validation loss: 7.569874552275643\n",
      "loss difference:\n",
      "-0.035248930879679785\n",
      "that didn't improve loss:  1\n",
      "epoch: 1651\n",
      "training loss: 0.4037511346121344\n",
      "validation loss: 7.822419267529781\n",
      "loss difference:\n",
      "0.03565296079633795\n",
      "epoch: 1652\n",
      "training loss: 0.43891422753597126\n",
      "validation loss: 7.568571328425526\n",
      "loss difference:\n",
      "-0.03516309292383685\n",
      "that didn't improve loss:  1\n",
      "epoch: 1653\n",
      "training loss: 0.4033479104834326\n",
      "validation loss: 7.821034929000439\n",
      "loss difference:\n",
      "0.035566317052538654\n",
      "epoch: 1654\n",
      "training loss: 0.438425219827461\n",
      "validation loss: 7.5672796861451666\n",
      "loss difference:\n",
      "-0.03507730934402842\n",
      "that didn't improve loss:  1\n",
      "epoch: 1655\n",
      "training loss: 0.40294545534852433\n",
      "validation loss: 7.819662191206069\n",
      "loss difference:\n",
      "0.03547976447893669\n",
      "epoch: 1656\n",
      "training loss: 0.43793703075775503\n",
      "validation loss: 7.565999675604499\n",
      "loss difference:\n",
      "-0.0349915754092307\n",
      "that didn't improve loss:  1\n",
      "epoch: 1657\n",
      "training loss: 0.4025437329874104\n",
      "validation loss: 7.818301049087214\n",
      "loss difference:\n",
      "0.03539329777034461\n",
      "epoch: 1658\n",
      "training loss: 0.4374496197395991\n",
      "validation loss: 7.5647313456341125\n",
      "loss difference:\n",
      "-0.0349058867521887\n",
      "that didn't improve loss:  1\n",
      "epoch: 1659\n",
      "training loss: 0.40214270803073704\n",
      "validation loss: 7.816951497773219\n",
      "loss difference:\n",
      "0.035306911708862077\n",
      "epoch: 1660\n",
      "training loss: 0.4369629474602108\n",
      "validation loss: 7.563474743539028\n",
      "loss difference:\n",
      "-0.034820239429473765\n",
      "that didn't improve loss:  1\n",
      "epoch: 1661\n",
      "training loss: 0.4017423462230802\n",
      "validation loss: 7.815613532890941\n",
      "loss difference:\n",
      "0.03522060123713061\n",
      "epoch: 1662\n",
      "training loss: 0.4364769761983359\n",
      "validation loss: 7.56222991492197\n",
      "loss difference:\n",
      "-0.034734629975255726\n",
      "that didn't improve loss:  1\n",
      "epoch: 1663\n",
      "training loss: 0.40134261467062693\n",
      "validation loss: 7.814287150852518\n",
      "loss difference:\n",
      "0.03513436152770899\n",
      "epoch: 1664\n",
      "training loss: 0.4359916701190495\n",
      "validation loss: 7.560996903517955\n",
      "loss difference:\n",
      "-0.03464905544842256\n",
      "that didn't improve loss:  1\n",
      "epoch: 1665\n",
      "training loss: 0.400943482071082\n",
      "validation loss: 7.812972349119623\n",
      "loss difference:\n",
      "0.0350481880479675\n",
      "epoch: 1666\n",
      "training loss: 0.4355069955437868\n",
      "validation loss: 7.559775751041443\n",
      "loss difference:\n",
      "-0.03456351347270481\n",
      "that didn't improve loss:  1\n",
      "epoch: 1667\n",
      "training loss: 0.40054491892383526\n",
      "validation loss: 7.811669126442175\n",
      "loss difference:\n",
      "0.03496207661995154\n",
      "epoch: 1668\n",
      "training loss: 0.43502292119341623\n",
      "validation loss: 7.558566497047636\n",
      "loss difference:\n",
      "-0.034478002269580976\n",
      "that didn't improve loss:  1\n",
      "epoch: 1669\n",
      "training loss: 0.40014689771866874\n",
      "validation loss: 7.8103774830698365\n",
      "loss difference:\n",
      "0.0348760234747475\n",
      "epoch: 1670\n",
      "training loss: 0.43453941840248855\n",
      "validation loss: 7.557369178808943\n",
      "loss difference:\n",
      "-0.034392520683819816\n",
      "that didn't improve loss:  1\n",
      "epoch: 1671\n",
      "training loss: 0.3997493931015427\n",
      "validation loss: 7.809097420934642\n",
      "loss difference:\n",
      "0.034790025300945826\n",
      "epoch: 1672\n",
      "training loss: 0.4340564613031146\n",
      "validation loss: 7.556183831207564\n",
      "loss difference:\n",
      "-0.034307068201571866\n",
      "that didn't improve loss:  1\n",
      "epoch: 1673\n",
      "training loss: 0.39935238201625767\n",
      "validation loss: 7.8078289438037185\n",
      "loss difference:\n",
      "0.034704079286856926\n",
      "epoch: 1674\n",
      "training loss: 0.43357402697728886\n",
      "validation loss: 7.555010486645096\n",
      "loss difference:\n",
      "-0.034221644961031195\n",
      "that didn't improve loss:  1\n",
      "epoch: 1675\n",
      "training loss: 0.39895584382106036\n",
      "validation loss: 7.806572057401402\n",
      "loss difference:\n",
      "0.0346181831562285\n",
      "epoch: 1676\n",
      "training loss: 0.4330920955768156\n",
      "validation loss: 7.553849174969701\n",
      "loss difference:\n",
      "-0.03413625175575524\n",
      "that didn't improve loss:  1\n",
      "epoch: 1677\n",
      "training loss: 0.39855976037954033\n",
      "validation loss: 7.8053267695000415\n",
      "loss difference:\n",
      "0.03453233519727528\n",
      "epoch: 1678\n",
      "training loss: 0.4326106504103179\n",
      "validation loss: 7.552699923421273\n",
      "loss difference:\n",
      "-0.03405089003077755\n",
      "that didn't improve loss:  1\n",
      "epoch: 1679\n",
      "training loss: 0.3981641161254443\n",
      "validation loss: 7.804093089979434\n",
      "loss difference:\n",
      "0.0344465342848736\n",
      "epoch: 1680\n",
      "training loss: 0.4321296779972278\n",
      "validation loss: 7.551562756594793\n",
      "loss difference:\n",
      "-0.03396556187178351\n",
      "that didn't improve loss:  1\n",
      "epoch: 1681\n",
      "training loss: 0.3977688981013089\n",
      "validation loss: 7.802871030855234\n",
      "loss difference:\n",
      "0.0343607798959189\n",
      "epoch: 1682\n",
      "training loss: 0.4316491680889191\n",
      "validation loss: 7.550437696421979\n",
      "loss difference:\n",
      "-0.033880269987610234\n",
      "that didn't improve loss:  1\n",
      "epoch: 1683\n",
      "training loss: 0.3973740959710683\n",
      "validation loss: 7.801660606276446\n",
      "loss difference:\n",
      "0.0342750721178508\n",
      "epoch: 1684\n",
      "training loss: 0.4311691136575456\n",
      "validation loss: 7.549324762170984\n",
      "loss difference:\n",
      "-0.0337950176864773\n",
      "that didn't improve loss:  1\n",
      "epoch: 1685\n",
      "training loss: 0.39697970200711513\n",
      "validation loss: 7.800461832493243\n",
      "loss difference:\n",
      "0.03418941165043049\n",
      "epoch: 1686\n",
      "training loss: 0.4306895108533968\n",
      "validation loss: 7.5482239704638925\n",
      "loss difference:\n",
      "-0.033709808846281664\n",
      "that didn't improve loss:  1\n",
      "epoch: 1687\n",
      "training loss: 0.39658571105245527\n",
      "validation loss: 7.799274727795781\n",
      "loss difference:\n",
      "0.034103799800941526\n",
      "epoch: 1688\n",
      "training loss: 0.4302103589319814\n",
      "validation loss: 7.547135335311486\n",
      "loss difference:\n",
      "-0.033624647879526126\n",
      "that didn't improve loss:  1\n",
      "epoch: 1689\n",
      "training loss: 0.39619212045892244\n",
      "validation loss: 7.798099312425641\n",
      "loss difference:\n",
      "0.03401823847305896\n",
      "epoch: 1690\n",
      "training loss: 0.4297316601522369\n",
      "validation loss: 7.546058868164558\n",
      "loss difference:\n",
      "-0.03353953969331447\n",
      "that didn't improve loss:  1\n",
      "epoch: 1691\n",
      "training loss: 0.39579893000260175\n",
      "validation loss: 7.796935608461346\n",
      "loss difference:\n",
      "0.03393273014963516\n",
      "epoch: 1692\n",
      "training loss: 0.4292534196475809\n",
      "validation loss: 7.544994577981071\n",
      "loss difference:\n",
      "-0.03345448964497916\n",
      "that didn't improve loss:  1\n",
      "epoch: 1693\n",
      "training loss: 0.39540614177781547\n",
      "validation loss: 7.795783639679794\n",
      "loss difference:\n",
      "0.033847277869765435\n",
      "epoch: 1694\n",
      "training loss: 0.4287756452717608\n",
      "validation loss: 7.54394247130812\n",
      "loss difference:\n",
      "-0.03336950349394535\n",
      "that didn't improve loss:  1\n",
      "epoch: 1695\n",
      "training loss: 0.3950137600712637\n",
      "validation loss: 7.7946434313957225\n",
      "loss difference:\n",
      "0.03376188520049711\n",
      "epoch: 1696\n",
      "training loss: 0.42829834742164735\n",
      "validation loss: 7.54290255237754\n",
      "loss difference:\n",
      "-0.03328458735038364\n",
      "that didn't improve loss:  1\n",
      "epoch: 1697\n",
      "training loss: 0.39462179121798957\n",
      "validation loss: 7.793515010281284\n",
      "loss difference:\n",
      "0.03367655620365778\n",
      "epoch: 1698\n",
      "training loss: 0.4278215388393133\n",
      "validation loss: 7.5418748232142026\n",
      "loss difference:\n",
      "-0.033199747621323716\n",
      "that didn't improve loss:  1\n",
      "epoch: 1699\n",
      "training loss: 0.39423024344110713\n",
      "validation loss: 7.792398404168148\n",
      "loss difference:\n",
      "0.033591295398206156\n",
      "epoch: 1700\n",
      "training loss: 0.4273452343959098\n",
      "validation loss: 7.540859283755406\n",
      "loss difference:\n",
      "-0.03311499095480269\n",
      "that didn't improve loss:  1\n",
      "epoch: 1701\n",
      "training loss: 0.3938391266772201\n",
      "validation loss: 7.7912936418346295\n",
      "loss difference:\n",
      "0.033506107718689726\n",
      "epoch: 1702\n",
      "training loss: 0.426869450859914\n",
      "validation loss: 7.539855931980239\n",
      "loss difference:\n",
      "-0.033030324182693915\n",
      "that didn't improve loss:  1\n",
      "epoch: 1703\n",
      "training loss: 0.3934484523896611\n",
      "validation loss: 7.790200752780357\n",
      "loss difference:\n",
      "0.03342099847025293\n",
      "epoch: 1704\n",
      "training loss: 0.4263942066525244\n",
      "validation loss: 7.5388647640472755\n",
      "loss difference:\n",
      "-0.032945754262863336\n",
      "that didn't improve loss:  1\n",
      "epoch: 1705\n",
      "training loss: 0.39305823337171364\n",
      "validation loss: 7.7891197669911065\n",
      "loss difference:\n",
      "0.03333597328081078\n",
      "epoch: 1706\n",
      "training loss: 0.4259195215929418\n",
      "validation loss: 7.537885774439221\n",
      "loss difference:\n",
      "-0.032861288221228135\n",
      "that didn't improve loss:  1\n",
      "epoch: 1707\n",
      "training loss: 0.39266848354200656\n",
      "validation loss: 7.78805071469654\n",
      "loss difference:\n",
      "0.03325103805093521\n",
      "epoch: 1708\n",
      "training loss: 0.4254454166363458\n",
      "validation loss: 7.536918956112984\n",
      "loss difference:\n",
      "-0.03277693309433921\n",
      "that didn't improve loss:  1\n",
      "epoch: 1709\n",
      "training loss: 0.3922792177343595\n",
      "validation loss: 7.786993626123403\n",
      "loss difference:\n",
      "0.0331661989019863\n",
      "epoch: 1710\n",
      "training loss: 0.4249719136073949\n",
      "validation loss: 7.535964300653557\n",
      "loss difference:\n",
      "-0.032692695873035416\n",
      "that didn't improve loss:  1\n",
      "epoch: 1711\n",
      "training loss: 0.3918904514842802\n",
      "validation loss: 7.785948531246964\n",
      "loss difference:\n",
      "0.03308146212311469\n",
      "epoch: 1712\n",
      "training loss: 0.42449903493202285\n",
      "validation loss: 7.535021798430214\n",
      "loss difference:\n",
      "-0.032608583447742645\n",
      "that didn't improve loss:  1\n",
      "epoch: 1713\n",
      "training loss: 0.3915022008143416\n",
      "validation loss: 7.784915459543154\n",
      "loss difference:\n",
      "0.03299683411768123\n",
      "epoch: 1714\n",
      "training loss: 0.4240268033702556\n",
      "validation loss: 7.534091438753545\n",
      "loss difference:\n",
      "-0.032524602555913995\n",
      "that didn't improve loss:  1\n",
      "epoch: 1715\n",
      "training loss: 0.3911144820206371\n",
      "validation loss: 7.783894439744065\n",
      "loss difference:\n",
      "0.03291232134961852\n",
      "epoch: 1716\n",
      "training loss: 0.42355524175271225\n",
      "validation loss: 7.53317321003168\n",
      "loss difference:\n",
      "-0.032440759732075164\n",
      "that didn't improve loss:  1\n",
      "epoch: 1717\n",
      "training loss: 0.39072731146236467\n",
      "validation loss: 7.782885499599136\n",
      "loss difference:\n",
      "0.032827930290347584\n",
      "epoch: 1718\n",
      "training loss: 0.4230843727232992\n",
      "validation loss: 7.532267099924432\n",
      "loss difference:\n",
      "-0.032357061260934517\n",
      "that didn't improve loss:  1\n",
      "epoch: 1719\n",
      "training loss: 0.3903407053566124\n",
      "validation loss: 7.78188866564439\n",
      "loss difference:\n",
      "0.03274366736668677\n",
      "epoch: 1720\n",
      "training loss: 0.42261421849053654\n",
      "validation loss: 7.531373095493845\n",
      "loss difference:\n",
      "-0.032273513133924125\n",
      "that didn't improve loss:  1\n",
      "epoch: 1721\n",
      "training loss: 0.3899546795802155\n",
      "validation loss: 7.780903962981886\n",
      "loss difference:\n",
      "0.03265953891032103\n",
      "epoch: 1722\n",
      "training loss: 0.42214480058972975\n",
      "validation loss: 7.53049118334985\n",
      "loss difference:\n",
      "-0.03219012100951424\n",
      "that didn't improve loss:  1\n",
      "epoch: 1723\n",
      "training loss: 0.3895692494805028\n",
      "validation loss: 7.779931415071398\n",
      "loss difference:\n",
      "0.03257555110922694\n",
      "epoch: 1724\n",
      "training loss: 0.42167613965813777\n",
      "validation loss: 7.5296213497897835\n",
      "loss difference:\n",
      "-0.03210689017763496\n",
      "that didn't improve loss:  1\n",
      "epoch: 1725\n",
      "training loss: 0.38918442969657585\n",
      "validation loss: 7.778971043536091\n",
      "loss difference:\n",
      "0.03249170996156192\n",
      "epoch: 1726\n",
      "training loss: 0.42120825522496846\n",
      "validation loss: 7.528763580930699\n",
      "loss difference:\n",
      "-0.03202382552839261\n",
      "that didn't improve loss:  1\n",
      "epoch: 1727\n",
      "training loss: 0.3888002339926339\n",
      "validation loss: 7.778022867983964\n",
      "loss difference:\n",
      "0.03240802123233455\n",
      "epoch: 1728\n",
      "training loss: 0.4207411655179425\n",
      "validation loss: 7.527917862833258\n",
      "loss difference:\n",
      "-0.03194093152530858\n",
      "that didn't improve loss:  1\n",
      "epoch: 1729\n",
      "training loss: 0.3884166751046865\n",
      "validation loss: 7.777086905846461\n",
      "loss difference:\n",
      "0.03232449041325597\n",
      "epoch: 1730\n",
      "training loss: 0.42027488728790285\n",
      "validation loss: 7.527084181616456\n",
      "loss difference:\n",
      "-0.03185821218321633\n",
      "that didn't improve loss:  1\n",
      "epoch: 1731\n",
      "training loss: 0.3880337646018267\n",
      "validation loss: 7.77616317223538\n",
      "loss difference:\n",
      "0.03224112268607615\n",
      "epoch: 1732\n",
      "training loss: 0.41980943565273793\n",
      "validation loss: 7.526262523562179\n",
      "loss difference:\n",
      "-0.031775671050911225\n",
      "that didn't improve loss:  1\n",
      "epoch: 1733\n",
      "training loss: 0.38765151276307136\n",
      "validation loss: 7.775251679819299\n",
      "loss difference:\n",
      "0.03215792288966657\n",
      "epoch: 1734\n",
      "training loss: 0.4193448239616523\n",
      "validation loss: 7.5254528752090595\n",
      "loss difference:\n",
      "-0.03169331119858093\n",
      "that didn't improve loss:  1\n",
      "epoch: 1735\n",
      "training loss: 0.3872699284705978\n",
      "validation loss: 7.774352438720207\n",
      "loss difference:\n",
      "0.03207489549105447\n",
      "epoch: 1736\n",
      "training loss: 0.41888106368062245\n",
      "validation loss: 7.524655223434874\n",
      "loss difference:\n",
      "-0.03161113521002462\n",
      "that didn't improve loss:  1\n",
      "epoch: 1737\n",
      "training loss: 0.386889019119994\n",
      "validation loss: 7.7734654564309436\n",
      "loss difference:\n",
      "0.03199204456062843\n",
      "epoch: 1738\n",
      "training loss: 0.4184181642995779\n",
      "validation loss: 7.523869555527212\n",
      "loss difference:\n",
      "-0.031529145179583884\n",
      "that didn't improve loss:  1\n",
      "epoch: 1739\n",
      "training loss: 0.3865087905479841\n",
      "validation loss: 7.772590737753803\n",
      "loss difference:\n",
      "0.031909373751593806\n",
      "epoch: 1740\n",
      "training loss: 0.41795613326168085\n",
      "validation loss: 7.523095859241975\n",
      "loss difference:\n",
      "-0.03144734271369676\n",
      "that didn't improve loss:  1\n",
      "epoch: 1741\n",
      "training loss: 0.38612924697788803\n",
      "validation loss: 7.771728284760501\n",
      "loss difference:\n",
      "0.03182688628379282\n",
      "epoch: 1742\n",
      "training loss: 0.4174949759148312\n",
      "validation loss: 7.522334122849472\n",
      "loss difference:\n",
      "-0.03136572893694317\n",
      "that didn't improve loss:  1\n",
      "epoch: 1743\n",
      "training loss: 0.3857503909829127\n",
      "validation loss: 7.770878096773358\n",
      "loss difference:\n",
      "0.03174458493191851\n",
      "epoch: 1744\n",
      "training loss: 0.4170346954852707\n",
      "validation loss: 7.521584335168268\n",
      "loss difference:\n",
      "-0.03128430450235803\n",
      "that didn't improve loss:  1\n",
      "epoch: 1745\n",
      "training loss: 0.3853722234671799\n",
      "validation loss: 7.770040170367499\n",
      "loss difference:\n",
      "0.031662472018090804\n",
      "epoch: 1746\n",
      "training loss: 0.4165752930730013\n",
      "validation loss: 7.520846485586471\n",
      "loss difference:\n",
      "-0.031203069605821365\n",
      "that didn't improve loss:  1\n",
      "epoch: 1747\n",
      "training loss: 0.38499474366420317\n",
      "validation loss: 7.769214499393565\n",
      "loss difference:\n",
      "0.03158054940879812\n",
      "epoch: 1748\n",
      "training loss: 0.4161167676684634\n",
      "validation loss: 7.520120564071046\n",
      "loss difference:\n",
      "-0.03112202400426023\n",
      "that didn't improve loss:  1\n",
      "epoch: 1749\n",
      "training loss: 0.38461794915241093\n",
      "validation loss: 7.768401075020273\n",
      "loss difference:\n",
      "0.03149881851605246\n",
      "epoch: 1750\n",
      "training loss: 0.415659116189783\n",
      "validation loss: 7.519406561165096\n",
      "loss difference:\n",
      "-0.031041167037372086\n",
      "that didn't improve loss:  1\n",
      "epoch: 1751\n",
      "training loss: 0.38424183588711813\n",
      "validation loss: 7.767599885795922\n",
      "loss difference:\n",
      "0.031417280302664885\n",
      "epoch: 1752\n",
      "training loss: 0.4152023335396637\n",
      "validation loss: 7.518704467973658\n",
      "loss difference:\n",
      "-0.03096049765254555\n",
      "that didn't improve loss:  1\n",
      "epoch: 1753\n",
      "training loss: 0.38386639824821084\n",
      "validation loss: 7.766810917727964\n",
      "loss difference:\n",
      "0.03133593529145284\n",
      "epoch: 1754\n",
      "training loss: 0.41474641268088325\n",
      "validation loss: 7.518014276138603\n",
      "loss difference:\n",
      "-0.03088001443267241\n",
      "that didn't improve loss:  1\n",
      "epoch: 1755\n",
      "training loss: 0.38349162910269197\n",
      "validation loss: 7.766034154379388\n",
      "loss difference:\n",
      "0.03125478357819128\n",
      "epoch: 1756\n",
      "training loss: 0.4142913447291487\n",
      "validation loss: 7.517335977802998\n",
      "loss difference:\n",
      "-0.030799715626456725\n",
      "that didn't improve loss:  1\n",
      "epoch: 1757\n",
      "training loss: 0.3831175198810711\n",
      "validation loss: 7.765269576980653\n",
      "loss difference:\n",
      "0.03117382484807757\n",
      "epoch: 1758\n",
      "training loss: 0.4138371190619549\n",
      "validation loss: 7.516669565565817\n",
      "loss difference:\n",
      "-0.030719599180883794\n",
      "that didn't improve loss:  1\n",
      "epoch: 1759\n",
      "training loss: 0.3827440606665292\n",
      "validation loss: 7.7645171645557625\n",
      "loss difference:\n",
      "0.0310930583954257\n",
      "epoch: 1760\n",
      "training loss: 0.4133837234419722\n",
      "validation loss: 7.5160150324277\n",
      "loss difference:\n",
      "-0.030639662775443\n",
      "that didn't improve loss:  1\n",
      "epoch: 1761\n",
      "training loss: 0.382371240295625\n",
      "validation loss: 7.763776894060965\n",
      "loss difference:\n",
      "0.03101248314634719\n",
      "epoch: 1762\n",
      "training loss: 0.41293114415336346\n",
      "validation loss: 7.515372371728481\n",
      "loss difference:\n",
      "-0.030559903857738435\n",
      "that didn't improve loss:  1\n",
      "epoch: 1763\n",
      "training loss: 0.38199904646929095\n",
      "validation loss: 7.763048740534422\n",
      "loss difference:\n",
      "0.030932097684072513\n",
      "epoch: 1764\n",
      "training loss: 0.4124793661493792\n",
      "validation loss: 7.514741577077579\n",
      "loss difference:\n",
      "-0.03048031968008824\n",
      "that didn't improve loss:  1\n",
      "epoch: 1765\n",
      "training loss: 0.3816274658727562\n",
      "validation loss: 7.762332677255296\n",
      "loss difference:\n",
      "0.03085190027662299\n",
      "epoch: 1766\n",
      "training loss: 0.41202837320946634\n",
      "validation loss: 7.51412264227794\n",
      "loss difference:\n",
      "-0.030400907336710137\n",
      "that didn't improve loss:  1\n",
      "epoch: 1767\n",
      "training loss: 0.3812564843029879\n",
      "validation loss: 7.761628675910467\n",
      "loss difference:\n",
      "0.030771888906478417\n",
      "epoch: 1768\n",
      "training loss: 0.4115781481041374\n",
      "validation loss: 7.513515561244694\n",
      "loss difference:\n",
      "-0.03032166380114948\n",
      "that didn't improve loss:  1\n",
      "epoch: 1769\n",
      "training loss: 0.3808860868022225\n",
      "validation loss: 7.760936706767107\n",
      "loss difference:\n",
      "0.030692061301914875\n",
      "epoch: 1770\n",
      "training loss: 0.4111286727657467\n",
      "validation loss: 7.512920327919448\n",
      "loss difference:\n",
      "-0.030242585963524193\n",
      "that didn't improve loss:  1\n",
      "epoch: 1771\n",
      "training loss: 0.3805162577960913\n",
      "validation loss: 7.760256738849372\n",
      "loss difference:\n",
      "0.030612414969655444\n",
      "epoch: 1772\n",
      "training loss: 0.41067992846337464\n",
      "validation loss: 7.512336936181218\n",
      "loss difference:\n",
      "-0.03016367066728337\n",
      "that didn't improve loss:  1\n",
      "epoch: 1773\n",
      "training loss: 0.3801469812349153\n",
      "validation loss: 7.759588740117494\n",
      "loss difference:\n",
      "0.03053294722845934\n",
      "epoch: 1774\n",
      "training loss: 0.4102318959799862\n",
      "validation loss: 7.511765379755026\n",
      "loss difference:\n",
      "-0.030084914745070912\n",
      "that didn't improve loss:  1\n",
      "epoch: 1775\n",
      "training loss: 0.37977824073663713\n",
      "validation loss: 7.758932677647488\n",
      "loss difference:\n",
      "0.030453655243349087\n",
      "epoch: 1776\n",
      "training loss: 0.409784555790064\n",
      "validation loss: 7.511205652119234\n",
      "loss difference:\n",
      "-0.03000631505342688\n",
      "that didn't improve loss:  1\n",
      "epoch: 1777\n",
      "training loss: 0.3794100197299825\n",
      "validation loss: 7.7582885178097944\n",
      "loss difference:\n",
      "0.030374536060081503\n",
      "epoch: 1778\n",
      "training loss: 0.4093378882359692\n",
      "validation loss: 7.510657746412551\n",
      "loss difference:\n",
      "-0.02992786850598672\n",
      "that didn't improve loss:  1\n",
      "epoch: 1779\n",
      "training loss: 0.3790423015964288\n",
      "validation loss: 7.75765622644514\n",
      "loss difference:\n",
      "0.030295586639540406\n",
      "epoch: 1780\n",
      "training loss: 0.4088918737013126\n",
      "validation loss: 7.510121655341713\n",
      "loss difference:\n",
      "-0.02984957210488376\n",
      "that didn't improve loss:  1\n",
      "epoch: 1781\n",
      "training loss: 0.37867506980957855\n",
      "validation loss: 7.7570357690362215\n",
      "loss difference:\n",
      "0.030216803891734034\n",
      "epoch: 1782\n",
      "training loss: 0.4084464927797355\n",
      "validation loss: 7.509597371090841\n",
      "loss difference:\n",
      "-0.029771422970156947\n",
      "that didn't improve loss:  1\n",
      "epoch: 1783\n",
      "training loss: 0.3783083080706739\n",
      "validation loss: 7.756427110873442\n",
      "loss difference:\n",
      "0.0301381847090616\n",
      "epoch: 1784\n",
      "training loss: 0.4080017264375315\n",
      "validation loss: 7.509084885233319\n",
      "loss difference:\n",
      "-0.029693418366857627\n",
      "that didn't improve loss:  1\n",
      "epoch: 1785\n",
      "training loss: 0.3779420004389596\n",
      "validation loss: 7.7558302172135765\n",
      "loss difference:\n",
      "0.03005972599857193\n",
      "epoch: 1786\n",
      "training loss: 0.4075575561687014\n",
      "validation loss: 7.508584188647065\n",
      "loss difference:\n",
      "-0.029615555729741783\n",
      "that didn't improve loss:  1\n",
      "epoch: 1787\n",
      "training loss: 0.3775761314557738\n",
      "validation loss: 7.755245053429782\n",
      "loss difference:\n",
      "0.029981424712927585\n",
      "epoch: 1788\n",
      "training loss: 0.4071139641410674\n",
      "validation loss: 7.508095271434057\n",
      "loss difference:\n",
      "-0.029537832685293586\n",
      "that didn't improve loss:  1\n",
      "epoch: 1789\n",
      "training loss: 0.37721068626127136\n",
      "validation loss: 7.754671585152113\n",
      "loss difference:\n",
      "0.02990327787979602\n",
      "epoch: 1790\n",
      "training loss: 0.4066709333322888\n",
      "validation loss: 7.50761812284483\n",
      "loss difference:\n",
      "-0.029460247071017465\n",
      "that didn't improve loss:  1\n",
      "epoch: 1791\n",
      "training loss: 0.37684565070282183\n",
      "validation loss: 7.7541097783971145\n",
      "loss difference:\n",
      "0.029825282629466987\n",
      "epoch: 1792\n",
      "training loss: 0.40622844765466076\n",
      "validation loss: 7.5071527312085395\n",
      "loss difference:\n",
      "-0.02938279695183893\n",
      "that didn't improve loss:  1\n",
      "epoch: 1793\n",
      "training loss: 0.376481011434195\n",
      "validation loss: 7.753559599685821\n",
      "loss difference:\n",
      "0.029747436220465773\n",
      "epoch: 1794\n",
      "training loss: 0.40578649206778045\n",
      "validation loss: 7.50669908386938\n",
      "loss difference:\n",
      "-0.029305480633585457\n",
      "that didn't improve loss:  1\n",
      "epoch: 1795\n",
      "training loss: 0.37611675600481226\n",
      "validation loss: 7.753021016149289\n",
      "loss difference:\n",
      "0.02966973606296819\n",
      "epoch: 1796\n",
      "training loss: 0.40534505267828347\n",
      "validation loss: 7.506257167129671\n",
      "loss difference:\n",
      "-0.02922829667347121\n",
      "that didn't improve loss:  1\n",
      "epoch: 1797\n",
      "training loss: 0.3757528729383942\n",
      "validation loss: 7.752493995621029\n",
      "loss difference:\n",
      "0.029592179739889257\n",
      "epoch: 1798\n",
      "training loss: 0.40490411682599114\n",
      "validation loss: 7.5058269662002655\n",
      "loss difference:\n",
      "-0.029151243887596934\n",
      "that didn't improve loss:  1\n",
      "epoch: 1799\n",
      "training loss: 0.3753893518005187\n",
      "validation loss: 7.751978506715791\n",
      "loss difference:\n",
      "0.029514765025472456\n",
      "epoch: 1800\n",
      "training loss: 0.40446367315597853\n",
      "validation loss: 7.50540846515847\n",
      "loss difference:\n",
      "-0.029074321355459842\n",
      "that didn't improve loss:  1\n",
      "epoch: 1801\n",
      "training loss: 0.37502618325466\n",
      "validation loss: 7.75147451889444\n",
      "loss difference:\n",
      "0.02943748990131856\n",
      "epoch: 1802\n",
      "training loss: 0.4040237116762281\n",
      "validation loss: 7.505001646913886\n",
      "loss difference:\n",
      "-0.02899752842156811\n",
      "that didn't improve loss:  1\n",
      "epoch: 1803\n",
      "training loss: 0.3746633591064761\n",
      "validation loss: 7.7509820025145855\n",
      "loss difference:\n",
      "0.029360352569752002\n",
      "epoch: 1804\n",
      "training loss: 0.40358422380067127\n",
      "validation loss: 7.504606493182303\n",
      "loss difference:\n",
      "-0.028920864694195192\n",
      "that didn't improve loss:  1\n",
      "epoch: 1805\n",
      "training loss: 0.37430087233618015\n",
      "validation loss: 7.7505009288670434\n",
      "loss difference:\n",
      "0.029283351464491125\n",
      "epoch: 1806\n",
      "training loss: 0.4031452023775671\n",
      "validation loss: 7.504222984467781\n",
      "loss difference:\n",
      "-0.02884433004138698\n",
      "that didn't improve loss:  1\n",
      "epoch: 1807\n",
      "training loss: 0.37393871711896787\n",
      "validation loss: 7.750031270198125\n",
      "loss difference:\n",
      "0.029206485258599257\n",
      "epoch: 1808\n",
      "training loss: 0.40270664170333514\n",
      "validation loss: 7.503851100052909\n",
      "loss difference:\n",
      "-0.028767924584367277\n",
      "that didn't improve loss:  1\n",
      "epoch: 1809\n",
      "training loss: 0.3735768888336029\n",
      "validation loss: 7.749572999717903\n",
      "loss difference:\n",
      "0.02912975286973224\n",
      "epoch: 1810\n",
      "training loss: 0.4022685375220749\n",
      "validation loss: 7.503490817997304\n",
      "loss difference:\n",
      "-0.028691648688472016\n",
      "that didn't improve loss:  1\n",
      "epoch: 1811\n",
      "training loss: 0.3732153840593687\n",
      "validation loss: 7.749126091595028\n",
      "loss difference:\n",
      "0.029053153462706205\n",
      "epoch: 1812\n",
      "training loss: 0.40183088701115977\n",
      "validation loss: 7.503142115144039\n",
      "loss difference:\n",
      "-0.02861550295179105\n",
      "that didn't improve loss:  1\n",
      "epoch: 1813\n",
      "training loss: 0.3728542005617094\n",
      "validation loss: 7.748690520938252\n",
      "loss difference:\n",
      "0.02897668644945034\n",
      "epoch: 1814\n",
      "training loss: 0.4013936887534186\n",
      "validation loss: 7.502804967133993\n",
      "loss difference:\n",
      "-0.02853948819170915\n",
      "that didn't improve loss:  1\n",
      "epoch: 1815\n",
      "training loss: 0.37249333726697437\n",
      "validation loss: 7.748266263765558\n",
      "loss difference:\n",
      "0.02890035148644421\n",
      "epoch: 1816\n",
      "training loss: 0.4009569426965119\n",
      "validation loss: 7.502479348427654\n",
      "loss difference:\n",
      "-0.02846360542953752\n",
      "that didn't improve loss:  1\n",
      "epoch: 1817\n",
      "training loss: 0.37213279422679285\n",
      "validation loss: 7.747853296961329\n",
      "loss difference:\n",
      "0.028824148469719035\n",
      "epoch: 1818\n",
      "training loss: 0.4005206501002757\n",
      "validation loss: 7.502165232334218\n",
      "loss difference:\n",
      "-0.02838785587348286\n",
      "that didn't improve loss:  1\n",
      "epoch: 1819\n",
      "training loss: 0.3717725725726945\n",
      "validation loss: 7.747451598222554\n",
      "loss difference:\n",
      "0.028748077527581184\n",
      "epoch: 1820\n",
      "training loss: 0.40008481347281083\n",
      "validation loss: 7.5018625910473755\n",
      "loss difference:\n",
      "-0.028312240900116303\n",
      "that didn't improve loss:  1\n",
      "epoch: 1821\n",
      "training loss: 0.371412674461657\n",
      "validation loss: 7.747061145994799\n",
      "loss difference:\n",
      "0.02867213901115384\n",
      "epoch: 1822\n",
      "training loss: 0.39964943649632245\n",
      "validation loss: 7.501571395687551\n",
      "loss difference:\n",
      "-0.028236762034665464\n",
      "that didn't improve loss:  1\n",
      "epoch: 1823\n",
      "training loss: 0.371053103013345\n",
      "validation loss: 7.746681919398995\n",
      "loss difference:\n",
      "0.028596333482977465\n",
      "epoch: 1824\n",
      "training loss: 0.3992145239436241\n",
      "validation loss: 7.501291616349841\n",
      "loss difference:\n",
      "-0.028161420930279124\n",
      "that didn't improve loss:  1\n",
      "epoch: 1825\n",
      "training loss: 0.3706938622398631\n",
      "validation loss: 7.746313898150044\n",
      "loss difference:\n",
      "0.028520661703760997\n",
      "epoch: 1826\n",
      "training loss: 0.3987800815864441\n",
      "validation loss: 7.501023222157345\n",
      "loss difference:\n",
      "-0.02808621934658101\n",
      "that didn't improve loss:  1\n",
      "epoch: 1827\n",
      "training loss: 0.3703349569689143\n",
      "validation loss: 7.745957062468304\n",
      "loss difference:\n",
      "0.02844512461752985\n",
      "epoch: 1828\n",
      "training loss: 0.3983461160966019\n",
      "validation loss: 7.500766181319014\n",
      "loss difference:\n",
      "-0.028011159127687646\n",
      "that didn't improve loss:  1\n",
      "epoch: 1829\n",
      "training loss: 0.3699763927612473\n",
      "validation loss: 7.745611392985022\n",
      "loss difference:\n",
      "0.028369723335354646\n",
      "epoch: 1830\n",
      "training loss: 0.39791263494124635\n",
      "validation loss: 7.500520461191698\n",
      "loss difference:\n",
      "-0.02793624217999907\n",
      "that didn't improve loss:  1\n",
      "epoch: 1831\n",
      "training loss: 0.36961817582339196\n",
      "validation loss: 7.745276870643025\n",
      "loss difference:\n",
      "0.028294459117854387\n",
      "epoch: 1832\n",
      "training loss: 0.39747964627329163\n",
      "validation loss: 7.500286028345517\n",
      "loss difference:\n",
      "-0.027861470449899672\n",
      "that didn't improve loss:  1\n",
      "epoch: 1833\n",
      "training loss: 0.36926031291659345\n",
      "validation loss: 7.744953476593537\n",
      "loss difference:\n",
      "0.028219333356698184\n",
      "epoch: 1834\n",
      "training loss: 0.39704715881832436\n",
      "validation loss: 7.50006284863197\n",
      "loss difference:\n",
      "-0.027786845901730917\n",
      "that didn't improve loss:  1\n",
      "epoch: 1835\n",
      "training loss: 0.3689028112629875\n",
      "validation loss: 7.744641192090666\n",
      "loss difference:\n",
      "0.028144347555336846\n",
      "epoch: 1836\n",
      "training loss: 0.39661518175908295\n",
      "validation loss: 7.499850887254091\n",
      "loss difference:\n",
      "-0.02771237049609543\n",
      "that didn't improve loss:  1\n",
      "epoch: 1837\n",
      "training loss: 0.3685456784499463\n",
      "validation loss: 7.74433999838435\n",
      "loss difference:\n",
      "0.028069503309136656\n",
      "epoch: 1838\n",
      "training loss: 0.3961837246187744\n",
      "validation loss: 7.499650108838121\n",
      "loss difference:\n",
      "-0.02763804616882809\n",
      "that didn't improve loss:  1\n",
      "epoch: 1839\n",
      "training loss: 0.3681889223335997\n",
      "validation loss: 7.744049876613153\n",
      "loss difference:\n",
      "0.027994802285174702\n",
      "epoch: 1840\n",
      "training loss: 0.3957527971443658\n",
      "validation loss: 7.4994604775057425\n",
      "loss difference:\n",
      "-0.02756387481076611\n",
      "that didn't improve loss:  1\n",
      "epoch: 1841\n",
      "training loss: 0.3678325509424796\n",
      "validation loss: 7.743770807697897\n",
      "loss difference:\n",
      "0.027920246201886212\n",
      "epoch: 1842\n",
      "training loss: 0.39532240919097333\n",
      "validation loss: 7.499281956946463\n",
      "loss difference:\n",
      "-0.02748985824849376\n",
      "that didn't improve loss:  1\n",
      "epoch: 1843\n",
      "training loss: 0.36747657238220044\n",
      "validation loss: 7.743502772237239\n",
      "loss difference:\n",
      "0.027845836808772895\n",
      "epoch: 1844\n",
      "training loss: 0.39489257060844474\n",
      "validation loss: 7.49911451048941\n",
      "loss difference:\n",
      "-0.027415998226244298\n",
      "that didn't improve loss:  1\n",
      "epoch: 1845\n",
      "training loss: 0.36712099474208243\n",
      "validation loss: 7.743245750406245\n",
      "loss difference:\n",
      "0.027771575866362308\n",
      "epoch: 1846\n",
      "training loss: 0.39446329113120454\n",
      "validation loss: 7.498958101173921\n",
      "loss difference:\n",
      "-0.02734229638912211\n",
      "that didn't improve loss:  1\n",
      "epoch: 1847\n",
      "training loss: 0.36676582600456414\n",
      "validation loss: 7.742999721858846\n",
      "loss difference:\n",
      "0.027697465126640397\n",
      "epoch: 1848\n",
      "training loss: 0.39403458027227034\n",
      "validation loss: 7.4988126918183475\n",
      "loss difference:\n",
      "-0.027268754267706197\n",
      "that didn't improve loss:  1\n",
      "epoch: 1849\n",
      "training loss: 0.36641107395818123\n",
      "validation loss: 7.742764665635105\n",
      "loss difference:\n",
      "0.027623506314089108\n",
      "epoch: 1850\n",
      "training loss: 0.39360644722242094\n",
      "validation loss: 7.498678245086469\n",
      "loss difference:\n",
      "-0.02719537326423971\n",
      "that didn't improve loss:  1\n",
      "epoch: 1851\n",
      "training loss: 0.36605674611488115\n",
      "validation loss: 7.74254056007423\n",
      "loss difference:\n",
      "0.027549701107539792\n",
      "epoch: 1852\n",
      "training loss: 0.39317890075529527\n",
      "validation loss: 7.49855472355109\n",
      "loss difference:\n",
      "-0.02712215464041412\n",
      "that didn't improve loss:  1\n",
      "epoch: 1853\n",
      "training loss: 0.365702849632326\n",
      "validation loss: 7.742327382733857\n",
      "loss difference:\n",
      "0.027476051122969247\n",
      "epoch: 1854\n",
      "training loss: 0.39275194913918604\n",
      "validation loss: 7.498442089754218\n",
      "loss difference:\n",
      "-0.02704909950686002\n",
      "that didn't improve loss:  1\n",
      "epoch: 1855\n",
      "training loss: 0.365349391241803\n",
      "validation loss: 7.742125110316512\n",
      "loss difference:\n",
      "0.02740255789738305\n",
      "epoch: 1856\n",
      "training loss: 0.3923256000562323\n",
      "validation loss: 7.498340306263511\n",
      "loss difference:\n",
      "-0.026976208814429303\n",
      "that didn't improve loss:  1\n",
      "epoch: 1857\n",
      "training loss: 0.3649963771822925\n",
      "validation loss: 7.741933718603661\n",
      "loss difference:\n",
      "0.027329222873939796\n",
      "epoch: 1858\n",
      "training loss: 0.3918998605294923\n",
      "validation loss: 7.498249335724517\n",
      "loss difference:\n",
      "-0.02690348334719983\n",
      "that didn't improve loss:  1\n",
      "epoch: 1859\n",
      "training loss: 0.3646438131411269\n",
      "validation loss: 7.74175318239789\n",
      "loss difference:\n",
      "0.0272560473883654\n",
      "epoch: 1860\n",
      "training loss: 0.3914747368584839\n",
      "validation loss: 7.498169140908342\n",
      "loss difference:\n",
      "-0.026830923717356958\n",
      "that didn't improve loss:  1\n",
      "epoch: 1861\n",
      "training loss: 0.3642917042016798\n",
      "validation loss: 7.741583475473651\n",
      "loss difference:\n",
      "0.027183032656804107\n",
      "epoch: 1862\n",
      "training loss: 0.391050234563508\n",
      "validation loss: 7.498099684754599\n",
      "loss difference:\n",
      "-0.026758530361828237\n",
      "that didn't improve loss:  1\n",
      "epoch: 1863\n",
      "training loss: 0.36394005479833136\n",
      "validation loss: 7.741424570536843\n",
      "loss difference:\n",
      "0.027110179765176656\n",
      "epoch: 1864\n",
      "training loss: 0.39062635833905174\n",
      "validation loss: 7.498040930409227\n",
      "loss difference:\n",
      "-0.02668630354072038\n",
      "that didn't improve loss:  1\n",
      "epoch: 1865\n",
      "training loss: 0.3635888686789865\n",
      "validation loss: 7.74127643919334\n",
      "loss difference:\n",
      "0.02703748966006525\n",
      "epoch: 1866\n",
      "training loss: 0.39020311201650054\n",
      "validation loss: 7.497992841257158\n",
      "loss difference:\n",
      "-0.026614243337514054\n",
      "that didn't improve loss:  1\n",
      "epoch: 1867\n",
      "training loss: 0.363238148875301\n",
      "validation loss: 7.741139051926814\n",
      "loss difference:\n",
      "0.02696496314119956\n",
      "epoch: 1868\n",
      "training loss: 0.3897804985362228\n",
      "validation loss: 7.4979553809496\n",
      "loss difference:\n",
      "-0.026542349660921838\n",
      "that didn't improve loss:  1\n",
      "epoch: 1869\n",
      "training loss: 0.36288789768064894\n",
      "validation loss: 7.741012378085654\n",
      "loss difference:\n",
      "0.026892600855573878\n",
      "epoch: 1870\n",
      "training loss: 0.3893585199290583\n",
      "validation loss: 7.497928513425895\n",
      "loss difference:\n",
      "-0.026470622248409348\n",
      "that didn't improve loss:  1\n",
      "epoch: 1871\n",
      "training loss: 0.36253811663588376\n",
      "validation loss: 7.74089638587903\n",
      "loss difference:\n",
      "0.026820403293174533\n",
      "epoch: 1872\n",
      "training loss: 0.3889371773070994\n",
      "validation loss: 7.497912202929933\n",
      "loss difference:\n",
      "-0.02639906067121567\n",
      "that didn't improve loss:  1\n",
      "epoch: 1873\n",
      "training loss: 0.36218880652276036\n",
      "validation loss: 7.7407910423819075\n",
      "loss difference:\n",
      "0.02674837078433906\n",
      "epoch: 1874\n",
      "training loss: 0.38851647086363794\n",
      "validation loss: 7.497906414021188\n",
      "loss difference:\n",
      "-0.026327664340877577\n",
      "that didn't improve loss:  1\n",
      "epoch: 1875\n",
      "training loss: 0.3618399673649312\n",
      "validation loss: 7.740696313548829\n",
      "loss difference:\n",
      "0.02667650349870676\n",
      "epoch: 1876\n",
      "training loss: 0.3880963998819747\n",
      "validation loss: 7.4979111115804\n",
      "loss difference:\n",
      "-0.026256432517043515\n",
      "that didn't improve loss:  1\n",
      "epoch: 1877\n",
      "training loss: 0.361491598436256\n",
      "validation loss: 7.740612164236089\n",
      "loss difference:\n",
      "0.026604801445718695\n",
      "epoch: 1878\n",
      "training loss: 0.3876769627528259\n",
      "validation loss: 7.49792626081004\n",
      "loss difference:\n",
      "-0.026185364316569926\n",
      "that didn't improve loss:  1\n",
      "epoch: 1879\n",
      "training loss: 0.36114369827617376\n",
      "validation loss: 7.740538558231968\n",
      "loss difference:\n",
      "0.026533264476652163\n",
      "epoch: 1880\n",
      "training loss: 0.3872581569998488\n",
      "validation loss: 7.497951827229775\n",
      "loss difference:\n",
      "-0.026114458723675016\n",
      "that didn't improve loss:  1\n",
      "epoch: 1881\n",
      "training loss: 0.3607962647117811\n",
      "validation loss: 7.740475458294576\n",
      "loss difference:\n",
      "0.026461892288067668\n",
      "epoch: 1882\n",
      "training loss: 0.3868399793128869\n",
      "validation loss: 7.49798777666716\n",
      "loss difference:\n",
      "-0.026043714601105772\n",
      "that didn't improve loss:  1\n",
      "epoch: 1883\n",
      "training loss: 0.36044929488625027\n",
      "validation loss: 7.740422826196756\n",
      "loss difference:\n",
      "0.026390684426636613\n",
      "epoch: 1884\n",
      "training loss: 0.386422425588378\n",
      "validation loss: 7.498034075243699\n",
      "loss difference:\n",
      "-0.025973130702127756\n",
      "that didn't improve loss:  1\n",
      "epoch: 1885\n",
      "training loss: 0.3601027852931185\n",
      "validation loss: 7.740380622777536\n",
      "loss difference:\n",
      "0.026319640295259517\n",
      "epoch: 1886\n",
      "training loss: 0.38600549097634324\n",
      "validation loss: 7.498090689356686\n",
      "loss difference:\n",
      "-0.025902705683224725\n",
      "that didn't improve loss:  1\n",
      "epoch: 1887\n",
      "training loss: 0.3597567318160029\n",
      "validation loss: 7.740348807999484\n",
      "loss difference:\n",
      "0.026248759160340362\n",
      "epoch: 1888\n",
      "training loss: 0.38558916993334885\n",
      "validation loss: 7.498157585657108\n",
      "loss difference:\n",
      "-0.02583243811734598\n",
      "that didn't improve loss:  1\n",
      "epoch: 1889\n",
      "training loss: 0.35941112977317413\n",
      "validation loss: 7.740327341011323\n",
      "loss difference:\n",
      "0.02617804016017472\n",
      "epoch: 1890\n",
      "training loss: 0.3851734562807549\n",
      "validation loss: 7.498234731023948\n",
      "loss difference:\n",
      "-0.025762326507580757\n",
      "that didn't improve loss:  1\n",
      "epoch: 1891\n",
      "training loss: 0.35906597396647666\n",
      "validation loss: 7.7403161802151805\n",
      "loss difference:\n",
      "0.02610748231427823\n",
      "epoch: 1892\n",
      "training loss: 0.384758343267577\n",
      "validation loss: 7.498322092535289\n",
      "loss difference:\n",
      "-0.02569236930110036\n",
      "that didn't improve loss:  1\n",
      "epoch: 1893\n",
      "training loss: 0.35872125873399036\n",
      "validation loss: 7.740315283337622\n",
      "loss difference:\n",
      "0.026037084533586663\n",
      "epoch: 1894\n",
      "training loss: 0.384343823637226\n",
      "validation loss: 7.498419637436562\n",
      "loss difference:\n",
      "-0.025622564903235667\n",
      "that didn't improve loss:  1\n",
      "epoch: 1895\n",
      "training loss: 0.35837697800586477\n",
      "validation loss: 7.740324607503918\n",
      "loss difference:\n",
      "0.025966845631361257\n",
      "epoch: 1896\n",
      "training loss: 0.383929889697409\n",
      "validation loss: 7.498527333106384\n",
      "loss difference:\n",
      "-0.025552911691544222\n",
      "that didn't improve loss:  1\n",
      "epoch: 1897\n",
      "training loss: 0.35803312536267784\n",
      "validation loss: 7.740344109314677\n",
      "loss difference:\n",
      "0.025896764334731148\n",
      "epoch: 1898\n",
      "training loss: 0.3835165333924243\n",
      "validation loss: 7.498645147020429\n",
      "loss difference:\n",
      "-0.025483408029746468\n",
      "that didn't improve loss:  1\n",
      "epoch: 1899\n",
      "training loss: 0.35768969409573564\n",
      "validation loss: 7.740373744924237\n",
      "loss difference:\n",
      "0.025826839296688664\n",
      "epoch: 1900\n",
      "training loss: 0.3831037463771112\n",
      "validation loss: 7.498773046713709\n",
      "loss difference:\n",
      "-0.025414052281375554\n",
      "that didn't improve loss:  1\n",
      "epoch: 1901\n",
      "training loss: 0.35734667726867164\n",
      "validation loss: 7.740413470119813\n",
      "loss difference:\n",
      "0.025757069108439556\n",
      "epoch: 1902\n",
      "training loss: 0.3826915200917553\n",
      "validation loss: 7.498910999741689\n",
      "loss difference:\n",
      "-0.025344842823083635\n",
      "that didn't improve loss:  1\n",
      "epoch: 1903\n",
      "training loss: 0.35700406777975924\n",
      "validation loss: 7.740463240401115\n",
      "loss difference:\n",
      "0.02568745231199604\n",
      "epoch: 1904\n",
      "training loss: 0.3822798458371409\n",
      "validation loss: 7.499058973640725\n",
      "loss difference:\n",
      "-0.02527577805738168\n",
      "that didn't improve loss:  1\n",
      "epoch: 1905\n",
      "training loss: 0.35666185842429216\n",
      "validation loss: 7.740523011059242\n",
      "loss difference:\n",
      "0.025617987412848764\n",
      "epoch: 1906\n",
      "training loss: 0.38186871484911894\n",
      "validation loss: 7.499216935888214\n",
      "loss difference:\n",
      "-0.025206856424826785\n",
      "that didn't improve loss:  1\n",
      "epoch: 1907\n",
      "training loss: 0.35632004195648337\n",
      "validation loss: 7.74059273725456\n",
      "loss difference:\n",
      "0.02554867289263557\n",
      "epoch: 1908\n",
      "training loss: 0.3814581183719641\n",
      "validation loss: 7.499384853862795\n",
      "loss difference:\n",
      "-0.025138076415480715\n",
      "that didn't improve loss:  1\n",
      "epoch: 1909\n",
      "training loss: 0.3559786111503102\n",
      "validation loss: 7.740672374092656\n",
      "loss difference:\n",
      "0.025479507221653874\n",
      "epoch: 1910\n",
      "training loss: 0.3810480477298832\n",
      "validation loss: 7.499562694805122\n",
      "loss difference:\n",
      "-0.025069436579573\n",
      "that didn't improve loss:  1\n",
      "epoch: 1911\n",
      "training loss: 0.35563755885873405\n",
      "validation loss: 7.740761876697862\n",
      "loss difference:\n",
      "0.02541048887114916\n",
      "epoch: 1912\n",
      "training loss: 0.38063849439603614\n",
      "validation loss: 7.499750425779566\n",
      "loss difference:\n",
      "-0.025000935537302094\n",
      "that didn't improve loss:  1\n",
      "epoch: 1913\n",
      "training loss: 0.3552968780708176\n",
      "validation loss: 7.740861200283768\n",
      "loss difference:\n",
      "0.02534161632521853\n",
      "epoch: 1914\n",
      "training loss: 0.380229450058529\n",
      "validation loss: 7.49994801363709\n",
      "loss difference:\n",
      "-0.02493257198771137\n",
      "that didn't improve loss:  1\n",
      "epoch: 1915\n",
      "training loss: 0.35495656196625025\n",
      "validation loss: 7.74097030022012\n",
      "loss difference:\n",
      "0.025272888092278734\n",
      "epoch: 1916\n",
      "training loss: 0.37982090668281243\n",
      "validation loss: 7.500155424979833\n",
      "loss difference:\n",
      "-0.02486434471656218\n",
      "that didn't improve loss:  1\n",
      "epoch: 1917\n",
      "training loss: 0.35461660396685163\n",
      "validation loss: 7.7410891320956665\n",
      "loss difference:\n",
      "0.025204302715960802\n",
      "epoch: 1918\n",
      "training loss: 0.37941285657003637\n",
      "validation loss: 7.5003726261275\n",
      "loss difference:\n",
      "-0.024796252603184743\n",
      "that didn't improve loss:  1\n",
      "epoch: 1919\n",
      "training loss: 0.35427699778462696\n",
      "validation loss: 7.741217651776562\n",
      "loss difference:\n",
      "0.025135858785409415\n",
      "epoch: 1920\n",
      "training loss: 0.3790052924108777\n",
      "validation loss: 7.500599583086084\n",
      "loss difference:\n",
      "-0.024728294626250757\n",
      "that didn't improve loss:  1\n",
      "epoch: 1921\n",
      "training loss: 0.35393773746605334\n",
      "validation loss: 7.741355815459756\n",
      "loss difference:\n",
      "0.025067554944824377\n",
      "epoch: 1922\n",
      "training loss: 0.3785982073345342\n",
      "validation loss: 7.500836261518941\n",
      "loss difference:\n",
      "-0.02466046986848086\n",
      "that didn't improve loss:  1\n",
      "epoch: 1923\n",
      "training loss: 0.35359881743226945\n",
      "validation loss: 7.741503579721286\n",
      "loss difference:\n",
      "0.024999389902264746\n",
      "epoch: 1924\n",
      "training loss: 0.3781915949525018\n",
      "validation loss: 7.501082626720671\n",
      "loss difference:\n",
      "-0.024592777520232367\n",
      "that didn't improve loss:  1\n",
      "epoch: 1925\n",
      "training loss: 0.3532602325148907\n",
      "validation loss: 7.741660901558961\n",
      "loss difference:\n",
      "0.024931362437611126\n",
      "epoch: 1926\n",
      "training loss: 0.37778544939689584\n",
      "validation loss: 7.501338643593841\n",
      "loss difference:\n",
      "-0.024525216882005152\n",
      "that didn't improve loss:  1\n",
      "epoch: 1927\n",
      "training loss: 0.3529219779872772\n",
      "validation loss: 7.7418277384294445\n",
      "loss difference:\n",
      "0.024863471409618643\n",
      "epoch: 1928\n",
      "training loss: 0.3773797653531419\n",
      "validation loss: 7.5016042766287585\n",
      "loss difference:\n",
      "-0.02445778736586468\n",
      "that didn't improve loss:  1\n",
      "epoch: 1929\n",
      "training loss: 0.35258404959104894\n",
      "validation loss: 7.742004048279397\n",
      "loss difference:\n",
      "0.02479571576209294\n",
      "epoch: 1930\n",
      "training loss: 0.3769745380868253\n",
      "validation loss: 7.501879489886456\n",
      "loss difference:\n",
      "-0.024390488495776352\n",
      "that didn't improve loss:  1\n",
      "epoch: 1931\n",
      "training loss: 0.35224644355774126\n",
      "validation loss: 7.742189789570668\n",
      "loss difference:\n",
      "0.024728094529084033\n",
      "epoch: 1932\n",
      "training loss: 0.3765697634646833\n",
      "validation loss: 7.502164246984977\n",
      "loss difference:\n",
      "-0.02432331990694203\n",
      "that didn't improve loss:  1\n",
      "epoch: 1933\n",
      "training loss: 0.3519091566255526\n",
      "validation loss: 7.7423849212995\n",
      "loss difference:\n",
      "0.024660606839130683\n",
      "epoch: 1934\n",
      "training loss: 0.37616543796966645\n",
      "validation loss: 7.502458511089042\n",
      "loss difference:\n",
      "-0.02425628134411384\n",
      "that didn't improve loss:  1\n",
      "epoch: 1935\n",
      "training loss: 0.35157218605113805\n",
      "validation loss: 7.742589403009743\n",
      "loss difference:\n",
      "0.024593251918528403\n",
      "epoch: 1936\n",
      "training loss: 0.3757615587101071\n",
      "validation loss: 7.502762244902976\n",
      "loss difference:\n",
      "-0.024189372658969033\n",
      "that didn't improve loss:  1\n",
      "epoch: 1937\n",
      "training loss: 0.35123552961649296\n",
      "validation loss: 7.742803194800127\n",
      "loss difference:\n",
      "0.02452602909361412\n",
      "epoch: 1938\n",
      "training loss: 0.37535812342307934\n",
      "validation loss: 7.503075410667213\n",
      "loss difference:\n",
      "-0.02412259380658638\n",
      "that didn't improve loss:  1\n",
      "epoch: 1939\n",
      "training loss: 0.35089918563099265\n",
      "validation loss: 7.743026257325753\n",
      "loss difference:\n",
      "0.024458937792086688\n",
      "epoch: 1940\n",
      "training loss: 0.3749551304720902\n",
      "validation loss: 7.503397970157956\n",
      "loss difference:\n",
      "-0.024055944841097576\n",
      "that didn't improve loss:  1\n",
      "epoch: 1941\n",
      "training loss: 0.3505631529287024\n",
      "validation loss: 7.743258551794\n",
      "loss difference:\n",
      "0.024391977543387844\n",
      "epoch: 1942\n",
      "training loss: 0.37455257883927273\n",
      "validation loss: 7.503729884690258\n",
      "loss difference:\n",
      "-0.02398942591057035\n",
      "that didn't improve loss:  1\n",
      "epoch: 1943\n",
      "training loss: 0.35022743086111247\n",
      "validation loss: 7.743500039954928\n",
      "loss difference:\n",
      "0.024325147978160266\n",
      "epoch: 1944\n",
      "training loss: 0.37415046811231695\n",
      "validation loss: 7.504071115124223\n",
      "loss difference:\n",
      "-0.023923037251204482\n",
      "that didn't improve loss:  1\n",
      "epoch: 1945\n",
      "training loss: 0.3498920192855103\n",
      "validation loss: 7.743750684086678\n",
      "loss difference:\n",
      "0.024258448826806667\n",
      "epoch: 1946\n",
      "training loss: 0.37374879846640463\n",
      "validation loss: 7.504421621874312\n",
      "loss difference:\n",
      "-0.02385677918089435\n",
      "that didn't improve loss:  1\n",
      "epoch: 1947\n",
      "training loss: 0.34955691854919707\n",
      "validation loss: 7.744010446975919\n",
      "loss difference:\n",
      "0.02419187991720756\n",
      "epoch: 1948\n",
      "training loss: 0.3733475706414767\n",
      "validation loss: 7.50478136492152\n",
      "loss difference:\n",
      "-0.02379065209227965\n",
      "that didn't improve loss:  1\n",
      "epoch: 1949\n",
      "training loss: 0.34922212946981673\n",
      "validation loss: 7.744279291893849\n",
      "loss difference:\n",
      "0.02412544117165999\n",
      "epoch: 1950\n",
      "training loss: 0.37294678591513564\n",
      "validation loss: 7.50515030382838\n",
      "loss difference:\n",
      "-0.023724656445318903\n",
      "that didn't improve loss:  1\n",
      "epoch: 1951\n",
      "training loss: 0.34888765331209853\n",
      "validation loss: 7.744557182568106\n",
      "loss difference:\n",
      "0.024059132603037103\n",
      "epoch: 1952\n",
      "training loss: 0.3725464460716065\n",
      "validation loss: 7.505528397756477\n",
      "loss difference:\n",
      "-0.02365879275950794\n",
      "that didn't improve loss:  1\n",
      "epoch: 1953\n",
      "training loss: 0.34855349176132133\n",
      "validation loss: 7.744844083150822\n",
      "loss difference:\n",
      "0.02399295431028514\n",
      "epoch: 1954\n",
      "training loss: 0.3721465533671218\n",
      "validation loss: 7.505915605486328\n",
      "loss difference:\n",
      "-0.02359306160580049\n",
      "that didn't improve loss:  1\n",
      "epoch: 1955\n",
      "training loss: 0.3482196468938359\n",
      "validation loss: 7.74513995818355\n",
      "loss difference:\n",
      "0.023926906473285936\n",
      "epoch: 1956\n",
      "training loss: 0.3717471104921784\n",
      "validation loss: 7.506311885439405\n",
      "loss difference:\n",
      "-0.023527463598342513\n",
      "that didn't improve loss:  1\n",
      "epoch: 1957\n",
      "training loss: 0.34788612114500317\n",
      "validation loss: 7.745444772559123\n",
      "loss difference:\n",
      "0.023860989347175232\n",
      "epoch: 1958\n",
      "training loss: 0.37134812053106603\n",
      "validation loss: 7.506717195702013\n",
      "loss difference:\n",
      "-0.02346199938606286\n",
      "that didn't improve loss:  1\n",
      "epoch: 1959\n",
      "training loss: 0.34755291727490734\n",
      "validation loss: 7.7457584914812605\n",
      "loss difference:\n",
      "0.023795203256158692\n",
      "epoch: 1960\n",
      "training loss: 0.3709495869191576\n",
      "validation loss: 7.507131494050883\n",
      "loss difference:\n",
      "-0.023396669644250245\n",
      "that didn't improve loss:  1\n",
      "epoch: 1961\n",
      "training loss: 0.3472200383322428\n",
      "validation loss: 7.746081080422045\n",
      "loss difference:\n",
      "0.023729548586914784\n",
      "epoch: 1962\n",
      "training loss: 0.370551513398397\n",
      "validation loss: 7.507554737980046\n",
      "loss difference:\n",
      "-0.023331475066154184\n",
      "that didn't improve loss:  1\n",
      "epoch: 1963\n",
      "training loss: 0.3468874876167351\n",
      "validation loss: 7.7464125050780925\n",
      "loss difference:\n",
      "0.02366402578166188\n",
      "epoch: 1964\n",
      "training loss: 0.37015390397145376\n",
      "validation loss: 7.507986884728886\n",
      "loss difference:\n",
      "-0.023266416354718655\n",
      "that didn't improve loss:  1\n",
      "epoch: 1965\n",
      "training loss: 0.3465552686404926\n",
      "validation loss: 7.7467527313254605\n",
      "loss difference:\n",
      "0.023598635330961182\n",
      "epoch: 1966\n",
      "training loss: 0.3697567628549873\n",
      "validation loss: 7.5084278913110705\n",
      "loss difference:\n",
      "-0.023201494214494744\n",
      "that didn't improve loss:  1\n",
      "epoch: 1967\n",
      "training loss: 0.346223385088681\n",
      "validation loss: 7.74710172517421\n",
      "loss difference:\n",
      "0.023533377766306318\n",
      "epoch: 1968\n",
      "training loss: 0.3693600944324961\n",
      "validation loss: 7.508877714544005\n",
      "loss difference:\n",
      "-0.02313670934381512\n",
      "that didn't improve loss:  1\n",
      "epoch: 1969\n",
      "training loss: 0.34589184077988716\n",
      "validation loss: 7.747459452722629\n",
      "loss difference:\n",
      "0.02346825365260896\n",
      "epoch: 1970\n",
      "training loss: 0.368963903207171\n",
      "validation loss: 7.509336311078621\n",
      "loss difference:\n",
      "-0.023072062427283824\n",
      "that didn't improve loss:  1\n",
      "epoch: 1971\n",
      "training loss: 0.3455606396265426\n",
      "validation loss: 7.747825880111919\n",
      "loss difference:\n",
      "0.023403263580628386\n",
      "epoch: 1972\n",
      "training loss: 0.3685681937552076\n",
      "validation loss: 7.509803637429269\n",
      "loss difference:\n",
      "-0.02300755412866501\n",
      "that didn't improve loss:  1\n",
      "epoch: 1973\n",
      "training loss: 0.3452297855957834\n",
      "validation loss: 7.748200973481517\n",
      "loss difference:\n",
      "0.02333840815942423\n",
      "epoch: 1974\n",
      "training loss: 0.3681729706799608\n",
      "validation loss: 7.510279650003381\n",
      "loss difference:\n",
      "-0.02294318508417742\n",
      "that didn't improve loss:  1\n",
      "epoch: 1975\n",
      "training loss: 0.34489928267107056\n",
      "validation loss: 7.74858469892563\n",
      "loss difference:\n",
      "0.023273688008890236\n",
      "epoch: 1976\n",
      "training loss: 0.3677782385673614\n",
      "validation loss: 7.51076430513067\n",
      "loss difference:\n",
      "-0.022878955896290853\n",
      "that didn't improve loss:  1\n",
      "epoch: 1977\n",
      "training loss: 0.3445691348149106\n",
      "validation loss: 7.748977022451193\n",
      "loss difference:\n",
      "0.023209103752450833\n",
      "epoch: 1978\n",
      "training loss: 0.3673840019429318\n",
      "validation loss: 7.511257559091723\n",
      "loss difference:\n",
      "-0.02281486712802122\n",
      "that didn't improve loss:  1\n",
      "epoch: 1979\n",
      "training loss: 0.3442393459329785\n",
      "validation loss: 7.749377909937768\n",
      "loss difference:\n",
      "0.0231446560099533\n",
      "epoch: 1980\n",
      "training loss: 0.36699026523078515\n",
      "validation loss: 7.511759368145617\n",
      "loss difference:\n",
      "-0.02275091929780665\n",
      "that didn't improve loss:  1\n",
      "epoch: 1981\n",
      "training loss: 0.34390991983993013\n",
      "validation loss: 7.749787327099607\n",
      "loss difference:\n",
      "0.023080345390855017\n",
      "epoch: 1982\n",
      "training loss: 0.3665970327148659\n",
      "validation loss: 7.51226968855651\n",
      "loss difference:\n",
      "-0.022687112874935744\n",
      "that didn't improve loss:  1\n",
      "epoch: 1983\n",
      "training loss: 0.34358086022716544\n",
      "validation loss: 7.750205239450155\n",
      "loss difference:\n",
      "0.023016172487700437\n",
      "epoch: 1984\n",
      "training loss: 0.3662043085027684\n",
      "validation loss: 7.512788476618866\n",
      "loss difference:\n",
      "-0.022623448275602975\n",
      "that didn't improve loss:  1\n",
      "epoch: 1985\n",
      "training loss: 0.3432521706327702\n",
      "validation loss: 7.7506316122694\n",
      "loss difference:\n",
      "0.022952137869998224\n",
      "epoch: 1986\n",
      "training loss: 0.36581209649234864\n",
      "validation loss: 7.513315688681268\n",
      "loss difference:\n",
      "-0.022559925859578445\n",
      "that didn't improve loss:  1\n",
      "epoch: 1987\n",
      "training loss: 0.3429238544138701\n",
      "validation loss: 7.751066410574108\n",
      "loss difference:\n",
      "0.02288824207847856\n",
      "epoch: 1988\n",
      "training loss: 0.3654204003413586\n",
      "validation loss: 7.513851281168563\n",
      "loss difference:\n",
      "-0.02249654592748851\n",
      "that didn't improve loss:  1\n",
      "epoch: 1989\n",
      "training loss: 0.34259591472153017\n",
      "validation loss: 7.751509599091292\n",
      "loss difference:\n",
      "0.022824485619828416\n",
      "epoch: 1990\n",
      "training loss: 0.3650292234402946\n",
      "validation loss: 7.51439521060227\n",
      "loss difference:\n",
      "-0.022433308718764422\n",
      "that didn't improve loss:  1\n",
      "epoch: 1991\n",
      "training loss: 0.3422683544784108\n",
      "validation loss: 7.7519611422349834\n",
      "loss difference:\n",
      "0.022760868961883785\n",
      "epoch: 1992\n",
      "training loss: 0.364638568888592\n",
      "validation loss: 7.514947433619082\n",
      "loss difference:\n",
      "-0.022370214410181166\n",
      "that didn't improve loss:  1\n",
      "epoch: 1993\n",
      "training loss: 0.3419411763592473\n",
      "validation loss: 7.752421004086512\n",
      "loss difference:\n",
      "0.022697392529344662\n",
      "epoch: 1994\n",
      "training loss: 0.3642484394742905\n",
      "validation loss: 7.5155079069874136\n",
      "loss difference:\n",
      "-0.022307263115043163\n",
      "that didn't improve loss:  1\n",
      "epoch: 1995\n",
      "training loss: 0.3416143827742821\n",
      "validation loss: 7.752889148378274\n",
      "loss difference:\n",
      "0.022634056700008398\n",
      "epoch: 1996\n",
      "training loss: 0.36385883765723737\n",
      "validation loss: 7.516076587621874\n",
      "loss difference:\n",
      "-0.02224445488295529\n",
      "that didn't improve loss:  1\n",
      "epoch: 1997\n",
      "training loss: 0.34128797585569304\n",
      "validation loss: 7.753365538481122\n",
      "loss difference:\n",
      "0.02257086180154433\n",
      "epoch: 1998\n",
      "training loss: 0.36346976555589394\n",
      "validation loss: 7.516653432595599\n",
      "loss difference:\n",
      "-0.022181789700200905\n",
      "that didn't improve loss:  1\n",
      "epoch: 1999\n",
      "training loss: 0.34096195744706037\n",
      "validation loss: 7.753850137395433\n",
      "loss difference:\n",
      "0.02250780810883357\n"
     ]
    }
   ],
   "source": [
    "nodes = [100, 100, 100] # use to specify a number of hidden nodes per layer\n",
    "activations = [] # use if you want a diff activationFn per layer\n",
    "\n",
    "nn = NeuralNetwork(layers=1, nnodes=100, batchSize=50, \n",
    "                   activationFn=\"tanh\", lr=.01, max_epoch=2000,\n",
    "                   momentum=0, tol = 0.0001)\n",
    "nn.fit(X_std, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error of Housing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: $817.48\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y, nn.predict(X_std))\n",
    "print('Mean absolute error: $%0.2f'%(mae*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these to results to those in nn_tuning_example.ipynb.  Goal: Get MAE Under $1000 with our NN.  Then, we know our NN is working well and can use it on the dataset for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR:\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        # create vector of ones...\n",
    "        ones = np.ones(shape=len(X_train))[..., None]\n",
    "        #...and add to feature matrix\n",
    "        X = np.concatenate((ones, X_train), 1)\n",
    "        #calculate coefficients using closed-form solution\n",
    "        self.coeffs = np.linalg.inv(X.transpose().dot(X)).dot(X.transpose()).dot(y_train)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        ones = np.ones(shape=len(X_test))[..., None]\n",
    "        X_test = np.concatenate((ones, X_test), 1)\n",
    "        y_hat = X_test.dot(self.coeffs)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: $17885.89\n"
     ]
    }
   ],
   "source": [
    "lr = LR()\n",
    "lr.fit(X, y)\n",
    "mae = mean_absolute_error(y, lr.predict(X_std))\n",
    "print('Mean absolute error: $%0.2f'%(mae*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
