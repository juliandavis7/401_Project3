{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs import *\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data to Test Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, layers=None, nodes=None, nnodes=None, \n",
    "                 activations=[], activationFn=\"\", batchSize=50, \n",
    "                 lr=.01, max_epoch=100, momentum=.9,tol=0.0001):\n",
    "        \n",
    "        if layers != None:\n",
    "            self.layers = layers # total number of hidden layers\n",
    "        else:\n",
    "            self.layers = len(nodes)\n",
    "            \n",
    "        self.tol = tol\n",
    "\n",
    "        # an int array of size [0, ..., Layers + 1]\n",
    "        # Nodes[0] shall represent the input size (typically 50)\n",
    "        # Nodes[Layers + 1] shall represent the output size (typically 1)\n",
    "        # all other Nodes represent the number of nodes (or width) in the hidden layer i\n",
    "        self.nodes = nodes\n",
    "        if nodes != None:\n",
    "            self.nodes.insert(0, batchSize)\n",
    "            self.nodes.append(1)\n",
    "        \n",
    "        # alternative to nodes where each hidden layer of the nueral network is the same size\n",
    "        self.nnodes = nnodes\n",
    "        if nnodes != None:\n",
    "            self.nodes = []\n",
    "            self.nodes.append(batchSize)\n",
    "            for i in range(layers):\n",
    "                self.nodes.append(nnodes)\n",
    "            self.nodes.append(1)\n",
    "        \n",
    "        # activations[i] values are labels indicating the activation function used in layer i\n",
    "        self.activations = activations\n",
    "        self.activationFn = activationFn\n",
    "        if activationFn != \"\":\n",
    "            self.activations = [activationFn] * layers\n",
    "        \n",
    "        self.batchSize = batchSize\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "        self.max_epoch = max_epoch\n",
    "        \n",
    "        self.mu = momentum\n",
    "        \n",
    "        self.layer_values = [None] * (self.layers + 2)\n",
    "        self.iters = 0\n",
    "        self.epochs = 0\n",
    "                \n",
    "    def validateHyperParams(self):\n",
    "        \n",
    "        if self.layers != (len(self.nodes) - 2):\n",
    "            raise ValueError(\"layers must be equal to the number of hidden layers, got %s.\" % self.layers)\n",
    "        if self.nnodes != None and self.nnodes <= 0:\n",
    "            raise ValueError(\"nnodes must be > 0, got %s.\" % self.nnodes)\n",
    "        if self.lr <= 0 or self.lr > 1:\n",
    "            raise ValueError(\"lr must be in (0, 1], got %s.\" % self.lr)\n",
    "            \n",
    "        if self.max_epoch <= 0:\n",
    "            raise ValueError(\"max_iter must be > 0, got %s.\" % self.max_epoch)\n",
    "               \n",
    "        activation_functions = list(ACTIVATIONS.keys())\n",
    "        if self.activationFn != \"\":\n",
    "            if self.activationFn not in activation_functions:\n",
    "                raise ValueError(\"%s is not an activation function\" % self.activationFn\n",
    "                                + \"\\nAvailable activation functions: relu, leaky_relu, sigmoid, tanh\")\n",
    "    \n",
    "    def initialize_weights(self, M):\n",
    "        weights = []\n",
    "        \n",
    "        for i in range(self.layers + 1):\n",
    "            if i == 0:\n",
    "                input_size = M # special case for w1\n",
    "            else:\n",
    "                input_size = self.nodes[i]\n",
    "            output_size = self.nodes[i + 1]\n",
    "            w_i = np.random.normal(size=(input_size, output_size))\n",
    "            w_i = np.round(w_i, 2)\n",
    "            w_i[input_size - 1:] = 0 # initialize bias to 0\n",
    "            weights.append(w_i)\n",
    "        return weights\n",
    "       \n",
    "        \n",
    "    def forward_pass(self, X_batch, y_batch):\n",
    "        \n",
    "        self.layer_values[0] = X_batch\n",
    "        \n",
    "        # calculate hidden layers\n",
    "        for i in range(self.layers):\n",
    "            X = self.layer_values[i]\n",
    "            weights = self.weights[i]\n",
    "            h_layer = X.dot(weights)\n",
    "            \n",
    "            # apply activation function\n",
    "            activation_fn = ACTIVATIONS[self.activations[i]]\n",
    "            activation_fn(h_layer)\n",
    "            self.layer_values[i + 1] = h_layer\n",
    "            \n",
    "        \n",
    "        # calculate predictions\n",
    "        X = self.layer_values[self.layers] # values in last hidden layer\n",
    "        weights = self.weights[self.layers]\n",
    "        y_pred = X.dot(weights)\n",
    "        y_pred = y_pred.flatten()\n",
    "        \n",
    "        # calculate the l2 loss\n",
    "        l2_loss = 0\n",
    "        # only need predictions once we have fit the data\n",
    "        if isinstance(y_batch, np.ndarray): \n",
    "            l2_loss = squared_loss(y_pred, y_batch)\n",
    "            self.layer_values[self.layers + 1] = l2_loss\n",
    "        \n",
    "        return l2_loss, y_pred\n",
    "    \n",
    "    \n",
    "    def backward_pass(self, y_pred, y_batch):\n",
    "        \n",
    "        # loss layer\n",
    "        J = squared_loss_derivative(y_pred, y_batch, self.batchSize)\n",
    "        J = np.reshape(J, (len(J), 1))\n",
    "        \n",
    "        J_weights = [None] * (self.layers + 1)\n",
    "        \n",
    "        # output layer\n",
    "        # jacobian w.r.t. weights\n",
    "        x_t = self.layer_values[self.layers].T\n",
    "        J_wi = x_t.dot(J)\n",
    "        J_weights[self.layers] = J_wi\n",
    "        \n",
    "        # update jacobian at output layer\n",
    "        w_t = self.weights[self.layers].T\n",
    "        w_t = np.delete(w_t, w_t.shape[1] - 1, 1) # take out the bias\n",
    "        J = np.dot(J, w_t)\n",
    "        zeros = [0] * len(J)\n",
    "        zeros = np.reshape(zeros, (len(J), 1))\n",
    "        J = np.append(J, zeros, axis=1)\n",
    "        \n",
    "        # iterate through hidden layers backwards\n",
    "        for i in range(self.layers, 0 , -1):\n",
    "            # update jacobian at activation layer\n",
    "            d_activation_fn = DERIVATIVES[self.activations[i - 1]]\n",
    "            d_activation_fn(self.layer_values[i], J)\n",
    "            \n",
    "            # hidden layer\n",
    "            # jacobian w.r.t. weights\n",
    "            x_t = self.layer_values[i - 1].T\n",
    "            J_wi = x_t.dot(J)\n",
    "            J_weights[i - 1] = J_wi\n",
    "            \n",
    "        # initialize velocity to 0\n",
    "        if self.epochs == 0 and self.iters == 0:\n",
    "            self.velocity = []\n",
    "            for i in range(len(J_weights)):\n",
    "                n_rows = J_weights[i].shape[0]\n",
    "                n_cols = J_weights[i].shape[1]\n",
    "                vel_i = np.zeros((n_rows, n_cols))\n",
    "                self.velocity.append(vel_i)\n",
    "        \n",
    "        for i in range(len(J_weights)):\n",
    "            self.velocity[i] = self.mu * self.velocity[i] - self.lr * J_weights[i]\n",
    "            self.weights[i] += self.velocity[i]\n",
    "      \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        self.validateHyperParams()\n",
    "        # convert to numpy arrays\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            X_train = X_train.to_numpy()\n",
    "            \n",
    "        if isinstance(y_train, pd.Series):\n",
    "            y_train = y_train.to_numpy()\n",
    "            \n",
    "        # add ones for bias\n",
    "        ones = [1] * len(X_train)\n",
    "        ones = np.reshape(ones, (len(X_train), 1))\n",
    "        X_train = np.append(X_train, ones, axis=1)\n",
    "        \n",
    "        # save 10% for validation\n",
    "        val_rows = round(len(X_train) * .1)\n",
    "        X_val = X_train[:val_rows, :]\n",
    "        y_val = y_train[:val_rows]\n",
    "        \n",
    "        X_train = X_train[val_rows:, :]\n",
    "        y_train = y_train[val_rows:]\n",
    "        \n",
    "        # initalize weights on first iteration\n",
    "        M = X_train.shape[1] # M = number of features\n",
    "        self.weights = self.initialize_weights(M)\n",
    "        \n",
    "        previous_loss = np.inf\n",
    "        didnt_improve_loss_count = 0\n",
    "        \n",
    "        print(\"NUMBER OF EPOCHS\")\n",
    "        print(self.epochs)\n",
    "        \n",
    "        while (self.epochs < self.max_epoch):\n",
    "            # ONE EPOCH \n",
    "            last_idx = 0\n",
    "            while (last_idx < len(X_train)):\n",
    "                first_idx = self.iters * self.batchSize\n",
    "                remaining_rows = len(X_train) - first_idx\n",
    "                last_idx = first_idx + min(self.batchSize, remaining_rows)\n",
    "                X_batch = X_train[first_idx: last_idx, :]\n",
    "                y_batch = y_train[first_idx: last_idx]\n",
    "\n",
    "                loss, y_pred = self.forward_pass(X_batch, y_batch)\n",
    "                self.backward_pass(y_pred, y_batch)\n",
    "                self.iters += 1\n",
    "            \n",
    "            # trainig and validation loss after one epoch\n",
    "            t_loss, y_pred = self.forward_pass(X_train, y_train)\n",
    "            v_loss, y_pred = self.forward_pass(X_val, y_val)\n",
    "            print(\"epoch:\", self.epochs)\n",
    "            print(\"training loss:\", t_loss)\n",
    "            print(\"validation loss:\", v_loss)\n",
    "            \n",
    "            self.iters = 0 # start over, next epoch\n",
    "            self.epochs += 1\n",
    "            \n",
    "            # Currently stops based on training loss, but could easily be modified to\n",
    "            # stop on validation loss by substituting t_loss with v_loss\n",
    "            print(\"loss difference:\")\n",
    "            print(previous_loss - t_loss)\n",
    "            if previous_loss - t_loss < self.tol:\n",
    "                didnt_improve_loss_count += 1\n",
    "                print(\"that didn't improve loss: \", didnt_improve_loss_count)\n",
    "            else:\n",
    "                didnt_improve_loss_count = 0\n",
    "            \n",
    "            previous_loss = t_loss\n",
    "            \n",
    "            if(didnt_improve_loss_count >= 10):\n",
    "                print(\"Training loss did not improve more than tol=\" + str(self.tol) + \" for 10 consecutive epochs. Stopping.\")\n",
    "                return\n",
    "            \n",
    "       \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        # convert to numpy array\n",
    "        if isinstance(X_test, pd.DataFrame):\n",
    "            X_test = X_test.to_numpy()\n",
    "        \n",
    "        # add ones for bias\n",
    "        ones = [1] * len(X_test)\n",
    "        ones = np.reshape(ones, (len(X_test), 1))\n",
    "        X_test = np.append(X_test, ones, axis=1)\n",
    "        \n",
    "        loss, y_pred = self.forward_pass(X_test, None)\n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Nueral Network on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF EPOCHS\n",
      "0\n",
      "epoch: 0\n",
      "training loss: 168.5671589424785\n",
      "validation loss: 165.74103893977775\n",
      "loss difference:\n",
      "inf\n",
      "epoch: 1\n",
      "training loss: 60.19675834634692\n",
      "validation loss: 74.85115537036792\n",
      "loss difference:\n",
      "108.37040059613159\n",
      "epoch: 2\n",
      "training loss: 30.725347853910066\n",
      "validation loss: 48.73639786026457\n",
      "loss difference:\n",
      "29.471410492436853\n",
      "epoch: 3\n",
      "training loss: 22.354542107114934\n",
      "validation loss: 40.24835248152516\n",
      "loss difference:\n",
      "8.370805746795131\n",
      "epoch: 4\n",
      "training loss: 18.797168493215466\n",
      "validation loss: 37.02636117397103\n",
      "loss difference:\n",
      "3.5573736138994683\n",
      "epoch: 5\n",
      "training loss: 16.581148496870522\n",
      "validation loss: 35.46771603633006\n",
      "loss difference:\n",
      "2.2160199963449436\n",
      "epoch: 6\n",
      "training loss: 14.944483495673733\n",
      "validation loss: 34.484250331735836\n",
      "loss difference:\n",
      "1.6366650011967891\n",
      "epoch: 7\n",
      "training loss: 13.642940241324158\n",
      "validation loss: 33.710516156905086\n",
      "loss difference:\n",
      "1.3015432543495749\n",
      "epoch: 8\n",
      "training loss: 12.567829218411626\n",
      "validation loss: 33.029162322894855\n",
      "loss difference:\n",
      "1.075111022912532\n",
      "epoch: 9\n",
      "training loss: 11.660508601310637\n",
      "validation loss: 32.39837122441666\n",
      "loss difference:\n",
      "0.9073206171009893\n",
      "epoch: 10\n",
      "training loss: 10.886157315579796\n",
      "validation loss: 31.803316449733057\n",
      "loss difference:\n",
      "0.774351285730841\n",
      "epoch: 11\n",
      "training loss: 10.218133514963707\n",
      "validation loss: 31.231448819550835\n",
      "loss difference:\n",
      "0.6680238006160888\n",
      "epoch: 12\n",
      "training loss: 9.632661421371006\n",
      "validation loss: 30.67165658135307\n",
      "loss difference:\n",
      "0.5854720935927009\n",
      "epoch: 13\n",
      "training loss: 9.112276636076858\n",
      "validation loss: 30.119311782597382\n",
      "loss difference:\n",
      "0.5203847852941479\n",
      "epoch: 14\n",
      "training loss: 8.645428855480416\n",
      "validation loss: 29.5763073122061\n",
      "loss difference:\n",
      "0.46684778059644216\n",
      "epoch: 15\n",
      "training loss: 8.22393844675203\n",
      "validation loss: 29.046599239210867\n",
      "loss difference:\n",
      "0.4214904087283866\n",
      "epoch: 16\n",
      "training loss: 7.841481867467426\n",
      "validation loss: 28.532982929979564\n",
      "loss difference:\n",
      "0.38245657928460375\n",
      "epoch: 17\n",
      "training loss: 7.49299271467408\n",
      "validation loss: 28.03657980976701\n",
      "loss difference:\n",
      "0.3484891527933458\n",
      "epoch: 18\n",
      "training loss: 7.174399605213152\n",
      "validation loss: 27.557366262722383\n",
      "loss difference:\n",
      "0.3185931094609282\n",
      "epoch: 19\n",
      "training loss: 6.882424910924748\n",
      "validation loss: 27.094633375790885\n",
      "loss difference:\n",
      "0.2919746942884034\n",
      "epoch: 20\n",
      "training loss: 6.6143761446170295\n",
      "validation loss: 26.647194145973273\n",
      "loss difference:\n",
      "0.2680487663077189\n",
      "epoch: 21\n",
      "training loss: 6.367937061087962\n",
      "validation loss: 26.213526457705832\n",
      "loss difference:\n",
      "0.24643908352906774\n",
      "epoch: 22\n",
      "training loss: 6.140990684823936\n",
      "validation loss: 25.792018405247035\n",
      "loss difference:\n",
      "0.22694637626402603\n",
      "epoch: 23\n",
      "training loss: 5.931526541190935\n",
      "validation loss: 25.38130278801814\n",
      "loss difference:\n",
      "0.20946414363300114\n",
      "epoch: 24\n",
      "training loss: 5.737650541848158\n",
      "validation loss: 24.980527769667372\n",
      "loss difference:\n",
      "0.19387599934277677\n",
      "epoch: 25\n",
      "training loss: 5.55764505076844\n",
      "validation loss: 24.589425771606173\n",
      "loss difference:\n",
      "0.18000549107971775\n",
      "epoch: 26\n",
      "training loss: 5.390013108106167\n",
      "validation loss: 24.208188099537047\n",
      "loss difference:\n",
      "0.16763194266227277\n",
      "epoch: 27\n",
      "training loss: 5.233481748040641\n",
      "validation loss: 23.83726173760322\n",
      "loss difference:\n",
      "0.15653136006552604\n",
      "epoch: 28\n",
      "training loss: 5.086973803377948\n",
      "validation loss: 23.477169818968672\n",
      "loss difference:\n",
      "0.14650794466269357\n",
      "epoch: 29\n",
      "training loss: 4.949567471197171\n",
      "validation loss: 23.12839253951084\n",
      "loss difference:\n",
      "0.13740633218077658\n",
      "epoch: 30\n",
      "training loss: 4.820458847800325\n",
      "validation loss: 22.791304042083212\n",
      "loss difference:\n",
      "0.1291086233968457\n",
      "epoch: 31\n",
      "training loss: 4.698934331487482\n",
      "validation loss: 22.46614758386668\n",
      "loss difference:\n",
      "0.12152451631284311\n",
      "epoch: 32\n",
      "training loss: 4.584352903907191\n",
      "validation loss: 22.153031805866725\n",
      "loss difference:\n",
      "0.11458142758029144\n",
      "epoch: 33\n",
      "training loss: 4.476135257629044\n",
      "validation loss: 21.85193736383761\n",
      "loss difference:\n",
      "0.10821764627814723\n",
      "epoch: 34\n",
      "training loss: 4.373756705903978\n",
      "validation loss: 21.5627294931706\n",
      "loss difference:\n",
      "0.10237855172506549\n",
      "epoch: 35\n",
      "training loss: 4.276741870838848\n",
      "validation loss: 21.285174630669175\n",
      "loss difference:\n",
      "0.09701483506513053\n",
      "epoch: 36\n",
      "training loss: 4.184660138117183\n",
      "validation loss: 21.018959173790197\n",
      "loss difference:\n",
      "0.09208173272166498\n",
      "epoch: 37\n",
      "training loss: 4.097121479897239\n",
      "validation loss: 20.763708299623442\n",
      "loss difference:\n",
      "0.08753865821994378\n",
      "epoch: 38\n",
      "training loss: 4.0137725419196135\n",
      "validation loss: 20.519003269702846\n",
      "loss difference:\n",
      "0.08334893797762533\n",
      "epoch: 39\n",
      "training loss: 3.9342929981597425\n",
      "validation loss: 20.28439640253655\n",
      "loss difference:\n",
      "0.07947954375987099\n",
      "epoch: 40\n",
      "training loss: 3.858392198372384\n",
      "validation loss: 20.05942348874635\n",
      "loss difference:\n",
      "0.07590079978735842\n",
      "epoch: 41\n",
      "training loss: 3.785806126790312\n",
      "validation loss: 19.843613755966864\n",
      "loss difference:\n",
      "0.07258607158207209\n",
      "epoch: 42\n",
      "training loss: 3.7162946775494077\n",
      "validation loss: 19.636497633369274\n",
      "loss difference:\n",
      "0.06951144924090435\n",
      "epoch: 43\n",
      "training loss: 3.6496392408284075\n",
      "validation loss: 19.43761261012842\n",
      "loss difference:\n",
      "0.06665543672100016\n",
      "epoch: 44\n",
      "training loss: 3.5856405838873164\n",
      "validation loss: 19.24650748699526\n",
      "loss difference:\n",
      "0.06399865694109108\n",
      "epoch: 45\n",
      "training loss: 3.524117002872249\n",
      "validation loss: 19.062745311680825\n",
      "loss difference:\n",
      "0.061523581015067386\n",
      "epoch: 46\n",
      "training loss: 3.4649027145861386\n",
      "validation loss: 18.88590527451116\n",
      "loss difference:\n",
      "0.05921428828611042\n",
      "epoch: 47\n",
      "training loss: 3.407846452869698\n",
      "validation loss: 18.715583820850558\n",
      "loss difference:\n",
      "0.05705626171644074\n",
      "epoch: 48\n",
      "training loss: 3.3528102321544315\n",
      "validation loss: 18.551395210196056\n",
      "loss difference:\n",
      "0.05503622071526637\n",
      "epoch: 49\n",
      "training loss: 3.2996682412146066\n",
      "validation loss: 18.392971719269145\n",
      "loss difference:\n",
      "0.05314199093982497\n",
      "epoch: 50\n",
      "training loss: 3.2483058330058006\n",
      "validation loss: 18.23996365023816\n",
      "loss difference:\n",
      "0.051362408208806\n",
      "epoch: 51\n",
      "training loss: 3.1986185814743973\n",
      "validation loss: 18.092039268544056\n",
      "loss difference:\n",
      "0.0496872515314033\n",
      "epoch: 52\n",
      "training loss: 3.1505113830384217\n",
      "validation loss: 17.948884760485765\n",
      "loss difference:\n",
      "0.04810719843597555\n",
      "epoch: 53\n",
      "training loss: 3.1038975886487297\n",
      "validation loss: 17.810204270468937\n",
      "loss difference:\n",
      "0.04661379438969204\n",
      "epoch: 54\n",
      "training loss: 3.0586981613022335\n",
      "validation loss: 17.6757200520592\n",
      "loss difference:\n",
      "0.04519942734649618\n",
      "epoch: 55\n",
      "training loss: 3.014840862689328\n",
      "validation loss: 17.545172745106555\n",
      "loss difference:\n",
      "0.04385729861290555\n",
      "epoch: 56\n",
      "training loss: 2.972259480206806\n",
      "validation loss: 17.418321772136835\n",
      "loss difference:\n",
      "0.04258138248252186\n",
      "epoch: 57\n",
      "training loss: 2.930893110754001\n",
      "validation loss: 17.294945829965435\n",
      "loss difference:\n",
      "0.04136636945280525\n",
      "epoch: 58\n",
      "training loss: 2.8906855197490047\n",
      "validation loss: 17.174843436597996\n",
      "loss difference:\n",
      "0.04020759100499616\n",
      "epoch: 59\n",
      "training loss: 2.8515845923919274\n",
      "validation loss: 17.057833478966455\n",
      "loss difference:\n",
      "0.039100927357077264\n",
      "epoch: 60\n",
      "training loss: 2.813541889701946\n",
      "validation loss: 16.943755693977675\n",
      "loss difference:\n",
      "0.03804270268998122\n",
      "epoch: 61\n",
      "training loss: 2.7765123150070234\n",
      "validation loss: 16.83247100314546\n",
      "loss difference:\n",
      "0.03702957469492274\n",
      "epoch: 62\n",
      "training loss: 2.740453888138849\n",
      "validation loss: 16.723861608087805\n",
      "loss difference:\n",
      "0.03605842686817429\n",
      "epoch: 63\n",
      "training loss: 2.705327615036357\n",
      "validation loss: 16.617830738334774\n",
      "loss difference:\n",
      "0.03512627310249217\n",
      "epoch: 64\n",
      "training loss: 2.6710974299312467\n",
      "validation loss: 16.514301924073234\n",
      "loss difference:\n",
      "0.03423018510511033\n",
      "epoch: 65\n",
      "training loss: 2.637730176179675\n",
      "validation loss: 16.41321765040218\n",
      "loss difference:\n",
      "0.03336725375157146\n",
      "epoch: 66\n",
      "training loss: 2.605195581847871\n",
      "validation loss: 16.31453725196206\n",
      "loss difference:\n",
      "0.03253459433180428\n",
      "epoch: 67\n",
      "training loss: 2.573466181324792\n",
      "validation loss: 16.218233952909305\n",
      "loss difference:\n",
      "0.03172940052307904\n",
      "epoch: 68\n",
      "training loss: 2.542517140137087\n",
      "validation loss: 16.12429107327822\n",
      "loss difference:\n",
      "0.030949041187704918\n",
      "epoch: 69\n",
      "training loss: 2.5123259607575403\n",
      "validation loss: 16.032697614139273\n",
      "loss difference:\n",
      "0.03019117937954663\n",
      "epoch: 70\n",
      "training loss: 2.482872079826673\n",
      "validation loss: 15.943443659326244\n",
      "loss difference:\n",
      "0.029453880930867538\n",
      "epoch: 71\n",
      "training loss: 2.4541364001461323\n",
      "validation loss: 15.856516196740154\n",
      "loss difference:\n",
      "0.02873567968054047\n",
      "epoch: 72\n",
      "training loss: 2.426100818767446\n",
      "validation loss: 15.771895960093964\n",
      "loss difference:\n",
      "0.028035581378686114\n",
      "epoch: 73\n",
      "training loss: 2.398747807908968\n",
      "validation loss: 15.689555679623423\n",
      "loss difference:\n",
      "0.0273530108584783\n",
      "epoch: 74\n",
      "training loss: 2.372060084747772\n",
      "validation loss: 15.6094597828061\n",
      "loss difference:\n",
      "0.02668772316119572\n",
      "epoch: 75\n",
      "training loss: 2.346020383255807\n",
      "validation loss: 15.531565260375396\n",
      "loss difference:\n",
      "0.026039701491965328\n",
      "epoch: 76\n",
      "training loss: 2.320611325145673\n",
      "validation loss: 15.455823239991307\n",
      "loss difference:\n",
      "0.02540905811013383\n",
      "epoch: 77\n",
      "training loss: 2.295815377489121\n",
      "validation loss: 15.38218081499905\n",
      "loss difference:\n",
      "0.02479594765655202\n",
      "epoch: 78\n",
      "training loss: 2.271614878256775\n",
      "validation loss: 15.310582792064574\n",
      "loss difference:\n",
      "0.02420049923234613\n",
      "epoch: 79\n",
      "training loss: 2.247992107047837\n",
      "validation loss: 15.240973162529528\n",
      "loss difference:\n",
      "0.023622771208938076\n",
      "epoch: 80\n",
      "training loss: 2.224929377947517\n",
      "validation loss: 15.173296215350872\n",
      "loss difference:\n",
      "0.02306272910031959\n",
      "epoch: 81\n",
      "training loss: 2.2024091351829465\n",
      "validation loss: 15.107497282227804\n",
      "loss difference:\n",
      "0.022520242764570764\n",
      "epoch: 82\n",
      "training loss: 2.1804140385236273\n",
      "validation loss: 15.04352314706634\n",
      "loss difference:\n",
      "0.021995096659319202\n",
      "epoch: 83\n",
      "training loss: 2.1589270319257046\n",
      "validation loss: 14.981322174714586\n",
      "loss difference:\n",
      "0.021487006597922687\n",
      "epoch: 84\n",
      "training loss: 2.1379313941102156\n",
      "validation loss: 14.920844225966524\n",
      "loss difference:\n",
      "0.020995637815488966\n",
      "epoch: 85\n",
      "training loss: 2.1174107730205742\n",
      "validation loss: 14.862040430507685\n",
      "loss difference:\n",
      "0.020520621089641367\n",
      "epoch: 86\n",
      "training loss: 2.097349207627809\n",
      "validation loss: 14.80486288762211\n",
      "loss difference:\n",
      "0.020061565392765157\n",
      "epoch: 87\n",
      "training loss: 2.0777311408634613\n",
      "validation loss: 14.749264356546828\n",
      "loss difference:\n",
      "0.01961806676434774\n",
      "epoch: 88\n",
      "training loss: 2.058541427070037\n",
      "validation loss: 14.695197985477755\n",
      "loss difference:\n",
      "0.019189713793424268\n",
      "epoch: 89\n",
      "training loss: 2.0397653366405195\n",
      "validation loss: 14.642617112360197\n",
      "loss difference:\n",
      "0.018776090429517556\n",
      "epoch: 90\n",
      "training loss: 2.021388559701941\n",
      "validation loss: 14.591475154131512\n",
      "loss difference:\n",
      "0.01837677693857831\n",
      "epoch: 91\n",
      "training loss: 2.003397209916788\n",
      "validation loss: 14.541725586272463\n",
      "loss difference:\n",
      "0.017991349785153155\n",
      "epoch: 92\n",
      "training loss: 1.9857778288062247\n",
      "validation loss: 14.493322002997058\n",
      "loss difference:\n",
      "0.01761938111056338\n",
      "epoch: 93\n",
      "training loss: 1.9685173904844604\n",
      "validation loss: 14.446218240953147\n",
      "loss difference:\n",
      "0.01726043832176427\n",
      "epoch: 94\n",
      "training loss: 1.9516033063514786\n",
      "validation loss: 14.400368545883383\n",
      "loss difference:\n",
      "0.016914084132981788\n",
      "epoch: 95\n",
      "training loss: 1.935023429116238\n",
      "validation loss: 14.355727761665076\n",
      "loss difference:\n",
      "0.01657987723524057\n",
      "epoch: 96\n",
      "training loss: 1.9187660554899526\n",
      "validation loss: 14.312251523536412\n",
      "loss difference:\n",
      "0.016257373626285432\n",
      "epoch: 97\n",
      "training loss: 1.9028199269627664\n",
      "validation loss: 14.269896441096474\n",
      "loss difference:\n",
      "0.015946128527186243\n",
      "epoch: 98\n",
      "training loss: 1.8871742282176631\n",
      "validation loss: 14.228620260934209\n",
      "loss difference:\n",
      "0.015645698745103243\n",
      "epoch: 99\n",
      "training loss: 1.8718185829076093\n",
      "validation loss: 14.18838200283184\n",
      "loss difference:\n",
      "0.015355645310053845\n",
      "epoch: 100\n",
      "training loss: 1.8567430466983021\n",
      "validation loss: 14.149142066981861\n",
      "loss difference:\n",
      "0.015075536209307128\n",
      "epoch: 101\n",
      "training loss: 1.8419380976418216\n",
      "validation loss: 14.110862312365017\n",
      "loss difference:\n",
      "0.014804949056480554\n",
      "epoch: 102\n",
      "training loss: 1.8273946240863752\n",
      "validation loss: 14.073506108332253\n",
      "loss difference:\n",
      "0.014543473555446385\n",
      "epoch: 103\n",
      "training loss: 1.8131039104401294\n",
      "validation loss: 14.037038362594663\n",
      "loss difference:\n",
      "0.01429071364624579\n",
      "epoch: 104\n",
      "training loss: 1.7990576211927967\n",
      "validation loss: 14.001425529385056\n",
      "loss difference:\n",
      "0.014046289247332755\n",
      "epoch: 105\n",
      "training loss: 1.785247783657834\n",
      "validation loss: 13.966635601657726\n",
      "loss difference:\n",
      "0.013809837534962677\n",
      "epoch: 106\n",
      "training loss: 1.7716667699319637\n",
      "validation loss: 13.932638090975994\n",
      "loss difference:\n",
      "0.013581013725870283\n",
      "epoch: 107\n",
      "training loss: 1.758307278577724\n",
      "validation loss: 13.899403998314853\n",
      "loss difference:\n",
      "0.013359491354239639\n",
      "epoch: 108\n",
      "training loss: 1.7451623165190675\n",
      "validation loss: 13.866905778471233\n",
      "loss difference:\n",
      "0.013144962058656562\n",
      "epoch: 109\n",
      "training loss: 1.7322251816000576\n",
      "validation loss: 13.835117300195645\n",
      "loss difference:\n",
      "0.01293713491900994\n",
      "epoch: 110\n",
      "training loss: 1.7194894461936765\n",
      "validation loss: 13.804013803587097\n",
      "loss difference:\n",
      "0.012735735406381066\n",
      "epoch: 111\n",
      "training loss: 1.7069489421646917\n",
      "validation loss: 13.773571855767628\n",
      "loss difference:\n",
      "0.012540504028984767\n",
      "epoch: 112\n",
      "training loss: 1.6945977473919656\n",
      "validation loss: 13.74376930539781\n",
      "loss difference:\n",
      "0.01235119477272617\n",
      "epoch: 113\n",
      "training loss: 1.6824301739486445\n",
      "validation loss: 13.71458523623187\n",
      "loss difference:\n",
      "0.01216757344332109\n",
      "epoch: 114\n",
      "training loss: 1.6704407579309837\n",
      "validation loss: 13.6859999196491\n",
      "loss difference:\n",
      "0.011989416017660792\n",
      "epoch: 115\n",
      "training loss: 1.658624250827226\n",
      "validation loss: 13.657994765942735\n",
      "loss difference:\n",
      "0.0118165071037577\n",
      "epoch: 116\n",
      "training loss: 1.6469756122345671\n",
      "validation loss: 13.630552274092626\n",
      "loss difference:\n",
      "0.011648638592658855\n",
      "epoch: 117\n",
      "training loss: 1.6354900036715339\n",
      "validation loss: 13.603655979785055\n",
      "loss difference:\n",
      "0.011485608563033267\n",
      "epoch: 118\n",
      "training loss: 1.6241627831984053\n",
      "validation loss: 13.577290401551233\n",
      "loss difference:\n",
      "0.011327220473128508\n",
      "epoch: 119\n",
      "training loss: 1.6129895005507053\n",
      "validation loss: 13.551440985054986\n",
      "loss difference:\n",
      "0.011173282647700011\n",
      "epoch: 120\n",
      "training loss: 1.6019658925079172\n",
      "validation loss: 13.52609404574363\n",
      "loss difference:\n",
      "0.011023608042788124\n",
      "epoch: 121\n",
      "training loss: 1.5910878782567817\n",
      "validation loss: 13.501236710259464\n",
      "loss difference:\n",
      "0.010878014251135548\n",
      "epoch: 122\n",
      "training loss: 1.5803515545597182\n",
      "validation loss: 13.476856857170874\n",
      "loss difference:\n",
      "0.010736323697063455\n",
      "epoch: 123\n",
      "training loss: 1.5697531905971107\n",
      "validation loss: 13.452943057704905\n",
      "loss difference:\n",
      "0.010598363962607493\n",
      "epoch: 124\n",
      "training loss: 1.5592892224112016\n",
      "validation loss: 13.429484517236284\n",
      "loss difference:\n",
      "0.010463968185909112\n",
      "epoch: 125\n",
      "training loss: 1.5489562469334732\n",
      "validation loss: 13.406471018308622\n",
      "loss difference:\n",
      "0.010332975477728379\n",
      "epoch: 126\n",
      "training loss: 1.5387510156231023\n",
      "validation loss: 13.383892865932493\n",
      "loss difference:\n",
      "0.010205231310370877\n",
      "epoch: 127\n",
      "training loss: 1.5286704277789085\n",
      "validation loss: 13.361740835830606\n",
      "loss difference:\n",
      "0.010080587844193856\n",
      "epoch: 128\n",
      "training loss: 1.518711523610724\n",
      "validation loss: 13.340006126192028\n",
      "loss difference:\n",
      "0.009958904168184457\n",
      "epoch: 129\n",
      "training loss: 1.5088714771686422\n",
      "validation loss: 13.318680313366047\n",
      "loss difference:\n",
      "0.009840046442081807\n",
      "epoch: 130\n",
      "training loss: 1.4991475892318293\n",
      "validation loss: 13.297755311785712\n",
      "loss difference:\n",
      "0.009723887936812892\n",
      "epoch: 131\n",
      "training loss: 1.4895372802541746\n",
      "validation loss: 13.277223338268529\n",
      "loss difference:\n",
      "0.009610308977654691\n",
      "epoch: 132\n",
      "training loss: 1.480038083454318\n",
      "validation loss: 13.25707688070882\n",
      "loss difference:\n",
      "0.009499196799856557\n",
      "epoch: 133\n",
      "training loss: 1.4706476381242921\n",
      "validation loss: 13.237308671056955\n",
      "loss difference:\n",
      "0.009390445330025976\n",
      "epoch: 134\n",
      "training loss: 1.4613636832160362\n",
      "validation loss: 13.21791166238022\n",
      "loss difference:\n",
      "0.009283954908255954\n",
      "epoch: 135\n",
      "training loss: 1.452184051249608\n",
      "validation loss: 13.198879009720274\n",
      "loss difference:\n",
      "0.009179631966428126\n",
      "epoch: 136\n",
      "training loss: 1.4431066625721913\n",
      "validation loss: 13.180204054403054\n",
      "loss difference:\n",
      "0.009077388677416698\n",
      "epoch: 137\n",
      "training loss: 1.4341295199835602\n",
      "validation loss: 13.16188031141843\n",
      "loss difference:\n",
      "0.008977142588631137\n",
      "epoch: 138\n",
      "training loss: 1.4252507037320306\n",
      "validation loss: 13.143901459466404\n",
      "loss difference:\n",
      "0.008878816251529642\n",
      "epoch: 139\n",
      "training loss: 1.4164683668751872\n",
      "validation loss: 13.126261333262761\n",
      "loss difference:\n",
      "0.008782336856843376\n",
      "epoch: 140\n",
      "training loss: 1.407780730991974\n",
      "validation loss: 13.108953917705785\n",
      "loss difference:\n",
      "0.008687635883213085\n",
      "epoch: 141\n",
      "training loss: 1.3991860822268947\n",
      "validation loss: 13.091973343527297\n",
      "loss difference:\n",
      "0.008594648765079427\n",
      "epoch: 142\n",
      "training loss: 1.3906827676429856\n",
      "validation loss: 13.075313884078382\n",
      "loss difference:\n",
      "0.008503314583909072\n",
      "epoch: 143\n",
      "training loss: 1.3822691918577306\n",
      "validation loss: 13.058969952936945\n",
      "loss difference:\n",
      "0.008413575785255034\n",
      "epoch: 144\n",
      "training loss: 1.3739438139348148\n",
      "validation loss: 13.042936102061047\n",
      "loss difference:\n",
      "0.008325377922915767\n",
      "epoch: 145\n",
      "training loss: 1.3657051445046258\n",
      "validation loss: 13.027207020254151\n",
      "loss difference:\n",
      "0.008238669430189027\n",
      "epoch: 146\n",
      "training loss: 1.35755174308718\n",
      "validation loss: 13.011777531748338\n",
      "loss difference:\n",
      "0.008153401417445805\n",
      "epoch: 147\n",
      "training loss: 1.3494822155926938\n",
      "validation loss: 12.996642594751915\n",
      "loss difference:\n",
      "0.008069527494486195\n",
      "epoch: 148\n",
      "training loss: 1.3414952119770538\n",
      "validation loss: 12.981797299844832\n",
      "loss difference:\n",
      "0.007987003615639976\n",
      "epoch: 149\n",
      "training loss: 1.3335894240318609\n",
      "validation loss: 12.967236868140512\n",
      "loss difference:\n",
      "0.007905787945192921\n",
      "epoch: 150\n",
      "training loss: 1.3257635832912953\n",
      "validation loss: 12.952956649162601\n",
      "loss difference:\n",
      "0.007825840740565582\n",
      "epoch: 151\n",
      "training loss: 1.3180164590407037\n",
      "validation loss: 12.938952118412384\n",
      "loss difference:\n",
      "0.007747124250591542\n",
      "epoch: 152\n",
      "training loss: 1.310346856414524\n",
      "validation loss: 12.925218874624491\n",
      "loss difference:\n",
      "0.007669602626179772\n",
      "epoch: 153\n",
      "training loss: 1.3027536145735719\n",
      "validation loss: 12.911752636726684\n",
      "loss difference:\n",
      "0.007593241840952114\n",
      "epoch: 154\n",
      "training loss: 1.2952356049541478\n",
      "validation loss: 12.898549240533086\n",
      "loss difference:\n",
      "0.00751800961942406\n",
      "epoch: 155\n",
      "training loss: 1.2877917295834642\n",
      "validation loss: 12.885604635209978\n",
      "loss difference:\n",
      "0.007443875370683584\n",
      "epoch: 156\n",
      "training loss: 1.2804209194577556\n",
      "validation loss: 12.87291487956006\n",
      "loss difference:\n",
      "0.007370810125708616\n",
      "epoch: 157\n",
      "training loss: 1.273122132980966\n",
      "validation loss: 12.860476138173354\n",
      "loss difference:\n",
      "0.007298786476789498\n",
      "epoch: 158\n",
      "training loss: 1.2658943544631727\n",
      "validation loss: 12.848284677494227\n",
      "loss difference:\n",
      "0.007227778517793437\n",
      "epoch: 159\n",
      "training loss: 1.2587365926789245\n",
      "validation loss: 12.83633686185187\n",
      "loss difference:\n",
      "0.007157761784248207\n",
      "epoch: 160\n",
      "training loss: 1.2516478794863293\n",
      "validation loss: 12.824629149498215\n",
      "loss difference:\n",
      "0.007088713192595186\n",
      "epoch: 161\n",
      "training loss: 1.2446272685082576\n",
      "validation loss: 12.813158088693143\n",
      "loss difference:\n",
      "0.007020610978071717\n",
      "epoch: 162\n",
      "training loss: 1.2376738338772777\n",
      "validation loss: 12.801920313870825\n",
      "loss difference:\n",
      "0.00695343463097986\n",
      "epoch: 163\n",
      "training loss: 1.230786669045997\n",
      "validation loss: 12.790912541915988\n",
      "loss difference:\n",
      "0.006887164831280712\n",
      "epoch: 164\n",
      "training loss: 1.2239648856644303\n",
      "validation loss: 12.780131568572378\n",
      "loss difference:\n",
      "0.006821783381566693\n",
      "epoch: 165\n",
      "training loss: 1.2172076125258067\n",
      "validation loss: 12.769574265000633\n",
      "loss difference:\n",
      "0.006757273138623621\n",
      "epoch: 166\n",
      "training loss: 1.2105139945818826\n",
      "validation loss: 12.759237574496971\n",
      "loss difference:\n",
      "0.006693617943924091\n",
      "epoch: 167\n",
      "training loss: 1.2038831920285196\n",
      "validation loss: 12.749118509379791\n",
      "loss difference:\n",
      "0.006630802553363013\n",
      "epoch: 168\n",
      "training loss: 1.1973143794618017\n",
      "validation loss: 12.739214148046647\n",
      "loss difference:\n",
      "0.006568812566717819\n",
      "epoch: 169\n",
      "training loss: 1.1908067451045068\n",
      "validation loss: 12.729521632201049\n",
      "loss difference:\n",
      "0.006507634357294956\n",
      "epoch: 170\n",
      "training loss: 1.1843594901023333\n",
      "validation loss: 12.720038164245407\n",
      "loss difference:\n",
      "0.006447255002173469\n",
      "epoch: 171\n",
      "training loss: 1.1779718278887346\n",
      "validation loss: 12.710761004834527\n",
      "loss difference:\n",
      "0.006387662213598766\n",
      "epoch: 172\n",
      "training loss: 1.1716429836168085\n",
      "validation loss: 12.701687470582266\n",
      "loss difference:\n",
      "0.006328844271926037\n",
      "epoch: 173\n",
      "training loss: 1.1653721936562584\n",
      "validation loss: 12.692814931913325\n",
      "loss difference:\n",
      "0.006270789960550083\n",
      "epoch: 174\n",
      "training loss: 1.1591587051530041\n",
      "validation loss: 12.684140811051417\n",
      "loss difference:\n",
      "0.006213488503254316\n",
      "epoch: 175\n",
      "training loss: 1.1530017756486795\n",
      "validation loss: 12.67566258013482\n",
      "loss difference:\n",
      "0.006156929504324671\n",
      "epoch: 176\n",
      "training loss: 1.1469006727569564\n",
      "validation loss: 12.667377759451192\n",
      "loss difference:\n",
      "0.006101102891723054\n",
      "epoch: 177\n",
      "training loss: 1.1408546738932939\n",
      "validation loss: 12.659283915782716\n",
      "loss difference:\n",
      "0.006045998863662527\n",
      "epoch: 178\n",
      "training loss: 1.1348630660545351\n",
      "validation loss: 12.651378660854839\n",
      "loss difference:\n",
      "0.005991607838758739\n",
      "epoch: 179\n",
      "training loss: 1.128925145644575\n",
      "validation loss: 12.643659649881107\n",
      "loss difference:\n",
      "0.005937920409960107\n",
      "epoch: 180\n",
      "training loss: 1.1230402183421522\n",
      "validation loss: 12.636124580198251\n",
      "loss difference:\n",
      "0.005884927302422849\n",
      "epoch: 181\n",
      "training loss: 1.1172075990067825\n",
      "validation loss: 12.628771189986084\n",
      "loss difference:\n",
      "0.005832619335369715\n",
      "epoch: 182\n",
      "training loss: 1.111426611618772\n",
      "validation loss: 12.621597257067512\n",
      "loss difference:\n",
      "0.005780987388010361\n",
      "epoch: 183\n",
      "training loss: 1.1056965892492359\n",
      "validation loss: 12.61460059778456\n",
      "loss difference:\n",
      "0.005730022369536236\n",
      "epoch: 184\n",
      "training loss: 1.1000168740561305\n",
      "validation loss: 12.607779065946932\n",
      "loss difference:\n",
      "0.005679715193105395\n",
      "epoch: 185\n",
      "training loss: 1.0943868173023394\n",
      "validation loss: 12.601130551849929\n",
      "loss difference:\n",
      "0.005630056753791024\n",
      "epoch: 186\n",
      "training loss: 1.088805779392001\n",
      "validation loss: 12.594652981359115\n",
      "loss difference:\n",
      "0.005581037910338482\n",
      "epoch: 187\n",
      "training loss: 1.083273129921381\n",
      "validation loss: 12.588344315059162\n",
      "loss difference:\n",
      "0.0055326494706200435\n",
      "epoch: 188\n",
      "training loss: 1.0777882477407832\n",
      "validation loss: 12.582202547464433\n",
      "loss difference:\n",
      "0.005484882180597728\n",
      "epoch: 189\n",
      "training loss: 1.0723505210241915\n",
      "validation loss: 12.576225706289211\n",
      "loss difference:\n",
      "0.0054377267165917065\n",
      "epoch: 190\n",
      "training loss: 1.0669593473435088\n",
      "validation loss: 12.570411851774969\n",
      "loss difference:\n",
      "0.005391173680682648\n",
      "epoch: 191\n",
      "training loss: 1.0616141337445453\n",
      "validation loss: 12.564759076072521\n",
      "loss difference:\n",
      "0.005345213598963561\n",
      "epoch: 192\n",
      "training loss: 1.0563142968221062\n",
      "validation loss: 12.55926550267635\n",
      "loss difference:\n",
      "0.005299836922439072\n",
      "epoch: 193\n",
      "training loss: 1.0510592627917814\n",
      "validation loss: 12.553929285908438\n",
      "loss difference:\n",
      "0.00525503403032479\n",
      "epoch: 194\n",
      "training loss: 1.045848467556302\n",
      "validation loss: 12.54874861044851\n",
      "loss difference:\n",
      "0.005210795235479404\n",
      "epoch: 195\n",
      "training loss: 1.0406813567645685\n",
      "validation loss: 12.543721690907764\n",
      "loss difference:\n",
      "0.005167110791733487\n",
      "epoch: 196\n",
      "training loss: 1.0355573858617053\n",
      "validation loss: 12.538846771442495\n",
      "loss difference:\n",
      "0.005123970902863206\n",
      "epoch: 197\n",
      "training loss: 1.030476020128734\n",
      "validation loss: 12.534122125403997\n",
      "loss difference:\n",
      "0.005081365732971355\n",
      "epoch: 198\n",
      "training loss: 1.0254367347106916\n",
      "validation loss: 12.529546055020951\n",
      "loss difference:\n",
      "0.0050392854180423274\n",
      "epoch: 199\n",
      "training loss: 1.0204390146322464\n",
      "validation loss: 12.525116891110452\n",
      "loss difference:\n",
      "0.004997720078445234\n",
      "epoch: 200\n",
      "training loss: 1.0154823548000627\n",
      "validation loss: 12.520832992813096\n",
      "loss difference:\n",
      "0.004956659832183741\n",
      "epoch: 201\n",
      "training loss: 1.0105662599913707\n",
      "validation loss: 12.516692747348264\n",
      "loss difference:\n",
      "0.004916094808691929\n",
      "epoch: 202\n",
      "training loss: 1.005690244828406\n",
      "validation loss: 12.512694569785069\n",
      "loss difference:\n",
      "0.004876015162964764\n",
      "epoch: 203\n",
      "training loss: 1.0008538337384665\n",
      "validation loss: 12.508836902824335\n",
      "loss difference:\n",
      "0.004836411089939485\n",
      "epoch: 204\n",
      "training loss: 0.9960565608996226\n",
      "validation loss: 12.505118216587709\n",
      "loss difference:\n",
      "0.004797272838843902\n",
      "epoch: 205\n",
      "training loss: 0.9912979701721033\n",
      "validation loss: 12.50153700840899\n",
      "loss difference:\n",
      "0.004758590727519274\n",
      "epoch: 206\n",
      "training loss: 0.9865776150156397\n",
      "validation loss: 12.498091802623758\n",
      "loss difference:\n",
      "0.004720355156463629\n",
      "epoch: 207\n",
      "training loss: 0.9818950583930491\n",
      "validation loss: 12.49478115035295\n",
      "loss difference:\n",
      "0.004682556622590539\n",
      "epoch: 208\n",
      "training loss: 0.9772498726604973\n",
      "validation loss: 12.49160362927656\n",
      "loss difference:\n",
      "0.004645185732551793\n",
      "epoch: 209\n",
      "training loss: 0.9726416394449419\n",
      "validation loss: 12.488557843393474\n",
      "loss difference:\n",
      "0.0046082332155554795\n",
      "epoch: 210\n",
      "training loss: 0.9680699495093094\n",
      "validation loss: 12.485642422764029\n",
      "loss difference:\n",
      "0.004571689935632506\n",
      "epoch: 211\n",
      "training loss: 0.9635344026060346\n",
      "validation loss: 12.482856023231951\n",
      "loss difference:\n",
      "0.004535546903274734\n",
      "epoch: 212\n",
      "training loss: 0.9590346073196248\n",
      "validation loss: 12.48019732612265\n",
      "loss difference:\n",
      "0.004499795286409869\n",
      "epoch: 213\n",
      "training loss: 0.9545701808989335\n",
      "validation loss: 12.47766503791535\n",
      "loss difference:\n",
      "0.004464426420691225\n",
      "epoch: 214\n",
      "training loss: 0.950140749079876\n",
      "validation loss: 12.475257889886313\n",
      "loss difference:\n",
      "0.004429431819057528\n",
      "epoch: 215\n",
      "training loss: 0.9457459458993074\n",
      "validation loss: 12.472974637721652\n",
      "loss difference:\n",
      "0.004394803180568618\n",
      "epoch: 216\n",
      "training loss: 0.9413854135008131\n",
      "validation loss: 12.470814061097776\n",
      "loss difference:\n",
      "0.004360532398494321\n",
      "epoch: 217\n",
      "training loss: 0.9370588019331441\n",
      "validation loss: 12.468774963228233\n",
      "loss difference:\n",
      "0.004326611567669003\n",
      "epoch: 218\n",
      "training loss: 0.9327657689420398\n",
      "validation loss: 12.46685617037612\n",
      "loss difference:\n",
      "0.004293032991104284\n",
      "epoch: 219\n",
      "training loss: 0.9285059797561698\n",
      "validation loss: 12.465056531331541\n",
      "loss difference:\n",
      "0.00425978918587\n",
      "epoch: 220\n",
      "training loss: 0.9242791068678953\n",
      "validation loss: 12.463374916853876\n",
      "loss difference:\n",
      "0.004226872888274502\n",
      "epoch: 221\n",
      "training loss: 0.9200848298095701\n",
      "validation loss: 12.461810219079124\n",
      "loss difference:\n",
      "0.004194277058325202\n",
      "epoch: 222\n",
      "training loss: 0.9159228349260442\n",
      "validation loss: 12.46036135089278\n",
      "loss difference:\n",
      "0.004161994883525866\n",
      "epoch: 223\n",
      "training loss: 0.9117928151440462\n",
      "validation loss: 12.459027245269315\n",
      "loss difference:\n",
      "0.004130019781998007\n",
      "epoch: 224\n",
      "training loss: 0.9076944697390775\n",
      "validation loss: 12.457806854579358\n",
      "loss difference:\n",
      "0.004098345404968673\n",
      "epoch: 225\n",
      "training loss: 0.9036275041004486\n",
      "validation loss: 12.456699149865997\n",
      "loss difference:\n",
      "0.004066965638628961\n",
      "epoch: 226\n",
      "training loss: 0.899591629495048\n",
      "validation loss: 12.455703120092211\n",
      "loss difference:\n",
      "0.004035874605400558\n",
      "epoch: 227\n",
      "training loss: 0.8955865628304377\n",
      "validation loss: 12.454817771361542\n",
      "loss difference:\n",
      "0.004005066664610313\n",
      "epoch: 228\n",
      "training loss: 0.8916120264178238\n",
      "validation loss: 12.454042126113972\n",
      "loss difference:\n",
      "0.003974536412613916\n",
      "epoch: 229\n",
      "training loss: 0.8876677477354595\n",
      "validation loss: 12.453375222300094\n",
      "loss difference:\n",
      "0.003944278682364244\n",
      "epoch: 230\n",
      "training loss: 0.8837534591929957\n",
      "validation loss: 12.452816112535906\n",
      "loss difference:\n",
      "0.003914288542463784\n",
      "epoch: 231\n",
      "training loss: 0.8798688978972927\n",
      "validation loss: 12.452363863241303\n",
      "loss difference:\n",
      "0.0038845612957030262\n",
      "epoch: 232\n",
      "training loss: 0.876013805420194\n",
      "validation loss: 12.45201755376551\n",
      "loss difference:\n",
      "0.0038550924770986983\n",
      "epoch: 233\n",
      "training loss: 0.8721879275687353\n",
      "validation loss: 12.45177627550243\n",
      "loss difference:\n",
      "0.0038258778514587144\n",
      "epoch: 234\n",
      "training loss: 0.8683910141582626\n",
      "validation loss: 12.451639130999416\n",
      "loss difference:\n",
      "0.0037969134104727242\n",
      "epoch: 235\n",
      "training loss: 0.8646228187889085\n",
      "validation loss: 12.451605233062736\n",
      "loss difference:\n",
      "0.0037681953693541326\n",
      "epoch: 236\n",
      "training loss: 0.860883098625886\n",
      "validation loss: 12.451673703863392\n",
      "loss difference:\n",
      "0.0037397201630224863\n",
      "epoch: 237\n",
      "training loss: 0.857171614184008\n",
      "validation loss: 12.45184367404658\n",
      "loss difference:\n",
      "0.0037114844418779658\n",
      "epoch: 238\n",
      "training loss: 0.8534881291168752\n",
      "validation loss: 12.45211428184841\n",
      "loss difference:\n",
      "0.0036834850671327857\n",
      "epoch: 239\n",
      "training loss: 0.8498324100111324\n",
      "validation loss: 12.452484672223433\n",
      "loss difference:\n",
      "0.003655719105742805\n",
      "epoch: 240\n",
      "training loss: 0.8462042261861927\n",
      "validation loss: 12.452953995986318\n",
      "loss difference:\n",
      "0.003628183824939679\n",
      "epoch: 241\n",
      "training loss: 0.842603349499792\n",
      "validation loss: 12.45352140897107\n",
      "loss difference:\n",
      "0.0036008766864007447\n",
      "epoch: 242\n",
      "training loss: 0.8390295541597804\n",
      "validation loss: 12.454186071211343\n",
      "loss difference:\n",
      "0.003573795340011565\n",
      "epoch: 243\n",
      "training loss: 0.8354826165424697\n",
      "validation loss: 12.454947146144649\n",
      "loss difference:\n",
      "0.0035469376173107303\n",
      "epoch: 244\n",
      "training loss: 0.8319623150178675\n",
      "validation loss: 12.455803799843915\n",
      "loss difference:\n",
      "0.003520301524602143\n",
      "epoch: 245\n",
      "training loss: 0.8284684297821544\n",
      "validation loss: 12.456755200279224\n",
      "loss difference:\n",
      "0.0034938852357131456\n",
      "epoch: 246\n",
      "training loss: 0.8250007426976339\n",
      "validation loss: 12.457800516612343\n",
      "loss difference:\n",
      "0.003467687084520499\n",
      "epoch: 247\n",
      "training loss: 0.8215590371404796\n",
      "validation loss: 12.458938918526847\n",
      "loss difference:\n",
      "0.0034417055571542843\n",
      "epoch: 248\n",
      "training loss: 0.8181430978564883\n",
      "validation loss: 12.460169575596199\n",
      "loss difference:\n",
      "0.0034159392839913094\n",
      "epoch: 249\n",
      "training loss: 0.8147527108250759\n",
      "validation loss: 12.46149165669178\n",
      "loss difference:\n",
      "0.0033903870314123674\n",
      "epoch: 250\n",
      "training loss: 0.8113876631316833\n",
      "validation loss: 12.462904329432943\n",
      "loss difference:\n",
      "0.003365047693392631\n",
      "epoch: 251\n",
      "training loss: 0.8080477428487689\n",
      "validation loss: 12.464406759680905\n",
      "loss difference:\n",
      "0.0033399202829144103\n",
      "epoch: 252\n",
      "training loss: 0.8047327389254912\n",
      "validation loss: 12.465998111077553\n",
      "loss difference:\n",
      "0.0033150039232776596\n",
      "epoch: 253\n",
      "training loss: 0.8014424410861959\n",
      "validation loss: 12.46767754463072\n",
      "loss difference:\n",
      "0.003290297839295353\n",
      "epoch: 254\n",
      "training loss: 0.7981766397377292\n",
      "validation loss: 12.469444218346553\n",
      "loss difference:\n",
      "0.003265801348466657\n",
      "epoch: 255\n",
      "training loss: 0.7949351258856294\n",
      "validation loss: 12.4712972869096\n",
      "loss difference:\n",
      "0.003241513852099809\n",
      "epoch: 256\n",
      "training loss: 0.7917176910591567\n",
      "validation loss: 12.473235901411218\n",
      "loss difference:\n",
      "0.0032174348264727426\n",
      "epoch: 257\n",
      "training loss: 0.7885241272451247\n",
      "validation loss: 12.475259209125863\n",
      "loss difference:\n",
      "0.003193563814032019\n",
      "epoch: 258\n",
      "training loss: 0.7853542268304314\n",
      "validation loss: 12.477366353335487\n",
      "loss difference:\n",
      "0.0031699004146932275\n",
      "epoch: 259\n",
      "training loss: 0.782207782553174\n",
      "validation loss: 12.479556473201193\n",
      "loss difference:\n",
      "0.0031464442772574097\n",
      "epoch: 260\n",
      "training loss: 0.7790845874621835\n",
      "validation loss: 12.481828703681483\n",
      "loss difference:\n",
      "0.0031231950909905715\n",
      "epoch: 261\n",
      "training loss: 0.7759844348847962\n",
      "validation loss: 12.484182175496116\n",
      "loss difference:\n",
      "0.003100152577387272\n",
      "epoch: 262\n",
      "training loss: 0.7729071184026227\n",
      "validation loss: 12.48661601513409\n",
      "loss difference:\n",
      "0.0030773164821734644\n",
      "epoch: 263\n",
      "training loss: 0.7698524318350735\n",
      "validation loss: 12.48912934490424\n",
      "loss difference:\n",
      "0.0030546865675492585\n",
      "epoch: 264\n",
      "training loss: 0.7668201692303536\n",
      "validation loss: 12.491721283026964\n",
      "loss difference:\n",
      "0.003032262604719893\n",
      "epoch: 265\n",
      "training loss: 0.763810124863622\n",
      "validation loss: 12.494390943764557\n",
      "loss difference:\n",
      "0.003010044366731579\n",
      "epoch: 266\n",
      "training loss: 0.760822093241972\n",
      "validation loss: 12.497137437588687\n",
      "loss difference:\n",
      "0.002988031621649956\n",
      "epoch: 267\n",
      "training loss: 0.7578558691159025\n",
      "validation loss: 12.499959871382043\n",
      "loss difference:\n",
      "0.0029662241260695055\n",
      "epoch: 268\n",
      "training loss: 0.7549112474968849\n",
      "validation loss: 12.502857348672181\n",
      "loss difference:\n",
      "0.002944621619017651\n",
      "epoch: 269\n",
      "training loss: 0.7519880236806602\n",
      "validation loss: 12.505828969894782\n",
      "loss difference:\n",
      "0.0029232238162246738\n",
      "epoch: 270\n",
      "training loss: 0.7490859932758595\n",
      "validation loss: 12.50887383268368\n",
      "loss difference:\n",
      "0.0029020304048007484\n",
      "epoch: 271\n",
      "training loss: 0.7462049522375315\n",
      "validation loss: 12.511991032184984\n",
      "loss difference:\n",
      "0.0028810410383279805\n",
      "epoch: 272\n",
      "training loss: 0.7433446969051924\n",
      "validation loss: 12.515179661392496\n",
      "loss difference:\n",
      "0.0028602553323390234\n",
      "epoch: 273\n",
      "training loss: 0.7405050240449433\n",
      "validation loss: 12.51843881150164\n",
      "loss difference:\n",
      "0.0028396728602491095\n",
      "epoch: 274\n",
      "training loss: 0.7376857308952615\n",
      "validation loss: 12.521767572279114\n",
      "loss difference:\n",
      "0.0028192931496818785\n",
      "epoch: 275\n",
      "training loss: 0.7348866152160398\n",
      "validation loss: 12.525165032445438\n",
      "loss difference:\n",
      "0.002799115679221642\n",
      "epoch: 276\n",
      "training loss: 0.7321074753404655\n",
      "validation loss: 12.528630280067834\n",
      "loss difference:\n",
      "0.0027791398755743213\n",
      "epoch: 277\n",
      "training loss: 0.7293481102293171\n",
      "validation loss: 12.532162402960529\n",
      "loss difference:\n",
      "0.002759365111148382\n",
      "epoch: 278\n",
      "training loss: 0.7266083195273105\n",
      "validation loss: 12.535760489090235\n",
      "loss difference:\n",
      "0.0027397907020065837\n",
      "epoch: 279\n",
      "training loss: 0.7238879036210639\n",
      "validation loss: 12.539423626984\n",
      "loss difference:\n",
      "0.0027204159062466093\n",
      "epoch: 280\n",
      "training loss: 0.7211866636983554\n",
      "validation loss: 12.543150906137367\n",
      "loss difference:\n",
      "0.0027012399227085426\n",
      "epoch: 281\n",
      "training loss: 0.7185044018082658\n",
      "validation loss: 12.54694141742035\n",
      "loss difference:\n",
      "0.0026822618900895767\n",
      "epoch: 282\n",
      "training loss: 0.715840920921891\n",
      "validation loss: 12.550794253479316\n",
      "loss difference:\n",
      "0.0026634808863748027\n",
      "epoch: 283\n",
      "training loss: 0.7131960249932857\n",
      "validation loss: 12.554708509132846\n",
      "loss difference:\n",
      "0.0026448959286052842\n",
      "epoch: 284\n",
      "training loss: 0.7105695190203183\n",
      "validation loss: 12.558683281759537\n",
      "loss difference:\n",
      "0.00262650597296743\n",
      "epoch: 285\n",
      "training loss: 0.7079612091051518\n",
      "validation loss: 12.562717671676435\n",
      "loss difference:\n",
      "0.0026083099151664735\n",
      "epoch: 286\n",
      "training loss: 0.705370902514075\n",
      "validation loss: 12.56681078250642\n",
      "loss difference:\n",
      "0.002590306591076841\n",
      "epoch: 287\n",
      "training loss: 0.7027984077364213\n",
      "validation loss: 12.570961721533433\n",
      "loss difference:\n",
      "0.0025724947776536444\n",
      "epoch: 288\n",
      "training loss: 0.7002435345423444\n",
      "validation loss: 12.575169600044022\n",
      "loss difference:\n",
      "0.0025548731940768787\n",
      "epoch: 289\n",
      "training loss: 0.6977060940392364\n",
      "validation loss: 12.579433533654933\n",
      "loss difference:\n",
      "0.0025374405031080016\n",
      "epoch: 290\n",
      "training loss: 0.6951858987265758\n",
      "validation loss: 12.583752642625068\n",
      "loss difference:\n",
      "0.002520195312660678\n",
      "epoch: 291\n",
      "training loss: 0.6926827625490468\n",
      "validation loss: 12.58812605215198\n",
      "loss difference:\n",
      "0.002503136177528953\n",
      "epoch: 292\n",
      "training loss: 0.6901965009477556\n",
      "validation loss: 12.592552892651804\n",
      "loss difference:\n",
      "0.002486261601291173\n",
      "epoch: 293\n",
      "training loss: 0.687726930909406\n",
      "validation loss: 12.597032300022706\n",
      "loss difference:\n",
      "0.002469570038349689\n",
      "epoch: 294\n",
      "training loss: 0.6852738710133158\n",
      "validation loss: 12.60156341589137\n",
      "loss difference:\n",
      "0.002453059896090126\n",
      "epoch: 295\n",
      "training loss: 0.6828371414761566\n",
      "validation loss: 12.606145387842487\n",
      "loss difference:\n",
      "0.0024367295371592324\n",
      "epoch: 296\n",
      "training loss: 0.6804165641943395\n",
      "validation loss: 12.610777369631485\n",
      "loss difference:\n",
      "0.0024205772818171045\n",
      "epoch: 297\n",
      "training loss: 0.6780119627839654\n",
      "validation loss: 12.615458521380463\n",
      "loss difference:\n",
      "0.0024046014103741298\n",
      "epoch: 298\n",
      "training loss: 0.6756231626182775\n",
      "validation loss: 12.620188009757618\n",
      "loss difference:\n",
      "0.0023888001656878766\n",
      "epoch: 299\n",
      "training loss: 0.6732499908625833\n",
      "validation loss: 12.624965008140725\n",
      "loss difference:\n",
      "0.002373171755694181\n",
      "epoch: 300\n",
      "training loss: 0.6708922765065986\n",
      "validation loss: 12.62978869676485\n",
      "loss difference:\n",
      "0.0023577143559847524\n",
      "epoch: 301\n",
      "training loss: 0.6685498503942078\n",
      "validation loss: 12.63465826285503\n",
      "loss difference:\n",
      "0.002342426112390772\n",
      "epoch: 302\n",
      "training loss: 0.6662225452506231\n",
      "validation loss: 12.639572900744499\n",
      "loss difference:\n",
      "0.0023273051435847014\n",
      "epoch: 303\n",
      "training loss: 0.6639101957069532\n",
      "validation loss: 12.644531811978979\n",
      "loss difference:\n",
      "0.002312349543669878\n",
      "epoch: 304\n",
      "training loss: 0.6616126383221921\n",
      "validation loss: 12.64953420540798\n",
      "loss difference:\n",
      "0.0022975573847611175\n",
      "epoch: 305\n",
      "training loss: 0.6593297116026418\n",
      "validation loss: 12.654579297263641\n",
      "loss difference:\n",
      "0.0022829267195503267\n",
      "epoch: 306\n",
      "training loss: 0.657061256018822\n",
      "validation loss: 12.659666311228037\n",
      "loss difference:\n",
      "0.0022684555838197173\n",
      "epoch: 307\n",
      "training loss: 0.6548071140198729\n",
      "validation loss: 12.664794478489666\n",
      "loss difference:\n",
      "0.002254141998949133\n",
      "epoch: 308\n",
      "training loss: 0.6525671300455343\n",
      "validation loss: 12.669963037790044\n",
      "loss difference:\n",
      "0.0022399839743385552\n",
      "epoch: 309\n",
      "training loss: 0.6503411505357137\n",
      "validation loss: 12.675171235461143\n",
      "loss difference:\n",
      "0.002225979509820619\n",
      "epoch: 310\n",
      "training loss: 0.6481290239377347\n",
      "validation loss: 12.680418325454584\n",
      "loss difference:\n",
      "0.0022121265979789806\n",
      "epoch: 311\n",
      "training loss: 0.6459306007113056\n",
      "validation loss: 12.685703569363335\n",
      "loss difference:\n",
      "0.002198423226429158\n",
      "epoch: 312\n",
      "training loss: 0.6437457333312808\n",
      "validation loss: 12.691026236436834\n",
      "loss difference:\n",
      "0.0021848673800247687\n",
      "epoch: 313\n",
      "training loss: 0.6415742762882957\n",
      "validation loss: 12.6963856035902\n",
      "loss difference:\n",
      "0.0021714570429851587\n",
      "epoch: 314\n",
      "training loss: 0.6394160860873304\n",
      "validation loss: 12.701780955408534\n",
      "loss difference:\n",
      "0.0021581902009653042\n",
      "epoch: 315\n",
      "training loss: 0.6372710212442946\n",
      "validation loss: 12.707211584146782\n",
      "loss difference:\n",
      "0.002145064843035782\n",
      "epoch: 316\n",
      "training loss: 0.6351389422807048\n",
      "validation loss: 12.712676789726105\n",
      "loss difference:\n",
      "0.0021320789635898008\n",
      "epoch: 317\n",
      "training loss: 0.6330197117165408\n",
      "validation loss: 12.718175879727433\n",
      "loss difference:\n",
      "0.0021192305641639653\n",
      "epoch: 318\n",
      "training loss: 0.6309131940613533\n",
      "validation loss: 12.723708169382617\n",
      "loss difference:\n",
      "0.0021065176551875453\n",
      "epoch: 319\n",
      "training loss: 0.6288192558037231\n",
      "validation loss: 12.729272981564208\n",
      "loss difference:\n",
      "0.002093938257630157\n",
      "epoch: 320\n",
      "training loss: 0.6267377653991395\n",
      "validation loss: 12.734869646774031\n",
      "loss difference:\n",
      "0.002081490404583608\n",
      "epoch: 321\n",
      "training loss: 0.6246685932563966\n",
      "validation loss: 12.740497503131344\n",
      "loss difference:\n",
      "0.0020691721427429366\n",
      "epoch: 322\n",
      "training loss: 0.6226116117225873\n",
      "validation loss: 12.746155896360902\n",
      "loss difference:\n",
      "0.002056981533809288\n",
      "epoch: 323\n",
      "training loss: 0.6205666950667805\n",
      "validation loss: 12.751844179781566\n",
      "loss difference:\n",
      "0.00204491665580675\n",
      "epoch: 324\n",
      "training loss: 0.6185337194624674\n",
      "validation loss: 12.757561714295598\n",
      "loss difference:\n",
      "0.0020329756043131475\n",
      "epoch: 325\n",
      "training loss: 0.6165125629688636\n",
      "validation loss: 12.763307868379115\n",
      "loss difference:\n",
      "0.002021156493603793\n",
      "epoch: 326\n",
      "training loss: 0.6145031055111563\n",
      "validation loss: 12.769082018074192\n",
      "loss difference:\n",
      "0.0020094574577073088\n",
      "epoch: 327\n",
      "training loss: 0.6125052288597597\n",
      "validation loss: 12.774883546982375\n",
      "loss difference:\n",
      "0.001997876651396613\n",
      "epoch: 328\n",
      "training loss: 0.6105188166086877\n",
      "validation loss: 12.780711846260333\n",
      "loss difference:\n",
      "0.0019864122510719895\n",
      "epoch: 329\n",
      "training loss: 0.608543754153112\n",
      "validation loss: 12.786566314617518\n",
      "loss difference:\n",
      "0.00197506245557566\n",
      "epoch: 330\n",
      "training loss: 0.6065799286661744\n",
      "validation loss: 12.79244635831597\n",
      "loss difference:\n",
      "0.0019638254869376315\n",
      "epoch: 331\n",
      "training loss: 0.6046272290751484\n",
      "validation loss: 12.79835139117255\n",
      "loss difference:\n",
      "0.0019526995910259526\n",
      "epoch: 332\n",
      "training loss: 0.6026855460370261\n",
      "validation loss: 12.804280834563228\n",
      "loss difference:\n",
      "0.001941683038122366\n",
      "epoch: 333\n",
      "training loss: 0.6007547719135781\n",
      "validation loss: 12.81023411743003\n",
      "loss difference:\n",
      "0.001930774123447998\n",
      "epoch: 334\n",
      "training loss: 0.5988348007459966\n",
      "validation loss: 12.816210676289941\n",
      "loss difference:\n",
      "0.001919971167581469\n",
      "epoch: 335\n",
      "training loss: 0.5969255282291577\n",
      "validation loss: 12.82220995524628\n",
      "loss difference:\n",
      "0.0019092725168389224\n",
      "epoch: 336\n",
      "training loss: 0.5950268516855873\n",
      "validation loss: 12.828231406002018\n",
      "loss difference:\n",
      "0.0018986765435703434\n",
      "epoch: 337\n",
      "training loss: 0.5931386700391902\n",
      "validation loss: 12.834274487875193\n",
      "loss difference:\n",
      "0.0018881816463971468\n",
      "epoch: 338\n",
      "training loss: 0.5912608837888114\n",
      "validation loss: 12.840338667816164\n",
      "loss difference:\n",
      "0.0018777862503788212\n",
      "epoch: 339\n",
      "training loss: 0.5893933949816635\n",
      "validation loss: 12.846423420426484\n",
      "loss difference:\n",
      "0.0018674888071478213\n",
      "epoch: 340\n",
      "training loss: 0.5875361071867142\n",
      "validation loss: 12.852528227979352\n",
      "loss difference:\n",
      "0.0018572877949493138\n",
      "epoch: 341\n",
      "training loss: 0.5856889254680603\n",
      "validation loss: 12.85865258044121\n",
      "loss difference:\n",
      "0.0018471817186539452\n",
      "epoch: 342\n",
      "training loss: 0.5838517563583362\n",
      "validation loss: 12.864795975494506\n",
      "loss difference:\n",
      "0.0018371691097240905\n",
      "epoch: 343\n",
      "training loss: 0.5820245078322338\n",
      "validation loss: 12.870957918561201\n",
      "loss difference:\n",
      "0.0018272485261023874\n",
      "epoch: 344\n",
      "training loss: 0.5802070892801358\n",
      "validation loss: 12.877137922826844\n",
      "loss difference:\n",
      "0.001817418552098049\n",
      "epoch: 345\n",
      "training loss: 0.5783994114819462\n",
      "validation loss: 12.88333550926502\n",
      "loss difference:\n",
      "0.0018076777981895775\n",
      "epoch: 346\n",
      "training loss: 0.5766013865811244\n",
      "validation loss: 12.889550206661733\n",
      "loss difference:\n",
      "0.0017980249008218152\n",
      "epoch: 347\n",
      "training loss: 0.5748129280589761\n",
      "validation loss: 12.895781551639724\n",
      "loss difference:\n",
      "0.0017884585221482618\n",
      "epoch: 348\n",
      "training loss: 0.5730339507092268\n",
      "validation loss: 12.902029088682177\n",
      "loss difference:\n",
      "0.0017789773497493\n",
      "epoch: 349\n",
      "training loss: 0.5712643706129077\n",
      "validation loss: 12.908292370155792\n",
      "loss difference:\n",
      "0.0017695800963191122\n",
      "epoch: 350\n",
      "training loss: 0.5695041051135894\n",
      "validation loss: 12.914570956332918\n",
      "loss difference:\n",
      "0.001760265499318292\n",
      "epoch: 351\n",
      "training loss: 0.5677530727929667\n",
      "validation loss: 12.920864415412263\n",
      "loss difference:\n",
      "0.0017510323206226808\n",
      "epoch: 352\n",
      "training loss: 0.5660111934468447\n",
      "validation loss: 12.927172323538345\n",
      "loss difference:\n",
      "0.0017418793461220217\n",
      "epoch: 353\n",
      "training loss: 0.5642783880615183\n",
      "validation loss: 12.93349426481908\n",
      "loss difference:\n",
      "0.0017328053853263858\n",
      "epoch: 354\n",
      "training loss: 0.5625545787905762\n",
      "validation loss: 12.939829831341477\n",
      "loss difference:\n",
      "0.0017238092709420672\n",
      "epoch: 355\n",
      "training loss: 0.5608396889321398\n",
      "validation loss: 12.946178623185265\n",
      "loss difference:\n",
      "0.0017148898584364858\n",
      "epoch: 356\n",
      "training loss: 0.5591336429065455\n",
      "validation loss: 12.952540248433992\n",
      "loss difference:\n",
      "0.00170604602559421\n",
      "epoch: 357\n",
      "training loss: 0.557436366234481\n",
      "validation loss: 12.958914323183656\n",
      "loss difference:\n",
      "0.0016972766720645405\n",
      "epoch: 358\n",
      "training loss: 0.5557477855155846\n",
      "validation loss: 12.965300471548726\n",
      "loss difference:\n",
      "0.0016885807188964375\n",
      "epoch: 359\n",
      "training loss: 0.5540678284075061\n",
      "validation loss: 12.971698325665011\n",
      "loss difference:\n",
      "0.0016799571080784448\n",
      "epoch: 360\n",
      "training loss: 0.5523964236054414\n",
      "validation loss: 12.97810752568972\n",
      "loss difference:\n",
      "0.0016714048020647354\n",
      "epoch: 361\n",
      "training loss: 0.5507335008221319\n",
      "validation loss: 12.98452771979823\n",
      "loss difference:\n",
      "0.001662922783309484\n",
      "epoch: 362\n",
      "training loss: 0.5490789907683316\n",
      "validation loss: 12.990958564177461\n",
      "loss difference:\n",
      "0.001654510053800351\n",
      "epoch: 363\n",
      "training loss: 0.5474328251337486\n",
      "validation loss: 12.997399723016027\n",
      "loss difference:\n",
      "0.0016461656345829745\n",
      "epoch: 364\n",
      "training loss: 0.5457949365684353\n",
      "validation loss: 13.003850868490659\n",
      "loss difference:\n",
      "0.001637888565313328\n",
      "epoch: 365\n",
      "training loss: 0.544165258664653\n",
      "validation loss: 13.01031168074917\n",
      "loss difference:\n",
      "0.0016296779037822118\n",
      "epoch: 366\n",
      "training loss: 0.5425437259391721\n",
      "validation loss: 13.016781847889625\n",
      "loss difference:\n",
      "0.0016215327254809342\n",
      "epoch: 367\n",
      "training loss: 0.5409302738160281\n",
      "validation loss: 13.02326106593585\n",
      "loss difference:\n",
      "0.0016134521231440102\n",
      "epoch: 368\n",
      "training loss: 0.5393248386097093\n",
      "validation loss: 13.02974903880916\n",
      "loss difference:\n",
      "0.0016054352063188393\n",
      "epoch: 369\n",
      "training loss: 0.5377273575087714\n",
      "validation loss: 13.036245478296147\n",
      "loss difference:\n",
      "0.0015974811009378254\n",
      "epoch: 370\n",
      "training loss: 0.5361377685598694\n",
      "validation loss: 13.042750104012772\n",
      "loss difference:\n",
      "0.0015895889489020432\n",
      "epoch: 371\n",
      "training loss: 0.5345560106521969\n",
      "validation loss: 13.049262643364543\n",
      "loss difference:\n",
      "0.0015817579076724542\n",
      "epoch: 372\n",
      "training loss: 0.5329820235023264\n",
      "validation loss: 13.055782831502729\n",
      "loss difference:\n",
      "0.0015739871498705593\n",
      "epoch: 373\n",
      "training loss: 0.5314157476394205\n",
      "validation loss: 13.062310411276824\n",
      "loss difference:\n",
      "0.0015662758629059192\n",
      "epoch: 374\n",
      "training loss: 0.5298571243908355\n",
      "validation loss: 13.068845133183206\n",
      "loss difference:\n",
      "0.0015586232485849116\n",
      "epoch: 375\n",
      "training loss: 0.5283060958680679\n",
      "validation loss: 13.075386755309845\n",
      "loss difference:\n",
      "0.0015510285227676723\n",
      "epoch: 376\n",
      "training loss: 0.5267626049530608\n",
      "validation loss: 13.081935043277275\n",
      "loss difference:\n",
      "0.0015434909150070508\n",
      "epoch: 377\n",
      "training loss: 0.5252265952848395\n",
      "validation loss: 13.088489770175821\n",
      "loss difference:\n",
      "0.0015360096682213165\n",
      "epoch: 378\n",
      "training loss: 0.5236980112464782\n",
      "validation loss: 13.095050716499168\n",
      "loss difference:\n",
      "0.0015285840383613136\n",
      "epoch: 379\n",
      "training loss: 0.5221767979523682\n",
      "validation loss: 13.101617670074166\n",
      "loss difference:\n",
      "0.0015212132941100354\n",
      "epoch: 380\n",
      "training loss: 0.5206629012357948\n",
      "validation loss: 13.108190425987138\n",
      "loss difference:\n",
      "0.0015138967165733153\n",
      "epoch: 381\n",
      "training loss: 0.5191562676367895\n",
      "validation loss: 13.114768786506612\n",
      "loss difference:\n",
      "0.0015066335990053803\n",
      "epoch: 382\n",
      "training loss: 0.5176568443902666\n",
      "validation loss: 13.121352561002594\n",
      "loss difference:\n",
      "0.0014994232465228574\n",
      "epoch: 383\n",
      "training loss: 0.5161645794144114\n",
      "validation loss: 13.127941565862463\n",
      "loss difference:\n",
      "0.0014922649758551954\n",
      "epoch: 384\n",
      "training loss: 0.5146794212993234\n",
      "validation loss: 13.134535624403584\n",
      "loss difference:\n",
      "0.0014851581150879811\n",
      "epoch: 385\n",
      "training loss: 0.5132013192958947\n",
      "validation loss: 13.141134566782648\n",
      "loss difference:\n",
      "0.001478102003428683\n",
      "epoch: 386\n",
      "training loss: 0.511730223304917\n",
      "validation loss: 13.147738229901938\n",
      "loss difference:\n",
      "0.0014710959909777221\n",
      "epoch: 387\n",
      "training loss: 0.5102660838663945\n",
      "validation loss: 13.15434645731254\n",
      "loss difference:\n",
      "0.001464139438522527\n",
      "epoch: 388\n",
      "training loss: 0.5088088521490733\n",
      "validation loss: 13.160959099114578\n",
      "loss difference:\n",
      "0.0014572317173211502\n",
      "epoch: 389\n",
      "training loss: 0.5073584799401517\n",
      "validation loss: 13.16757601185473\n",
      "loss difference:\n",
      "0.0014503722089216353\n",
      "epoch: 390\n",
      "training loss: 0.5059149196351765\n",
      "validation loss: 13.174197058420802\n",
      "loss difference:\n",
      "0.0014435603049751666\n",
      "epoch: 391\n",
      "training loss: 0.5044781242281084\n",
      "validation loss: 13.18082210793398\n",
      "loss difference:\n",
      "0.0014367954070680922\n",
      "epoch: 392\n",
      "training loss: 0.50304804730156\n",
      "validation loss: 13.187451035638297\n",
      "loss difference:\n",
      "0.001430076926548396\n",
      "epoch: 393\n",
      "training loss: 0.5016246430171685\n",
      "validation loss: 13.194083722787907\n",
      "loss difference:\n",
      "0.0014234042843915828\n",
      "epoch: 394\n",
      "training loss: 0.5002078661061314\n",
      "validation loss: 13.200720056531932\n",
      "loss difference:\n",
      "0.001416776911037032\n",
      "epoch: 395\n",
      "training loss: 0.49879767185985463\n",
      "validation loss: 13.207359929797365\n",
      "loss difference:\n",
      "0.001410194246276808\n",
      "epoch: 396\n",
      "training loss: 0.4973940161207507\n",
      "validation loss: 13.214003241169781\n",
      "loss difference:\n",
      "0.0014036557391039484\n",
      "epoch: 397\n",
      "training loss: 0.49599685527314036\n",
      "validation loss: 13.22064989477227\n",
      "loss difference:\n",
      "0.0013971608476103237\n",
      "epoch: 398\n",
      "training loss: 0.4946061462342642\n",
      "validation loss: 13.227299800142577\n",
      "loss difference:\n",
      "0.00139070903887617\n",
      "epoch: 399\n",
      "training loss: 0.4932218464454102\n",
      "validation loss: 13.233952872108627\n",
      "loss difference:\n",
      "0.0013842997888540154\n",
      "epoch: 400\n",
      "training loss: 0.49184391386312637\n",
      "validation loss: 13.24060903066261\n",
      "loss difference:\n",
      "0.0013779325822838029\n",
      "epoch: 401\n",
      "training loss: 0.49047230695053134\n",
      "validation loss: 13.247268200833735\n",
      "loss difference:\n",
      "0.0013716069125950248\n",
      "epoch: 402\n",
      "training loss: 0.48910698466870495\n",
      "validation loss: 13.253930312559751\n",
      "loss difference:\n",
      "0.0013653222818263977\n",
      "epoch: 403\n",
      "training loss: 0.4877479064681661\n",
      "validation loss: 13.260595300557462\n",
      "loss difference:\n",
      "0.0013590782005388213\n",
      "epoch: 404\n",
      "training loss: 0.48639503228041664\n",
      "validation loss: 13.26726310419235\n",
      "loss difference:\n",
      "0.0013528741877494865\n",
      "epoch: 405\n",
      "training loss: 0.48504832250956376\n",
      "validation loss: 13.273933667347432\n",
      "loss difference:\n",
      "0.001346709770852883\n",
      "epoch: 406\n",
      "training loss: 0.48370773802399863\n",
      "validation loss: 13.280606938291584\n",
      "loss difference:\n",
      "0.0013405844855651217\n",
      "epoch: 407\n",
      "training loss: 0.4823732401481492\n",
      "validation loss: 13.287282869547319\n",
      "loss difference:\n",
      "0.0013344978758494386\n",
      "epoch: 408\n",
      "training loss: 0.48104479065428424\n",
      "validation loss: 13.29396141775838\n",
      "loss difference:\n",
      "0.0013284494938649583\n",
      "epoch: 409\n",
      "training loss: 0.4797223517543748\n",
      "validation loss: 13.300642543557057\n",
      "loss difference:\n",
      "0.0013224388999094616\n",
      "epoch: 410\n",
      "training loss: 0.47840588609201234\n",
      "validation loss: 13.307326211431723\n",
      "loss difference:\n",
      "0.0013164656623624316\n",
      "epoch: 411\n",
      "training loss: 0.47709535673437936\n",
      "validation loss: 13.31401238959431\n",
      "loss difference:\n",
      "0.0013105293576329835\n",
      "epoch: 412\n",
      "training loss: 0.4757907271642653\n",
      "validation loss: 13.320701049848227\n",
      "loss difference:\n",
      "0.0013046295701140687\n",
      "epoch: 413\n",
      "training loss: 0.4744919612721384\n",
      "validation loss: 13.327392167456713\n",
      "loss difference:\n",
      "0.0012987658921269074\n",
      "epoch: 414\n",
      "training loss: 0.4731990233482662\n",
      "validation loss: 13.3340857210118\n",
      "loss difference:\n",
      "0.001292937923872195\n",
      "epoch: 415\n",
      "training loss: 0.4719118780748752\n",
      "validation loss: 13.340781692303949\n",
      "loss difference:\n",
      "0.001287145273390966\n",
      "epoch: 416\n",
      "training loss: 0.47063049051837275\n",
      "validation loss: 13.347480066192736\n",
      "loss difference:\n",
      "0.001281387556502478\n",
      "epoch: 417\n",
      "training loss: 0.4693548261216106\n",
      "validation loss: 13.354180830478361\n",
      "loss difference:\n",
      "0.0012756643967621328\n",
      "epoch: 418\n",
      "training loss: 0.46808485069619654\n",
      "validation loss: 13.360883975774547\n",
      "loss difference:\n",
      "0.0012699754254140716\n",
      "epoch: 419\n",
      "training loss: 0.46682053041486105\n",
      "validation loss: 13.367589495382502\n",
      "loss difference:\n",
      "0.001264320281335496\n",
      "epoch: 420\n",
      "training loss: 0.46556183180387845\n",
      "validation loss: 13.374297385166496\n",
      "loss difference:\n",
      "0.0012586986109826004\n",
      "epoch: 421\n",
      "training loss: 0.46430872173553533\n",
      "validation loss: 13.381007643430916\n",
      "loss difference:\n",
      "0.0012531100683431107\n",
      "epoch: 422\n",
      "training loss: 0.4630611674206623\n",
      "validation loss: 13.387720270798921\n",
      "loss difference:\n",
      "0.0012475543148730561\n",
      "epoch: 423\n",
      "training loss: 0.46181913640122135\n",
      "validation loss: 13.394435270092915\n",
      "loss difference:\n",
      "0.0012420310194409256\n",
      "epoch: 424\n",
      "training loss: 0.4605825965429586\n",
      "validation loss: 13.401152646217001\n",
      "loss difference:\n",
      "0.0012365398582627751\n",
      "epoch: 425\n",
      "training loss: 0.4593515160281136\n",
      "validation loss: 13.40787240604122\n",
      "loss difference:\n",
      "0.0012310805148449955\n",
      "epoch: 426\n",
      "training loss: 0.45812586334820493\n",
      "validation loss: 13.414594558288066\n",
      "loss difference:\n",
      "0.001225652679908651\n",
      "epoch: 427\n",
      "training loss: 0.45690560729688606\n",
      "validation loss: 13.421319113421006\n",
      "loss difference:\n",
      "0.0012202560513188687\n",
      "epoch: 428\n",
      "training loss: 0.45569071696286956\n",
      "validation loss: 13.42804608353538\n",
      "loss difference:\n",
      "0.0012148903340165051\n",
      "epoch: 429\n",
      "training loss: 0.4544811617229331\n",
      "validation loss: 13.43477548225156\n",
      "loss difference:\n",
      "0.0012095552399364329\n",
      "epoch: 430\n",
      "training loss: 0.4532769112350107\n",
      "validation loss: 13.441507324610493\n",
      "loss difference:\n",
      "0.0012042504879224425\n",
      "epoch: 431\n",
      "training loss: 0.45207793543136543\n",
      "validation loss: 13.448241626971829\n",
      "loss difference:\n",
      "0.0011989758036452525\n",
      "epoch: 432\n",
      "training loss: 0.45088420451185474\n",
      "validation loss: 13.454978406914332\n",
      "loss difference:\n",
      "0.0011937309195106938\n",
      "epoch: 433\n",
      "training loss: 0.44969568893728756\n",
      "validation loss: 13.461717683139128\n",
      "loss difference:\n",
      "0.0011885155745671727\n",
      "epoch: 434\n",
      "training loss: 0.4485123594228811\n",
      "validation loss: 13.46845947537538\n",
      "loss difference:\n",
      "0.0011833295144064726\n",
      "epoch: 435\n",
      "training loss: 0.4473341869318193\n",
      "validation loss: 13.4752038042887\n",
      "loss difference:\n",
      "0.0011781724910617797\n",
      "epoch: 436\n",
      "training loss: 0.4461611426689187\n",
      "validation loss: 13.481950691392225\n",
      "loss difference:\n",
      "0.0011730442629006022\n",
      "epoch: 437\n",
      "training loss: 0.4449931980744032\n",
      "validation loss: 13.488700158960356\n",
      "loss difference:\n",
      "0.0011679445945155242\n",
      "epoch: 438\n",
      "training loss: 0.44383032481779133\n",
      "validation loss: 13.495452229945272\n",
      "loss difference:\n",
      "0.0011628732566118516\n",
      "epoch: 439\n",
      "training loss: 0.44267249479190746\n",
      "validation loss: 13.502206927896166\n",
      "loss difference:\n",
      "0.001157830025883877\n",
      "epoch: 440\n",
      "training loss: 0.44151968010700865\n",
      "validation loss: 13.508964276881166\n",
      "loss difference:\n",
      "0.0011528146848988063\n",
      "epoch: 441\n",
      "training loss: 0.44037185308503946\n",
      "validation loss: 13.5157243014121\n",
      "loss difference:\n",
      "0.0011478270219691944\n",
      "epoch: 442\n",
      "training loss: 0.4392289862540184\n",
      "validation loss: 13.522487026371955\n",
      "loss difference:\n",
      "0.00114286683102105\n",
      "epoch: 443\n",
      "training loss: 0.43809105234255064\n",
      "validation loss: 13.529252476944889\n",
      "loss difference:\n",
      "0.00113793391146777\n",
      "epoch: 444\n",
      "training loss: 0.4369580242744859\n",
      "validation loss: 13.536020678549262\n",
      "loss difference:\n",
      "0.0011330280680647564\n",
      "epoch: 445\n",
      "training loss: 0.4358298751637037\n",
      "validation loss: 13.542791656773101\n",
      "loss difference:\n",
      "0.001128149110782184\n",
      "epoch: 446\n",
      "training loss: 0.4347065783090477\n",
      "validation loss: 13.549565437312276\n",
      "loss difference:\n",
      "0.0011232968546560085\n",
      "epoch: 447\n",
      "training loss: 0.43358810718940266\n",
      "validation loss: 13.556342045911439\n",
      "loss difference:\n",
      "0.0011184711196450259\n",
      "epoch: 448\n",
      "training loss: 0.4324744354589177\n",
      "validation loss: 13.563121508307306\n",
      "loss difference:\n",
      "0.001113671730484933\n",
      "epoch: 449\n",
      "training loss: 0.43136553694237034\n",
      "validation loss: 13.569903850174763\n",
      "loss difference:\n",
      "0.0011088985165473852\n",
      "epoch: 450\n",
      "training loss: 0.4302613856306957\n",
      "validation loss: 13.576689097075235\n",
      "loss difference:\n",
      "0.0011041513116746282\n",
      "epoch: 451\n",
      "training loss: 0.4291619556766544\n",
      "validation loss: 13.583477274407784\n",
      "loss difference:\n",
      "0.001099429954041331\n",
      "epoch: 452\n",
      "training loss: 0.4280672213906541\n",
      "validation loss: 13.590268407362354\n",
      "loss difference:\n",
      "0.0010947342860002651\n",
      "epoch: 453\n",
      "training loss: 0.42697715723673413\n",
      "validation loss: 13.59706252087562\n",
      "loss difference:\n",
      "0.0010900641539199896\n",
      "epoch: 454\n",
      "training loss: 0.42589173782869466\n",
      "validation loss: 13.603859639589011\n",
      "loss difference:\n",
      "0.0010854194080394675\n",
      "epoch: 455\n",
      "training loss: 0.4248109379263856\n",
      "validation loss: 13.610659787809077\n",
      "loss difference:\n",
      "0.001080799902309082\n",
      "epoch: 456\n",
      "training loss: 0.4237347324321482\n",
      "validation loss: 13.617462989470061\n",
      "loss difference:\n",
      "0.00107620549423737\n",
      "epoch: 457\n",
      "training loss: 0.4226630963874132\n",
      "validation loss: 13.624269268098551\n",
      "loss difference:\n",
      "0.001071636044735036\n",
      "epoch: 458\n",
      "training loss: 0.42159600496945243\n",
      "validation loss: 13.631078646780301\n",
      "loss difference:\n",
      "0.0010670914179607416\n",
      "epoch: 459\n",
      "training loss: 0.4205334334882818\n",
      "validation loss: 13.637891148129123\n",
      "loss difference:\n",
      "0.0010625714811706155\n",
      "epoch: 460\n",
      "training loss: 0.4194753573837219\n",
      "validation loss: 13.644706794257594\n",
      "loss difference:\n",
      "0.0010580761045599352\n",
      "epoch: 461\n",
      "training loss: 0.41842175222260325\n",
      "validation loss: 13.65152560674998\n",
      "loss difference:\n",
      "0.0010536051611186315\n",
      "epoch: 462\n",
      "training loss: 0.4173725936961271\n",
      "validation loss: 13.658347606636625\n",
      "loss difference:\n",
      "0.001049158526476135\n",
      "epoch: 463\n",
      "training loss: 0.4163278576173682\n",
      "validation loss: 13.665172814370528\n",
      "loss difference:\n",
      "0.0010447360787589344\n",
      "epoch: 464\n",
      "training loss: 0.41528751991893\n",
      "validation loss: 13.672001249805334\n",
      "loss difference:\n",
      "0.0010403376984381985\n",
      "epoch: 465\n",
      "training loss: 0.4142515566507342\n",
      "validation loss: 13.67883293217529\n",
      "loss difference:\n",
      "0.001035963268195772\n",
      "epoch: 466\n",
      "training loss: 0.41321994397796263\n",
      "validation loss: 13.685667880076606\n",
      "loss difference:\n",
      "0.0010316126727715758\n",
      "epoch: 467\n",
      "training loss: 0.4121926581791242\n",
      "validation loss: 13.69250611145052\n",
      "loss difference:\n",
      "0.0010272857988384287\n",
      "epoch: 468\n",
      "training loss: 0.41116967564426776\n",
      "validation loss: 13.699347643567776\n",
      "loss difference:\n",
      "0.0010229825348564425\n",
      "epoch: 469\n",
      "training loss: 0.4101509728733216\n",
      "validation loss: 13.706192493014642\n",
      "loss difference:\n",
      "0.0010187027709461782\n",
      "epoch: 470\n",
      "training loss: 0.4091365264745617\n",
      "validation loss: 13.713040675680299\n",
      "loss difference:\n",
      "0.0010144463987598606\n",
      "epoch: 471\n",
      "training loss: 0.4081263131632037\n",
      "validation loss: 13.719892206745458\n",
      "loss difference:\n",
      "0.0010102133113580325\n",
      "epoch: 472\n",
      "training loss: 0.4071203097601242\n",
      "validation loss: 13.726747100672629\n",
      "loss difference:\n",
      "0.0010060034030794918\n",
      "epoch: 473\n",
      "training loss: 0.4061184931906862\n",
      "validation loss: 13.73360537119707\n",
      "loss difference:\n",
      "0.0010018165694379855\n",
      "epoch: 474\n",
      "training loss: 0.40512084048369046\n",
      "validation loss: 13.740467031319486\n",
      "loss difference:\n",
      "0.0009976527069957553\n",
      "epoch: 475\n",
      "training loss: 0.4041273287704282\n",
      "validation loss: 13.747332093299514\n",
      "loss difference:\n",
      "0.000993511713262285\n",
      "epoch: 476\n",
      "training loss: 0.4031379352838469\n",
      "validation loss: 13.754200568650532\n",
      "loss difference:\n",
      "0.0009893934865812803\n",
      "epoch: 477\n",
      "training loss: 0.40215263735780726\n",
      "validation loss: 13.7610724681353\n",
      "loss difference:\n",
      "0.00098529792603963\n",
      "epoch: 478\n",
      "training loss: 0.40117141242644694\n",
      "validation loss: 13.76794780176283\n",
      "loss difference:\n",
      "0.000981224931360325\n",
      "epoch: 479\n",
      "training loss: 0.4001942380236309\n",
      "validation loss: 13.774826578786117\n",
      "loss difference:\n",
      "0.0009771744028160279\n",
      "epoch: 480\n",
      "training loss: 0.39922109178249543\n",
      "validation loss: 13.781708807700754\n",
      "loss difference:\n",
      "0.0009731462411354808\n",
      "epoch: 481\n",
      "training loss: 0.39825195143506287\n",
      "validation loss: 13.78859449624455\n",
      "loss difference:\n",
      "0.0009691403474325622\n",
      "epoch: 482\n",
      "training loss: 0.39728679481195583\n",
      "validation loss: 13.795483651397952\n",
      "loss difference:\n",
      "0.000965156623107033\n",
      "epoch: 483\n",
      "training loss: 0.3963255998421718\n",
      "validation loss: 13.8023762793852\n",
      "loss difference:\n",
      "0.0009611949697840294\n",
      "epoch: 484\n",
      "training loss: 0.39536834455293124\n",
      "validation loss: 13.809272385676403\n",
      "loss difference:\n",
      "0.0009572552892405661\n",
      "epoch: 485\n",
      "training loss: 0.39441500706959387\n",
      "validation loss: 13.81617197499028\n",
      "loss difference:\n",
      "0.0009533374833373687\n",
      "epoch: 486\n",
      "training loss: 0.3934655656156361\n",
      "validation loss: 13.823075051297602\n",
      "loss difference:\n",
      "0.0009494414539577556\n",
      "epoch: 487\n",
      "training loss: 0.39251999851268515\n",
      "validation loss: 13.829981617825304\n",
      "loss difference:\n",
      "0.0009455671029509616\n",
      "epoch: 488\n",
      "training loss: 0.3915782841806109\n",
      "validation loss: 13.83689167706138\n",
      "loss difference:\n",
      "0.0009417143320742394\n",
      "epoch: 489\n",
      "training loss: 0.39064040113765747\n",
      "validation loss: 13.84380523076014\n",
      "loss difference:\n",
      "0.0009378830429534468\n",
      "epoch: 490\n",
      "training loss: 0.38970632800063143\n",
      "validation loss: 13.85072227994835\n",
      "loss difference:\n",
      "0.0009340731370260369\n",
      "epoch: 491\n",
      "training loss: 0.3887760434851209\n",
      "validation loss: 13.85764282493169\n",
      "loss difference:\n",
      "0.0009302845155105266\n",
      "epoch: 492\n",
      "training loss: 0.3878495264057604\n",
      "validation loss: 13.864566865301914\n",
      "loss difference:\n",
      "0.0009265170793604782\n",
      "epoch: 493\n",
      "training loss: 0.38692675567652113\n",
      "validation loss: 13.871494399944446\n",
      "loss difference:\n",
      "0.0009227707292392973\n",
      "epoch: 494\n",
      "training loss: 0.38600771031103764\n",
      "validation loss: 13.878425427046425\n",
      "loss difference:\n",
      "0.000919045365483484\n",
      "epoch: 495\n",
      "training loss: 0.3850923694229555\n",
      "validation loss: 13.8853599441053\n",
      "loss difference:\n",
      "0.0009153408880821501\n",
      "epoch: 496\n",
      "training loss: 0.384180712226304\n",
      "validation loss: 13.892297947937784\n",
      "loss difference:\n",
      "0.000911657196651483\n",
      "epoch: 497\n",
      "training loss: 0.38327271803588675\n",
      "validation loss: 13.899239434689298\n",
      "loss difference:\n",
      "0.0009079941904172606\n",
      "epoch: 498\n",
      "training loss: 0.3823683662676899\n",
      "validation loss: 13.906184399843683\n",
      "loss difference:\n",
      "0.0009043517681968649\n",
      "epoch: 499\n",
      "training loss: 0.38146763643930254\n",
      "validation loss: 13.913132838233391\n",
      "loss difference:\n",
      "0.0009007298283873477\n",
      "epoch: 500\n",
      "training loss: 0.3805705081703422\n",
      "validation loss: 13.920084744049996\n",
      "loss difference:\n",
      "0.0008971282689603233\n",
      "epoch: 501\n",
      "training loss: 0.3796769611828937\n",
      "validation loss: 13.927040110854966\n",
      "loss difference:\n",
      "0.0008935469874485347\n",
      "epoch: 502\n",
      "training loss: 0.3787869753019517\n",
      "validation loss: 13.933998931590851\n",
      "loss difference:\n",
      "0.0008899858809419681\n",
      "epoch: 503\n",
      "training loss: 0.37790053045585736\n",
      "validation loss: 13.94096119859268\n",
      "loss difference:\n",
      "0.0008864448460943475\n",
      "epoch: 504\n",
      "training loss: 0.3770176066767421\n",
      "validation loss: 13.947926903599532\n",
      "loss difference:\n",
      "0.0008829237791152522\n",
      "epoch: 505\n",
      "training loss: 0.37613818410096406\n",
      "validation loss: 13.954896037766598\n",
      "loss difference:\n",
      "0.0008794225757780549\n",
      "epoch: 506\n",
      "training loss: 0.37526224296954175\n",
      "validation loss: 13.961868591677248\n",
      "loss difference:\n",
      "0.0008759411314223087\n",
      "epoch: 507\n",
      "training loss: 0.3743897636285742\n",
      "validation loss: 13.968844555355345\n",
      "loss difference:\n",
      "0.0008724793409675691\n",
      "epoch: 508\n",
      "training loss: 0.3735207265296577\n",
      "validation loss: 13.975823918277841\n",
      "loss difference:\n",
      "0.000869037098916503\n",
      "epoch: 509\n",
      "training loss: 0.3726551122302902\n",
      "validation loss: 13.98280666938745\n",
      "loss difference:\n",
      "0.0008656142993674898\n",
      "epoch: 510\n",
      "training loss: 0.3717929013942588\n",
      "validation loss: 13.98979279710552\n",
      "loss difference:\n",
      "0.0008622108360313852\n",
      "epoch: 511\n",
      "training loss: 0.3709340747920164\n",
      "validation loss: 13.996782289344967\n",
      "loss difference:\n",
      "0.0008588266022424018\n",
      "epoch: 512\n",
      "training loss: 0.3700786133010393\n",
      "validation loss: 14.003775133523467\n",
      "loss difference:\n",
      "0.0008554614909770941\n",
      "epoch: 513\n",
      "training loss: 0.3692264979061718\n",
      "validation loss: 14.010771316576594\n",
      "loss difference:\n",
      "0.0008521153948675142\n",
      "epoch: 514\n",
      "training loss: 0.3683777096999454\n",
      "validation loss: 14.01777082497109\n",
      "loss difference:\n",
      "0.000848788206226414\n",
      "epoch: 515\n",
      "training loss: 0.36753222988288553\n",
      "validation loss: 14.024773644718284\n",
      "loss difference:\n",
      "0.0008454798170598465\n",
      "epoch: 516\n",
      "training loss: 0.3666900397637926\n",
      "validation loss: 14.031779761387472\n",
      "loss difference:\n",
      "0.0008421901190929226\n",
      "epoch: 517\n",
      "training loss: 0.3658511207600021\n",
      "validation loss: 14.03878916011929\n",
      "loss difference:\n",
      "0.000838919003790517\n",
      "epoch: 518\n",
      "training loss: 0.3650154543976239\n",
      "validation loss: 14.04580182563926\n",
      "loss difference:\n",
      "0.0008356663623781957\n",
      "epoch: 519\n",
      "training loss: 0.36418302231176136\n",
      "validation loss: 14.052817742271234\n",
      "loss difference:\n",
      "0.0008324320858625334\n",
      "epoch: 520\n",
      "training loss: 0.3633538062466952\n",
      "validation loss: 14.059836893950758\n",
      "loss difference:\n",
      "0.0008292160650661407\n",
      "epoch: 521\n",
      "training loss: 0.36252778805606073\n",
      "validation loss: 14.066859264238595\n",
      "loss difference:\n",
      "0.0008260181906344921\n",
      "epoch: 522\n",
      "training loss: 0.36170494970298495\n",
      "validation loss: 14.073884836334054\n",
      "loss difference:\n",
      "0.0008228383530757832\n",
      "epoch: 523\n",
      "training loss: 0.36088527326020514\n",
      "validation loss: 14.080913593088328\n",
      "loss difference:\n",
      "0.0008196764427798042\n",
      "epoch: 524\n",
      "training loss: 0.36006874091016766\n",
      "validation loss: 14.08794551701774\n",
      "loss difference:\n",
      "0.0008165323500374799\n",
      "epoch: 525\n",
      "training loss: 0.3592553349450907\n",
      "validation loss: 14.09498059031697\n",
      "loss difference:\n",
      "0.0008134059650769521\n",
      "epoch: 526\n",
      "training loss: 0.3584450377670109\n",
      "validation loss: 14.102018794872073\n",
      "loss difference:\n",
      "0.0008102971780797885\n",
      "epoch: 527\n",
      "training loss: 0.3576378318877974\n",
      "validation loss: 14.109060112273472\n",
      "loss difference:\n",
      "0.0008072058792135128\n",
      "epoch: 528\n",
      "training loss: 0.35683369992914954\n",
      "validation loss: 14.116104523828895\n",
      "loss difference:\n",
      "0.000804131958647869\n",
      "epoch: 529\n",
      "training loss: 0.3560326246225591\n",
      "validation loss: 14.123152010575977\n",
      "loss difference:\n",
      "0.0008010753065904597\n",
      "epoch: 530\n",
      "training loss: 0.35523458880925657\n",
      "validation loss: 14.130202553294968\n",
      "loss difference:\n",
      "0.0007980358133025112\n",
      "epoch: 531\n",
      "training loss: 0.35443957544012583\n",
      "validation loss: 14.13725613252109\n",
      "loss difference:\n",
      "0.0007950133691307371\n",
      "epoch: 532\n",
      "training loss: 0.35364756757559984\n",
      "validation loss: 14.144312728556839\n",
      "loss difference:\n",
      "0.0007920078645259898\n",
      "epoch: 533\n",
      "training loss: 0.3528585483855266\n",
      "validation loss: 14.15137232148413\n",
      "loss difference:\n",
      "0.0007890191900732368\n",
      "epoch: 534\n",
      "training loss: 0.35207250114901706\n",
      "validation loss: 14.158434891176144\n",
      "loss difference:\n",
      "0.0007860472365095461\n",
      "epoch: 535\n",
      "training loss: 0.3512894092542648\n",
      "validation loss: 14.165500417309083\n",
      "loss difference:\n",
      "0.0007830918947522858\n",
      "epoch: 536\n",
      "training loss: 0.35050925619834455\n",
      "validation loss: 14.172568879373733\n",
      "loss difference:\n",
      "0.0007801530559202186\n",
      "epoch: 537\n",
      "training loss: 0.34973202558698874\n",
      "validation loss: 14.179640256686751\n",
      "loss difference:\n",
      "0.000777230611355817\n",
      "epoch: 538\n",
      "training loss: 0.34895770113434205\n",
      "validation loss: 14.186714528401794\n",
      "loss difference:\n",
      "0.0007743244526466908\n",
      "epoch: 539\n",
      "training loss: 0.3481862666626904\n",
      "validation loss: 14.193791673520407\n",
      "loss difference:\n",
      "0.0007714344716516219\n",
      "epoch: 540\n",
      "training loss: 0.347417706102176\n",
      "validation loss: 14.200871670902638\n",
      "loss difference:\n",
      "0.0007685605605144419\n",
      "epoch: 541\n",
      "training loss: 0.34665200349048503\n",
      "validation loss: 14.207954499277513\n",
      "loss difference:\n",
      "0.0007657026116909549\n",
      "epoch: 542\n",
      "training loss: 0.34588914297251877\n",
      "validation loss: 14.215040137253192\n",
      "loss difference:\n",
      "0.0007628605179662573\n",
      "epoch: 543\n",
      "training loss: 0.3451291088000447\n",
      "validation loss: 14.222128563326876\n",
      "loss difference:\n",
      "0.0007600341724740556\n",
      "epoch: 544\n",
      "training loss: 0.34437188533133\n",
      "validation loss: 14.229219755894528\n",
      "loss difference:\n",
      "0.0007572234687147072\n",
      "epoch: 545\n",
      "training loss: 0.34361745703075514\n",
      "validation loss: 14.23631369326028\n",
      "loss difference:\n",
      "0.000754428300574872\n",
      "epoch: 546\n",
      "training loss: 0.34286580846840875\n",
      "validation loss: 14.2434103536456\n",
      "loss difference:\n",
      "0.0007516485623463853\n",
      "epoch: 547\n",
      "training loss: 0.3421169243196688\n",
      "validation loss: 14.250509715198163\n",
      "loss difference:\n",
      "0.00074888414873997\n",
      "epoch: 548\n",
      "training loss: 0.3413707893647681\n",
      "validation loss: 14.257611756000536\n",
      "loss difference:\n",
      "0.000746134954900668\n",
      "epoch: 549\n",
      "training loss: 0.34062738848833524\n",
      "validation loss: 14.264716454078494\n",
      "loss difference:\n",
      "0.0007434008764328759\n",
      "epoch: 550\n",
      "training loss: 0.33988670667893445\n",
      "validation loss: 14.271823787409103\n",
      "loss difference:\n",
      "0.0007406818094007894\n",
      "epoch: 551\n",
      "training loss: 0.3391487290285807\n",
      "validation loss: 14.278933733928582\n",
      "loss difference:\n",
      "0.0007379776503537716\n",
      "epoch: 552\n",
      "training loss: 0.33841344073224155\n",
      "validation loss: 14.286046271539831\n",
      "loss difference:\n",
      "0.0007352882963391205\n",
      "epoch: 553\n",
      "training loss: 0.33768082708733144\n",
      "validation loss: 14.293161378119649\n",
      "loss difference:\n",
      "0.0007326136449101184\n",
      "epoch: 554\n",
      "training loss: 0.3369508734931907\n",
      "validation loss: 14.300279031525767\n",
      "loss difference:\n",
      "0.000729953594140742\n",
      "epoch: 555\n",
      "training loss: 0.3362235654505475\n",
      "validation loss: 14.30739920960351\n",
      "loss difference:\n",
      "0.0007273080426432044\n",
      "epoch: 556\n",
      "training loss: 0.33549888856097826\n",
      "validation loss: 14.314521890192333\n",
      "loss difference:\n",
      "0.0007246768895692313\n",
      "epoch: 557\n",
      "training loss: 0.33477682852634805\n",
      "validation loss: 14.321647051131778\n",
      "loss difference:\n",
      "0.000722060034630212\n",
      "epoch: 558\n",
      "training loss: 0.334057371148249\n",
      "validation loss: 14.32877467026753\n",
      "loss difference:\n",
      "0.000719457378099031\n",
      "epoch: 559\n",
      "training loss: 0.33334050232741935\n",
      "validation loss: 14.335904725456961\n",
      "loss difference:\n",
      "0.0007168688208296636\n",
      "epoch: 560\n",
      "training loss: 0.332626208063165\n",
      "validation loss: 14.343037194574435\n",
      "loss difference:\n",
      "0.0007142942642543448\n",
      "epoch: 561\n",
      "training loss: 0.3319144744527611\n",
      "validation loss: 14.350172055516335\n",
      "loss difference:\n",
      "0.0007117336104038863\n",
      "epoch: 562\n",
      "training loss: 0.3312052876908566\n",
      "validation loss: 14.357309286205941\n",
      "loss difference:\n",
      "0.0007091867619045122\n",
      "epoch: 563\n",
      "training loss: 0.3304986340688615\n",
      "validation loss: 14.364448864597813\n",
      "loss difference:\n",
      "0.0007066536219951236\n",
      "epoch: 564\n",
      "training loss: 0.3297944999743352\n",
      "validation loss: 14.37159076868214\n",
      "loss difference:\n",
      "0.0007041340945262986\n",
      "epoch: 565\n",
      "training loss: 0.32909287189036485\n",
      "validation loss: 14.378734976488756\n",
      "loss difference:\n",
      "0.0007016280839703404\n",
      "epoch: 566\n",
      "training loss: 0.328393736394936\n",
      "validation loss: 14.385881466090686\n",
      "loss difference:\n",
      "0.0006991354954288265\n",
      "epoch: 567\n",
      "training loss: 0.3276970801603028\n",
      "validation loss: 14.393030215607823\n",
      "loss difference:\n",
      "0.0006966562346332195\n",
      "epoch: 568\n",
      "training loss: 0.32700288995234855\n",
      "validation loss: 14.400181203210009\n",
      "loss difference:\n",
      "0.0006941902079542484\n",
      "epoch: 569\n",
      "training loss: 0.32631115262994836\n",
      "validation loss: 14.407334407120088\n",
      "loss difference:\n",
      "0.0006917373224001877\n",
      "epoch: 570\n",
      "training loss: 0.32562185514431635\n",
      "validation loss: 14.414489805616515\n",
      "loss difference:\n",
      "0.0006892974856320122\n",
      "epoch: 571\n",
      "training loss: 0.3249349845383625\n",
      "validation loss: 14.421647377035987\n",
      "loss difference:\n",
      "0.0006868706059538487\n",
      "epoch: 572\n",
      "training loss: 0.3242505279460404\n",
      "validation loss: 14.428807099775545\n",
      "loss difference:\n",
      "0.0006844565923220802\n",
      "epoch: 573\n",
      "training loss: 0.32356847259168836\n",
      "validation loss: 14.435968952294697\n",
      "loss difference:\n",
      "0.0006820553543520624\n",
      "epoch: 574\n",
      "training loss: 0.3228888057893764\n",
      "validation loss: 14.443132913117143\n",
      "loss difference:\n",
      "0.0006796668023119623\n",
      "epoch: 575\n",
      "training loss: 0.3222115149422437\n",
      "validation loss: 14.450298960832296\n",
      "loss difference:\n",
      "0.0006772908471326944\n",
      "epoch: 576\n",
      "training loss: 0.32153658754184056\n",
      "validation loss: 14.457467074096735\n",
      "loss difference:\n",
      "0.0006749274004031469\n",
      "epoch: 577\n",
      "training loss: 0.32086401116746727\n",
      "validation loss: 14.464637231635276\n",
      "loss difference:\n",
      "0.0006725763743732904\n",
      "epoch: 578\n",
      "training loss: 0.32019377348550765\n",
      "validation loss: 14.471809412241846\n",
      "loss difference:\n",
      "0.0006702376819596179\n",
      "epoch: 579\n",
      "training loss: 0.31952586224877116\n",
      "validation loss: 14.478983594780305\n",
      "loss difference:\n",
      "0.0006679112367364848\n",
      "epoch: 580\n",
      "training loss: 0.31886026529582506\n",
      "validation loss: 14.486159758184838\n",
      "loss difference:\n",
      "0.0006655969529461014\n",
      "epoch: 581\n",
      "training loss: 0.3181969705503321\n",
      "validation loss: 14.493337881460457\n",
      "loss difference:\n",
      "0.0006632947454929816\n",
      "epoch: 582\n",
      "training loss: 0.31753596602039136\n",
      "validation loss: 14.500517943682935\n",
      "loss difference:\n",
      "0.000661004529940723\n",
      "epoch: 583\n",
      "training loss: 0.3168772397978716\n",
      "validation loss: 14.50769992399899\n",
      "loss difference:\n",
      "0.0006587262225197787\n",
      "epoch: 584\n",
      "training loss: 0.3162207800577522\n",
      "validation loss: 14.51488380162588\n",
      "loss difference:\n",
      "0.0006564597401193528\n",
      "epoch: 585\n",
      "training loss: 0.3155665750574624\n",
      "validation loss: 14.522069555851116\n",
      "loss difference:\n",
      "0.0006542050002898425\n",
      "epoch: 586\n",
      "training loss: 0.3149146131362235\n",
      "validation loss: 14.52925716603191\n",
      "loss difference:\n",
      "0.0006519619212388972\n",
      "epoch: 587\n",
      "training loss: 0.31426488271439107\n",
      "validation loss: 14.536446611594425\n",
      "loss difference:\n",
      "0.0006497304218324174\n",
      "epoch: 588\n",
      "training loss: 0.31361737229280057\n",
      "validation loss: 14.543637872032956\n",
      "loss difference:\n",
      "0.0006475104215905025\n",
      "epoch: 589\n",
      "training loss: 0.3129720704521131\n",
      "validation loss: 14.55083092690894\n",
      "loss difference:\n",
      "0.0006453018406874511\n",
      "epoch: 590\n",
      "training loss: 0.3123289658521665\n",
      "validation loss: 14.55802575584966\n",
      "loss difference:\n",
      "0.0006431045999465979\n",
      "epoch: 591\n",
      "training loss: 0.3116880472313255\n",
      "validation loss: 14.56522233854718\n",
      "loss difference:\n",
      "0.0006409186208410356\n",
      "epoch: 592\n",
      "training loss: 0.3110493034058371\n",
      "validation loss: 14.572420654756733\n",
      "loss difference:\n",
      "0.000638743825488397\n",
      "epoch: 593\n",
      "training loss: 0.3104127232691867\n",
      "validation loss: 14.57962068429528\n",
      "loss difference:\n",
      "0.0006365801366504109\n",
      "epoch: 594\n",
      "training loss: 0.3097782957914595\n",
      "validation loss: 14.586822407039806\n",
      "loss difference:\n",
      "0.0006344274777271841\n",
      "epoch: 595\n",
      "training loss: 0.30914601001870345\n",
      "validation loss: 14.594025802925534\n",
      "loss difference:\n",
      "0.000632285772756036\n",
      "epoch: 596\n",
      "training loss: 0.30851585507229473\n",
      "validation loss: 14.601230851944047\n",
      "loss difference:\n",
      "0.000630154946408723\n",
      "epoch: 597\n",
      "training loss: 0.3078878201483091\n",
      "validation loss: 14.608437534141288\n",
      "loss difference:\n",
      "0.0006280349239856098\n",
      "epoch: 598\n",
      "training loss: 0.30726189451689506\n",
      "validation loss: 14.61564582961547\n",
      "loss difference:\n",
      "0.0006259256314140593\n",
      "epoch: 599\n",
      "training loss: 0.30663806752164935\n",
      "validation loss: 14.622855718514899\n",
      "loss difference:\n",
      "0.0006238269952457132\n",
      "epoch: 600\n",
      "training loss: 0.30601632857899935\n",
      "validation loss: 14.63006718103564\n",
      "loss difference:\n",
      "0.0006217389426499964\n",
      "epoch: 601\n",
      "training loss: 0.30539666717758784\n",
      "validation loss: 14.63728019741923\n",
      "loss difference:\n",
      "0.0006196614014115087\n",
      "epoch: 602\n",
      "training loss: 0.3047790728776612\n",
      "validation loss: 14.644494747950226\n",
      "loss difference:\n",
      "0.0006175942999266382\n",
      "epoch: 603\n",
      "training loss: 0.3041635353104618\n",
      "validation loss: 14.65171081295361\n",
      "loss difference:\n",
      "0.0006155375671993979\n",
      "epoch: 604\n",
      "training loss: 0.30355004417762427\n",
      "validation loss: 14.658928372792369\n",
      "loss difference:\n",
      "0.0006134911328375403\n",
      "epoch: 605\n",
      "training loss: 0.30293858925057654\n",
      "validation loss: 14.66614740786462\n",
      "loss difference:\n",
      "0.0006114549270477276\n",
      "epoch: 606\n",
      "training loss: 0.30232916036994717\n",
      "validation loss: 14.673367898601178\n",
      "loss difference:\n",
      "0.0006094288806293702\n",
      "epoch: 607\n",
      "training loss: 0.30172174744497054\n",
      "validation loss: 14.68058982546257\n",
      "loss difference:\n",
      "0.0006074129249766247\n",
      "epoch: 608\n",
      "training loss: 0.3011163404529057\n",
      "validation loss: 14.687813168936312\n",
      "loss difference:\n",
      "0.0006054069920648497\n",
      "epoch: 609\n",
      "training loss: 0.300512929438448\n",
      "validation loss: 14.695037909534118\n",
      "loss difference:\n",
      "0.000603411014457711\n",
      "epoch: 610\n",
      "training loss: 0.29991150451315896\n",
      "validation loss: 14.702264027788862\n",
      "loss difference:\n",
      "0.0006014249252890291\n",
      "epoch: 611\n",
      "training loss: 0.2993120558548899\n",
      "validation loss: 14.709491504251778\n",
      "loss difference:\n",
      "0.0005994486582690528\n",
      "epoch: 612\n",
      "training loss: 0.2987145737072112\n",
      "validation loss: 14.716720319489399\n",
      "loss difference:\n",
      "0.0005974821476786851\n",
      "epoch: 613\n",
      "training loss: 0.29811904837885334\n",
      "validation loss: 14.723950454080647\n",
      "loss difference:\n",
      "0.0005955253283578821\n",
      "epoch: 614\n",
      "training loss: 0.2975254702431437\n",
      "validation loss: 14.731181888613675\n",
      "loss difference:\n",
      "0.0005935781357096492\n",
      "epoch: 615\n",
      "training loss: 0.29693382973745625\n",
      "validation loss: 14.738414603683013\n",
      "loss difference:\n",
      "0.0005916405056874408\n",
      "epoch: 616\n",
      "training loss: 0.29634411736265664\n",
      "validation loss: 14.745648579886321\n",
      "loss difference:\n",
      "0.0005897123747996003\n",
      "epoch: 617\n",
      "training loss: 0.29575632368256166\n",
      "validation loss: 14.752883797821475\n",
      "loss difference:\n",
      "0.0005877936800949835\n",
      "epoch: 618\n",
      "training loss: 0.29517043932339365\n",
      "validation loss: 14.760120238083312\n",
      "loss difference:\n",
      "0.0005858843591680096\n",
      "epoch: 619\n",
      "training loss: 0.2945864549732494\n",
      "validation loss: 14.767357881260766\n",
      "loss difference:\n",
      "0.0005839843501442288\n",
      "epoch: 620\n",
      "training loss: 0.2940043613815674\n",
      "validation loss: 14.774596707933478\n",
      "loss difference:\n",
      "0.0005820935916820424\n",
      "epoch: 621\n",
      "training loss: 0.29342414935859845\n",
      "validation loss: 14.781836698669018\n",
      "loss difference:\n",
      "0.0005802120229689289\n",
      "epoch: 622\n",
      "training loss: 0.2928458097748877\n",
      "validation loss: 14.78907783401951\n",
      "loss difference:\n",
      "0.0005783395837107297\n",
      "epoch: 623\n",
      "training loss: 0.2922693335607559\n",
      "validation loss: 14.796320094518734\n",
      "loss difference:\n",
      "0.0005764762141318158\n",
      "epoch: 624\n",
      "training loss: 0.29169471170578604\n",
      "validation loss: 14.803563460678957\n",
      "loss difference:\n",
      "0.0005746218549698701\n",
      "epoch: 625\n",
      "training loss: 0.29112193525831664\n",
      "validation loss: 14.81080791298792\n",
      "loss difference:\n",
      "0.0005727764474693919\n",
      "epoch: 626\n",
      "training loss: 0.29055099532493894\n",
      "validation loss: 14.81805343190573\n",
      "loss difference:\n",
      "0.000570939933377701\n",
      "epoch: 627\n",
      "training loss: 0.28998188306999473\n",
      "validation loss: 14.825299997861835\n",
      "loss difference:\n",
      "0.0005691122549442151\n",
      "epoch: 628\n",
      "training loss: 0.28941458971508827\n",
      "validation loss: 14.832547591252032\n",
      "loss difference:\n",
      "0.0005672933549064618\n",
      "epoch: 629\n",
      "training loss: 0.28884910653859275\n",
      "validation loss: 14.839796192435461\n",
      "loss difference:\n",
      "0.0005654831764955182\n",
      "epoch: 630\n",
      "training loss: 0.2882854248751679\n",
      "validation loss: 14.84704578173163\n",
      "loss difference:\n",
      "0.0005636816634248532\n",
      "epoch: 631\n",
      "training loss: 0.28772353611527735\n",
      "validation loss: 14.854296339417434\n",
      "loss difference:\n",
      "0.0005618887598905498\n",
      "epoch: 632\n",
      "training loss: 0.28716343170471487\n",
      "validation loss: 14.861547845724331\n",
      "loss difference:\n",
      "0.0005601044105624786\n",
      "epoch: 633\n",
      "training loss: 0.28660510314413246\n",
      "validation loss: 14.868800280835353\n",
      "loss difference:\n",
      "0.0005583285605824106\n",
      "epoch: 634\n",
      "training loss: 0.28604854198857654\n",
      "validation loss: 14.87605362488232\n",
      "loss difference:\n",
      "0.0005565611555559125\n",
      "epoch: 635\n",
      "training loss: 0.2854937398470218\n",
      "validation loss: 14.883307857942965\n",
      "loss difference:\n",
      "0.0005548021415547333\n",
      "epoch: 636\n",
      "training loss: 0.2849406883819152\n",
      "validation loss: 14.890562960038201\n",
      "loss difference:\n",
      "0.000553051465106591\n",
      "epoch: 637\n",
      "training loss: 0.2843893793087251\n",
      "validation loss: 14.897818911129358\n",
      "loss difference:\n",
      "0.0005513090731901205\n",
      "epoch: 638\n",
      "training loss: 0.2838398043954899\n",
      "validation loss: 14.905075691115492\n",
      "loss difference:\n",
      "0.0005495749132352068\n",
      "epoch: 639\n",
      "training loss: 0.2832919554623728\n",
      "validation loss: 14.912333279830644\n",
      "loss difference:\n",
      "0.000547848933117101\n",
      "epoch: 640\n",
      "training loss: 0.2827458243812268\n",
      "validation loss: 14.919591657041343\n",
      "loss difference:\n",
      "0.0005461310811459841\n",
      "epoch: 641\n",
      "training loss: 0.2822014030751528\n",
      "validation loss: 14.926850802443914\n",
      "loss difference:\n",
      "0.0005444213060740166\n",
      "epoch: 642\n",
      "training loss: 0.281658683518073\n",
      "validation loss: 14.934110695662008\n",
      "loss difference:\n",
      "0.000542719557079796\n",
      "epoch: 643\n",
      "training loss: 0.2811176577343017\n",
      "validation loss: 14.941371316244116\n",
      "loss difference:\n",
      "0.0005410257837712984\n",
      "epoch: 644\n",
      "training loss: 0.2805783177981216\n",
      "validation loss: 14.948632643661071\n",
      "loss difference:\n",
      "0.0005393399361801055\n",
      "epoch: 645\n",
      "training loss: 0.28004065583336707\n",
      "validation loss: 14.955894657303764\n",
      "loss difference:\n",
      "0.0005376619647545211\n",
      "epoch: 646\n",
      "training loss: 0.27950466401301005\n",
      "validation loss: 14.963157336480677\n",
      "loss difference:\n",
      "0.000535991820357018\n",
      "epoch: 647\n",
      "training loss: 0.2789703345587464\n",
      "validation loss: 14.970420660415687\n",
      "loss difference:\n",
      "0.0005343294542636268\n",
      "epoch: 648\n",
      "training loss: 0.2784376597405921\n",
      "validation loss: 14.977684608245795\n",
      "loss difference:\n",
      "0.0005326748181543328\n",
      "epoch: 649\n",
      "training loss: 0.2779066318764815\n",
      "validation loss: 14.984949159018925\n",
      "loss difference:\n",
      "0.0005310278641105781\n",
      "epoch: 650\n",
      "training loss: 0.2773772433318666\n",
      "validation loss: 14.992214291691818\n",
      "loss difference:\n",
      "0.0005293885446149282\n",
      "epoch: 651\n",
      "training loss: 0.27684948651932606\n",
      "validation loss: 14.999479985127978\n",
      "loss difference:\n",
      "0.0005277568125405252\n",
      "epoch: 652\n",
      "training loss: 0.276323353898172\n",
      "validation loss: 15.006746218095575\n",
      "loss difference:\n",
      "0.0005261326211540851\n",
      "epoch: 653\n",
      "training loss: 0.2757988379740651\n",
      "validation loss: 15.014012969265496\n",
      "loss difference:\n",
      "0.0005245159241068498\n",
      "epoch: 654\n",
      "training loss: 0.2752759312986321\n",
      "validation loss: 15.021280217209517\n",
      "loss difference:\n",
      "0.0005229066754330325\n",
      "epoch: 655\n",
      "training loss: 0.27475462646908666\n",
      "validation loss: 15.02854794039833\n",
      "loss difference:\n",
      "0.0005213048295454326\n",
      "epoch: 656\n",
      "training loss: 0.27423491612785605\n",
      "validation loss: 15.035816117199797\n",
      "loss difference:\n",
      "0.0005197103412306059\n",
      "epoch: 657\n",
      "training loss: 0.27371679296220724\n",
      "validation loss: 15.043084725877211\n",
      "loss difference:\n",
      "0.0005181231656488094\n",
      "epoch: 658\n",
      "training loss: 0.2732002497038827\n",
      "validation loss: 15.050353744587596\n",
      "loss difference:\n",
      "0.0005165432583245644\n",
      "epoch: 659\n",
      "training loss: 0.27268527912873547\n",
      "validation loss: 15.057623151380076\n",
      "loss difference:\n",
      "0.0005149705751472111\n",
      "epoch: 660\n",
      "training loss: 0.2721718740563704\n",
      "validation loss: 15.064892924194327\n",
      "loss difference:\n",
      "0.0005134050723650807\n",
      "epoch: 661\n",
      "training loss: 0.2716600273497832\n",
      "validation loss: 15.072163040859007\n",
      "loss difference:\n",
      "0.0005118467065872156\n",
      "epoch: 662\n",
      "training loss: 0.27114973191501557\n",
      "validation loss: 15.07943347909034\n",
      "loss difference:\n",
      "0.0005102954347676047\n",
      "epoch: 663\n",
      "training loss: 0.2706409807008008\n",
      "validation loss: 15.08670421649075\n",
      "loss difference:\n",
      "0.0005087512142147865\n",
      "epoch: 664\n",
      "training loss: 0.27013376669821954\n",
      "validation loss: 15.093975230547453\n",
      "loss difference:\n",
      "0.0005072140025812466\n",
      "epoch: 665\n",
      "training loss: 0.26962808294035673\n",
      "validation loss: 15.101246498631175\n",
      "loss difference:\n",
      "0.0005056837578628071\n",
      "epoch: 666\n",
      "training loss: 0.26912392250196576\n",
      "validation loss: 15.108517997995037\n",
      "loss difference:\n",
      "0.0005041604383909659\n",
      "epoch: 667\n",
      "training loss: 0.26862127849913253\n",
      "validation loss: 15.11578970577319\n",
      "loss difference:\n",
      "0.0005026440028332302\n",
      "epoch: 668\n",
      "training loss: 0.26812014408894075\n",
      "validation loss: 15.123061598979922\n",
      "loss difference:\n",
      "0.0005011344101917836\n",
      "epoch: 669\n",
      "training loss: 0.2676205124691479\n",
      "validation loss: 15.130333654508465\n",
      "loss difference:\n",
      "0.0004996316197928286\n",
      "epoch: 670\n",
      "training loss: 0.26712237687785645\n",
      "validation loss: 15.137605849130034\n",
      "loss difference:\n",
      "0.0004981355912914709\n",
      "epoch: 671\n",
      "training loss: 0.2666257305931956\n",
      "validation loss: 15.144878159492881\n",
      "loss difference:\n",
      "0.0004966462846608399\n",
      "epoch: 672\n",
      "training loss: 0.2661305669330017\n",
      "validation loss: 15.152150562121486\n",
      "loss difference:\n",
      "0.0004951636601939202\n",
      "epoch: 673\n",
      "training loss: 0.2656368792545017\n",
      "validation loss: 15.15942303341561\n",
      "loss difference:\n",
      "0.0004936876784999988\n",
      "epoch: 674\n",
      "training loss: 0.26514466095400224\n",
      "validation loss: 15.166695549649592\n",
      "loss difference:\n",
      "0.0004922183004994474\n",
      "epoch: 675\n",
      "training loss: 0.2646539054665814\n",
      "validation loss: 15.173968086971678\n",
      "loss difference:\n",
      "0.0004907554874208353\n",
      "epoch: 676\n",
      "training loss: 0.2641646062657817\n",
      "validation loss: 15.18124062140329\n",
      "loss difference:\n",
      "0.0004892992007997088\n",
      "epoch: 677\n",
      "training loss: 0.2636767568633094\n",
      "validation loss: 15.188513128838437\n",
      "loss difference:\n",
      "0.0004878494024723179\n",
      "epoch: 678\n",
      "training loss: 0.26319035080873504\n",
      "validation loss: 15.195785585043222\n",
      "loss difference:\n",
      "0.00048640605457433983\n",
      "epoch: 679\n",
      "training loss: 0.2627053816891943\n",
      "validation loss: 15.203057965655296\n",
      "loss difference:\n",
      "0.00048496911954076793\n",
      "epoch: 680\n",
      "training loss: 0.2622218431290969\n",
      "validation loss: 15.210330246183416\n",
      "loss difference:\n",
      "0.00048353856009736296\n",
      "epoch: 681\n",
      "training loss: 0.261739728789837\n",
      "validation loss: 15.217602402007067\n",
      "loss difference:\n",
      "0.0004821143392599314\n",
      "epoch: 682\n",
      "training loss: 0.2612590323695035\n",
      "validation loss: 15.224874408376186\n",
      "loss difference:\n",
      "0.0004806964203334929\n",
      "epoch: 683\n",
      "training loss: 0.26077974760259853\n",
      "validation loss: 15.23214624041082\n",
      "loss difference:\n",
      "0.0004792847669049527\n",
      "epoch: 684\n",
      "training loss: 0.260301868259752\n",
      "validation loss: 15.239417873100821\n",
      "loss difference:\n",
      "0.0004778793428465433\n",
      "epoch: 685\n",
      "training loss: 0.259825388147447\n",
      "validation loss: 15.246689281305876\n",
      "loss difference:\n",
      "0.000476480112305\n",
      "epoch: 686\n",
      "training loss: 0.25935030110774127\n",
      "validation loss: 15.25396043975517\n",
      "loss difference:\n",
      "0.00047508703970572386\n",
      "epoch: 687\n",
      "training loss: 0.25887660101799626\n",
      "validation loss: 15.261231323047445\n",
      "loss difference:\n",
      "0.00047370008974501054\n",
      "epoch: 688\n",
      "training loss: 0.25840428179060293\n",
      "validation loss: 15.268501905650902\n",
      "loss difference:\n",
      "0.0004723192273933252\n",
      "epoch: 689\n",
      "training loss: 0.25793333737272095\n",
      "validation loss: 15.275772161903243\n",
      "loss difference:\n",
      "0.00047094441788197994\n",
      "epoch: 690\n",
      "training loss: 0.25746376174600816\n",
      "validation loss: 15.28304206601175\n",
      "loss difference:\n",
      "0.0004695756267127926\n",
      "epoch: 691\n",
      "training loss: 0.25699554892636045\n",
      "validation loss: 15.290311592053365\n",
      "loss difference:\n",
      "0.00046821281964770645\n",
      "epoch: 692\n",
      "training loss: 0.25652869296365455\n",
      "validation loss: 15.29758071397489\n",
      "loss difference:\n",
      "0.00046685596270590324\n",
      "epoch: 693\n",
      "training loss: 0.25606318794148775\n",
      "validation loss: 15.304849405593217\n",
      "loss difference:\n",
      "0.0004655050221668011\n",
      "epoch: 694\n",
      "training loss: 0.2555990279769282\n",
      "validation loss: 15.312117640595499\n",
      "loss difference:\n",
      "0.0004641599645595629\n",
      "epoch: 695\n",
      "training loss: 0.2551362072202584\n",
      "validation loss: 15.319385392539516\n",
      "loss difference:\n",
      "0.0004628207566697573\n",
      "epoch: 696\n",
      "training loss: 0.254674719854731\n",
      "validation loss: 15.326652634854035\n",
      "loss difference:\n",
      "0.0004614873655274243\n",
      "epoch: 697\n",
      "training loss: 0.2542145600963217\n",
      "validation loss: 15.333919340839152\n",
      "loss difference:\n",
      "0.00046015975840929535\n",
      "epoch: 698\n",
      "training loss: 0.25375572219348264\n",
      "validation loss: 15.341185483666735\n",
      "loss difference:\n",
      "0.000458837902839071\n",
      "epoch: 699\n",
      "training loss: 0.25329820042690543\n",
      "validation loss: 15.348451036380917\n",
      "loss difference:\n",
      "0.0004575217665772069\n",
      "epoch: 700\n",
      "training loss: 0.2528419891092798\n",
      "validation loss: 15.355715971898567\n",
      "loss difference:\n",
      "0.00045621131762563216\n",
      "epoch: 701\n",
      "training loss: 0.2523870825850574\n",
      "validation loss: 15.362980263009902\n",
      "loss difference:\n",
      "0.0004549065242224204\n",
      "epoch: 702\n",
      "training loss: 0.25193347523021975\n",
      "validation loss: 15.370243882379045\n",
      "loss difference:\n",
      "0.00045360735483762626\n",
      "epoch: 703\n",
      "training loss: 0.25148116145204635\n",
      "validation loss: 15.377506802544689\n",
      "loss difference:\n",
      "0.0004523137781733966\n",
      "epoch: 704\n",
      "training loss: 0.25103013568888577\n",
      "validation loss: 15.384768995920744\n",
      "loss difference:\n",
      "0.00045102576316058407\n",
      "epoch: 705\n",
      "training loss: 0.2505803924099269\n",
      "validation loss: 15.392030434797034\n",
      "loss difference:\n",
      "0.00044974327895885846\n",
      "epoch: 706\n",
      "training loss: 0.2501319261149799\n",
      "validation loss: 15.39929109134012\n",
      "loss difference:\n",
      "0.00044846629494699197\n",
      "epoch: 707\n",
      "training loss: 0.24968473133424804\n",
      "validation loss: 15.406550937594018\n",
      "loss difference:\n",
      "0.0004471947807318799\n",
      "epoch: 708\n",
      "training loss: 0.2492388026281137\n",
      "validation loss: 15.413809945481049\n",
      "loss difference:\n",
      "0.0004459287061343298\n",
      "epoch: 709\n",
      "training loss: 0.2487941345869194\n",
      "validation loss: 15.421068086802643\n",
      "loss difference:\n",
      "0.00044466804119430714\n",
      "epoch: 710\n",
      "training loss: 0.24835072183075121\n",
      "validation loss: 15.428325333240345\n",
      "loss difference:\n",
      "0.00044341275616818776\n",
      "epoch: 711\n",
      "training loss: 0.2479085590092273\n",
      "validation loss: 15.435581656356645\n",
      "loss difference:\n",
      "0.00044216282152392816\n",
      "epoch: 712\n",
      "training loss: 0.24746764080128905\n",
      "validation loss: 15.442837027595951\n",
      "loss difference:\n",
      "0.00044091820793823455\n",
      "epoch: 713\n",
      "training loss: 0.24702796191499088\n",
      "validation loss: 15.450091418285627\n",
      "loss difference:\n",
      "0.00043967888629817264\n",
      "epoch: 714\n",
      "training loss: 0.24658951708729426\n",
      "validation loss: 15.457344799636934\n",
      "loss difference:\n",
      "0.00043844482769661575\n",
      "epoch: 715\n",
      "training loss: 0.24615230108386635\n",
      "validation loss: 15.464597142746227\n",
      "loss difference:\n",
      "0.0004372160034279149\n",
      "epoch: 716\n",
      "training loss: 0.24571630869887395\n",
      "validation loss: 15.471848418595787\n",
      "loss difference:\n",
      "0.00043599238499239523\n",
      "epoch: 717\n",
      "training loss: 0.2452815347547889\n",
      "validation loss: 15.479098598055254\n",
      "loss difference:\n",
      "0.00043477394408505954\n",
      "epoch: 718\n",
      "training loss: 0.24484797410218795\n",
      "validation loss: 15.48634765188252\n",
      "loss difference:\n",
      "0.000433560652600945\n",
      "epoch: 719\n",
      "training loss: 0.24441562161955774\n",
      "validation loss: 15.49359555072501\n",
      "loss difference:\n",
      "0.00043235248263021053\n",
      "epoch: 720\n",
      "training loss: 0.24398447221310207\n",
      "validation loss: 15.500842265120863\n",
      "loss difference:\n",
      "0.00043114940645566646\n",
      "epoch: 721\n",
      "training loss: 0.2435545208165503\n",
      "validation loss: 15.508087765500141\n",
      "loss difference:\n",
      "0.0004299513965517754\n",
      "epoch: 722\n",
      "training loss: 0.2431257623909702\n",
      "validation loss: 15.515332022186099\n",
      "loss difference:\n",
      "0.00042875842558010024\n",
      "epoch: 723\n",
      "training loss: 0.24269819192457756\n",
      "validation loss: 15.522575005396462\n",
      "loss difference:\n",
      "0.00042757046639263496\n",
      "epoch: 724\n",
      "training loss: 0.24227180443255578\n",
      "validation loss: 15.529816685244691\n",
      "loss difference:\n",
      "0.0004263874920217847\n",
      "epoch: 725\n",
      "training loss: 0.2418465949568669\n",
      "validation loss: 15.537057031741377\n",
      "loss difference:\n",
      "0.0004252094756888869\n",
      "epoch: 726\n",
      "training loss: 0.24142255856607797\n",
      "validation loss: 15.544296014795513\n",
      "loss difference:\n",
      "0.00042403639078891775\n",
      "epoch: 727\n",
      "training loss: 0.24099969035517535\n",
      "validation loss: 15.551533604215905\n",
      "loss difference:\n",
      "0.0004228682109026216\n",
      "epoch: 728\n",
      "training loss: 0.24057798544539113\n",
      "validation loss: 15.558769769712573\n",
      "loss difference:\n",
      "0.00042170490978421515\n",
      "epoch: 729\n",
      "training loss: 0.2401574389840284\n",
      "validation loss: 15.566004480898194\n",
      "loss difference:\n",
      "0.0004205464613627474\n",
      "epoch: 730\n",
      "training loss: 0.23973804614428695\n",
      "validation loss: 15.573237707289408\n",
      "loss difference:\n",
      "0.0004193928397414337\n",
      "epoch: 731\n",
      "training loss: 0.23931980212509252\n",
      "validation loss: 15.580469418308462\n",
      "loss difference:\n",
      "0.0004182440191944359\n",
      "epoch: 732\n",
      "training loss: 0.2389027021509263\n",
      "validation loss: 15.587699583284541\n",
      "loss difference:\n",
      "0.000417099974166224\n",
      "epoch: 733\n",
      "training loss: 0.23848674147166\n",
      "validation loss: 15.594928171455324\n",
      "loss difference:\n",
      "0.00041596067926630287\n",
      "epoch: 734\n",
      "training loss: 0.23807191536238667\n",
      "validation loss: 15.602155151968507\n",
      "loss difference:\n",
      "0.00041482610927331964\n",
      "epoch: 735\n",
      "training loss: 0.23765821912326204\n",
      "validation loss: 15.609380493883274\n",
      "loss difference:\n",
      "0.00041369623912462794\n",
      "epoch: 736\n",
      "training loss: 0.23724564807933718\n",
      "validation loss: 15.61660416617193\n",
      "loss difference:\n",
      "0.0004125710439248642\n",
      "epoch: 737\n",
      "training loss: 0.23683419758040186\n",
      "validation loss: 15.623826137721407\n",
      "loss difference:\n",
      "0.0004114504989353174\n",
      "epoch: 738\n",
      "training loss: 0.23642386300082682\n",
      "validation loss: 15.63104637733486\n",
      "loss difference:\n",
      "0.00041033457957503905\n",
      "epoch: 739\n",
      "training loss: 0.23601463973940406\n",
      "validation loss: 15.638264853733261\n",
      "loss difference:\n",
      "0.00040922326142275867\n",
      "epoch: 740\n",
      "training loss: 0.2356065232191963\n",
      "validation loss: 15.645481535557037\n",
      "loss difference:\n",
      "0.0004081165202077519\n",
      "epoch: 741\n",
      "training loss: 0.23519950888737978\n",
      "validation loss: 15.65269639136762\n",
      "loss difference:\n",
      "0.0004070143318165298\n",
      "epoch: 742\n",
      "training loss: 0.23479359221509738\n",
      "validation loss: 15.659909389649238\n",
      "loss difference:\n",
      "0.0004059166722824026\n",
      "epoch: 743\n",
      "training loss: 0.23438876869730743\n",
      "validation loss: 15.667120498810398\n",
      "loss difference:\n",
      "0.0004048235177899484\n",
      "epoch: 744\n",
      "training loss: 0.23398503385263492\n",
      "validation loss: 15.674329687185658\n",
      "loss difference:\n",
      "0.0004037348446725153\n",
      "epoch: 745\n",
      "training loss: 0.23358238322322802\n",
      "validation loss: 15.681536923037225\n",
      "loss difference:\n",
      "0.0004026506294068921\n",
      "epoch: 746\n",
      "training loss: 0.23318081237461188\n",
      "validation loss: 15.688742174556795\n",
      "loss difference:\n",
      "0.00040157084861613956\n",
      "epoch: 747\n",
      "training loss: 0.23278031689554765\n",
      "validation loss: 15.695945409867008\n",
      "loss difference:\n",
      "0.00040049547906423344\n",
      "epoch: 748\n",
      "training loss: 0.23238089239789145\n",
      "validation loss: 15.703146597023444\n",
      "loss difference:\n",
      "0.00039942449765620336\n",
      "epoch: 749\n",
      "training loss: 0.23198253451645395\n",
      "validation loss: 15.710345704016104\n",
      "loss difference:\n",
      "0.0003983578814374944\n",
      "epoch: 750\n",
      "training loss: 0.23158523890886595\n",
      "validation loss: 15.717542698771334\n",
      "loss difference:\n",
      "0.00039729560758799964\n",
      "epoch: 751\n",
      "training loss: 0.23118900125543854\n",
      "validation loss: 15.724737549153362\n",
      "loss difference:\n",
      "0.000396237653427417\n",
      "epoch: 752\n",
      "training loss: 0.2307938172590332\n",
      "validation loss: 15.731930222966238\n",
      "loss difference:\n",
      "0.0003951839964053405\n",
      "epoch: 753\n",
      "training loss: 0.23039968264492472\n",
      "validation loss: 15.73912068795548\n",
      "loss difference:\n",
      "0.0003941346141084767\n",
      "epoch: 754\n",
      "training loss: 0.2300065931606759\n",
      "validation loss: 15.746308911809871\n",
      "loss difference:\n",
      "0.00039308948424882084\n",
      "epoch: 755\n",
      "training loss: 0.22961454457600355\n",
      "validation loss: 15.753494862163235\n",
      "loss difference:\n",
      "0.00039204858467234427\n",
      "epoch: 756\n",
      "training loss: 0.2292235326826529\n",
      "validation loss: 15.76067850659621\n",
      "loss difference:\n",
      "0.0003910118933506679\n",
      "epoch: 757\n",
      "training loss: 0.22883355329427085\n",
      "validation loss: 15.76785981263801\n",
      "loss difference:\n",
      "0.0003899793883820335\n",
      "epoch: 758\n",
      "training loss: 0.22844460224628385\n",
      "validation loss: 15.775038747768303\n",
      "loss difference:\n",
      "0.00038895104798700175\n",
      "epoch: 759\n",
      "training loss: 0.2280566753957694\n",
      "validation loss: 15.782215279418898\n",
      "loss difference:\n",
      "0.0003879268505144473\n",
      "epoch: 760\n",
      "training loss: 0.22766976862134183\n",
      "validation loss: 15.789389374975546\n",
      "loss difference:\n",
      "0.00038690677442757004\n",
      "epoch: 761\n",
      "training loss: 0.22728387782302567\n",
      "validation loss: 15.79656100177991\n",
      "loss difference:\n",
      "0.000385890798316163\n",
      "epoch: 762\n",
      "training loss: 0.2268989989221435\n",
      "validation loss: 15.803730127131153\n",
      "loss difference:\n",
      "0.0003848789008821796\n",
      "epoch: 763\n",
      "training loss: 0.22651512786119427\n",
      "validation loss: 15.810896718287943\n",
      "loss difference:\n",
      "0.00038387106094922574\n",
      "epoch: 764\n",
      "training loss: 0.22613226060373984\n",
      "validation loss: 15.818060742470132\n",
      "loss difference:\n",
      "0.00038286725745442785\n",
      "epoch: 765\n",
      "training loss: 0.2257503931342923\n",
      "validation loss: 15.825222166860627\n",
      "loss difference:\n",
      "0.00038186746944754435\n",
      "epoch: 766\n",
      "training loss: 0.22536952145819913\n",
      "validation loss: 15.832380958607263\n",
      "loss difference:\n",
      "0.00038087167609315853\n",
      "epoch: 767\n",
      "training loss: 0.22498964160153515\n",
      "validation loss: 15.839537084824576\n",
      "loss difference:\n",
      "0.0003798798566639894\n",
      "epoch: 768\n",
      "training loss: 0.2246107496109914\n",
      "validation loss: 15.846690512595659\n",
      "loss difference:\n",
      "0.00037889199054375045\n",
      "epoch: 769\n",
      "training loss: 0.22423284155376758\n",
      "validation loss: 15.853841208973906\n",
      "loss difference:\n",
      "0.00037790805722381915\n",
      "epoch: 770\n",
      "training loss: 0.22385591351746473\n",
      "validation loss: 15.860989140984993\n",
      "loss difference:\n",
      "0.0003769280363028482\n",
      "epoch: 771\n",
      "training loss: 0.22347996160998304\n",
      "validation loss: 15.868134275628597\n",
      "loss difference:\n",
      "0.0003759519074816864\n",
      "epoch: 772\n",
      "training loss: 0.22310498195941442\n",
      "validation loss: 15.875276579880271\n",
      "loss difference:\n",
      "0.00037497965056862426\n",
      "epoch: 773\n",
      "training loss: 0.2227309707139424\n",
      "validation loss: 15.882416020693285\n",
      "loss difference:\n",
      "0.00037401124547201126\n",
      "epoch: 774\n",
      "training loss: 0.22235792404174107\n",
      "validation loss: 15.889552565000418\n",
      "loss difference:\n",
      "0.00037304667220133814\n",
      "epoch: 775\n",
      "training loss: 0.22198583813087694\n",
      "validation loss: 15.89668617971585\n",
      "loss difference:\n",
      "0.00037208591086412834\n",
      "epoch: 776\n",
      "training loss: 0.22161470918920656\n",
      "validation loss: 15.903816831736936\n",
      "loss difference:\n",
      "0.0003711289416703789\n",
      "epoch: 777\n",
      "training loss: 0.22124453344428535\n",
      "validation loss: 15.910944487946107\n",
      "loss difference:\n",
      "0.0003701757449212084\n",
      "epoch: 778\n",
      "training loss: 0.22087530714326764\n",
      "validation loss: 15.918069115212635\n",
      "loss difference:\n",
      "0.00036922630101771103\n",
      "epoch: 779\n",
      "training loss: 0.22050702655281668\n",
      "validation loss: 15.925190680394488\n",
      "loss difference:\n",
      "0.0003682805904509645\n",
      "epoch: 780\n",
      "training loss: 0.2201396879590085\n",
      "validation loss: 15.932309150340199\n",
      "loss difference:\n",
      "0.00036733859380816414\n",
      "epoch: 781\n",
      "training loss: 0.21977328766724138\n",
      "validation loss: 15.9394244918906\n",
      "loss difference:\n",
      "0.0003664002917671272\n",
      "epoch: 782\n",
      "training loss: 0.219407822002148\n",
      "validation loss: 15.946536671880759\n",
      "loss difference:\n",
      "0.0003654656650933785\n",
      "epoch: 783\n",
      "training loss: 0.21904328730750397\n",
      "validation loss: 15.953645657141708\n",
      "loss difference:\n",
      "0.00036453469464403643\n",
      "epoch: 784\n",
      "training loss: 0.21867967994614126\n",
      "validation loss: 15.96075141450229\n",
      "loss difference:\n",
      "0.00036360736136270555\n",
      "epoch: 785\n",
      "training loss: 0.2183169962998628\n",
      "validation loss: 15.96785391079104\n",
      "loss difference:\n",
      "0.0003626836462784777\n",
      "epoch: 786\n",
      "training loss: 0.217955232769356\n",
      "validation loss: 15.974953112837852\n",
      "loss difference:\n",
      "0.00036176353050679233\n",
      "epoch: 787\n",
      "training loss: 0.2175943857741103\n",
      "validation loss: 15.982048987475968\n",
      "loss difference:\n",
      "0.0003608469952456894\n",
      "epoch: 788\n",
      "training loss: 0.21723445175233438\n",
      "validation loss: 15.989141501543672\n",
      "loss difference:\n",
      "0.0003599340217759206\n",
      "epoch: 789\n",
      "training loss: 0.2168754271608744\n",
      "validation loss: 15.996230621886076\n",
      "loss difference:\n",
      "0.00035902459145997767\n",
      "epoch: 790\n",
      "training loss: 0.21651730847513473\n",
      "validation loss: 16.003316315357004\n",
      "loss difference:\n",
      "0.00035811868573967787\n",
      "epoch: 791\n",
      "training loss: 0.21616009218899845\n",
      "validation loss: 16.010398548820746\n",
      "loss difference:\n",
      "0.0003572162861362749\n",
      "epoch: 792\n",
      "training loss: 0.21580377481474927\n",
      "validation loss: 16.017477289153796\n",
      "loss difference:\n",
      "0.0003563173742491821\n",
      "epoch: 793\n",
      "training loss: 0.2154483528829972\n",
      "validation loss: 16.024552503246746\n",
      "loss difference:\n",
      "0.00035542193175205905\n",
      "epoch: 794\n",
      "training loss: 0.2150938229426002\n",
      "validation loss: 16.03162415800598\n",
      "loss difference:\n",
      "0.0003545299403970026\n",
      "epoch: 795\n",
      "training loss: 0.2147401815605923\n",
      "validation loss: 16.038692220355465\n",
      "loss difference:\n",
      "0.0003536413820079132\n",
      "epoch: 796\n",
      "training loss: 0.214387425322109\n",
      "validation loss: 16.045756657238574\n",
      "loss difference:\n",
      "0.0003527562384832983\n",
      "epoch: 797\n",
      "training loss: 0.21403555083031653\n",
      "validation loss: 16.052817435619765\n",
      "loss difference:\n",
      "0.0003518744917924699\n",
      "epoch: 798\n",
      "training loss: 0.21368455470634076\n",
      "validation loss: 16.059874522486446\n",
      "loss difference:\n",
      "0.0003509961239757664\n",
      "epoch: 799\n",
      "training loss: 0.21333443358919646\n",
      "validation loss: 16.066927884850635\n",
      "loss difference:\n",
      "0.00035012111714430305\n",
      "epoch: 800\n",
      "training loss: 0.21298518413571912\n",
      "validation loss: 16.07397748975076\n",
      "loss difference:\n",
      "0.00034924945347733494\n",
      "epoch: 801\n",
      "training loss: 0.21263680302049792\n",
      "validation loss: 16.081023304253417\n",
      "loss difference:\n",
      "0.0003483811152212024\n",
      "epoch: 802\n",
      "training loss: 0.21228928693580867\n",
      "validation loss: 16.088065295455028\n",
      "loss difference:\n",
      "0.00034751608468924777\n",
      "epoch: 803\n",
      "training loss: 0.21194263259154827\n",
      "validation loss: 16.095103430483693\n",
      "loss difference:\n",
      "0.00034665434426039976\n",
      "epoch: 804\n",
      "training loss: 0.2115968367151698\n",
      "validation loss: 16.102137676500828\n",
      "loss difference:\n",
      "0.00034579587637847964\n",
      "epoch: 805\n",
      "training loss: 0.2112518960516197\n",
      "validation loss: 16.10916800070291\n",
      "loss difference:\n",
      "0.0003449406635500918\n",
      "epoch: 806\n",
      "training loss: 0.2109078073632742\n",
      "validation loss: 16.116194370323136\n",
      "loss difference:\n",
      "0.00034408868834551187\n",
      "epoch: 807\n",
      "training loss: 0.21056456742987809\n",
      "validation loss: 16.123216752633265\n",
      "loss difference:\n",
      "0.0003432399333961056\n",
      "epoch: 808\n",
      "training loss: 0.21022217304848598\n",
      "validation loss: 16.130235114945197\n",
      "loss difference:\n",
      "0.0003423943813921082\n",
      "epoch: 809\n",
      "training loss: 0.2098806210333991\n",
      "validation loss: 16.13724942461272\n",
      "loss difference:\n",
      "0.00034155201508687116\n",
      "epoch: 810\n",
      "training loss: 0.20953990821610882\n",
      "validation loss: 16.144259649033163\n",
      "loss difference:\n",
      "0.000340712817290284\n",
      "epoch: 811\n",
      "training loss: 0.20920003144523755\n",
      "validation loss: 16.151265755649103\n",
      "loss difference:\n",
      "0.00033987677087127244\n",
      "epoch: 812\n",
      "training loss: 0.20886098758648358\n",
      "validation loss: 16.15826771195003\n",
      "loss difference:\n",
      "0.0003390438587539679\n",
      "epoch: 813\n",
      "training loss: 0.20852277352256235\n",
      "validation loss: 16.16526548547403\n",
      "loss difference:\n",
      "0.00033821406392123277\n",
      "epoch: 814\n",
      "training loss: 0.20818538615315266\n",
      "validation loss: 16.172259043809415\n",
      "loss difference:\n",
      "0.00033738736940969183\n",
      "epoch: 815\n",
      "training loss: 0.20784882239484181\n",
      "validation loss: 16.17924835459634\n",
      "loss difference:\n",
      "0.00033656375831084273\n",
      "epoch: 816\n",
      "training loss: 0.20751307918107284\n",
      "validation loss: 16.186233385528602\n",
      "loss difference:\n",
      "0.0003357432137689742\n",
      "epoch: 817\n",
      "training loss: 0.207178153462089\n",
      "validation loss: 16.19321410435506\n",
      "loss difference:\n",
      "0.0003349257189838306\n",
      "epoch: 818\n",
      "training loss: 0.2068440422048852\n",
      "validation loss: 16.200190478881492\n",
      "loss difference:\n",
      "0.00033411125720381185\n",
      "epoch: 819\n",
      "training loss: 0.2065107423931535\n",
      "validation loss: 16.207162476971945\n",
      "loss difference:\n",
      "0.000333299811731691\n",
      "epoch: 820\n",
      "training loss: 0.2061782510272341\n",
      "validation loss: 16.21413006655067\n",
      "loss difference:\n",
      "0.0003324913659193962\n",
      "epoch: 821\n",
      "training loss: 0.20584656512406474\n",
      "validation loss: 16.221093215603457\n",
      "loss difference:\n",
      "0.00033168590316937085\n",
      "epoch: 822\n",
      "training loss: 0.2055156817171319\n",
      "validation loss: 16.228051892179376\n",
      "loss difference:\n",
      "0.00033088340693285256\n",
      "epoch: 823\n",
      "training loss: 0.20518559785642176\n",
      "validation loss: 16.235006064392344\n",
      "loss difference:\n",
      "0.0003300838607101231\n",
      "epoch: 824\n",
      "training loss: 0.2048563106083728\n",
      "validation loss: 16.24195570042272\n",
      "loss difference:\n",
      "0.00032928724804895393\n",
      "epoch: 825\n",
      "training loss: 0.2045278170558286\n",
      "validation loss: 16.24890076851881\n",
      "loss difference:\n",
      "0.00032849355254421786\n",
      "epoch: 826\n",
      "training loss: 0.20420011429798818\n",
      "validation loss: 16.25584123699857\n",
      "loss difference:\n",
      "0.0003277027578404146\n",
      "epoch: 827\n",
      "training loss: 0.20387319945036536\n",
      "validation loss: 16.26277707425103\n",
      "loss difference:\n",
      "0.00032691484762281675\n",
      "epoch: 828\n",
      "training loss: 0.2035470696447391\n",
      "validation loss: 16.269708248737953\n",
      "loss difference:\n",
      "0.0003261298056262685\n",
      "epoch: 829\n",
      "training loss: 0.20322172202910915\n",
      "validation loss: 16.2766347289953\n",
      "loss difference:\n",
      "0.0003253476156299395\n",
      "epoch: 830\n",
      "training loss: 0.2028971537676514\n",
      "validation loss: 16.283556483634843\n",
      "loss difference:\n",
      "0.00032456826145774165\n",
      "epoch: 831\n",
      "training loss: 0.20257336204067558\n",
      "validation loss: 16.29047348134561\n",
      "loss difference:\n",
      "0.0003237917269758306\n",
      "epoch: 832\n",
      "training loss: 0.20225034404458003\n",
      "validation loss: 16.297385690895556\n",
      "loss difference:\n",
      "0.00032301799609554815\n",
      "epoch: 833\n",
      "training loss: 0.20192809699180822\n",
      "validation loss: 16.30429308113287\n",
      "loss difference:\n",
      "0.0003222470527718124\n",
      "epoch: 834\n",
      "training loss: 0.20160661811080763\n",
      "validation loss: 16.31119562098767\n",
      "loss difference:\n",
      "0.00032147888100059197\n",
      "epoch: 835\n",
      "training loss: 0.20128590464598684\n",
      "validation loss: 16.318093279473374\n",
      "loss difference:\n",
      "0.0003207134648207932\n",
      "epoch: 836\n",
      "training loss: 0.2009659538576725\n",
      "validation loss: 16.324986025688336\n",
      "loss difference:\n",
      "0.00031995078831434376\n",
      "epoch: 837\n",
      "training loss: 0.2006467630220698\n",
      "validation loss: 16.331873828817137\n",
      "loss difference:\n",
      "0.0003191908356026951\n",
      "epoch: 838\n",
      "training loss: 0.20032832943121837\n",
      "validation loss: 16.33875665813222\n",
      "loss difference:\n",
      "0.0003184335908514302\n",
      "epoch: 839\n",
      "training loss: 0.20001065039295446\n",
      "validation loss: 16.34563448299532\n",
      "loss difference:\n",
      "0.0003176790382639072\n",
      "epoch: 840\n",
      "training loss: 0.19969372323086856\n",
      "validation loss: 16.352507272858865\n",
      "loss difference:\n",
      "0.0003169271620858949\n",
      "epoch: 841\n",
      "training loss: 0.19937754528426468\n",
      "validation loss: 16.359374997267516\n",
      "loss difference:\n",
      "0.00031617794660387943\n",
      "epoch: 842\n",
      "training loss: 0.19906211390812062\n",
      "validation loss: 16.36623762585952\n",
      "loss difference:\n",
      "0.00031543137614406525\n",
      "epoch: 843\n",
      "training loss: 0.19874742647304797\n",
      "validation loss: 16.373095128368252\n",
      "loss difference:\n",
      "0.0003146874350726525\n",
      "epoch: 844\n",
      "training loss: 0.1984334803652513\n",
      "validation loss: 16.379947474623552\n",
      "loss difference:\n",
      "0.00031394610779666987\n",
      "epoch: 845\n",
      "training loss: 0.19812027298649162\n",
      "validation loss: 16.386794634553222\n",
      "loss difference:\n",
      "0.0003132073787596723\n",
      "epoch: 846\n",
      "training loss: 0.1978078017540415\n",
      "validation loss: 16.39363657818435\n",
      "loss difference:\n",
      "0.0003124712324501233\n",
      "epoch: 847\n",
      "training loss: 0.19749606410065026\n",
      "validation loss: 16.40047327564484\n",
      "loss difference:\n",
      "0.0003117376533912364\n",
      "epoch: 848\n",
      "training loss: 0.19718505747450116\n",
      "validation loss: 16.40730469716465\n",
      "loss difference:\n",
      "0.00031100662614910735\n",
      "epoch: 849\n",
      "training loss: 0.19687477933917494\n",
      "validation loss: 16.414130813077364\n",
      "loss difference:\n",
      "0.0003102781353262196\n",
      "epoch: 850\n",
      "training loss: 0.19656522717360814\n",
      "validation loss: 16.42095159382143\n",
      "loss difference:\n",
      "0.000309552165566801\n",
      "epoch: 851\n",
      "training loss: 0.1962563984720526\n",
      "validation loss: 16.427767009941594\n",
      "loss difference:\n",
      "0.00030882870155554687\n",
      "epoch: 852\n",
      "training loss: 0.1959482907440397\n",
      "validation loss: 16.434577032090285\n",
      "loss difference:\n",
      "0.00030810772801290187\n",
      "epoch: 853\n",
      "training loss: 0.1956409015143376\n",
      "validation loss: 16.441381631028907\n",
      "loss difference:\n",
      "0.00030738922970208193\n",
      "epoch: 854\n",
      "training loss: 0.1953342283229125\n",
      "validation loss: 16.44818077762929\n",
      "loss difference:\n",
      "0.0003066731914251053\n",
      "epoch: 855\n",
      "training loss: 0.195028268724889\n",
      "validation loss: 16.454974442874892\n",
      "loss difference:\n",
      "0.00030595959802351413\n",
      "epoch: 856\n",
      "training loss: 0.19472302029050953\n",
      "validation loss: 16.46176259786234\n",
      "loss difference:\n",
      "0.00030524843437945703\n",
      "epoch: 857\n",
      "training loss: 0.19441848060509315\n",
      "validation loss: 16.46854521380253\n",
      "loss difference:\n",
      "0.0003045396854163829\n",
      "epoch: 858\n",
      "training loss: 0.1941146472689975\n",
      "validation loss: 16.4753222620221\n",
      "loss difference:\n",
      "0.00030383333609565466\n",
      "epoch: 859\n",
      "training loss: 0.19381151789757714\n",
      "validation loss: 16.482093713964687\n",
      "loss difference:\n",
      "0.000303129371420352\n",
      "epoch: 860\n",
      "training loss: 0.19350909012113965\n",
      "validation loss: 16.488859541192227\n",
      "loss difference:\n",
      "0.00030242777643749164\n",
      "epoch: 861\n",
      "training loss: 0.1932073615849095\n",
      "validation loss: 16.495619715386304\n",
      "loss difference:\n",
      "0.00030172853623014473\n",
      "epoch: 862\n",
      "training loss: 0.19290632994898205\n",
      "validation loss: 16.502374208349337\n",
      "loss difference:\n",
      "0.00030103163592745674\n",
      "epoch: 863\n",
      "training loss: 0.19260599288828298\n",
      "validation loss: 16.50912299200594\n",
      "loss difference:\n",
      "0.0003003370606990685\n",
      "epoch: 864\n",
      "training loss: 0.19230634809252706\n",
      "validation loss: 16.515866038404198\n",
      "loss difference:\n",
      "0.0002996447957559212\n",
      "epoch: 865\n",
      "training loss: 0.19200739326617253\n",
      "validation loss: 16.5226033197169\n",
      "loss difference:\n",
      "0.0002989548263545305\n",
      "epoch: 866\n",
      "training loss: 0.1917091261283805\n",
      "validation loss: 16.529334808242755\n",
      "loss difference:\n",
      "0.00029826713779201874\n",
      "epoch: 867\n",
      "training loss: 0.1914115444129696\n",
      "validation loss: 16.53606047640771\n",
      "loss difference:\n",
      "0.00029758171541091616\n",
      "epoch: 868\n",
      "training loss: 0.1911146458683714\n",
      "validation loss: 16.5427802967662\n",
      "loss difference:\n",
      "0.00029689854459818976\n",
      "epoch: 869\n",
      "training loss: 0.19081842825758705\n",
      "validation loss: 16.549494242002293\n",
      "loss difference:\n",
      "0.00029621761078435505\n",
      "epoch: 870\n",
      "training loss: 0.19052288935814066\n",
      "validation loss: 16.556202284930933\n",
      "loss difference:\n",
      "0.00029553889944639034\n",
      "epoch: 871\n",
      "training loss: 0.19022802696203298\n",
      "validation loss: 16.562904398499274\n",
      "loss difference:\n",
      "0.0002948623961076813\n",
      "epoch: 872\n",
      "training loss: 0.18993383887569557\n",
      "validation loss: 16.569600555787698\n",
      "loss difference:\n",
      "0.0002941880863374102\n",
      "epoch: 873\n",
      "training loss: 0.18964032291994434\n",
      "validation loss: 16.576290730011152\n",
      "loss difference:\n",
      "0.00029351595575122236\n",
      "epoch: 874\n",
      "training loss: 0.18934747692992834\n",
      "validation loss: 16.582974894520294\n",
      "loss difference:\n",
      "0.00029284599001599965\n",
      "epoch: 875\n",
      "training loss: 0.18905529875508423\n",
      "validation loss: 16.58965302280261\n",
      "loss difference:\n",
      "0.00029217817484411546\n",
      "epoch: 876\n",
      "training loss: 0.18876378625908694\n",
      "validation loss: 16.59632508848374\n",
      "loss difference:\n",
      "0.00029151249599729256\n",
      "epoch: 877\n",
      "training loss: 0.1884729373197966\n",
      "validation loss: 16.602991065328418\n",
      "loss difference:\n",
      "0.0002908489392903224\n",
      "epoch: 878\n",
      "training loss: 0.18818274982921032\n",
      "validation loss: 16.60965092724184\n",
      "loss difference:\n",
      "0.0002901874905862911\n",
      "epoch: 879\n",
      "training loss: 0.1878932216934091\n",
      "validation loss: 16.616304648270678\n",
      "loss difference:\n",
      "0.0002895281358012147\n",
      "epoch: 880\n",
      "training loss: 0.18760435083250673\n",
      "validation loss: 16.622952202604257\n",
      "loss difference:\n",
      "0.0002888708609023738\n",
      "epoch: 881\n",
      "training loss: 0.18731613518059384\n",
      "validation loss: 16.629593564575643\n",
      "loss difference:\n",
      "0.0002882156519128931\n",
      "epoch: 882\n",
      "training loss: 0.18702857268568662\n",
      "validation loss: 16.636228708662845\n",
      "loss difference:\n",
      "0.0002875624949072175\n",
      "epoch: 883\n",
      "training loss: 0.18674166130966877\n",
      "validation loss: 16.642857609489788\n",
      "loss difference:\n",
      "0.00028691137601785655\n",
      "epoch: 884\n",
      "training loss: 0.18645539902823824\n",
      "validation loss: 16.649480241827533\n",
      "loss difference:\n",
      "0.0002862622814305271\n",
      "epoch: 885\n",
      "training loss: 0.18616978383084795\n",
      "validation loss: 16.6560965805953\n",
      "loss difference:\n",
      "0.0002856151973902876\n",
      "epoch: 886\n",
      "training loss: 0.18588481372064844\n",
      "validation loss: 16.662706600861537\n",
      "loss difference:\n",
      "0.0002849701101995117\n",
      "epoch: 887\n",
      "training loss: 0.18560048671442966\n",
      "validation loss: 16.669310277845007\n",
      "loss difference:\n",
      "0.0002843270062187764\n",
      "epoch: 888\n",
      "training loss: 0.18531680084256003\n",
      "validation loss: 16.675907586915876\n",
      "loss difference:\n",
      "0.0002836858718696378\n",
      "epoch: 889\n",
      "training loss: 0.18503375414892584\n",
      "validation loss: 16.682498503596662\n",
      "loss difference:\n",
      "0.0002830466936341869\n",
      "epoch: 890\n",
      "training loss: 0.1847513446908692\n",
      "validation loss: 16.689083003563326\n",
      "loss difference:\n",
      "0.00028240945805663165\n",
      "epoch: 891\n",
      "training loss: 0.18446957053912638\n",
      "validation loss: 16.695661062646337\n",
      "loss difference:\n",
      "0.00028177415174282516\n",
      "epoch: 892\n",
      "training loss: 0.18418842977776043\n",
      "validation loss: 16.702232656831626\n",
      "loss difference:\n",
      "0.00028114076136595556\n",
      "epoch: 893\n",
      "training loss: 0.18390792050409835\n",
      "validation loss: 16.70879776226157\n",
      "loss difference:\n",
      "0.00028050927366207734\n",
      "epoch: 894\n",
      "training loss: 0.18362804082866493\n",
      "validation loss: 16.71535635523602\n",
      "loss difference:\n",
      "0.0002798796754334143\n",
      "epoch: 895\n",
      "training loss: 0.18334878887511502\n",
      "validation loss: 16.721908412213264\n",
      "loss difference:\n",
      "0.00027925195354991383\n",
      "epoch: 896\n",
      "training loss: 0.18307016278016294\n",
      "validation loss: 16.728453909811\n",
      "loss difference:\n",
      "0.000278626094952078\n",
      "epoch: 897\n",
      "training loss: 0.182792160693516\n",
      "validation loss: 16.734992824807257\n",
      "loss difference:\n",
      "0.00027800208664693904\n",
      "epoch: 898\n",
      "training loss: 0.18251478077780228\n",
      "validation loss: 16.741525134141426\n",
      "loss difference:\n",
      "0.00027737991571372134\n",
      "epoch: 899\n",
      "training loss: 0.1822380212084981\n",
      "validation loss: 16.74805081491503\n",
      "loss difference:\n",
      "0.00027675956930417467\n",
      "epoch: 900\n",
      "training loss: 0.18196188017385503\n",
      "validation loss: 16.754569844392766\n",
      "loss difference:\n",
      "0.0002761410346430737\n",
      "epoch: 901\n",
      "training loss: 0.1816863558748257\n",
      "validation loss: 16.761082200003326\n",
      "loss difference:\n",
      "0.0002755242990293283\n",
      "epoch: 902\n",
      "training loss: 0.1814114465249903\n",
      "validation loss: 16.767587859340395\n",
      "loss difference:\n",
      "0.0002749093498354005\n",
      "epoch: 903\n",
      "training loss: 0.18113715035047562\n",
      "validation loss: 16.774086800163413\n",
      "loss difference:\n",
      "0.0002742961745146877\n",
      "epoch: 904\n",
      "training loss: 0.18086346558988098\n",
      "validation loss: 16.780579000398443\n",
      "loss difference:\n",
      "0.0002736847605946391\n",
      "epoch: 905\n",
      "training loss: 0.18059039049419798\n",
      "validation loss: 16.78706443813907\n",
      "loss difference:\n",
      "0.0002730750956830008\n",
      "epoch: 906\n",
      "training loss: 0.1803179233267291\n",
      "validation loss: 16.79354309164723\n",
      "loss difference:\n",
      "0.00027246716746887056\n",
      "epoch: 907\n",
      "training loss: 0.1800460623630075\n",
      "validation loss: 16.800014939353968\n",
      "loss difference:\n",
      "0.00027186096372161517\n",
      "epoch: 908\n",
      "training loss: 0.17977480589071512\n",
      "validation loss: 16.806479959860294\n",
      "loss difference:\n",
      "0.0002712564722923694\n",
      "epoch: 909\n",
      "training loss: 0.17950415220959606\n",
      "validation loss: 16.81293813193789\n",
      "loss difference:\n",
      "0.00027065368111905963\n",
      "epoch: 910\n",
      "training loss: 0.1792340996313735\n",
      "validation loss: 16.81938943453\n",
      "loss difference:\n",
      "0.0002700525782225738\n",
      "epoch: 911\n",
      "training loss: 0.17896464647966398\n",
      "validation loss: 16.82583384675208\n",
      "loss difference:\n",
      "0.0002694531517095089\n",
      "epoch: 912\n",
      "training loss: 0.17869579108988817\n",
      "validation loss: 16.832271347892586\n",
      "loss difference:\n",
      "0.00026885538977580725\n",
      "epoch: 913\n",
      "training loss: 0.1784275318091835\n",
      "validation loss: 16.838701917413665\n",
      "loss difference:\n",
      "0.00026825928070467464\n",
      "epoch: 914\n",
      "training loss: 0.17815986699631364\n",
      "validation loss: 16.845125534951837\n",
      "loss difference:\n",
      "0.00026766481286985555\n",
      "epoch: 915\n",
      "training loss: 0.17789279502157848\n",
      "validation loss: 16.851542180318795\n",
      "loss difference:\n",
      "0.0002670719747351613\n",
      "epoch: 916\n",
      "training loss: 0.1776263142667205\n",
      "validation loss: 16.8579518335019\n",
      "loss difference:\n",
      "0.00026648075485799505\n",
      "epoch: 917\n",
      "training loss: 0.17736042312483272\n",
      "validation loss: 16.864354474664975\n",
      "loss difference:\n",
      "0.00026589114188776963\n",
      "epoch: 918\n",
      "training loss: 0.17709512000026398\n",
      "validation loss: 16.870750084148852\n",
      "loss difference:\n",
      "0.0002653031245687387\n",
      "epoch: 919\n",
      "training loss: 0.17683040330852345\n",
      "validation loss: 16.877138642472044\n",
      "loss difference:\n",
      "0.00026471669174052415\n",
      "epoch: 920\n",
      "training loss: 0.1765662714761825\n",
      "validation loss: 16.883520130331252\n",
      "loss difference:\n",
      "0.00026413183234094695\n",
      "epoch: 921\n",
      "training loss: 0.1763027229407796\n",
      "validation loss: 16.88989452860205\n",
      "loss difference:\n",
      "0.0002635485354029188\n",
      "epoch: 922\n",
      "training loss: 0.1760397561507196\n",
      "validation loss: 16.896261818339354\n",
      "loss difference:\n",
      "0.000262966790059993\n",
      "epoch: 923\n",
      "training loss: 0.175777369565174\n",
      "validation loss: 16.902621980777965\n",
      "loss difference:\n",
      "0.0002623865855455876\n",
      "epoch: 924\n",
      "training loss: 0.17551556165397977\n",
      "validation loss: 16.90897499733311\n",
      "loss difference:\n",
      "0.00026180791119423397\n",
      "epoch: 925\n",
      "training loss: 0.1752543308975395\n",
      "validation loss: 16.915320849600977\n",
      "loss difference:\n",
      "0.0002612307564402727\n",
      "epoch: 926\n",
      "training loss: 0.1749936757867148\n",
      "validation loss: 16.921659519359068\n",
      "loss difference:\n",
      "0.00026065511082470905\n",
      "epoch: 927\n",
      "training loss: 0.17473359482272555\n",
      "validation loss: 16.92799098856675\n",
      "loss difference:\n",
      "0.0002600809639892454\n",
      "epoch: 928\n",
      "training loss: 0.17447408651704302\n",
      "validation loss: 16.934315239365645\n",
      "loss difference:\n",
      "0.0002595083056825265\n",
      "epoch: 929\n",
      "training loss: 0.1742151493912842\n",
      "validation loss: 16.940632254080032\n",
      "loss difference:\n",
      "0.0002589371257588069\n",
      "epoch: 930\n",
      "training loss: 0.1739567819771066\n",
      "validation loss: 16.946942015217296\n",
      "loss difference:\n",
      "0.0002583674141776182\n",
      "epoch: 931\n",
      "training loss: 0.17369898281609855\n",
      "validation loss: 16.95324450546814\n",
      "loss difference:\n",
      "0.00025779916100804323\n",
      "epoch: 932\n",
      "training loss: 0.17344175045967164\n",
      "validation loss: 16.959539707707126\n",
      "loss difference:\n",
      "0.0002572323564269119\n",
      "epoch: 933\n",
      "training loss: 0.17318508346895167\n",
      "validation loss: 16.9658276049928\n",
      "loss difference:\n",
      "0.000256666990719967\n",
      "epoch: 934\n",
      "training loss: 0.17292898041466748\n",
      "validation loss: 16.972108180568103\n",
      "loss difference:\n",
      "0.0002561030542841958\n",
      "epoch: 935\n",
      "training loss: 0.17267343987704112\n",
      "validation loss: 16.978381417860618\n",
      "loss difference:\n",
      "0.00025554053762635864\n",
      "epoch: 936\n",
      "training loss: 0.17241846044567585\n",
      "validation loss: 16.98464730048277\n",
      "loss difference:\n",
      "0.00025497943136526535\n",
      "epoch: 937\n",
      "training loss: 0.17216404071944277\n",
      "validation loss: 16.990905812232125\n",
      "loss difference:\n",
      "0.0002544197262330794\n",
      "epoch: 938\n",
      "training loss: 0.17191017930636915\n",
      "validation loss: 16.99715693709149\n",
      "loss difference:\n",
      "0.000253861413073625\n",
      "epoch: 939\n",
      "training loss: 0.1716568748235253\n",
      "validation loss: 17.003400659229147\n",
      "loss difference:\n",
      "0.000253304482843858\n",
      "epoch: 940\n",
      "training loss: 0.17140412589690782\n",
      "validation loss: 17.00963696299901\n",
      "loss difference:\n",
      "0.0002527489266174743\n",
      "epoch: 941\n",
      "training loss: 0.17115193116132682\n",
      "validation loss: 17.01586583294063\n",
      "loss difference:\n",
      "0.00025219473558099614\n",
      "epoch: 942\n",
      "training loss: 0.17090028926028994\n",
      "validation loss: 17.022087253779507\n",
      "loss difference:\n",
      "0.0002516419010368809\n",
      "epoch: 943\n",
      "training loss: 0.1706491988458867\n",
      "validation loss: 17.028301210426893\n",
      "loss difference:\n",
      "0.0002510904144032433\n",
      "epoch: 944\n",
      "training loss: 0.17039865857867234\n",
      "validation loss: 17.03450768798006\n",
      "loss difference:\n",
      "0.0002505402672143553\n",
      "epoch: 945\n",
      "training loss: 0.17014866712754997\n",
      "validation loss: 17.04070667172216\n",
      "loss difference:\n",
      "0.00024999145112236665\n",
      "epoch: 946\n",
      "training loss: 0.16989922316965522\n",
      "validation loss: 17.046898147122306\n",
      "loss difference:\n",
      "0.0002494439578947516\n",
      "epoch: 947\n",
      "training loss: 0.1696503253902376\n",
      "validation loss: 17.053082099835486\n",
      "loss difference:\n",
      "0.0002488977794176117\n",
      "epoch: 948\n",
      "training loss: 0.16940197248254282\n",
      "validation loss: 17.05925851570254\n",
      "loss difference:\n",
      "0.0002483529076947877\n",
      "epoch: 949\n",
      "training loss: 0.16915416314769618\n",
      "validation loss: 17.06542738075002\n",
      "loss difference:\n",
      "0.00024780933484663814\n",
      "epoch: 950\n",
      "training loss: 0.16890689609458218\n",
      "validation loss: 17.071588681190086\n",
      "loss difference:\n",
      "0.00024726705311400865\n",
      "epoch: 951\n",
      "training loss: 0.16866017003972852\n",
      "validation loss: 17.077742403420377\n",
      "loss difference:\n",
      "0.00024672605485365207\n",
      "epoch: 952\n",
      "training loss: 0.16841398370718547\n",
      "validation loss: 17.083888534023828\n",
      "loss difference:\n",
      "0.000246186332543058\n",
      "epoch: 953\n",
      "training loss: 0.16816833582840876\n",
      "validation loss: 17.09002705976846\n",
      "loss difference:\n",
      "0.0002456478787767058\n",
      "epoch: 954\n",
      "training loss: 0.167923225142141\n",
      "validation loss: 17.096157967607134\n",
      "loss difference:\n",
      "0.00024511068626775767\n",
      "epoch: 955\n",
      "training loss: 0.16767865039429225\n",
      "validation loss: 17.102281244677354\n",
      "loss difference:\n",
      "0.00024457474784875255\n",
      "epoch: 956\n",
      "training loss: 0.1674346103378216\n",
      "validation loss: 17.108396878300923\n",
      "loss difference:\n",
      "0.0002440400564706624\n",
      "epoch: 957\n",
      "training loss: 0.16719110373261997\n",
      "validation loss: 17.114504855983633\n",
      "loss difference:\n",
      "0.0002435066052016155\n",
      "epoch: 958\n",
      "training loss: 0.1669481293453902\n",
      "validation loss: 17.120605165414965\n",
      "loss difference:\n",
      "0.00024297438722978293\n",
      "epoch: 959\n",
      "training loss: 0.16670568594952967\n",
      "validation loss: 17.126697794467702\n",
      "loss difference:\n",
      "0.00024244339586051988\n",
      "epoch: 960\n",
      "training loss: 0.166463772325012\n",
      "validation loss: 17.13278273119748\n",
      "loss difference:\n",
      "0.00024191362451767007\n",
      "epoch: 961\n",
      "training loss: 0.16622238725827068\n",
      "validation loss: 17.138859963842425\n",
      "loss difference:\n",
      "0.00024138506674131754\n",
      "epoch: 962\n",
      "training loss: 0.165981529542079\n",
      "validation loss: 17.144929480822718\n",
      "loss difference:\n",
      "0.0002408577161916725\n",
      "epoch: 963\n",
      "training loss: 0.16574119797543643\n",
      "validation loss: 17.150991270740047\n",
      "loss difference:\n",
      "0.0002403315666425765\n",
      "epoch: 964\n",
      "training loss: 0.16550139136344974\n",
      "validation loss: 17.157045322377108\n",
      "loss difference:\n",
      "0.00023980661198669262\n",
      "epoch: 965\n",
      "training loss: 0.1652621085172175\n",
      "validation loss: 17.163091624697152\n",
      "loss difference:\n",
      "0.0002392828462322305\n",
      "epoch: 966\n",
      "training loss: 0.16502334825371362\n",
      "validation loss: 17.169130166843296\n",
      "loss difference:\n",
      "0.0002387602635038899\n",
      "epoch: 967\n",
      "training loss: 0.1647851093956747\n",
      "validation loss: 17.17516093813802\n",
      "loss difference:\n",
      "0.00023823885803891942\n",
      "epoch: 968\n",
      "training loss: 0.1645473907714819\n",
      "validation loss: 17.181183928082547\n",
      "loss difference:\n",
      "0.00023771862419280643\n",
      "epoch: 969\n",
      "training loss: 0.16431019121504947\n",
      "validation loss: 17.187199126356138\n",
      "loss difference:\n",
      "0.0002371995564324214\n",
      "epoch: 970\n",
      "training loss: 0.16407350956571057\n",
      "validation loss: 17.193206522815487\n",
      "loss difference:\n",
      "0.00023668164933890457\n",
      "epoch: 971\n",
      "training loss: 0.1638373446681048\n",
      "validation loss: 17.19920610749393\n",
      "loss difference:\n",
      "0.0002361648976057784\n",
      "epoch: 972\n",
      "training loss: 0.1636016953720656\n",
      "validation loss: 17.20519787060085\n",
      "loss difference:\n",
      "0.0002356492960391976\n",
      "epoch: 973\n",
      "training loss: 0.1633665605325101\n",
      "validation loss: 17.211181802520798\n",
      "loss difference:\n",
      "0.00023513483955547865\n",
      "epoch: 974\n",
      "training loss: 0.16313193900932912\n",
      "validation loss: 17.217157893812796\n",
      "loss difference:\n",
      "0.00023462152318098894\n",
      "epoch: 975\n",
      "training loss: 0.16289782966727556\n",
      "validation loss: 17.223126135209505\n",
      "loss difference:\n",
      "0.00023410934205356226\n",
      "epoch: 976\n",
      "training loss: 0.16266423137585662\n",
      "validation loss: 17.229086517616356\n",
      "loss difference:\n",
      "0.00023359829141894606\n",
      "epoch: 977\n",
      "training loss: 0.16243114300922787\n",
      "validation loss: 17.235039032110766\n",
      "loss difference:\n",
      "0.00023308836662874755\n",
      "epoch: 978\n",
      "training loss: 0.16219856344608555\n",
      "validation loss: 17.240983669941205\n",
      "loss difference:\n",
      "0.0002325795631423211\n",
      "epoch: 979\n",
      "training loss: 0.16196649156955903\n",
      "validation loss: 17.24692042252631\n",
      "loss difference:\n",
      "0.0002320718765265184\n",
      "epoch: 980\n",
      "training loss: 0.16173492626710717\n",
      "validation loss: 17.252849281453955\n",
      "loss difference:\n",
      "0.00023156530245185825\n",
      "epoch: 981\n",
      "training loss: 0.16150386643041695\n",
      "validation loss: 17.258770238480295\n",
      "loss difference:\n",
      "0.00023105983669022279\n",
      "epoch: 982\n",
      "training loss: 0.1612733109552961\n",
      "validation loss: 17.264683285528793\n",
      "loss difference:\n",
      "0.00023055547512085273\n",
      "epoch: 983\n",
      "training loss: 0.16104325874157768\n",
      "validation loss: 17.270588414689186\n",
      "loss difference:\n",
      "0.00023005221371841245\n",
      "epoch: 984\n",
      "training loss: 0.16081370869301326\n",
      "validation loss: 17.27648561821653\n",
      "loss difference:\n",
      "0.0002295500485644253\n",
      "epoch: 985\n",
      "training loss: 0.16058465971717845\n",
      "validation loss: 17.282374888530057\n",
      "loss difference:\n",
      "0.00022904897583481132\n",
      "epoch: 986\n",
      "training loss: 0.160356110725374\n",
      "validation loss: 17.2882562182122\n",
      "loss difference:\n",
      "0.00022854899180443922\n",
      "epoch: 987\n",
      "training loss: 0.16012806063252732\n",
      "validation loss: 17.29412960000747\n",
      "loss difference:\n",
      "0.0002280500928466822\n",
      "epoch: 988\n",
      "training loss: 0.15990050835709896\n",
      "validation loss: 17.299995026821307\n",
      "loss difference:\n",
      "0.00022755227542836653\n",
      "epoch: 989\n",
      "training loss: 0.1596734528209894\n",
      "validation loss: 17.30585249171901\n",
      "loss difference:\n",
      "0.00022705553610954943\n",
      "epoch: 990\n",
      "training loss: 0.15944689294944134\n",
      "validation loss: 17.31170198792455\n",
      "loss difference:\n",
      "0.000226559871548071\n",
      "epoch: 991\n",
      "training loss: 0.15922082767095483\n",
      "validation loss: 17.31754350881938\n",
      "loss difference:\n",
      "0.00022606527848650915\n",
      "epoch: 992\n",
      "training loss: 0.15899525591719257\n",
      "validation loss: 17.32337704794134\n",
      "loss difference:\n",
      "0.0002255717537622548\n",
      "epoch: 993\n",
      "training loss: 0.1587701766228924\n",
      "validation loss: 17.32920259898328\n",
      "loss difference:\n",
      "0.00022507929430018447\n",
      "epoch: 994\n",
      "training loss: 0.15854558872578103\n",
      "validation loss: 17.335020155792016\n",
      "loss difference:\n",
      "0.00022458789711135574\n",
      "epoch: 995\n",
      "training loss: 0.1583214911664865\n",
      "validation loss: 17.340829712366936\n",
      "loss difference:\n",
      "0.0002240975592945338\n",
      "epoch: 996\n",
      "training loss: 0.15809788288845522\n",
      "validation loss: 17.346631262858867\n",
      "loss difference:\n",
      "0.0002236082780312787\n",
      "epoch: 997\n",
      "training loss: 0.15787476283786736\n",
      "validation loss: 17.35242480156869\n",
      "loss difference:\n",
      "0.00022312005058786055\n",
      "epoch: 998\n",
      "training loss: 0.15765212996355726\n",
      "validation loss: 17.358210322946096\n",
      "loss difference:\n",
      "0.00022263287431009693\n",
      "epoch: 999\n",
      "training loss: 0.15742998321693152\n",
      "validation loss: 17.363987821588278\n",
      "loss difference:\n",
      "0.00022214674662573985\n",
      "epoch: 1000\n",
      "training loss: 0.15720832155189235\n",
      "validation loss: 17.369757292238585\n",
      "loss difference:\n",
      "0.0002216616650391745\n",
      "epoch: 1001\n",
      "training loss: 0.156987143924759\n",
      "validation loss: 17.375518729785238\n",
      "loss difference:\n",
      "0.0002211776271333621\n",
      "epoch: 1002\n",
      "training loss: 0.1567664492941925\n",
      "validation loss: 17.381272129259887\n",
      "loss difference:\n",
      "0.00022069463056648142\n",
      "epoch: 1003\n",
      "training loss: 0.15654623662112227\n",
      "validation loss: 17.387017485836367\n",
      "loss difference:\n",
      "0.00022021267307023584\n",
      "epoch: 1004\n",
      "training loss: 0.1563265048686739\n",
      "validation loss: 17.392754794829177\n",
      "loss difference:\n",
      "0.00021973175244838217\n",
      "epoch: 1005\n",
      "training loss: 0.156107253002098\n",
      "validation loss: 17.39848405169225\n",
      "loss difference:\n",
      "0.000219251866575898\n",
      "epoch: 1006\n",
      "training loss: 0.15588847998869945\n",
      "validation loss: 17.404205252017412\n",
      "loss difference:\n",
      "0.00021877301339853772\n",
      "epoch: 1007\n",
      "training loss: 0.15567018479777284\n",
      "validation loss: 17.409918391533115\n",
      "loss difference:\n",
      "0.0002182951909266151\n",
      "epoch: 1008\n",
      "training loss: 0.15545236640053317\n",
      "validation loss: 17.415623466102847\n",
      "loss difference:\n",
      "0.00021781839723966634\n",
      "epoch: 1009\n",
      "training loss: 0.15523502377005302\n",
      "validation loss: 17.42132047172387\n",
      "loss difference:\n",
      "0.00021734263048014957\n",
      "epoch: 1010\n",
      "training loss: 0.15501815588119844\n",
      "validation loss: 17.427009404525688\n",
      "loss difference:\n",
      "0.00021686788885458275\n",
      "epoch: 1011\n",
      "training loss: 0.15480176171056897\n",
      "validation loss: 17.432690260768616\n",
      "loss difference:\n",
      "0.00021639417062946364\n",
      "epoch: 1012\n",
      "training loss: 0.15458584023643668\n",
      "validation loss: 17.438363036842354\n",
      "loss difference:\n",
      "0.0002159214741322968\n",
      "epoch: 1013\n",
      "training loss: 0.1543703904386874\n",
      "validation loss: 17.444027729264526\n",
      "loss difference:\n",
      "0.00021544979774928974\n",
      "epoch: 1014\n",
      "training loss: 0.15415541129876495\n",
      "validation loss: 17.44968433467921\n",
      "loss difference:\n",
      "0.00021497913992243878\n",
      "epoch: 1015\n",
      "training loss: 0.15394090179961634\n",
      "validation loss: 17.45533284985544\n",
      "loss difference:\n",
      "0.00021450949914861295\n",
      "epoch: 1016\n",
      "training loss: 0.15372686092563667\n",
      "validation loss: 17.460973271685777\n",
      "loss difference:\n",
      "0.0002140408739796651\n",
      "epoch: 1017\n",
      "training loss: 0.15351328766261776\n",
      "validation loss: 17.466605597184817\n",
      "loss difference:\n",
      "0.0002135732630189069\n",
      "epoch: 1018\n",
      "training loss: 0.15330018099769796\n",
      "validation loss: 17.472229823487716\n",
      "loss difference:\n",
      "0.00021310666491980435\n",
      "epoch: 1019\n",
      "training loss: 0.15308753991931331\n",
      "validation loss: 17.477845947848696\n",
      "loss difference:\n",
      "0.00021264107838464552\n",
      "epoch: 1020\n",
      "training loss: 0.1528753634171498\n",
      "validation loss: 17.483453967639555\n",
      "loss difference:\n",
      "0.00021217650216351358\n",
      "epoch: 1021\n",
      "training loss: 0.15266365048209649\n",
      "validation loss: 17.489053880348205\n",
      "loss difference:\n",
      "0.00021171293505331534\n",
      "epoch: 1022\n",
      "training loss: 0.15245240010620298\n",
      "validation loss: 17.494645683577165\n",
      "loss difference:\n",
      "0.00021125037589350693\n",
      "epoch: 1023\n",
      "training loss: 0.15224161128263525\n",
      "validation loss: 17.50022937504209\n",
      "loss difference:\n",
      "0.00021078882356773132\n",
      "epoch: 1024\n",
      "training loss: 0.15203128300563487\n",
      "validation loss: 17.50580495257026\n",
      "loss difference:\n",
      "0.0002103282770003767\n",
      "epoch: 1025\n",
      "training loss: 0.15182141427047893\n",
      "validation loss: 17.511372414099117\n",
      "loss difference:\n",
      "0.00020986873515593807\n",
      "epoch: 1026\n",
      "training loss: 0.15161200407344122\n",
      "validation loss: 17.51693175767479\n",
      "loss difference:\n",
      "0.0002094101970377127\n",
      "epoch: 1027\n",
      "training loss: 0.15140305141175558\n",
      "validation loss: 17.522482981450533\n",
      "loss difference:\n",
      "0.0002089526616856352\n",
      "epoch: 1028\n",
      "training loss: 0.15119455528358092\n",
      "validation loss: 17.528026083685422\n",
      "loss difference:\n",
      "0.00020849612817466778\n",
      "epoch: 1029\n",
      "training loss: 0.15098651468796578\n",
      "validation loss: 17.533561062742635\n",
      "loss difference:\n",
      "0.00020804059561513322\n",
      "epoch: 1030\n",
      "training loss: 0.15077892862481748\n",
      "validation loss: 17.53908791708822\n",
      "loss difference:\n",
      "0.00020758606314830175\n",
      "epoch: 1031\n",
      "training loss: 0.15057179609486904\n",
      "validation loss: 17.544606645289463\n",
      "loss difference:\n",
      "0.000207132529948445\n",
      "epoch: 1032\n",
      "training loss: 0.15036511609965048\n",
      "validation loss: 17.550117246013528\n",
      "loss difference:\n",
      "0.00020667999521856162\n",
      "epoch: 1033\n",
      "training loss: 0.1501588876414589\n",
      "validation loss: 17.555619718025902\n",
      "loss difference:\n",
      "0.00020622845819157076\n",
      "epoch: 1034\n",
      "training loss: 0.14995310972333323\n",
      "validation loss: 17.56111406018905\n",
      "loss difference:\n",
      "0.00020577791812567692\n",
      "epoch: 1035\n",
      "training loss: 0.14974778134902764\n",
      "validation loss: 17.5666002714609\n",
      "loss difference:\n",
      "0.00020532837430559114\n",
      "epoch: 1036\n",
      "training loss: 0.14954290152298458\n",
      "validation loss: 17.572078350893467\n",
      "loss difference:\n",
      "0.00020487982604305843\n",
      "epoch: 1037\n",
      "training loss: 0.14933846925031544\n",
      "validation loss: 17.5775482976313\n",
      "loss difference:\n",
      "0.00020443227266914166\n",
      "epoch: 1038\n",
      "training loss: 0.1491344835367765\n",
      "validation loss: 17.583010110910248\n",
      "loss difference:\n",
      "0.00020398571353894002\n",
      "epoch: 1039\n",
      "training loss: 0.14893094338874674\n",
      "validation loss: 17.588463790055872\n",
      "loss difference:\n",
      "0.00020354014802975717\n",
      "epoch: 1040\n",
      "training loss: 0.14872784781321263\n",
      "validation loss: 17.593909334482195\n",
      "loss difference:\n",
      "0.00020309557553410684\n",
      "epoch: 1041\n",
      "training loss: 0.14852519581774348\n",
      "validation loss: 17.599346743690152\n",
      "loss difference:\n",
      "0.0002026519954691497\n",
      "epoch: 1042\n",
      "training loss: 0.14832298641048053\n",
      "validation loss: 17.60477601726638\n",
      "loss difference:\n",
      "0.00020220940726295433\n",
      "epoch: 1043\n",
      "training loss: 0.14812121860011743\n",
      "validation loss: 17.61019715488167\n",
      "loss difference:\n",
      "0.00020176781036310154\n",
      "epoch: 1044\n",
      "training loss: 0.14791989139588613\n",
      "validation loss: 17.615610156289744\n",
      "loss difference:\n",
      "0.00020132720423129968\n",
      "epoch: 1045\n",
      "training loss: 0.14771900380754277\n",
      "validation loss: 17.62101502132586\n",
      "loss difference:\n",
      "0.00020088758834335696\n",
      "epoch: 1046\n",
      "training loss: 0.1475185548453562\n",
      "validation loss: 17.626411749905422\n",
      "loss difference:\n",
      "0.00020044896218657238\n",
      "epoch: 1047\n",
      "training loss: 0.14731854352009602\n",
      "validation loss: 17.63180034202276\n",
      "loss difference:\n",
      "0.00020001132526017984\n",
      "epoch: 1048\n",
      "training loss: 0.14711896884302073\n",
      "validation loss: 17.6371807977497\n",
      "loss difference:\n",
      "0.00019957467707529264\n",
      "epoch: 1049\n",
      "training loss: 0.1469198298258702\n",
      "validation loss: 17.642553117234353\n",
      "loss difference:\n",
      "0.00019913901715051807\n",
      "epoch: 1050\n",
      "training loss: 0.14672112548085572\n",
      "validation loss: 17.647917300699806\n",
      "loss difference:\n",
      "0.0001987043450144832\n",
      "epoch: 1051\n",
      "training loss: 0.14652285482065405\n",
      "validation loss: 17.653273348442788\n",
      "loss difference:\n",
      "0.0001982706602016715\n",
      "epoch: 1052\n",
      "training loss: 0.14632501685839971\n",
      "validation loss: 17.658621260832483\n",
      "loss difference:\n",
      "0.00019783796225433803\n",
      "epoch: 1053\n",
      "training loss: 0.14612761060767868\n",
      "validation loss: 17.663961038309274\n",
      "loss difference:\n",
      "0.00019740625072103835\n",
      "epoch: 1054\n",
      "training loss: 0.14593063508252688\n",
      "validation loss: 17.669292681383478\n",
      "loss difference:\n",
      "0.00019697552515179906\n",
      "epoch: 1055\n",
      "training loss: 0.145734089297422\n",
      "validation loss: 17.674616190634158\n",
      "loss difference:\n",
      "0.00019654578510489018\n",
      "epoch: 1056\n",
      "training loss: 0.14553797226728518\n",
      "validation loss: 17.679931566707904\n",
      "loss difference:\n",
      "0.00019611703013680537\n",
      "epoch: 1057\n",
      "training loss: 0.1453422830074754\n",
      "validation loss: 17.68523881031762\n",
      "loss difference:\n",
      "0.0001956892598097837\n",
      "epoch: 1058\n",
      "training loss: 0.14514702053378994\n",
      "validation loss: 17.690537922241454\n",
      "loss difference:\n",
      "0.00019526247368545357\n",
      "epoch: 1059\n",
      "training loss: 0.1449521838624641\n",
      "validation loss: 17.695828903321544\n",
      "loss difference:\n",
      "0.00019483667132583204\n",
      "epoch: 1060\n",
      "training loss: 0.14475777201017048\n",
      "validation loss: 17.701111754462868\n",
      "loss difference:\n",
      "0.00019441185229363\n",
      "epoch: 1061\n",
      "training loss: 0.14456378399402142\n",
      "validation loss: 17.706386476632233\n",
      "loss difference:\n",
      "0.00019398801614906036\n",
      "epoch: 1062\n",
      "training loss: 0.14437021883156997\n",
      "validation loss: 17.71165307085705\n",
      "loss difference:\n",
      "0.00019356516245144784\n",
      "epoch: 1063\n",
      "training loss: 0.1441770755408131\n",
      "validation loss: 17.716911538224277\n",
      "loss difference:\n",
      "0.00019314329075686976\n",
      "epoch: 1064\n",
      "training loss: 0.14398435314019387\n",
      "validation loss: 17.722161879879373\n",
      "loss difference:\n",
      "0.0001927224006192385\n",
      "epoch: 1065\n",
      "training loss: 0.1437920506486072\n",
      "validation loss: 17.72740409702527\n",
      "loss difference:\n",
      "0.00019230249158666557\n",
      "epoch: 1066\n",
      "training loss: 0.14360016708540177\n",
      "validation loss: 17.73263819092119\n",
      "loss difference:\n",
      "0.00019188356320543054\n",
      "epoch: 1067\n",
      "training loss: 0.14340870147038975\n",
      "validation loss: 17.73786416288182\n",
      "loss difference:\n",
      "0.0001914656150120153\n",
      "epoch: 1068\n",
      "training loss: 0.1432176528238463\n",
      "validation loss: 17.7430820142761\n",
      "loss difference:\n",
      "0.00019104864654345688\n",
      "epoch: 1069\n",
      "training loss: 0.14302702016652297\n",
      "validation loss: 17.748291746526476\n",
      "loss difference:\n",
      "0.0001906326573233308\n",
      "epoch: 1070\n",
      "training loss: 0.14283680251964861\n",
      "validation loss: 17.753493361107665\n",
      "loss difference:\n",
      "0.00019021764687435216\n",
      "epoch: 1071\n",
      "training loss: 0.14264699890493998\n",
      "validation loss: 17.758686859545858\n",
      "loss difference:\n",
      "0.0001898036147086335\n",
      "epoch: 1072\n",
      "training loss: 0.14245760834461074\n",
      "validation loss: 17.763872243417786\n",
      "loss difference:\n",
      "0.00018939056032923896\n",
      "epoch: 1073\n",
      "training loss: 0.14226862986137676\n",
      "validation loss: 17.769049514349746\n",
      "loss difference:\n",
      "0.00018897848323398692\n",
      "epoch: 1074\n",
      "training loss: 0.1420800624784682\n",
      "validation loss: 17.774218674016716\n",
      "loss difference:\n",
      "0.00018856738290856656\n",
      "epoch: 1075\n",
      "training loss: 0.1418919052196368\n",
      "validation loss: 17.779379724141467\n",
      "loss difference:\n",
      "0.0001881572588313951\n",
      "epoch: 1076\n",
      "training loss: 0.14170415710916726\n",
      "validation loss: 17.784532666493764\n",
      "loss difference:\n",
      "0.00018774811046953777\n",
      "epoch: 1077\n",
      "training loss: 0.14151681717188694\n",
      "validation loss: 17.789677502889358\n",
      "loss difference:\n",
      "0.0001873399372803175\n",
      "epoch: 1078\n",
      "training loss: 0.14132988443317707\n",
      "validation loss: 17.794814235189293\n",
      "loss difference:\n",
      "0.00018693273870987182\n",
      "epoch: 1079\n",
      "training loss: 0.14114335791898347\n",
      "validation loss: 17.79994286529911\n",
      "loss difference:\n",
      "0.00018652651419359678\n",
      "epoch: 1080\n",
      "training loss: 0.14095723665582832\n",
      "validation loss: 17.805063395167917\n",
      "loss difference:\n",
      "0.00018612126315514788\n",
      "epoch: 1081\n",
      "training loss: 0.140771519670822\n",
      "validation loss: 17.810175826787745\n",
      "loss difference:\n",
      "0.00018571698500632894\n",
      "epoch: 1082\n",
      "training loss: 0.14058620599167543\n",
      "validation loss: 17.815280162192675\n",
      "loss difference:\n",
      "0.00018531367914656482\n",
      "epoch: 1083\n",
      "training loss: 0.14040129464671183\n",
      "validation loss: 17.820376403458205\n",
      "loss difference:\n",
      "0.0001849113449635953\n",
      "epoch: 1084\n",
      "training loss: 0.14021678466488055\n",
      "validation loss: 17.825464552700435\n",
      "loss difference:\n",
      "0.0001845099818312823\n",
      "epoch: 1085\n",
      "training loss: 0.14003267507577058\n",
      "validation loss: 17.83054461207539\n",
      "loss difference:\n",
      "0.00018410958910997088\n",
      "epoch: 1086\n",
      "training loss: 0.13984896490962168\n",
      "validation loss: 17.835616583778357\n",
      "loss difference:\n",
      "0.00018371016614890379\n",
      "epoch: 1087\n",
      "training loss: 0.13966565319734056\n",
      "validation loss: 17.84068047004316\n",
      "loss difference:\n",
      "0.00018331171228111454\n",
      "epoch: 1088\n",
      "training loss: 0.1394827389705142\n",
      "validation loss: 17.845736273141547\n",
      "loss difference:\n",
      "0.00018291422682636949\n",
      "epoch: 1089\n",
      "training loss: 0.13930022126142208\n",
      "validation loss: 17.85078399538248\n",
      "loss difference:\n",
      "0.0001825177090921115\n",
      "epoch: 1090\n",
      "training loss: 0.13911809910305314\n",
      "validation loss: 17.855823639111623\n",
      "loss difference:\n",
      "0.00018212215836893586\n",
      "epoch: 1091\n",
      "training loss: 0.13893637152911817\n",
      "validation loss: 17.86085520671065\n",
      "loss difference:\n",
      "0.00018172757393497552\n",
      "epoch: 1092\n",
      "training loss: 0.1387550375740656\n",
      "validation loss: 17.86587870059665\n",
      "loss difference:\n",
      "0.00018133395505257055\n",
      "epoch: 1093\n",
      "training loss: 0.1385740962730966\n",
      "validation loss: 17.87089412322162\n",
      "loss difference:\n",
      "0.00018094130096898975\n",
      "epoch: 1094\n",
      "training loss: 0.13839354666217943\n",
      "validation loss: 17.875901477071835\n",
      "loss difference:\n",
      "0.00018054961091718003\n",
      "epoch: 1095\n",
      "training loss: 0.1382133877780635\n",
      "validation loss: 17.880900764667388\n",
      "loss difference:\n",
      "0.00018015888411593295\n",
      "epoch: 1096\n",
      "training loss: 0.13803361865829794\n",
      "validation loss: 17.885891988561568\n",
      "loss difference:\n",
      "0.00017976911976555487\n",
      "epoch: 1097\n",
      "training loss: 0.13785423834124325\n",
      "validation loss: 17.890875151340406\n",
      "loss difference:\n",
      "0.00017938031705469482\n",
      "epoch: 1098\n",
      "training loss: 0.13767524586608887\n",
      "validation loss: 17.895850255622232\n",
      "loss difference:\n",
      "0.000178992475154377\n",
      "epoch: 1099\n",
      "training loss: 0.13749664027286898\n",
      "validation loss: 17.900817304057053\n",
      "loss difference:\n",
      "0.00017860559321988823\n",
      "epoch: 1100\n",
      "training loss: 0.13731842060247695\n",
      "validation loss: 17.90577629932624\n",
      "loss difference:\n",
      "0.0001782196703920269\n",
      "epoch: 1101\n",
      "training loss: 0.13714058589668165\n",
      "validation loss: 17.910727244142016\n",
      "loss difference:\n",
      "0.00017783470579529892\n",
      "epoch: 1102\n",
      "training loss: 0.13696313519814207\n",
      "validation loss: 17.915670141246995\n",
      "loss difference:\n",
      "0.00017745069853958295\n",
      "epoch: 1103\n",
      "training loss: 0.13678606755042688\n",
      "validation loss: 17.920604993413814\n",
      "loss difference:\n",
      "0.00017706764771519\n",
      "epoch: 1104\n",
      "training loss: 0.13660938199802505\n",
      "validation loss: 17.925531803444724\n",
      "loss difference:\n",
      "0.00017668555240182848\n",
      "epoch: 1105\n",
      "training loss: 0.13643307758636553\n",
      "validation loss: 17.93045057417117\n",
      "loss difference:\n",
      "0.00017630441165952804\n",
      "epoch: 1106\n",
      "training loss: 0.136257153361832\n",
      "validation loss: 17.935361308453427\n",
      "loss difference:\n",
      "0.00017592422453352463\n",
      "epoch: 1107\n",
      "training loss: 0.13608160837177766\n",
      "validation loss: 17.940264009180268\n",
      "loss difference:\n",
      "0.00017554499005434376\n",
      "epoch: 1108\n",
      "training loss: 0.13590644166454396\n",
      "validation loss: 17.945158679268612\n",
      "loss difference:\n",
      "0.00017516670723369265\n",
      "epoch: 1109\n",
      "training loss: 0.13573165228947287\n",
      "validation loss: 17.950045321663122\n",
      "loss difference:\n",
      "0.00017478937507109382\n",
      "epoch: 1110\n",
      "training loss: 0.13555723929692567\n",
      "validation loss: 17.954923939336012\n",
      "loss difference:\n",
      "0.000174412992547196\n",
      "epoch: 1111\n",
      "training loss: 0.13538320173829765\n",
      "validation loss: 17.959794535286623\n",
      "loss difference:\n",
      "0.00017403755862802073\n",
      "epoch: 1112\n",
      "training loss: 0.1352095386660333\n",
      "validation loss: 17.96465711254119\n",
      "loss difference:\n",
      "0.00017366307226435174\n",
      "epoch: 1113\n",
      "training loss: 0.135036249133644\n",
      "validation loss: 17.969511674152532\n",
      "loss difference:\n",
      "0.00017328953238929246\n",
      "epoch: 1114\n",
      "training loss: 0.13486333219572155\n",
      "validation loss: 17.974358223199808\n",
      "loss difference:\n",
      "0.0001729169379224571\n",
      "epoch: 1115\n",
      "training loss: 0.13469078690795502\n",
      "validation loss: 17.979196762788273\n",
      "loss difference:\n",
      "0.000172545287766529\n",
      "epoch: 1116\n",
      "training loss: 0.13451861232714613\n",
      "validation loss: 17.984027296049\n",
      "loss difference:\n",
      "0.00017217458080889814\n",
      "epoch: 1117\n",
      "training loss: 0.1343468075112251\n",
      "validation loss: 17.988849826138654\n",
      "loss difference:\n",
      "0.0001718048159210228\n",
      "epoch: 1118\n",
      "training loss: 0.13417537151926553\n",
      "validation loss: 17.99366435623928\n",
      "loss difference:\n",
      "0.0001714359919595676\n",
      "epoch: 1119\n",
      "training loss: 0.13400430341150066\n",
      "validation loss: 17.99847088955811\n",
      "loss difference:\n",
      "0.0001710681077648768\n",
      "epoch: 1120\n",
      "training loss: 0.13383360224933646\n",
      "validation loss: 18.00326942932732\n",
      "loss difference:\n",
      "0.00017070116216419406\n",
      "epoch: 1121\n",
      "training loss: 0.13366326709537038\n",
      "validation loss: 18.008059978803907\n",
      "loss difference:\n",
      "0.00017033515396608356\n",
      "epoch: 1122\n",
      "training loss: 0.13349329701340323\n",
      "validation loss: 18.012842541269446\n",
      "loss difference:\n",
      "0.0001699700819671468\n",
      "epoch: 1123\n",
      "training loss: 0.13332369106845648\n",
      "validation loss: 18.017617120029982\n",
      "loss difference:\n",
      "0.00016960594494674908\n",
      "epoch: 1124\n",
      "training loss: 0.13315444832678514\n",
      "validation loss: 18.022383718415824\n",
      "loss difference:\n",
      "0.00016924274167134934\n",
      "epoch: 1125\n",
      "training loss: 0.132985567855894\n",
      "validation loss: 18.027142339781424\n",
      "loss difference:\n",
      "0.00016888047089114178\n",
      "epoch: 1126\n",
      "training loss: 0.13281704872455224\n",
      "validation loss: 18.031892987505277\n",
      "loss difference:\n",
      "0.0001685191313417489\n",
      "epoch: 1127\n",
      "training loss: 0.13264889000280658\n",
      "validation loss: 18.036635664989745\n",
      "loss difference:\n",
      "0.00016815872174566482\n",
      "epoch: 1128\n",
      "training loss: 0.13248109076199718\n",
      "validation loss: 18.041370375660915\n",
      "loss difference:\n",
      "0.00016779924080939645\n",
      "epoch: 1129\n",
      "training loss: 0.13231365007477283\n",
      "validation loss: 18.04609712296854\n",
      "loss difference:\n",
      "0.00016744068722435168\n",
      "epoch: 1130\n",
      "training loss: 0.13214656701510072\n",
      "validation loss: 18.05081591038599\n",
      "loss difference:\n",
      "0.0001670830596721129\n",
      "epoch: 1131\n",
      "training loss: 0.1319798406582864\n",
      "validation loss: 18.055526741410038\n",
      "loss difference:\n",
      "0.00016672635681430625\n",
      "epoch: 1132\n",
      "training loss: 0.1318134700809834\n",
      "validation loss: 18.06022961956083\n",
      "loss difference:\n",
      "0.00016637057730300997\n",
      "epoch: 1133\n",
      "training loss: 0.1316474543612082\n",
      "validation loss: 18.064924548381885\n",
      "loss difference:\n",
      "0.00016601571977520324\n",
      "epoch: 1134\n",
      "training loss: 0.131481792578355\n",
      "validation loss: 18.06961153143991\n",
      "loss difference:\n",
      "0.00016566178285321032\n",
      "epoch: 1135\n",
      "training loss: 0.13131648381320657\n",
      "validation loss: 18.07429057232481\n",
      "loss difference:\n",
      "0.00016530876514841975\n",
      "epoch: 1136\n",
      "training loss: 0.13115152714795097\n",
      "validation loss: 18.078961674649634\n",
      "loss difference:\n",
      "0.0001649566652555945\n",
      "epoch: 1137\n",
      "training loss: 0.1309869216661913\n",
      "validation loss: 18.08362484205053\n",
      "loss difference:\n",
      "0.00016460548175967205\n",
      "epoch: 1138\n",
      "training loss: 0.13082266645296192\n",
      "validation loss: 18.08828007818663\n",
      "loss difference:\n",
      "0.00016425521322938064\n",
      "epoch: 1139\n",
      "training loss: 0.1306587605947383\n",
      "validation loss: 18.092927386740183\n",
      "loss difference:\n",
      "0.00016390585822362302\n",
      "epoch: 1140\n",
      "training loss: 0.1304952031794518\n",
      "validation loss: 18.097566771416368\n",
      "loss difference:\n",
      "0.00016355741528650825\n",
      "epoch: 1141\n",
      "training loss: 0.13033199329650155\n",
      "validation loss: 18.10219823594337\n",
      "loss difference:\n",
      "0.0001632098829502382\n",
      "epoch: 1142\n",
      "training loss: 0.13016913003676664\n",
      "validation loss: 18.10682178407234\n",
      "loss difference:\n",
      "0.00016286325973491333\n",
      "epoch: 1143\n",
      "training loss: 0.13000661249261816\n",
      "validation loss: 18.11143741957741\n",
      "loss difference:\n",
      "0.0001625175441484772\n",
      "epoch: 1144\n",
      "training loss: 0.1298444397579328\n",
      "validation loss: 18.116045146255647\n",
      "loss difference:\n",
      "0.0001621727346853563\n",
      "epoch: 1145\n",
      "training loss: 0.1296826109281023\n",
      "validation loss: 18.12064496792712\n",
      "loss difference:\n",
      "0.0001618288298305126\n",
      "epoch: 1146\n",
      "training loss: 0.12952112510004726\n",
      "validation loss: 18.125236888434806\n",
      "loss difference:\n",
      "0.0001614858280550302\n",
      "epoch: 1147\n",
      "training loss: 0.1293599813722277\n",
      "validation loss: 18.129820911644806\n",
      "loss difference:\n",
      "0.0001611437278195571\n",
      "epoch: 1148\n",
      "training loss: 0.12919917884465423\n",
      "validation loss: 18.134397041446114\n",
      "loss difference:\n",
      "0.00016080252757347258\n",
      "epoch: 1149\n",
      "training loss: 0.12903871661890087\n",
      "validation loss: 18.138965281750888\n",
      "loss difference:\n",
      "0.00016046222575336055\n",
      "epoch: 1150\n",
      "training loss: 0.12887859379811295\n",
      "validation loss: 18.143525636494232\n",
      "loss difference:\n",
      "0.0001601228207879224\n",
      "epoch: 1151\n",
      "training loss: 0.12871880948702244\n",
      "validation loss: 18.148078109634493\n",
      "loss difference:\n",
      "0.0001597843110905106\n",
      "epoch: 1152\n",
      "training loss: 0.12855936279195407\n",
      "validation loss: 18.15262270515307\n",
      "loss difference:\n",
      "0.0001594466950683715\n",
      "epoch: 1153\n",
      "training loss: 0.1284002528208397\n",
      "validation loss: 18.157159427054587\n",
      "loss difference:\n",
      "0.00015910997111437397\n",
      "epoch: 1154\n",
      "training loss: 0.12824147868322622\n",
      "validation loss: 18.161688279366917\n",
      "loss difference:\n",
      "0.00015877413761347658\n",
      "epoch: 1155\n",
      "training loss: 0.12808303949028682\n",
      "validation loss: 18.16620926614121\n",
      "loss difference:\n",
      "0.0001584391929393969\n",
      "epoch: 1156\n",
      "training loss: 0.12792493435483107\n",
      "validation loss: 18.170722391451964\n",
      "loss difference:\n",
      "0.00015810513545574945\n",
      "epoch: 1157\n",
      "training loss: 0.12776716239131422\n",
      "validation loss: 18.17522765939707\n",
      "loss difference:\n",
      "0.00015777196351685063\n",
      "epoch: 1158\n",
      "training loss: 0.12760972271584792\n",
      "validation loss: 18.179725074097874\n",
      "loss difference:\n",
      "0.00015743967546630322\n",
      "epoch: 1159\n",
      "training loss: 0.1274526144462081\n",
      "validation loss: 18.184214639699263\n",
      "loss difference:\n",
      "0.00015710826963982738\n",
      "epoch: 1160\n",
      "training loss: 0.12729583670184652\n",
      "validation loss: 18.188696360369704\n",
      "loss difference:\n",
      "0.00015677774436156922\n",
      "epoch: 1161\n",
      "training loss: 0.12713938860389856\n",
      "validation loss: 18.19317024030131\n",
      "loss difference:\n",
      "0.00015644809794795878\n",
      "epoch: 1162\n",
      "training loss: 0.12698326927519163\n",
      "validation loss: 18.197636283709873\n",
      "loss difference:\n",
      "0.0001561193287069329\n",
      "epoch: 1163\n",
      "training loss: 0.12682747784025605\n",
      "validation loss: 18.20209449483509\n",
      "loss difference:\n",
      "0.000155791434935576\n",
      "epoch: 1164\n",
      "training loss: 0.1266720134253322\n",
      "validation loss: 18.20654487794046\n",
      "loss difference:\n",
      "0.00015546441492383933\n",
      "epoch: 1165\n",
      "training loss: 0.12651687515838034\n",
      "validation loss: 18.21098743731341\n",
      "loss difference:\n",
      "0.00015513826695187638\n",
      "epoch: 1166\n",
      "training loss: 0.12636206216908666\n",
      "validation loss: 18.215422177265424\n",
      "loss difference:\n",
      "0.00015481298929367893\n",
      "epoch: 1167\n",
      "training loss: 0.1262075735888741\n",
      "validation loss: 18.219849102132084\n",
      "loss difference:\n",
      "0.00015448858021255285\n",
      "epoch: 1168\n",
      "training loss: 0.12605340855090913\n",
      "validation loss: 18.224268216273185\n",
      "loss difference:\n",
      "0.00015416503796497616\n",
      "epoch: 1169\n",
      "training loss: 0.12589956619010992\n",
      "validation loss: 18.22867952407271\n",
      "loss difference:\n",
      "0.0001538423607992112\n",
      "epoch: 1170\n",
      "training loss: 0.12574604564315348\n",
      "validation loss: 18.23308302993912\n",
      "loss difference:\n",
      "0.00015352054695644268\n",
      "epoch: 1171\n",
      "training loss: 0.12559284604848417\n",
      "validation loss: 18.23747873830519\n",
      "loss difference:\n",
      "0.00015319959466930655\n",
      "epoch: 1172\n",
      "training loss: 0.12543996654632078\n",
      "validation loss: 18.241866653628264\n",
      "loss difference:\n",
      "0.00015287950216338886\n",
      "epoch: 1173\n",
      "training loss: 0.1252874062786633\n",
      "validation loss: 18.24624678039031\n",
      "loss difference:\n",
      "0.00015256026765747555\n",
      "epoch: 1174\n",
      "training loss: 0.1251351643893003\n",
      "validation loss: 18.25061912309801\n",
      "loss difference:\n",
      "0.00015224188936299732\n",
      "epoch: 1175\n",
      "training loss: 0.12498324002381649\n",
      "validation loss: 18.254983686282728\n",
      "loss difference:\n",
      "0.0001519243654838215\n",
      "epoch: 1176\n",
      "training loss: 0.12483163232959768\n",
      "validation loss: 18.2593404745008\n",
      "loss difference:\n",
      "0.0001516076942188055\n",
      "epoch: 1177\n",
      "training loss: 0.1246803404558396\n",
      "validation loss: 18.26368949233349\n",
      "loss difference:\n",
      "0.00015129187375807762\n",
      "epoch: 1178\n",
      "training loss: 0.12452936355355358\n",
      "validation loss: 18.268030744387083\n",
      "loss difference:\n",
      "0.0001509769022860208\n",
      "epoch: 1179\n",
      "training loss: 0.12437870077557192\n",
      "validation loss: 18.272364235293015\n",
      "loss difference:\n",
      "0.00015066277798166106\n",
      "epoch: 1180\n",
      "training loss: 0.12422835127655496\n",
      "validation loss: 18.276689969707967\n",
      "loss difference:\n",
      "0.0001503494990169607\n",
      "epoch: 1181\n",
      "training loss: 0.12407831421299695\n",
      "validation loss: 18.281007952313896\n",
      "loss difference:\n",
      "0.00015003706355801172\n",
      "epoch: 1182\n",
      "training loss: 0.12392858874323223\n",
      "validation loss: 18.285318187818184\n",
      "loss difference:\n",
      "0.00014972546976471657\n",
      "epoch: 1183\n",
      "training loss: 0.12377917402744028\n",
      "validation loss: 18.289620680953664\n",
      "loss difference:\n",
      "0.00014941471579195398\n",
      "epoch: 1184\n",
      "training loss: 0.12363006922765102\n",
      "validation loss: 18.293915436478787\n",
      "loss difference:\n",
      "0.00014910479978925972\n",
      "epoch: 1185\n",
      "training loss: 0.12348127350775139\n",
      "validation loss: 18.298202459177634\n",
      "loss difference:\n",
      "0.00014879571989963314\n",
      "epoch: 1186\n",
      "training loss: 0.12333278603349021\n",
      "validation loss: 18.302481753860025\n",
      "loss difference:\n",
      "0.0001484874742611747\n",
      "epoch: 1187\n",
      "training loss: 0.1231846059724826\n",
      "validation loss: 18.306753325361655\n",
      "loss difference:\n",
      "0.00014818006100761338\n",
      "epoch: 1188\n",
      "training loss: 0.1230367324942151\n",
      "validation loss: 18.31101717854407\n",
      "loss difference:\n",
      "0.00014787347826750175\n",
      "epoch: 1189\n",
      "training loss: 0.12288916477005207\n",
      "validation loss: 18.315273318294853\n",
      "loss difference:\n",
      "0.00014756772416302244\n",
      "epoch: 1190\n",
      "training loss: 0.12274190197323792\n",
      "validation loss: 18.31952174952766\n",
      "loss difference:\n",
      "0.00014726279681415155\n",
      "epoch: 1191\n",
      "training loss: 0.12259494327890401\n",
      "validation loss: 18.32376247718232\n",
      "loss difference:\n",
      "0.0001469586943339124\n",
      "epoch: 1192\n",
      "training loss: 0.12244828786407147\n",
      "validation loss: 18.327995506224884\n",
      "loss difference:\n",
      "0.00014665541483253886\n",
      "epoch: 1193\n",
      "training loss: 0.12230193490765535\n",
      "validation loss: 18.332220841647736\n",
      "loss difference:\n",
      "0.00014635295641611534\n",
      "epoch: 1194\n",
      "training loss: 0.12215588359047075\n",
      "validation loss: 18.33643848846966\n",
      "loss difference:\n",
      "0.00014605131718460618\n",
      "epoch: 1195\n",
      "training loss: 0.12201013309523498\n",
      "validation loss: 18.340648451735916\n",
      "loss difference:\n",
      "0.0001457504952357691\n",
      "epoch: 1196\n",
      "training loss: 0.1218646826065725\n",
      "validation loss: 18.344850736518264\n",
      "loss difference:\n",
      "0.0001454504886624769\n",
      "epoch: 1197\n",
      "training loss: 0.12171953131101729\n",
      "validation loss: 18.349045347915208\n",
      "loss difference:\n",
      "0.00014515129555521533\n",
      "epoch: 1198\n",
      "training loss: 0.12157467839701866\n",
      "validation loss: 18.353232291051842\n",
      "loss difference:\n",
      "0.00014485291399862765\n",
      "epoch: 1199\n",
      "training loss: 0.121430123054942\n",
      "validation loss: 18.35741157108001\n",
      "loss difference:\n",
      "0.0001445553420766632\n",
      "epoch: 1200\n",
      "training loss: 0.12128586447707557\n",
      "validation loss: 18.361583193178507\n",
      "loss difference:\n",
      "0.0001442585778664296\n",
      "epoch: 1201\n",
      "training loss: 0.1211419018576304\n",
      "validation loss: 18.365747162552907\n",
      "loss difference:\n",
      "0.0001439626194451732\n",
      "epoch: 1202\n",
      "training loss: 0.12099823439274575\n",
      "validation loss: 18.369903484435838\n",
      "loss difference:\n",
      "0.00014366746488464477\n",
      "epoch: 1203\n",
      "training loss: 0.12085486128049139\n",
      "validation loss: 18.37405216408692\n",
      "loss difference:\n",
      "0.00014337311225436078\n",
      "epoch: 1204\n",
      "training loss: 0.12071178172086956\n",
      "validation loss: 18.378193206792847\n",
      "loss difference:\n",
      "0.0001430795596218254\n",
      "epoch: 1205\n",
      "training loss: 0.12056899491581931\n",
      "validation loss: 18.382326617867495\n",
      "loss difference:\n",
      "0.00014278680505025454\n",
      "epoch: 1206\n",
      "training loss: 0.12042650006921884\n",
      "validation loss: 18.386452402651948\n",
      "loss difference:\n",
      "0.0001424948466004633\n",
      "epoch: 1207\n",
      "training loss: 0.12028429638688759\n",
      "validation loss: 18.390570566514526\n",
      "loss difference:\n",
      "0.00014220368233125447\n",
      "epoch: 1208\n",
      "training loss: 0.12014238307658719\n",
      "validation loss: 18.3946811148509\n",
      "loss difference:\n",
      "0.00014191331030040388\n",
      "epoch: 1209\n",
      "training loss: 0.12000075934802765\n",
      "validation loss: 18.39878405308411\n",
      "loss difference:\n",
      "0.00014162372855953953\n",
      "epoch: 1210\n",
      "training loss: 0.11985942441286605\n",
      "validation loss: 18.402879386664573\n",
      "loss difference:\n",
      "0.0001413349351615939\n",
      "epoch: 1211\n",
      "training loss: 0.11971837748471015\n",
      "validation loss: 18.40696712107024\n",
      "loss difference:\n",
      "0.00014104692815590514\n",
      "epoch: 1212\n",
      "training loss: 0.11957761777912024\n",
      "validation loss: 18.41104726180652\n",
      "loss difference:\n",
      "0.00014075970558991013\n",
      "epoch: 1213\n",
      "training loss: 0.1194371445136106\n",
      "validation loss: 18.415119814406424\n",
      "loss difference:\n",
      "0.00014047326550964412\n",
      "epoch: 1214\n",
      "training loss: 0.11929695690765137\n",
      "validation loss: 18.419184784430485\n",
      "loss difference:\n",
      "0.0001401876059592272\n",
      "epoch: 1215\n",
      "training loss: 0.11915705418267161\n",
      "validation loss: 18.423242177466943\n",
      "loss difference:\n",
      "0.0001399027249797541\n",
      "epoch: 1216\n",
      "training loss: 0.11901743556205867\n",
      "validation loss: 18.427291999131675\n",
      "loss difference:\n",
      "0.00013961862061294406\n",
      "epoch: 1217\n",
      "training loss: 0.1188781002711611\n",
      "validation loss: 18.431334255068307\n",
      "loss difference:\n",
      "0.00013933529089757424\n",
      "epoch: 1218\n",
      "training loss: 0.11873904753728905\n",
      "validation loss: 18.435368950948124\n",
      "loss difference:\n",
      "0.00013905273387204709\n",
      "epoch: 1219\n",
      "training loss: 0.1186002765897169\n",
      "validation loss: 18.439396092470247\n",
      "loss difference:\n",
      "0.00013877094757214214\n",
      "epoch: 1220\n",
      "training loss: 0.11846178665968303\n",
      "validation loss: 18.443415685361558\n",
      "loss difference:\n",
      "0.00013848993003387489\n",
      "epoch: 1221\n",
      "training loss: 0.11832357698039209\n",
      "validation loss: 18.447427735376746\n",
      "loss difference:\n",
      "0.0001382096792909432\n",
      "epoch: 1222\n",
      "training loss: 0.11818564678701429\n",
      "validation loss: 18.451432248298374\n",
      "loss difference:\n",
      "0.00013793019337779433\n",
      "epoch: 1223\n",
      "training loss: 0.11804799531668864\n",
      "validation loss: 18.45542922993685\n",
      "loss difference:\n",
      "0.00013765147032565594\n",
      "epoch: 1224\n",
      "training loss: 0.11791062180852194\n",
      "validation loss: 18.45941868613045\n",
      "loss difference:\n",
      "0.00013737350816669935\n",
      "epoch: 1225\n",
      "training loss: 0.11777352550358985\n",
      "validation loss: 18.463400622745382\n",
      "loss difference:\n",
      "0.0001370963049320828\n",
      "epoch: 1226\n",
      "training loss: 0.11763670564493771\n",
      "validation loss: 18.46737504567569\n",
      "loss difference:\n",
      "0.00013681985865214574\n",
      "epoch: 1227\n",
      "training loss: 0.11750016147758119\n",
      "validation loss: 18.471341960843382\n",
      "loss difference:\n",
      "0.00013654416735651986\n",
      "epoch: 1228\n",
      "training loss: 0.11736389224850635\n",
      "validation loss: 18.475301374198384\n",
      "loss difference:\n",
      "0.00013626922907483685\n",
      "epoch: 1229\n",
      "training loss: 0.11722789720667041\n",
      "validation loss: 18.47925329171855\n",
      "loss difference:\n",
      "0.00013599504183593736\n",
      "epoch: 1230\n",
      "training loss: 0.11709217560300166\n",
      "validation loss: 18.483197719409656\n",
      "loss difference:\n",
      "0.00013572160366875918\n",
      "epoch: 1231\n",
      "training loss: 0.11695672669039947\n",
      "validation loss: 18.487134663305426\n",
      "loss difference:\n",
      "0.0001354489126021846\n",
      "epoch: 1232\n",
      "training loss: 0.11682154972373467\n",
      "validation loss: 18.491064129467482\n",
      "loss difference:\n",
      "0.0001351769666648045\n",
      "epoch: 1233\n",
      "training loss: 0.11668664395985065\n",
      "validation loss: 18.494986123985413\n",
      "loss difference:\n",
      "0.0001349057638840162\n",
      "epoch: 1234\n",
      "training loss: 0.11655200865756032\n",
      "validation loss: 18.498900652976758\n",
      "loss difference:\n",
      "0.00013463530229032572\n",
      "epoch: 1235\n",
      "training loss: 0.1164176430776494\n",
      "validation loss: 18.502807722586834\n",
      "loss difference:\n",
      "0.00013436557991092224\n",
      "epoch: 1236\n",
      "training loss: 0.11628354648287373\n",
      "validation loss: 18.506707338988964\n",
      "loss difference:\n",
      "0.00013409659477567337\n",
      "epoch: 1237\n",
      "training loss: 0.11614971813795981\n",
      "validation loss: 18.510599508384328\n",
      "loss difference:\n",
      "0.00013382834491391937\n",
      "epoch: 1238\n",
      "training loss: 0.11601615730960488\n",
      "validation loss: 18.514484237001987\n",
      "loss difference:\n",
      "0.0001335608283549311\n",
      "epoch: 1239\n",
      "training loss: 0.11588286326647576\n",
      "validation loss: 18.51836153109884\n",
      "loss difference:\n",
      "0.0001332940431291174\n",
      "epoch: 1240\n",
      "training loss: 0.11574983527920855\n",
      "validation loss: 18.522231396959572\n",
      "loss difference:\n",
      "0.00013302798726720633\n",
      "epoch: 1241\n",
      "training loss: 0.11561707262040845\n",
      "validation loss: 18.52609384089673\n",
      "loss difference:\n",
      "0.0001327626588001063\n",
      "epoch: 1242\n",
      "training loss: 0.11548457456464756\n",
      "validation loss: 18.52994886925059\n",
      "loss difference:\n",
      "0.0001324980557608907\n",
      "epoch: 1243\n",
      "training loss: 0.11535234038846634\n",
      "validation loss: 18.533796488389225\n",
      "loss difference:\n",
      "0.00013223417618121736\n",
      "epoch: 1244\n",
      "training loss: 0.1152203693703717\n",
      "validation loss: 18.537636704708355\n",
      "loss difference:\n",
      "0.0001319710180946454\n",
      "epoch: 1245\n",
      "training loss: 0.11508866079083503\n",
      "validation loss: 18.541469524631495\n",
      "loss difference:\n",
      "0.00013170857953666293\n",
      "epoch: 1246\n",
      "training loss: 0.11495721393229312\n",
      "validation loss: 18.545294954609645\n",
      "loss difference:\n",
      "0.00013144685854191152\n",
      "epoch: 1247\n",
      "training loss: 0.11482602807914596\n",
      "validation loss: 18.549113001121537\n",
      "loss difference:\n",
      "0.00013118585314715603\n",
      "epoch: 1248\n",
      "training loss: 0.11469510251775634\n",
      "validation loss: 18.552923670673437\n",
      "loss difference:\n",
      "0.0001309255613896193\n",
      "epoch: 1249\n",
      "training loss: 0.11456443653644756\n",
      "validation loss: 18.55672696979913\n",
      "loss difference:\n",
      "0.00013066598130878626\n",
      "epoch: 1250\n",
      "training loss: 0.11443402942550403\n",
      "validation loss: 18.560522905059894\n",
      "loss difference:\n",
      "0.0001304071109435312\n",
      "epoch: 1251\n",
      "training loss: 0.11430388047716843\n",
      "validation loss: 18.564311483044392\n",
      "loss difference:\n",
      "0.0001301489483356011\n",
      "epoch: 1252\n",
      "training loss: 0.11417398898564089\n",
      "validation loss: 18.568092710368717\n",
      "loss difference:\n",
      "0.000129891491527534\n",
      "epoch: 1253\n",
      "training loss: 0.1140443542470773\n",
      "validation loss: 18.57186659367629\n",
      "loss difference:\n",
      "0.00012963473856358876\n",
      "epoch: 1254\n",
      "training loss: 0.11391497555958816\n",
      "validation loss: 18.57563313963778\n",
      "loss difference:\n",
      "0.00012937868748914838\n",
      "epoch: 1255\n",
      "training loss: 0.11378585222323742\n",
      "validation loss: 18.57939235495107\n",
      "loss difference:\n",
      "0.0001291233363507338\n",
      "epoch: 1256\n",
      "training loss: 0.11365698354004002\n",
      "validation loss: 18.583144246341263\n",
      "loss difference:\n",
      "0.00012886868319740563\n",
      "epoch: 1257\n",
      "training loss: 0.11352836881396133\n",
      "validation loss: 18.5868888205605\n",
      "loss difference:\n",
      "0.0001286147260786824\n",
      "epoch: 1258\n",
      "training loss: 0.11340000735091363\n",
      "validation loss: 18.590626084387956\n",
      "loss difference:\n",
      "0.0001283614630477048\n",
      "epoch: 1259\n",
      "training loss: 0.1132718984587568\n",
      "validation loss: 18.594356044629826\n",
      "loss difference:\n",
      "0.00012810889215682242\n",
      "epoch: 1260\n",
      "training loss: 0.11314404144729442\n",
      "validation loss: 18.59807870811915\n",
      "loss difference:\n",
      "0.0001278570114623817\n",
      "epoch: 1261\n",
      "training loss: 0.11301643562827288\n",
      "validation loss: 18.601794081715845\n",
      "loss difference:\n",
      "0.00012760581902154788\n",
      "epoch: 1262\n",
      "training loss: 0.11288908031537932\n",
      "validation loss: 18.605502172306583\n",
      "loss difference:\n",
      "0.00012735531289355395\n",
      "epoch: 1263\n",
      "training loss: 0.11276197482423957\n",
      "validation loss: 18.609202986804682\n",
      "loss difference:\n",
      "0.00012710549113975622\n",
      "epoch: 1264\n",
      "training loss: 0.11263511847241697\n",
      "validation loss: 18.61289653215015\n",
      "loss difference:\n",
      "0.00012685635182259347\n",
      "epoch: 1265\n",
      "training loss: 0.11250851057940825\n",
      "validation loss: 18.61658281530943\n",
      "loss difference:\n",
      "0.00012660789300872333\n",
      "epoch: 1266\n",
      "training loss: 0.11238215046664315\n",
      "validation loss: 18.620261843275514\n",
      "loss difference:\n",
      "0.00012636011276509485\n",
      "epoch: 1267\n",
      "training loss: 0.11225603745748221\n",
      "validation loss: 18.623933623067714\n",
      "loss difference:\n",
      "0.00012611300916094692\n",
      "epoch: 1268\n",
      "training loss: 0.11213017087721372\n",
      "validation loss: 18.62759816173164\n",
      "loss difference:\n",
      "0.0001258665802684883\n",
      "epoch: 1269\n",
      "training loss: 0.11200455005305142\n",
      "validation loss: 18.63125546633909\n",
      "loss difference:\n",
      "0.0001256208241623008\n",
      "epoch: 1270\n",
      "training loss: 0.11187917431413408\n",
      "validation loss: 18.634905543987994\n",
      "loss difference:\n",
      "0.000125375738917341\n",
      "epoch: 1271\n",
      "training loss: 0.11175404299151964\n",
      "validation loss: 18.638548401802293\n",
      "loss difference:\n",
      "0.00012513132261443571\n",
      "epoch: 1272\n",
      "training loss: 0.11162915541818651\n",
      "validation loss: 18.64218404693194\n",
      "loss difference:\n",
      "0.00012488757333313505\n",
      "epoch: 1273\n",
      "training loss: 0.11150451092902829\n",
      "validation loss: 18.64581248655259\n",
      "loss difference:\n",
      "0.00012464448915822102\n",
      "epoch: 1274\n",
      "training loss: 0.11138010886085306\n",
      "validation loss: 18.649433727865773\n",
      "loss difference:\n",
      "0.00012440206817522503\n",
      "epoch: 1275\n",
      "training loss: 0.11125594855238012\n",
      "validation loss: 18.65304777809856\n",
      "loss difference:\n",
      "0.0001241603084729398\n",
      "epoch: 1276\n",
      "training loss: 0.11113202934423735\n",
      "validation loss: 18.656654644503657\n",
      "loss difference:\n",
      "0.00012391920814276702\n",
      "epoch: 1277\n",
      "training loss: 0.11100835057895853\n",
      "validation loss: 18.660254334359195\n",
      "loss difference:\n",
      "0.00012367876527882848\n",
      "epoch: 1278\n",
      "training loss: 0.11088491160098153\n",
      "validation loss: 18.663846854968615\n",
      "loss difference:\n",
      "0.00012343897797699455\n",
      "epoch: 1279\n",
      "training loss: 0.11076171175664423\n",
      "validation loss: 18.66743221366064\n",
      "loss difference:\n",
      "0.00012319984433729891\n",
      "epoch: 1280\n",
      "training loss: 0.11063875039418261\n",
      "validation loss: 18.671010417789144\n",
      "loss difference:\n",
      "0.00012296136246162104\n",
      "epoch: 1281\n",
      "training loss: 0.11051602686372836\n",
      "validation loss: 18.674581474732978\n",
      "loss difference:\n",
      "0.0001227235304542551\n",
      "epoch: 1282\n",
      "training loss: 0.11039354051730521\n",
      "validation loss: 18.678145391895963\n",
      "loss difference:\n",
      "0.00012248634642314515\n",
      "epoch: 1283\n",
      "training loss: 0.11027129070882671\n",
      "validation loss: 18.6817021767067\n",
      "loss difference:\n",
      "0.0001222498084784973\n",
      "epoch: 1284\n",
      "training loss: 0.11014927679409241\n",
      "validation loss: 18.685251836618534\n",
      "loss difference:\n",
      "0.00012201391473430634\n",
      "epoch: 1285\n",
      "training loss: 0.1100274981307861\n",
      "validation loss: 18.68879437910932\n",
      "loss difference:\n",
      "0.00012177866330630172\n",
      "epoch: 1286\n",
      "training loss: 0.10990595407847216\n",
      "validation loss: 18.692329811681507\n",
      "loss difference:\n",
      "0.00012154405231394605\n",
      "epoch: 1287\n",
      "training loss: 0.10978464399859252\n",
      "validation loss: 18.69585814186172\n",
      "loss difference:\n",
      "0.00012131007987964404\n",
      "epoch: 1288\n",
      "training loss: 0.1096635672544642\n",
      "validation loss: 18.69937937720101\n",
      "loss difference:\n",
      "0.00012107674412831226\n",
      "epoch: 1289\n",
      "training loss: 0.10954272321127587\n",
      "validation loss: 18.7028935252744\n",
      "loss difference:\n",
      "0.00012084404318833675\n",
      "epoch: 1290\n",
      "training loss: 0.10942211123608422\n",
      "validation loss: 18.70640059368099\n",
      "loss difference:\n",
      "0.00012061197519164235\n",
      "epoch: 1291\n",
      "training loss: 0.10930173069781217\n",
      "validation loss: 18.709900590043716\n",
      "loss difference:\n",
      "0.00012038053827205519\n",
      "epoch: 1292\n",
      "training loss: 0.1091815809672442\n",
      "validation loss: 18.7133935220093\n",
      "loss difference:\n",
      "0.00012014973056796718\n",
      "epoch: 1293\n",
      "training loss: 0.10906166141702385\n",
      "validation loss: 18.716879397248032\n",
      "loss difference:\n",
      "0.0001199195502203515\n",
      "epoch: 1294\n",
      "training loss: 0.10894197142165102\n",
      "validation loss: 18.72035822345374\n",
      "loss difference:\n",
      "0.00011968999537283198\n",
      "epoch: 1295\n",
      "training loss: 0.10882251035747713\n",
      "validation loss: 18.723830008343626\n",
      "loss difference:\n",
      "0.00011946106417388969\n",
      "epoch: 1296\n",
      "training loss: 0.10870327760270451\n",
      "validation loss: 18.72729475965812\n",
      "loss difference:\n",
      "0.0001192327547726163\n",
      "epoch: 1297\n",
      "training loss: 0.1085842725373798\n",
      "validation loss: 18.73075248516074\n",
      "loss difference:\n",
      "0.00011900506532470934\n",
      "epoch: 1298\n",
      "training loss: 0.10846549454339385\n",
      "validation loss: 18.734203192638034\n",
      "loss difference:\n",
      "0.00011877799398594957\n",
      "epoch: 1299\n",
      "training loss: 0.10834694300447495\n",
      "validation loss: 18.737646889899374\n",
      "loss difference:\n",
      "0.00011855153891890402\n",
      "epoch: 1300\n",
      "training loss: 0.10822861730618849\n",
      "validation loss: 18.74108358477682\n",
      "loss difference:\n",
      "0.00011832569828645889\n",
      "epoch: 1301\n",
      "training loss: 0.10811051683593181\n",
      "validation loss: 18.744513285125038\n",
      "loss difference:\n",
      "0.0001181004702566768\n",
      "epoch: 1302\n",
      "training loss: 0.10799264098293192\n",
      "validation loss: 18.74793599882114\n",
      "loss difference:\n",
      "0.00011787585299989634\n",
      "epoch: 1303\n",
      "training loss: 0.10787498913824008\n",
      "validation loss: 18.751351733764515\n",
      "loss difference:\n",
      "0.00011765184469184065\n",
      "epoch: 1304\n",
      "training loss: 0.10775756069473023\n",
      "validation loss: 18.75476049787677\n",
      "loss difference:\n",
      "0.00011742844350984272\n",
      "epoch: 1305\n",
      "training loss: 0.10764035504709582\n",
      "validation loss: 18.758162299101475\n",
      "loss difference:\n",
      "0.00011720564763441355\n",
      "epoch: 1306\n",
      "training loss: 0.10752337159184282\n",
      "validation loss: 18.76155714540412\n",
      "loss difference:\n",
      "0.00011698345525300302\n",
      "epoch: 1307\n",
      "training loss: 0.10740660972729042\n",
      "validation loss: 18.76494504477192\n",
      "loss difference:\n",
      "0.0001167618645523949\n",
      "epoch: 1308\n",
      "training loss: 0.10729006885356482\n",
      "validation loss: 18.768326005213783\n",
      "loss difference:\n",
      "0.00011654087372560407\n",
      "epoch: 1309\n",
      "training loss: 0.10717374837259651\n",
      "validation loss: 18.77170003475991\n",
      "loss difference:\n",
      "0.00011632048096830994\n",
      "epoch: 1310\n",
      "training loss: 0.10705764768811653\n",
      "validation loss: 18.775067141461975\n",
      "loss difference:\n",
      "0.00011610068447998056\n",
      "epoch: 1311\n",
      "training loss: 0.10694176620565198\n",
      "validation loss: 18.77842733339269\n",
      "loss difference:\n",
      "0.00011588148246455265\n",
      "epoch: 1312\n",
      "training loss: 0.10682610333252425\n",
      "validation loss: 18.781780618645907\n",
      "loss difference:\n",
      "0.00011566287312772539\n",
      "epoch: 1313\n",
      "training loss: 0.10671065847784335\n",
      "validation loss: 18.785127005336303\n",
      "loss difference:\n",
      "0.00011544485468090171\n",
      "epoch: 1314\n",
      "training loss: 0.10659543105250467\n",
      "validation loss: 18.78846650159928\n",
      "loss difference:\n",
      "0.00011522742533867647\n",
      "epoch: 1315\n",
      "training loss: 0.10648042046918664\n",
      "validation loss: 18.791799115590816\n",
      "loss difference:\n",
      "0.00011501058331803149\n",
      "epoch: 1316\n",
      "training loss: 0.10636562614234463\n",
      "validation loss: 18.79512485548735\n",
      "loss difference:\n",
      "0.00011479432684201318\n",
      "epoch: 1317\n",
      "training loss: 0.10625104748820885\n",
      "validation loss: 18.79844372948558\n",
      "loss difference:\n",
      "0.00011457865413577739\n",
      "epoch: 1318\n",
      "training loss: 0.10613668392478053\n",
      "validation loss: 18.80175574580231\n",
      "loss difference:\n",
      "0.0001143635634283241\n",
      "epoch: 1319\n",
      "training loss: 0.10602253487182638\n",
      "validation loss: 18.80506091267437\n",
      "loss difference:\n",
      "0.0001141490529541489\n",
      "epoch: 1320\n",
      "training loss: 0.10590859975087703\n",
      "validation loss: 18.808359238358403\n",
      "loss difference:\n",
      "0.00011393512094934333\n",
      "epoch: 1321\n",
      "training loss: 0.10579487798522219\n",
      "validation loss: 18.811650731130694\n",
      "loss difference:\n",
      "0.00011372176565484227\n",
      "epoch: 1322\n",
      "training loss: 0.1056813689999062\n",
      "validation loss: 18.814935399287087\n",
      "loss difference:\n",
      "0.00011350898531599374\n",
      "epoch: 1323\n",
      "training loss: 0.10556807222172403\n",
      "validation loss: 18.81821325114274\n",
      "loss difference:\n",
      "0.00011329677818217032\n",
      "epoch: 1324\n",
      "training loss: 0.10545498707921966\n",
      "validation loss: 18.821484295032086\n",
      "loss difference:\n",
      "0.0001130851425043683\n",
      "epoch: 1325\n",
      "training loss: 0.10534211300267904\n",
      "validation loss: 18.824748539308594\n",
      "loss difference:\n",
      "0.00011287407654061998\n",
      "epoch: 1326\n",
      "training loss: 0.1052294494241284\n",
      "validation loss: 18.828005992344558\n",
      "loss difference:\n",
      "0.00011266357855063691\n",
      "epoch: 1327\n",
      "training loss: 0.105116995777328\n",
      "validation loss: 18.83125666253112\n",
      "loss difference:\n",
      "0.00011245364680040337\n",
      "epoch: 1328\n",
      "training loss: 0.10500475149777182\n",
      "validation loss: 18.834500558277956\n",
      "loss difference:\n",
      "0.00011224427955618121\n",
      "epoch: 1329\n",
      "training loss: 0.10489271602267985\n",
      "validation loss: 18.83773768801314\n",
      "loss difference:\n",
      "0.00011203547509196221\n",
      "epoch: 1330\n",
      "training loss: 0.10478088879099587\n",
      "validation loss: 18.840968060183048\n",
      "loss difference:\n",
      "0.00011182723168398634\n",
      "epoch: 1331\n",
      "training loss: 0.10466926924338356\n",
      "validation loss: 18.84419168325218\n",
      "loss difference:\n",
      "0.00011161954761230997\n",
      "epoch: 1332\n",
      "training loss: 0.10455785682222125\n",
      "validation loss: 18.847408565702946\n",
      "loss difference:\n",
      "0.00011141242116230465\n",
      "epoch: 1333\n",
      "training loss: 0.10444665097159987\n",
      "validation loss: 18.85061871603556\n",
      "loss difference:\n",
      "0.000111205850621382\n",
      "epoch: 1334\n",
      "training loss: 0.10433565113731631\n",
      "validation loss: 18.853822142767886\n",
      "loss difference:\n",
      "0.00011099983428355942\n",
      "epoch: 1335\n",
      "training loss: 0.10422485676687243\n",
      "validation loss: 18.85701885443527\n",
      "loss difference:\n",
      "0.0001107943704438813\n",
      "epoch: 1336\n",
      "training loss: 0.10411426730946781\n",
      "validation loss: 18.860208859590262\n",
      "loss difference:\n",
      "0.00011058945740462234\n",
      "epoch: 1337\n",
      "training loss: 0.10400388221599821\n",
      "validation loss: 18.86339216680269\n",
      "loss difference:\n",
      "0.00011038509346959768\n",
      "epoch: 1338\n",
      "training loss: 0.10389370093904976\n",
      "validation loss: 18.866568784659297\n",
      "loss difference:\n",
      "0.00011018127694845115\n",
      "epoch: 1339\n",
      "training loss: 0.1037837229328955\n",
      "validation loss: 18.869738721763675\n",
      "loss difference:\n",
      "0.00010997800615425435\n",
      "epoch: 1340\n",
      "training loss: 0.10367394765349229\n",
      "validation loss: 18.87290198673607\n",
      "loss difference:\n",
      "0.0001097752794032153\n",
      "epoch: 1341\n",
      "training loss: 0.10356437455847417\n",
      "validation loss: 18.876058588213212\n",
      "loss difference:\n",
      "0.00010957309501812007\n",
      "epoch: 1342\n",
      "training loss: 0.10345500310715088\n",
      "validation loss: 18.87920853484817\n",
      "loss difference:\n",
      "0.00010937145132329518\n",
      "epoch: 1343\n",
      "training loss: 0.10334583276050152\n",
      "validation loss: 18.88235183531022\n",
      "loss difference:\n",
      "0.00010917034664935377\n",
      "epoch: 1344\n",
      "training loss: 0.10323686298117288\n",
      "validation loss: 18.88548849828463\n",
      "loss difference:\n",
      "0.00010896977932864371\n",
      "epoch: 1345\n",
      "training loss: 0.10312809323347179\n",
      "validation loss: 18.8886185324725\n",
      "loss difference:\n",
      "0.00010876974770109016\n",
      "epoch: 1346\n",
      "training loss: 0.10301952298336446\n",
      "validation loss: 18.89174194659059\n",
      "loss difference:\n",
      "0.00010857025010732602\n",
      "epoch: 1347\n",
      "training loss: 0.10291115169847011\n",
      "validation loss: 18.89485874937127\n",
      "loss difference:\n",
      "0.0001083712848943541\n",
      "epoch: 1348\n",
      "training loss: 0.10280297884805774\n",
      "validation loss: 18.897968949562163\n",
      "loss difference:\n",
      "0.00010817285041236913\n",
      "epoch: 1349\n",
      "training loss: 0.10269500390304145\n",
      "validation loss: 18.90107255592612\n",
      "loss difference:\n",
      "0.00010797494501628424\n",
      "epoch: 1350\n",
      "training loss: 0.10258722633597593\n",
      "validation loss: 18.904169577241046\n",
      "loss difference:\n",
      "0.00010777756706552288\n",
      "epoch: 1351\n",
      "training loss: 0.10247964562105359\n",
      "validation loss: 18.907260022299656\n",
      "loss difference:\n",
      "0.00010758071492233956\n",
      "epoch: 1352\n",
      "training loss: 0.10237226123409875\n",
      "validation loss: 18.91034389990942\n",
      "loss difference:\n",
      "0.0001073843869548452\n",
      "epoch: 1353\n",
      "training loss: 0.10226507265256456\n",
      "validation loss: 18.9134212188923\n",
      "loss difference:\n",
      "0.00010718858153418998\n",
      "epoch: 1354\n",
      "training loss: 0.10215807935552756\n",
      "validation loss: 18.91649198808463\n",
      "loss difference:\n",
      "0.0001069932970369919\n",
      "epoch: 1355\n",
      "training loss: 0.1020512808236849\n",
      "validation loss: 18.919556216336936\n",
      "loss difference:\n",
      "0.00010679853184265842\n",
      "epoch: 1356\n",
      "training loss: 0.10194467653934863\n",
      "validation loss: 18.92261391251383\n",
      "loss difference:\n",
      "0.000106604284336273\n",
      "epoch: 1357\n",
      "training loss: 0.10183826598644305\n",
      "validation loss: 18.925665085493748\n",
      "loss difference:\n",
      "0.00010641055290558366\n",
      "epoch: 1358\n",
      "training loss: 0.10173204865049888\n",
      "validation loss: 18.92870974416884\n",
      "loss difference:\n",
      "0.00010621733594416705\n",
      "epoch: 1359\n",
      "training loss: 0.10162602401864987\n",
      "validation loss: 18.93174789744484\n",
      "loss difference:\n",
      "0.00010602463184901378\n",
      "epoch: 1360\n",
      "training loss: 0.10152019157962844\n",
      "validation loss: 18.93477955424083\n",
      "loss difference:\n",
      "0.00010583243902143047\n",
      "epoch: 1361\n",
      "training loss: 0.10141455082376111\n",
      "validation loss: 18.93780472348909\n",
      "loss difference:\n",
      "0.00010564075586733113\n",
      "epoch: 1362\n",
      "training loss: 0.10130910124296408\n",
      "validation loss: 18.940823414134957\n",
      "loss difference:\n",
      "0.00010544958079702904\n",
      "epoch: 1363\n",
      "training loss: 0.10120384233073976\n",
      "validation loss: 18.943835635136676\n",
      "loss difference:\n",
      "0.00010525891222432082\n",
      "epoch: 1364\n",
      "training loss: 0.10109877358217181\n",
      "validation loss: 18.94684139546518\n",
      "loss difference:\n",
      "0.00010506874856794357\n",
      "epoch: 1365\n",
      "training loss: 0.10099389449392097\n",
      "validation loss: 18.949840704103977\n",
      "loss difference:\n",
      "0.00010487908825083936\n",
      "epoch: 1366\n",
      "training loss: 0.10088920456422093\n",
      "validation loss: 18.952833570048995\n",
      "loss difference:\n",
      "0.0001046899297000442\n",
      "epoch: 1367\n",
      "training loss: 0.10078470329287342\n",
      "validation loss: 18.955820002308286\n",
      "loss difference:\n",
      "0.00010450127134750686\n",
      "epoch: 1368\n",
      "training loss: 0.10068039018124494\n",
      "validation loss: 18.95880000990207\n",
      "loss difference:\n",
      "0.000104313111628479\n",
      "epoch: 1369\n",
      "training loss: 0.10057626473226175\n",
      "validation loss: 18.961773601862404\n",
      "loss difference:\n",
      "0.00010412544898319442\n",
      "epoch: 1370\n",
      "training loss: 0.10047232645040492\n",
      "validation loss: 18.964740787233104\n",
      "loss difference:\n",
      "0.00010393828185682741\n",
      "epoch: 1371\n",
      "training loss: 0.10036857484170815\n",
      "validation loss: 18.96770157506957\n",
      "loss difference:\n",
      "0.00010375160869677269\n",
      "epoch: 1372\n",
      "training loss: 0.10026500941375131\n",
      "validation loss: 18.970655974438543\n",
      "loss difference:\n",
      "0.00010356542795683654\n",
      "epoch: 1373\n",
      "training loss: 0.10016162967565656\n",
      "validation loss: 18.97360399441809\n",
      "loss difference:\n",
      "0.00010337973809475265\n",
      "epoch: 1374\n",
      "training loss: 0.10005843513808532\n",
      "validation loss: 18.976545644097282\n",
      "loss difference:\n",
      "0.00010319453757123842\n",
      "epoch: 1375\n",
      "training loss: 0.09995542531323214\n",
      "validation loss: 18.979480932576173\n",
      "loss difference:\n",
      "0.00010300982485318688\n",
      "epoch: 1376\n",
      "training loss: 0.0998525997148217\n",
      "validation loss: 18.982409868965473\n",
      "loss difference:\n",
      "0.00010282559841043315\n",
      "epoch: 1377\n",
      "training loss: 0.09974995785810468\n",
      "validation loss: 18.985332462386587\n",
      "loss difference:\n",
      "0.00010264185671701731\n",
      "epoch: 1378\n",
      "training loss: 0.09964749925985113\n",
      "validation loss: 18.98824872197128\n",
      "loss difference:\n",
      "0.00010245859825355752\n",
      "epoch: 1379\n",
      "training loss: 0.09954522343834878\n",
      "validation loss: 18.991158656861614\n",
      "loss difference:\n",
      "0.00010227582150235115\n",
      "epoch: 1380\n",
      "training loss: 0.09944312991339858\n",
      "validation loss: 18.994062276209746\n",
      "loss difference:\n",
      "0.00010209352495019197\n",
      "epoch: 1381\n",
      "training loss: 0.09934121820630774\n",
      "validation loss: 18.996959589177756\n",
      "loss difference:\n",
      "0.00010191170709084041\n",
      "epoch: 1382\n",
      "training loss: 0.09923948783988908\n",
      "validation loss: 18.99985060493753\n",
      "loss difference:\n",
      "0.0001017303664186675\n",
      "epoch: 1383\n",
      "training loss: 0.09913793833845327\n",
      "validation loss: 19.002735332670554\n",
      "loss difference:\n",
      "0.00010154950143580199\n",
      "epoch: 1384\n",
      "training loss: 0.09903656922780729\n",
      "validation loss: 19.00561378156778\n",
      "loss difference:\n",
      "0.00010136911064598242\n",
      "epoch: 1385\n",
      "training loss: 0.09893538003524754\n",
      "validation loss: 19.008485960829457\n",
      "loss difference:\n",
      "0.00010118919255974745\n",
      "epoch: 1386\n",
      "training loss: 0.0988343702895585\n",
      "validation loss: 19.011351879664947\n",
      "loss difference:\n",
      "0.00010100974568903742\n",
      "epoch: 1387\n",
      "training loss: 0.0987335395210055\n",
      "validation loss: 19.01421154729262\n",
      "loss difference:\n",
      "0.0001008307685530091\n",
      "epoch: 1388\n",
      "training loss: 0.0986328872613322\n",
      "validation loss: 19.017064972939664\n",
      "loss difference:\n",
      "0.00010065225967330338\n",
      "epoch: 1389\n",
      "training loss: 0.09853241304375539\n",
      "validation loss: 19.019912165841916\n",
      "loss difference:\n",
      "0.00010047421757680697\n",
      "epoch: 1390\n",
      "training loss: 0.0984321164029618\n",
      "validation loss: 19.022753135243693\n",
      "loss difference:\n",
      "0.00010029664079358458\n",
      "epoch: 1391\n",
      "training loss: 0.0983319968751022\n",
      "validation loss: 19.025587890397663\n",
      "loss difference:\n",
      "0.00010011952785959899\n",
      "epoch: 1392\n",
      "training loss: 0.09823205399778824\n",
      "validation loss: 19.028416440564698\n",
      "loss difference:\n",
      "9.994287731396323e-05\n",
      "that didn't improve loss:  1\n",
      "epoch: 1393\n",
      "training loss: 0.0981322873100875\n",
      "validation loss: 19.031238795013657\n",
      "loss difference:\n",
      "9.97666877007447e-05\n",
      "that didn't improve loss:  2\n",
      "epoch: 1394\n",
      "training loss: 0.09803269635252003\n",
      "validation loss: 19.034054963021266\n",
      "loss difference:\n",
      "9.959095756746639e-05\n",
      "that didn't improve loss:  3\n",
      "epoch: 1395\n",
      "training loss: 0.09793328066705306\n",
      "validation loss: 19.036864953872023\n",
      "loss difference:\n",
      "9.941568546696644e-05\n",
      "that didn't improve loss:  4\n",
      "epoch: 1396\n",
      "training loss: 0.0978340397970973\n",
      "validation loss: 19.039668776857912\n",
      "loss difference:\n",
      "9.924086995576065e-05\n",
      "that didn't improve loss:  5\n",
      "epoch: 1397\n",
      "training loss: 0.09773497328750212\n",
      "validation loss: 19.042466441278343\n",
      "loss difference:\n",
      "9.906650959518037e-05\n",
      "that didn't improve loss:  6\n",
      "epoch: 1398\n",
      "training loss: 0.09763608068455198\n",
      "validation loss: 19.04525795643993\n",
      "loss difference:\n",
      "9.889260295013746e-05\n",
      "that didn't improve loss:  7\n",
      "epoch: 1399\n",
      "training loss: 0.09753736153596154\n",
      "validation loss: 19.048043331656434\n",
      "loss difference:\n",
      "9.871914859044262e-05\n",
      "that didn't improve loss:  8\n",
      "epoch: 1400\n",
      "training loss: 0.09743881539087171\n",
      "validation loss: 19.05082257624849\n",
      "loss difference:\n",
      "9.854614508983395e-05\n",
      "that didn't improve loss:  9\n",
      "epoch: 1401\n",
      "training loss: 0.09734044179984515\n",
      "validation loss: 19.053595699543546\n",
      "loss difference:\n",
      "9.837359102655985e-05\n",
      "that didn't improve loss:  10\n",
      "Training loss did not improve more than tol=0.0001 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "nodes = [100, 100, 100] # use to specify a number of hidden nodes per layer\n",
    "activations = [] # use if you want a diff activationFn per layer\n",
    "\n",
    "nn = NeuralNetwork(layers=1, nnodes=100, batchSize=50, \n",
    "                   activationFn=\"tanh\", lr=.01, max_epoch=2000,\n",
    "                   momentum=0, tol = 0.0001)\n",
    "nn.fit(X_std, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error of Housing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: $757.99\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y, nn.predict(X_std))\n",
    "print('Mean absolute error: $%0.2f'%(mae*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these to results to those in nn_tuning_example.ipynb.  Goal: Get MAE Under $1000 with our NN.  Then, we know our NN is working well and can use it on the dataset for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR:\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        # create vector of ones...\n",
    "        ones = np.ones(shape=len(X_train))[..., None]\n",
    "        #...and add to feature matrix\n",
    "        X = np.concatenate((ones, X_train), 1)\n",
    "        #calculate coefficients using closed-form solution\n",
    "        self.coeffs = np.linalg.inv(X.transpose().dot(X)).dot(X.transpose()).dot(y_train)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        ones = np.ones(shape=len(X_test))[..., None]\n",
    "        X_test = np.concatenate((ones, X_test), 1)\n",
    "        y_hat = X_test.dot(self.coeffs)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: $17885.89\n"
     ]
    }
   ],
   "source": [
    "lr = LR()\n",
    "lr.fit(X, y)\n",
    "mae = mean_absolute_error(y, lr.predict(X_std))\n",
    "print('Mean absolute error: $%0.2f'%(mae*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
