{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs import *\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data to Test Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4],\n",
       "       [ 9, 16]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sq = x ** 2\n",
    "x_sq\n",
    "np.sum(x_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, layers=None, nodes=None, nnodes=None, \n",
    "                 activations=[], activationFn=\"relu\", batchSize=50, \n",
    "                 lr=.001, lr_type=\"constant\", power_t=.5,\n",
    "                 annealing_rate=.999, max_epoch=200, momentum=.9, \n",
    "                 tol=0.0001, alpha=.0001, early_stopping=False, \n",
    "                 num_epochs_stop=10):\n",
    "        \n",
    "        if layers != None:\n",
    "            self.layers = layers # total number of hidden layers\n",
    "        else:\n",
    "            self.layers = len(nodes)\n",
    "\n",
    "        # an int array of size [0, ..., Layers + 1]\n",
    "        # Nodes[0] shall represent the input size (typically 50)\n",
    "        # Nodes[Layers + 1] shall represent the output size (typically 1)\n",
    "        # all other Nodes represent the number of nodes (or width) in the hidden layer i\n",
    "        self.nodes = nodes\n",
    "        if nodes != None:\n",
    "            self.nodes.insert(0, batchSize)\n",
    "            self.nodes.append(1)\n",
    "        \n",
    "        # alternative to nodes where each hidden layer of the nueral network is the same size\n",
    "        self.nnodes = nnodes\n",
    "        if nnodes != None:\n",
    "            self.nodes = []\n",
    "            self.nodes.append(batchSize)\n",
    "            for i in range(layers):\n",
    "                self.nodes.append(nnodes)\n",
    "            self.nodes.append(1)\n",
    "        \n",
    "        # activations[i] values are labels indicating the activation function used in layer i\n",
    "        self.activations = activations\n",
    "        self.activationFn = activationFn\n",
    "        if activationFn != \"\":\n",
    "            self.activations = [activationFn] * self.layers\n",
    "        \n",
    "        self.batchSize = batchSize\n",
    "        self.lr = lr\n",
    "        self.lr_type = lr_type\n",
    "        self.power_t = power_t\n",
    "        self.annealing_rate = annealing_rate\n",
    "        self.max_epoch = max_epoch\n",
    "        self.mu = momentum\n",
    "        self.tol = tol\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        if early_stopping == False:\n",
    "            self.num_epochs_stop = max_epoch\n",
    "        else:\n",
    "            self.num_epochs_stop = num_epochs_stop\n",
    "    \n",
    "        self.layer_values = [None] * (self.layers + 2)\n",
    "        self.iters = 0\n",
    "        self.epochs = 0\n",
    "                \n",
    "    def validateHyperParams(self):\n",
    "        \n",
    "        if self.layers != (len(self.nodes) - 2):\n",
    "            raise ValueError(\"layers must be equal to the number of hidden layers, got %s.\" % self.layers)\n",
    "        if self.nnodes != None and self.nnodes <= 0:\n",
    "            raise ValueError(\"nnodes must be > 0, got %s.\" % self.nnodes)\n",
    "        if self.lr <= 0 or self.lr > 1:\n",
    "            raise ValueError(\"lr must be in (0, 1], got %s.\" % self.lr)\n",
    "            \n",
    "        if self.lr_type not in [\"constant\", \"invscaling\", \"annealing\", \"adaptive\"]:\n",
    "            raise ValueError(\"lr_type is not valid\" % self.lr_type\n",
    "                            + \"\\nAvailable lr types: constant, invscaling, adaptive\")\n",
    "            \n",
    "        if self.max_epoch <= 0:\n",
    "            raise ValueError(\"max_iter must be > 0, got %s.\" % self.max_epoch)\n",
    "               \n",
    "        activation_functions = list(ACTIVATIONS.keys())\n",
    "        if self.activationFn != \"\":\n",
    "            if self.activationFn not in activation_functions:\n",
    "                raise ValueError(\"%s is not an activation function\" % self.activationFn\n",
    "                                + \"\\nAvailable activation functions: relu, leaky_relu, sigmoid, tanh\")\n",
    "    \n",
    "    def initialize_weights(self, M):\n",
    "        weights = []\n",
    "        \n",
    "        for i in range(self.layers + 1):\n",
    "            if i == 0:\n",
    "                input_size = M # special case for w1\n",
    "            else:\n",
    "                input_size = self.nodes[i]\n",
    "            output_size = self.nodes[i + 1]\n",
    "            \n",
    "            # Xavier (Glorot) Initialization\n",
    "            if self.activationFn == \"tanh\":\n",
    "                target_variance = 2 / (input_size + output_size)\n",
    "                w_i = np.random.normal(loc= 0, scale = np.sqrt(target_variance), size=(input_size, output_size))\n",
    "            # He Initialization\n",
    "            elif self.activationFn == \"relu\":\n",
    "                target_variance = 2 / input_size\n",
    "                w_i = np.random.normal(loc= 0, scale = np.sqrt(target_variance), size=(input_size, output_size))\n",
    "            # Random Uniform\n",
    "            else:\n",
    "                w_i = np.random.uniform(-1/np.sqrt(input_size), 1/np.sqrt(input_size))\n",
    "                #w_i = np.random.normal(size=(input_size, output_size))\n",
    "            w_i = np.round(w_i, 2)\n",
    "            w_i[input_size - 1:] = 0 # initialize bias to 0\n",
    "            weights.append(w_i)\n",
    "        return weights\n",
    "    \n",
    "    # returns the weight term for L2 regularization\n",
    "    def get_weight_term(self):\n",
    "        weight_term = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            weight_term = np.sum(self.weights[i] ** 2)\n",
    "        return weight_term\n",
    "        \n",
    "    def forward_pass(self, X_batch, y_batch):\n",
    "        \n",
    "        self.layer_values[0] = X_batch\n",
    "        \n",
    "        # calculate hidden layers\n",
    "        for i in range(self.layers):\n",
    "            X = self.layer_values[i]\n",
    "            weights = self.weights[i]\n",
    "            h_layer = X.dot(weights)\n",
    "            \n",
    "            # apply activation function\n",
    "            activation_fn = ACTIVATIONS[self.activations[i]]\n",
    "            activation_fn(h_layer)\n",
    "            self.layer_values[i + 1] = h_layer\n",
    "            \n",
    "        \n",
    "        # calculate predictions\n",
    "        X = self.layer_values[self.layers] # values in last hidden layer\n",
    "        weights = self.weights[self.layers]\n",
    "        y_pred = X.dot(weights)\n",
    "        y_pred = y_pred.flatten()\n",
    "        \n",
    "        # calculate the l2 loss\n",
    "        l2_loss = 0\n",
    "        # only need predictions once we have fit the data\n",
    "        if isinstance(y_batch, np.ndarray): \n",
    "            l2_loss = squared_loss(y_pred, y_batch) # l2\n",
    "#             weight_term = self.get_weight_term()\n",
    "#             l2_loss += self.alpha * weight_term # l2 regularization\n",
    "            self.layer_values[self.layers + 1] = l2_loss\n",
    "        \n",
    "        return l2_loss, y_pred\n",
    "    \n",
    "    \n",
    "    def backward_pass(self, y_pred, y_batch):\n",
    "        \n",
    "        # loss layer\n",
    "        J = squared_loss_derivative(y_pred, y_batch, self.batchSize)\n",
    "        J = np.reshape(J, (len(J), 1))\n",
    "        \n",
    "        J_weights = [None] * (self.layers + 1)\n",
    "        \n",
    "        # output layer\n",
    "        # jacobian w.r.t. weights\n",
    "        x_t = self.layer_values[self.layers].T\n",
    "        J_wi = x_t.dot(J)\n",
    "        J_weights[self.layers] = J_wi\n",
    "        \n",
    "        # update jacobian at output layer\n",
    "        w_t = self.weights[self.layers].T\n",
    "        w_t = np.delete(w_t, w_t.shape[1] - 1, 1) # take out the bias\n",
    "        J = np.dot(J, w_t)\n",
    "        zeros = [0] * len(J)\n",
    "        zeros = np.reshape(zeros, (len(J), 1))\n",
    "        J = np.append(J, zeros, axis=1)\n",
    "        \n",
    "        # iterate through hidden layers backwards\n",
    "        for i in range(self.layers, 0 , -1):\n",
    "            # update jacobian at activation layer\n",
    "            d_activation_fn = DERIVATIVES[self.activations[i - 1]]\n",
    "            d_activation_fn(self.layer_values[i], J)\n",
    "            \n",
    "            # hidden layer\n",
    "            # jacobian w.r.t. weights\n",
    "            x_t = self.layer_values[i - 1].T\n",
    "            J_wi = x_t.dot(J)\n",
    "            J_weights[i - 1] = J_wi\n",
    "            \n",
    "            # jacobian w.r.t. inputs\n",
    "            w_t = self.weights[i - 1].T\n",
    "            w_t = np.delete(w_t, w_t.shape[1] - 1, 1)\n",
    "            J = np.dot(J, w_t)\n",
    "            zeros = [0] * len(J)\n",
    "            zeros = np.reshape(zeros, (len(J), 1))\n",
    "            J = np.append(J, zeros, axis=1)\n",
    "            \n",
    "            \n",
    "        # initialize velocity to 0\n",
    "        if self.epochs == 0 and self.iters == 0:\n",
    "            self.velocity = []\n",
    "            for i in range(len(J_weights)):\n",
    "                n_rows = J_weights[i].shape[0]\n",
    "                n_cols = J_weights[i].shape[1]\n",
    "                vel_i = np.zeros((n_rows, n_cols))\n",
    "                self.velocity.append(vel_i)\n",
    "        \n",
    "        for i in range(len(J_weights)):\n",
    "            self.velocity[i] = self.mu * self.velocity[i] - self.lr * J_weights[i]\n",
    "            self.weights[i] += self.velocity[i]\n",
    "      \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        self.validateHyperParams()\n",
    "        # convert to numpy arrays\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            X_train = X_train.to_numpy()\n",
    "            \n",
    "        if isinstance(y_train, pd.Series):\n",
    "            y_train = y_train.to_numpy()\n",
    "            \n",
    "        # add ones for bias\n",
    "        ones = [1] * len(X_train)\n",
    "        ones = np.reshape(ones, (len(X_train), 1))\n",
    "        X_train = np.append(X_train, ones, axis=1)\n",
    "        \n",
    "        # save 10% for validation\n",
    "        val_rows = round(len(X_train) * .1)\n",
    "        X_val = X_train[:val_rows, :]\n",
    "        y_val = y_train[:val_rows]\n",
    "        \n",
    "        X_train = X_train[val_rows:, :]\n",
    "        y_train = y_train[val_rows:]\n",
    "        \n",
    "        # initalize weights on first iteration\n",
    "        M = X_train.shape[1] # M = number of features\n",
    "        self.weights = self.initialize_weights(M)\n",
    "        \n",
    "        previous_loss = np.inf\n",
    "        n_epoch_no_change = 0\n",
    "            \n",
    "        while (self.epochs < self.max_epoch and n_epoch_no_change <= self.num_epochs_stop):\n",
    "            # ONE EPOCH \n",
    "            last_idx = 0\n",
    "            #np.random.shuffle(X_train) # shuffle data for each epoch \n",
    "            while (last_idx < len(X_train)):\n",
    "                first_idx = self.iters * self.batchSize\n",
    "                remaining_rows = len(X_train) - first_idx\n",
    "                last_idx = first_idx + min(self.batchSize, remaining_rows)\n",
    "                X_batch = X_train[first_idx: last_idx, :]\n",
    "                y_batch = y_train[first_idx: last_idx]\n",
    "\n",
    "                loss, y_pred = self.forward_pass(X_batch, y_batch)\n",
    "                self.backward_pass(y_pred, y_batch)\n",
    "                self.iters += 1\n",
    "            \n",
    "            # trainig and validation loss after one epoch\n",
    "            t_loss, y_pred = self.forward_pass(X_train, y_train)\n",
    "            v_loss, y_pred = self.forward_pass(X_val, y_val)\n",
    "            print(\"epoch:\", self.epochs)\n",
    "            print(\"training loss:\", t_loss)\n",
    "            print(\"validation loss:\", v_loss)\n",
    "            \n",
    "            self.iters = 0 # start over, next epoch\n",
    "            self.epochs += 1\n",
    "            \n",
    "            # decrease the learning rate by one of three methods, if specified\n",
    "            if self.lr_type == \"invscaling\":\n",
    "                self.lr = self.lr/pow(self.epochs, self.power_t)\n",
    "            elif self.lr_type == \"annealing\":\n",
    "                self.lr = self.lr * self.annealing_rate\n",
    "            elif self.lr_type == \"adaptive\":\n",
    "                if n_epoch_no_change >= 2: \n",
    "                    self.lr = self.lr/5\n",
    "                \n",
    "            # stops when validation loss doesn't improve for num_epochs_stop\n",
    "            if previous_loss - v_loss < self.tol: \n",
    "                n_epoch_no_change += 1\n",
    "            else:\n",
    "                n_epoch_no_change = 0\n",
    "            previous_loss = v_loss\n",
    "            print(\"num epoch no change:\", n_epoch_no_change)\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        # convert to numpy array\n",
    "        if isinstance(X_test, pd.DataFrame):\n",
    "            X_test = X_test.to_numpy()\n",
    "        \n",
    "        # add ones for bias\n",
    "        ones = [1] * len(X_test)\n",
    "        ones = np.reshape(ones, (len(X_test), 1))\n",
    "        X_test = np.append(X_test, ones, axis=1)\n",
    "        \n",
    "        loss, y_pred = self.forward_pass(X_test, None)\n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Nueral Network on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "training loss: 264.72394330398276\n",
      "validation loss: 184.21362989874277\n",
      "num epoch no change: 0\n",
      "epoch: 1\n",
      "training loss: 121.54397043887226\n",
      "validation loss: 95.60397606267593\n",
      "num epoch no change: 0\n",
      "epoch: 2\n",
      "training loss: 47.3516510024182\n",
      "validation loss: 33.58201280550993\n",
      "num epoch no change: 0\n",
      "epoch: 3\n",
      "training loss: 38.659051177770024\n",
      "validation loss: 14.941949024046995\n",
      "num epoch no change: 0\n",
      "epoch: 4\n",
      "training loss: 29.70672121159587\n",
      "validation loss: 32.53632481235325\n",
      "num epoch no change: 1\n",
      "epoch: 5\n",
      "training loss: 23.526012380034985\n",
      "validation loss: 9.395078123534958\n",
      "num epoch no change: 0\n",
      "epoch: 6\n",
      "training loss: 19.255157526750207\n",
      "validation loss: 5.2729295585895315\n",
      "num epoch no change: 0\n",
      "epoch: 7\n",
      "training loss: 15.314856627167826\n",
      "validation loss: 4.145429410196056\n",
      "num epoch no change: 0\n",
      "epoch: 8\n",
      "training loss: 11.716295428243793\n",
      "validation loss: 3.873445998387917\n",
      "num epoch no change: 0\n",
      "epoch: 9\n",
      "training loss: 9.455016986122011\n",
      "validation loss: 2.750354871333595\n",
      "num epoch no change: 0\n",
      "epoch: 10\n",
      "training loss: 10.402762710584541\n",
      "validation loss: 4.883949042220721\n",
      "num epoch no change: 1\n",
      "epoch: 11\n",
      "training loss: 8.688302195403434\n",
      "validation loss: 4.116975519380959\n",
      "num epoch no change: 0\n",
      "epoch: 12\n",
      "training loss: 7.687608842730054\n",
      "validation loss: 2.889253889953336\n",
      "num epoch no change: 0\n",
      "epoch: 13\n",
      "training loss: 7.017779344782441\n",
      "validation loss: 3.5664171392477773\n",
      "num epoch no change: 1\n",
      "epoch: 14\n",
      "training loss: 6.611438549241905\n",
      "validation loss: 3.390760274273178\n",
      "num epoch no change: 0\n",
      "epoch: 15\n",
      "training loss: 6.273773709944801\n",
      "validation loss: 3.788047886503064\n",
      "num epoch no change: 1\n",
      "epoch: 16\n",
      "training loss: 6.256823947848096\n",
      "validation loss: 3.397305353543844\n",
      "num epoch no change: 0\n",
      "epoch: 17\n",
      "training loss: 5.696168234428712\n",
      "validation loss: 3.990431408983631\n",
      "num epoch no change: 1\n",
      "epoch: 18\n",
      "training loss: 5.40275306765343\n",
      "validation loss: 3.6427605453606695\n",
      "num epoch no change: 0\n",
      "epoch: 19\n",
      "training loss: 5.148717543717835\n",
      "validation loss: 4.255272560593613\n",
      "num epoch no change: 1\n",
      "epoch: 20\n",
      "training loss: 4.9669105419402975\n",
      "validation loss: 3.6756086564336097\n",
      "num epoch no change: 0\n",
      "epoch: 21\n",
      "training loss: 4.761418731871235\n",
      "validation loss: 4.760331611099042\n",
      "num epoch no change: 1\n",
      "epoch: 22\n",
      "training loss: 4.7593539030214105\n",
      "validation loss: 3.603615852398277\n",
      "num epoch no change: 0\n",
      "epoch: 23\n",
      "training loss: 5.317286653804065\n",
      "validation loss: 5.698816165805186\n",
      "num epoch no change: 1\n",
      "epoch: 24\n",
      "training loss: 7.784414153981633\n",
      "validation loss: 3.8659069459500492\n",
      "num epoch no change: 0\n",
      "epoch: 25\n",
      "training loss: 8.74556651693878\n",
      "validation loss: 11.856996194098215\n",
      "num epoch no change: 1\n",
      "epoch: 26\n",
      "training loss: 8.413699890154023\n",
      "validation loss: 5.463500281703962\n",
      "num epoch no change: 0\n",
      "epoch: 27\n",
      "training loss: 7.935294611631565\n",
      "validation loss: 9.108991454986251\n",
      "num epoch no change: 1\n",
      "epoch: 28\n",
      "training loss: 5.554259546364255\n",
      "validation loss: 4.666239511398749\n",
      "num epoch no change: 0\n",
      "epoch: 29\n",
      "training loss: 8.048995371536108\n",
      "validation loss: 4.798205592722236\n",
      "num epoch no change: 1\n",
      "epoch: 30\n",
      "training loss: 9.0441788756703\n",
      "validation loss: 6.367015947547106\n",
      "num epoch no change: 2\n",
      "epoch: 31\n",
      "training loss: 13.402071045532436\n",
      "validation loss: 11.781408418965812\n",
      "num epoch no change: 3\n",
      "epoch: 32\n",
      "training loss: 9.23920462507367\n",
      "validation loss: 8.515962332113483\n",
      "num epoch no change: 0\n",
      "epoch: 33\n",
      "training loss: 10.616819626664274\n",
      "validation loss: 7.730375778232232\n",
      "num epoch no change: 0\n",
      "epoch: 34\n",
      "training loss: 10.561738580200787\n",
      "validation loss: 6.4467169081213465\n",
      "num epoch no change: 0\n",
      "epoch: 35\n",
      "training loss: 8.361249727014393\n",
      "validation loss: 9.517939130814026\n",
      "num epoch no change: 1\n",
      "epoch: 36\n",
      "training loss: 6.593863725991035\n",
      "validation loss: 5.052026555494946\n",
      "num epoch no change: 0\n",
      "epoch: 37\n",
      "training loss: 4.270939504427714\n",
      "validation loss: 4.452570984776472\n",
      "num epoch no change: 0\n",
      "epoch: 38\n",
      "training loss: 4.083733070886802\n",
      "validation loss: 3.8189017883750953\n",
      "num epoch no change: 0\n",
      "epoch: 39\n",
      "training loss: 4.251126181024409\n",
      "validation loss: 5.095904438817879\n",
      "num epoch no change: 1\n",
      "epoch: 40\n",
      "training loss: 5.400603056447112\n",
      "validation loss: 5.1042568420760315\n",
      "num epoch no change: 2\n",
      "epoch: 41\n",
      "training loss: 6.696160566128263\n",
      "validation loss: 5.7072294300791535\n",
      "num epoch no change: 3\n",
      "epoch: 42\n",
      "training loss: 7.432656326676924\n",
      "validation loss: 7.755913061344717\n",
      "num epoch no change: 4\n",
      "epoch: 43\n",
      "training loss: 8.1203330379493\n",
      "validation loss: 6.37716332555689\n",
      "num epoch no change: 0\n",
      "epoch: 44\n",
      "training loss: 7.702755151091158\n",
      "validation loss: 9.482849900526352\n",
      "num epoch no change: 1\n",
      "epoch: 45\n",
      "training loss: 8.180343484559796\n",
      "validation loss: 6.440480552414417\n",
      "num epoch no change: 0\n",
      "epoch: 46\n",
      "training loss: 7.548067291373203\n",
      "validation loss: 9.670040136295578\n",
      "num epoch no change: 1\n",
      "epoch: 47\n",
      "training loss: 7.816931957292106\n",
      "validation loss: 6.188858229316289\n",
      "num epoch no change: 0\n",
      "epoch: 48\n",
      "training loss: 7.733263971025038\n",
      "validation loss: 10.113730081354598\n",
      "num epoch no change: 1\n",
      "epoch: 49\n",
      "training loss: 8.546903033468562\n",
      "validation loss: 6.762035256759187\n",
      "num epoch no change: 0\n",
      "epoch: 50\n",
      "training loss: 8.35257128598867\n",
      "validation loss: 10.75767865964495\n",
      "num epoch no change: 1\n",
      "epoch: 51\n",
      "training loss: 8.789890448009219\n",
      "validation loss: 6.7542570657713945\n",
      "num epoch no change: 0\n",
      "epoch: 52\n",
      "training loss: 7.79905619085445\n",
      "validation loss: 10.87689405992361\n",
      "num epoch no change: 1\n",
      "epoch: 53\n",
      "training loss: 7.667459948001086\n",
      "validation loss: 6.183632353672138\n",
      "num epoch no change: 0\n",
      "epoch: 54\n",
      "training loss: 6.472123116551245\n",
      "validation loss: 9.423155489980138\n",
      "num epoch no change: 1\n",
      "epoch: 55\n",
      "training loss: 5.907614041427589\n",
      "validation loss: 5.121411624800121\n",
      "num epoch no change: 0\n",
      "epoch: 56\n",
      "training loss: 4.999917805823547\n",
      "validation loss: 7.680044001558224\n",
      "num epoch no change: 1\n",
      "epoch: 57\n",
      "training loss: 4.618036719061474\n",
      "validation loss: 4.416638005755392\n",
      "num epoch no change: 0\n",
      "epoch: 58\n",
      "training loss: 4.082989736288705\n",
      "validation loss: 6.362685356441331\n",
      "num epoch no change: 1\n",
      "epoch: 59\n",
      "training loss: 3.8405631695546436\n",
      "validation loss: 4.0661755351150175\n",
      "num epoch no change: 0\n",
      "epoch: 60\n",
      "training loss: 3.524357531220863\n",
      "validation loss: 5.551785495082317\n",
      "num epoch no change: 1\n",
      "epoch: 61\n",
      "training loss: 3.3933527984160214\n",
      "validation loss: 3.895786608457738\n",
      "num epoch no change: 0\n",
      "epoch: 62\n",
      "training loss: 3.1987443050294986\n",
      "validation loss: 5.030391567491983\n",
      "num epoch no change: 1\n",
      "epoch: 63\n",
      "training loss: 3.1215111038293837\n",
      "validation loss: 3.834357817686756\n",
      "num epoch no change: 0\n",
      "epoch: 64\n",
      "training loss: 2.994094761146332\n",
      "validation loss: 4.688451558449034\n",
      "num epoch no change: 1\n",
      "epoch: 65\n",
      "training loss: 2.9483439927159734\n",
      "validation loss: 3.8283998892886775\n",
      "num epoch no change: 0\n",
      "epoch: 66\n",
      "training loss: 2.860009626711914\n",
      "validation loss: 4.465231005417109\n",
      "num epoch no change: 1\n",
      "epoch: 67\n",
      "training loss: 2.8294127939708265\n",
      "validation loss: 3.844404163296067\n",
      "num epoch no change: 0\n",
      "epoch: 68\n",
      "training loss: 2.764290229257054\n",
      "validation loss: 4.310766596351988\n",
      "num epoch no change: 1\n",
      "epoch: 69\n",
      "training loss: 2.740838008895349\n",
      "validation loss: 3.8733835476292424\n",
      "num epoch no change: 0\n",
      "epoch: 70\n",
      "training loss: 2.6911133584398708\n",
      "validation loss: 4.201542174447825\n",
      "num epoch no change: 1\n",
      "epoch: 71\n",
      "training loss: 2.6705008725125134\n",
      "validation loss: 3.908283098836533\n",
      "num epoch no change: 0\n",
      "epoch: 72\n",
      "training loss: 2.631849771469678\n",
      "validation loss: 4.121426508447256\n",
      "num epoch no change: 1\n",
      "epoch: 73\n",
      "training loss: 2.6118211548306265\n",
      "validation loss: 3.947099706437453\n",
      "num epoch no change: 0\n",
      "epoch: 74\n",
      "training loss: 2.581838218591884\n",
      "validation loss: 4.061837144488846\n",
      "num epoch no change: 1\n",
      "epoch: 75\n",
      "training loss: 2.561292813435279\n",
      "validation loss: 3.987458658320929\n",
      "num epoch no change: 0\n",
      "epoch: 76\n",
      "training loss: 2.538490883551058\n",
      "validation loss: 4.0173025288051205\n",
      "num epoch no change: 1\n",
      "epoch: 77\n",
      "training loss: 2.5169505157453527\n",
      "validation loss: 4.0271795609780785\n",
      "num epoch no change: 2\n",
      "epoch: 78\n",
      "training loss: 2.5001836409755662\n",
      "validation loss: 3.9848682753034588\n",
      "num epoch no change: 0\n",
      "epoch: 79\n",
      "training loss: 2.477379830648887\n",
      "validation loss: 4.062979456471448\n",
      "num epoch no change: 1\n",
      "epoch: 80\n",
      "training loss: 2.4652269932702486\n",
      "validation loss: 3.963594207671261\n",
      "num epoch no change: 0\n",
      "epoch: 81\n",
      "training loss: 2.4407715706619237\n",
      "validation loss: 4.089314533365495\n",
      "num epoch no change: 1\n",
      "epoch: 82\n",
      "training loss: 2.430915543190315\n",
      "validation loss: 3.95483182341624\n",
      "num epoch no change: 0\n",
      "epoch: 83\n",
      "training loss: 2.4043844529390888\n",
      "validation loss: 4.096704498904479\n",
      "num epoch no change: 1\n",
      "epoch: 84\n",
      "training loss: 2.3933166752862305\n",
      "validation loss: 3.9637218335089783\n",
      "num epoch no change: 0\n",
      "epoch: 85\n",
      "training loss: 2.3657140830895615\n",
      "validation loss: 4.069931110052989\n",
      "num epoch no change: 1\n",
      "epoch: 86\n",
      "training loss: 2.350379905430131\n",
      "validation loss: 4.0044553957110525\n",
      "num epoch no change: 0\n",
      "epoch: 87\n",
      "training loss: 2.330467585334346\n",
      "validation loss: 3.991252877635341\n",
      "num epoch no change: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 88\n",
      "training loss: 2.31803105803724\n",
      "validation loss: 4.116690882384755\n",
      "num epoch no change: 1\n",
      "epoch: 89\n",
      "training loss: 2.343785540213691\n",
      "validation loss: 3.8723193575221537\n",
      "num epoch no change: 0\n",
      "epoch: 90\n",
      "training loss: 2.3793361419088255\n",
      "validation loss: 4.398370402301302\n",
      "num epoch no change: 1\n",
      "epoch: 91\n",
      "training loss: 2.54751905666823\n",
      "validation loss: 3.8571306886232284\n",
      "num epoch no change: 0\n",
      "epoch: 92\n",
      "training loss: 2.7162975564498635\n",
      "validation loss: 4.97612358931157\n",
      "num epoch no change: 1\n",
      "epoch: 93\n",
      "training loss: 3.0575028516625844\n",
      "validation loss: 4.1439548418154\n",
      "num epoch no change: 0\n",
      "epoch: 94\n",
      "training loss: 3.3239700505397356\n",
      "validation loss: 5.8019646157653115\n",
      "num epoch no change: 1\n",
      "epoch: 95\n",
      "training loss: 3.698631938902314\n",
      "validation loss: 4.551520387468745\n",
      "num epoch no change: 0\n",
      "epoch: 96\n",
      "training loss: 3.7352286069634504\n",
      "validation loss: 6.455278294776914\n",
      "num epoch no change: 1\n",
      "epoch: 97\n",
      "training loss: 3.802215363748722\n",
      "validation loss: 4.653276565172733\n",
      "num epoch no change: 0\n",
      "epoch: 98\n",
      "training loss: 3.313987796283772\n",
      "validation loss: 5.931595043650461\n",
      "num epoch no change: 1\n",
      "epoch: 99\n",
      "training loss: 3.347777668819892\n",
      "validation loss: 4.012432817722152\n",
      "num epoch no change: 0\n",
      "epoch: 100\n",
      "training loss: 2.8743182193574195\n",
      "validation loss: 5.537105303669249\n",
      "num epoch no change: 1\n",
      "epoch: 101\n",
      "training loss: 2.629274378129575\n",
      "validation loss: 3.7014813042402808\n",
      "num epoch no change: 0\n",
      "epoch: 102\n",
      "training loss: 2.3508586943750593\n",
      "validation loss: 4.606143937011376\n",
      "num epoch no change: 1\n",
      "epoch: 103\n",
      "training loss: 2.281781748080301\n",
      "validation loss: 3.9839396155238673\n",
      "num epoch no change: 0\n",
      "epoch: 104\n",
      "training loss: 2.2288038356381854\n",
      "validation loss: 4.363337897464653\n",
      "num epoch no change: 1\n",
      "epoch: 105\n",
      "training loss: 2.216013988001021\n",
      "validation loss: 4.007373898263334\n",
      "num epoch no change: 0\n",
      "epoch: 106\n",
      "training loss: 2.1807018719849736\n",
      "validation loss: 4.277793559479266\n",
      "num epoch no change: 1\n",
      "epoch: 107\n",
      "training loss: 2.1696670981144717\n",
      "validation loss: 3.9784588741650793\n",
      "num epoch no change: 0\n",
      "epoch: 108\n",
      "training loss: 2.1356599627361748\n",
      "validation loss: 4.203305427880596\n",
      "num epoch no change: 1\n",
      "epoch: 109\n",
      "training loss: 2.124304722873096\n",
      "validation loss: 3.991553081877762\n",
      "num epoch no change: 0\n",
      "epoch: 110\n",
      "training loss: 2.0956828150515525\n",
      "validation loss: 4.139268354638593\n",
      "num epoch no change: 1\n",
      "epoch: 111\n",
      "training loss: 2.0832580215802783\n",
      "validation loss: 4.013048370114776\n",
      "num epoch no change: 0\n",
      "epoch: 112\n",
      "training loss: 2.0636689325555118\n",
      "validation loss: 4.074979016915574\n",
      "num epoch no change: 1\n",
      "epoch: 113\n",
      "training loss: 2.050932309592619\n",
      "validation loss: 4.056919274182989\n",
      "num epoch no change: 0\n",
      "epoch: 114\n",
      "training loss: 2.044342999687181\n",
      "validation loss: 4.018425457698996\n",
      "num epoch no change: 0\n",
      "epoch: 115\n",
      "training loss: 2.032173508980666\n",
      "validation loss: 4.116676364078636\n",
      "num epoch no change: 1\n",
      "epoch: 116\n",
      "training loss: 2.0408288114843356\n",
      "validation loss: 3.9774752035009318\n",
      "num epoch no change: 0\n",
      "epoch: 117\n",
      "training loss: 2.0286377537560623\n",
      "validation loss: 4.187526965899408\n",
      "num epoch no change: 1\n",
      "epoch: 118\n",
      "training loss: 2.0504053175040156\n",
      "validation loss: 3.958779288218577\n",
      "num epoch no change: 0\n",
      "epoch: 119\n",
      "training loss: 2.033498362715716\n",
      "validation loss: 4.251539676005261\n",
      "num epoch no change: 1\n",
      "epoch: 120\n",
      "training loss: 2.0574568256977077\n",
      "validation loss: 3.9631179225007442\n",
      "num epoch no change: 0\n",
      "epoch: 121\n",
      "training loss: 2.024903928809206\n",
      "validation loss: 4.2667394431797065\n",
      "num epoch no change: 1\n",
      "epoch: 122\n",
      "training loss: 2.0305855019908368\n",
      "validation loss: 3.983887506475605\n",
      "num epoch no change: 0\n",
      "epoch: 123\n",
      "training loss: 1.9758856686583233\n",
      "validation loss: 4.17854628405389\n",
      "num epoch no change: 1\n",
      "epoch: 124\n",
      "training loss: 1.9601633117179493\n",
      "validation loss: 4.022508618818429\n",
      "num epoch no change: 0\n",
      "epoch: 125\n",
      "training loss: 1.932138176640017\n",
      "validation loss: 4.023526748376354\n",
      "num epoch no change: 1\n",
      "epoch: 126\n",
      "training loss: 1.9616311871762582\n",
      "validation loss: 4.135441685995653\n",
      "num epoch no change: 2\n",
      "epoch: 127\n",
      "training loss: 2.0540434087789814\n",
      "validation loss: 4.015191093016449\n",
      "num epoch no change: 0\n",
      "epoch: 128\n",
      "training loss: 2.18370544447377\n",
      "validation loss: 4.493575464804178\n",
      "num epoch no change: 1\n",
      "epoch: 129\n",
      "training loss: 2.4429165014177094\n",
      "validation loss: 4.193188122872484\n",
      "num epoch no change: 0\n",
      "epoch: 130\n",
      "training loss: 2.673680778851629\n",
      "validation loss: 5.222846769888145\n",
      "num epoch no change: 1\n",
      "epoch: 131\n",
      "training loss: 3.0051261707309416\n",
      "validation loss: 4.544079052439895\n",
      "num epoch no change: 0\n",
      "epoch: 132\n",
      "training loss: 3.114245102533926\n",
      "validation loss: 5.894854115631133\n",
      "num epoch no change: 1\n",
      "epoch: 133\n",
      "training loss: 3.2412543126035867\n",
      "validation loss: 4.678821404127501\n",
      "num epoch no change: 0\n",
      "epoch: 134\n",
      "training loss: 2.980009008320156\n",
      "validation loss: 5.844674465890073\n",
      "num epoch no change: 1\n",
      "epoch: 135\n",
      "training loss: 2.935965666624961\n",
      "validation loss: 4.243764185433963\n",
      "num epoch no change: 0\n",
      "epoch: 136\n",
      "training loss: 2.580460073163613\n",
      "validation loss: 5.4755189031429925\n",
      "num epoch no change: 1\n",
      "epoch: 137\n",
      "training loss: 2.392581782934191\n",
      "validation loss: 3.926282792073377\n",
      "num epoch no change: 0\n",
      "epoch: 138\n",
      "training loss: 2.1486828329934458\n",
      "validation loss: 4.871779960198782\n",
      "num epoch no change: 1\n",
      "epoch: 139\n",
      "training loss: 2.0660409239092035\n",
      "validation loss: 3.983116039222096\n",
      "num epoch no change: 0\n",
      "epoch: 140\n",
      "training loss: 1.990580132838143\n",
      "validation loss: 4.544701519075789\n",
      "num epoch no change: 1\n",
      "epoch: 141\n",
      "training loss: 1.9847361746333163\n",
      "validation loss: 4.007544576989982\n",
      "num epoch no change: 0\n",
      "epoch: 142\n",
      "training loss: 1.9435037107070636\n",
      "validation loss: 4.447147930051789\n",
      "num epoch no change: 1\n",
      "epoch: 143\n",
      "training loss: 1.9460367318448244\n",
      "validation loss: 3.9910828045961515\n",
      "num epoch no change: 0\n",
      "epoch: 144\n",
      "training loss: 1.9039211112218106\n",
      "validation loss: 4.387256444084638\n",
      "num epoch no change: 1\n",
      "epoch: 145\n",
      "training loss: 1.9035023421566921\n",
      "validation loss: 3.984500347476864\n",
      "num epoch no change: 0\n",
      "epoch: 146\n",
      "training loss: 1.8602412305078773\n",
      "validation loss: 4.331893337990601\n",
      "num epoch no change: 1\n",
      "epoch: 147\n",
      "training loss: 1.855696887803453\n",
      "validation loss: 3.981927760144666\n",
      "num epoch no change: 0\n",
      "epoch: 148\n",
      "training loss: 1.8137937064720322\n",
      "validation loss: 4.2708254216481505\n",
      "num epoch no change: 1\n",
      "epoch: 149\n",
      "training loss: 1.8058802545351258\n",
      "validation loss: 3.986049093619954\n",
      "num epoch no change: 0\n",
      "epoch: 150\n",
      "training loss: 1.7689806745944345\n",
      "validation loss: 4.2067234210678865\n",
      "num epoch no change: 1\n",
      "epoch: 151\n",
      "training loss: 1.7594057956863285\n",
      "validation loss: 3.9986734230147123\n",
      "num epoch no change: 0\n",
      "epoch: 152\n",
      "training loss: 1.7308167898297875\n",
      "validation loss: 4.148102035226908\n",
      "num epoch no change: 1\n",
      "epoch: 153\n",
      "training loss: 1.7210737419702002\n",
      "validation loss: 4.0221953920918505\n",
      "num epoch no change: 0\n",
      "epoch: 154\n",
      "training loss: 1.7032468586286151\n",
      "validation loss: 4.101955614811746\n",
      "num epoch no change: 1\n",
      "epoch: 155\n",
      "training loss: 1.6946422870068043\n",
      "validation loss: 4.058200495854658\n",
      "num epoch no change: 0\n",
      "epoch: 156\n",
      "training loss: 1.6892598217053636\n",
      "validation loss: 4.073343982772952\n",
      "num epoch no change: 1\n",
      "epoch: 157\n",
      "training loss: 1.6828055499439736\n",
      "validation loss: 4.106725125906244\n",
      "num epoch no change: 2\n",
      "epoch: 158\n",
      "training loss: 1.6904600213060277\n",
      "validation loss: 4.065387817494775\n",
      "num epoch no change: 0\n",
      "epoch: 159\n",
      "training loss: 1.6862622749505802\n",
      "validation loss: 4.165616756899423\n",
      "num epoch no change: 1\n",
      "epoch: 160\n",
      "training loss: 1.705230330188941\n",
      "validation loss: 4.077992881763154\n",
      "num epoch no change: 0\n",
      "epoch: 161\n",
      "training loss: 1.7009317312650292\n",
      "validation loss: 4.2273247604870905\n",
      "num epoch no change: 1\n",
      "epoch: 162\n",
      "training loss: 1.7249426476435583\n",
      "validation loss: 4.104680099951656\n",
      "num epoch no change: 0\n",
      "epoch: 163\n",
      "training loss: 1.7138635256476735\n",
      "validation loss: 4.275066603979408\n",
      "num epoch no change: 1\n",
      "epoch: 164\n",
      "training loss: 1.7310960780713458\n",
      "validation loss: 4.1290996711559185\n",
      "num epoch no change: 0\n",
      "epoch: 165\n",
      "training loss: 1.703942507244246\n",
      "validation loss: 4.285569433603401\n",
      "num epoch no change: 1\n",
      "epoch: 166\n",
      "training loss: 1.7035022395449613\n",
      "validation loss: 4.129035440128235\n",
      "num epoch no change: 0\n",
      "epoch: 167\n",
      "training loss: 1.6594921943226912\n",
      "validation loss: 4.250852269350274\n",
      "num epoch no change: 1\n",
      "epoch: 168\n",
      "training loss: 1.6446824461763607\n",
      "validation loss: 4.1017336270798594\n",
      "num epoch no change: 0\n",
      "epoch: 169\n",
      "training loss: 1.6026593421651687\n",
      "validation loss: 4.2013623017779596\n",
      "num epoch no change: 1\n",
      "epoch: 170\n",
      "training loss: 1.5903765406123092\n",
      "validation loss: 4.094595927259319\n",
      "num epoch no change: 0\n",
      "epoch: 171\n",
      "training loss: 1.579753847958623\n",
      "validation loss: 4.176490363578966\n",
      "num epoch no change: 1\n",
      "epoch: 172\n",
      "training loss: 1.5919149754698352\n",
      "validation loss: 4.168606808540435\n",
      "num epoch no change: 0\n",
      "epoch: 173\n",
      "training loss: 1.6358605576547525\n",
      "validation loss: 4.211848381749364\n",
      "num epoch no change: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 174\n",
      "training loss: 1.688091402384213\n",
      "validation loss: 4.3375101750621425\n",
      "num epoch no change: 2\n",
      "epoch: 175\n",
      "training loss: 1.7907104488000118\n",
      "validation loss: 4.335930551763446\n",
      "num epoch no change: 0\n",
      "epoch: 176\n",
      "training loss: 1.8807592735989715\n",
      "validation loss: 4.583366685441302\n",
      "num epoch no change: 1\n",
      "epoch: 177\n",
      "training loss: 2.016888054353651\n",
      "validation loss: 4.522405206242128\n",
      "num epoch no change: 0\n",
      "epoch: 178\n",
      "training loss: 2.1033085400202234\n",
      "validation loss: 4.847622688003241\n",
      "num epoch no change: 1\n",
      "epoch: 179\n",
      "training loss: 2.206336063673731\n",
      "validation loss: 4.658586872060743\n",
      "num epoch no change: 0\n",
      "epoch: 180\n",
      "training loss: 2.2073115538949892\n",
      "validation loss: 4.999355809533918\n",
      "num epoch no change: 1\n",
      "epoch: 181\n",
      "training loss: 2.2301228950247474\n",
      "validation loss: 4.603601983124702\n",
      "num epoch no change: 0\n",
      "epoch: 182\n",
      "training loss: 2.134886951790056\n",
      "validation loss: 5.007426910912195\n",
      "num epoch no change: 1\n",
      "epoch: 183\n",
      "training loss: 2.088592364381173\n",
      "validation loss: 4.45559837195815\n",
      "num epoch no change: 0\n",
      "epoch: 184\n",
      "training loss: 1.9723410577070908\n",
      "validation loss: 4.926969803099033\n",
      "num epoch no change: 1\n",
      "epoch: 185\n",
      "training loss: 1.920990396082662\n",
      "validation loss: 4.403502516673333\n",
      "num epoch no change: 0\n",
      "epoch: 186\n",
      "training loss: 1.8545879704231898\n",
      "validation loss: 4.782292042467338\n",
      "num epoch no change: 1\n",
      "epoch: 187\n",
      "training loss: 1.8555308933598773\n",
      "validation loss: 4.42469098192074\n",
      "num epoch no change: 0\n",
      "epoch: 188\n",
      "training loss: 1.8444284774149413\n",
      "validation loss: 4.743838020357135\n",
      "num epoch no change: 1\n",
      "epoch: 189\n",
      "training loss: 1.8800400651765787\n",
      "validation loss: 4.483939826350147\n",
      "num epoch no change: 0\n",
      "epoch: 190\n",
      "training loss: 1.8920645655650743\n",
      "validation loss: 4.796607646293021\n",
      "num epoch no change: 1\n",
      "epoch: 191\n",
      "training loss: 1.9377272623993984\n",
      "validation loss: 4.553585350059952\n",
      "num epoch no change: 0\n",
      "epoch: 192\n",
      "training loss: 1.952650463979341\n",
      "validation loss: 4.883384395649576\n",
      "num epoch no change: 1\n",
      "epoch: 193\n",
      "training loss: 1.9957904690196508\n",
      "validation loss: 4.616625833886097\n",
      "num epoch no change: 0\n",
      "epoch: 194\n",
      "training loss: 2.004148659868154\n",
      "validation loss: 4.968959413328634\n",
      "num epoch no change: 1\n",
      "epoch: 195\n",
      "training loss: 2.038627528122786\n",
      "validation loss: 4.664544773590737\n",
      "num epoch no change: 0\n",
      "epoch: 196\n",
      "training loss: 2.037748221932884\n",
      "validation loss: 5.0370283881345355\n",
      "num epoch no change: 1\n",
      "epoch: 197\n",
      "training loss: 2.0632536118661498\n",
      "validation loss: 4.699470307703901\n",
      "num epoch no change: 0\n",
      "epoch: 198\n",
      "training loss: 2.056477223021327\n",
      "validation loss: 5.08580002551188\n",
      "num epoch no change: 1\n",
      "epoch: 199\n",
      "training loss: 2.0765438196549706\n",
      "validation loss: 4.728736969154811\n",
      "num epoch no change: 0\n",
      "epoch: 200\n",
      "training loss: 2.0682972923402905\n",
      "validation loss: 5.12244777926576\n",
      "num epoch no change: 1\n",
      "epoch: 201\n",
      "training loss: 2.0856704835103304\n",
      "validation loss: 4.756800895206726\n",
      "num epoch no change: 0\n",
      "epoch: 202\n",
      "training loss: 2.077380090925703\n",
      "validation loss: 5.153414595327176\n",
      "num epoch no change: 1\n",
      "epoch: 203\n",
      "training loss: 2.0917302804573716\n",
      "validation loss: 4.782461604451843\n",
      "num epoch no change: 0\n",
      "epoch: 204\n",
      "training loss: 2.0816457557337635\n",
      "validation loss: 5.178770292982068\n",
      "num epoch no change: 1\n",
      "epoch: 205\n",
      "training loss: 2.0906415432259684\n",
      "validation loss: 4.801581287431977\n",
      "num epoch no change: 0\n",
      "epoch: 206\n",
      "training loss: 2.076126722897799\n",
      "validation loss: 5.193752077725259\n",
      "num epoch no change: 1\n",
      "epoch: 207\n",
      "training loss: 2.077722903495797\n",
      "validation loss: 4.810745044300206\n",
      "num epoch no change: 0\n",
      "epoch: 208\n",
      "training loss: 2.057371898400869\n",
      "validation loss: 5.193745083322774\n",
      "num epoch no change: 1\n",
      "epoch: 209\n",
      "training loss: 2.0511263612207804\n",
      "validation loss: 4.8093010305730965\n",
      "num epoch no change: 0\n",
      "epoch: 210\n",
      "training loss: 2.0253011074180174\n",
      "validation loss: 5.177611234405989\n",
      "num epoch no change: 1\n",
      "epoch: 211\n",
      "training loss: 2.012272220786876\n",
      "validation loss: 4.7990854165600085\n",
      "num epoch no change: 0\n",
      "epoch: 212\n",
      "training loss: 1.9824638385259818\n",
      "validation loss: 5.14777532562938\n",
      "num epoch no change: 1\n",
      "epoch: 213\n",
      "training loss: 1.964440266958921\n",
      "validation loss: 4.783060033252977\n",
      "num epoch no change: 0\n",
      "epoch: 214\n",
      "training loss: 1.9324343380283548\n",
      "validation loss: 5.108535892836681\n",
      "num epoch no change: 1\n",
      "epoch: 215\n",
      "training loss: 1.911263939736621\n",
      "validation loss: 4.764194052869507\n",
      "num epoch no change: 0\n",
      "epoch: 216\n",
      "training loss: 1.878653070287976\n",
      "validation loss: 5.0644152418747055\n",
      "num epoch no change: 1\n",
      "epoch: 217\n",
      "training loss: 1.8559212154259954\n",
      "validation loss: 4.744976309932015\n",
      "num epoch no change: 0\n",
      "epoch: 218\n",
      "training loss: 1.8239518946350461\n",
      "validation loss: 5.019286368277821\n",
      "num epoch no change: 1\n",
      "epoch: 219\n",
      "training loss: 1.800887714147537\n",
      "validation loss: 4.727299735766122\n",
      "num epoch no change: 0\n",
      "epoch: 220\n",
      "training loss: 1.770446391476825\n",
      "validation loss: 4.976093904711516\n",
      "num epoch no change: 1\n",
      "epoch: 221\n",
      "training loss: 1.7479128572734186\n",
      "validation loss: 4.7124525264816945\n",
      "num epoch no change: 0\n",
      "epoch: 222\n",
      "training loss: 1.7195497572410343\n",
      "validation loss: 4.936833797067207\n",
      "num epoch no change: 1\n",
      "epoch: 223\n",
      "training loss: 1.698072682114549\n",
      "validation loss: 4.701157719031766\n",
      "num epoch no change: 0\n",
      "epoch: 224\n",
      "training loss: 1.6720505059283053\n",
      "validation loss: 4.902647350336544\n",
      "num epoch no change: 1\n",
      "epoch: 225\n",
      "training loss: 1.6518800980163948\n",
      "validation loss: 4.69367179852499\n",
      "num epoch no change: 0\n",
      "epoch: 226\n",
      "training loss: 1.6282441128288656\n",
      "validation loss: 4.87398931579657\n",
      "num epoch no change: 1\n",
      "epoch: 227\n",
      "training loss: 1.6094336460633318\n",
      "validation loss: 4.6899204117775355\n",
      "num epoch no change: 0\n",
      "epoch: 228\n",
      "training loss: 1.5880866803667582\n",
      "validation loss: 4.8508292982743315\n",
      "num epoch no change: 1\n",
      "epoch: 229\n",
      "training loss: 1.5705673894074967\n",
      "validation loss: 4.689630595189015\n",
      "num epoch no change: 0\n",
      "epoch: 230\n",
      "training loss: 1.55133338057619\n",
      "validation loss: 4.832839979681759\n",
      "num epoch no change: 1\n",
      "epoch: 231\n",
      "training loss: 1.534972711390075\n",
      "validation loss: 4.692433390351624\n",
      "num epoch no change: 0\n",
      "epoch: 232\n",
      "training loss: 1.5176419666682968\n",
      "validation loss: 4.8195433501359\n",
      "num epoch no change: 1\n",
      "epoch: 233\n",
      "training loss: 1.502282742641348\n",
      "validation loss: 4.697931672850825\n",
      "num epoch no change: 0\n",
      "epoch: 234\n",
      "training loss: 1.4866401207172202\n",
      "validation loss: 4.810409179733263\n",
      "num epoch no change: 1\n",
      "epoch: 235\n",
      "training loss: 1.4721240165370593\n",
      "validation loss: 4.7057395434427605\n",
      "num epoch no change: 0\n",
      "epoch: 236\n",
      "training loss: 1.4579644562218608\n",
      "validation loss: 4.804913693036907\n",
      "num epoch no change: 1\n",
      "epoch: 237\n",
      "training loss: 1.4441445636309378\n",
      "validation loss: 4.715502163916242\n",
      "num epoch no change: 0\n",
      "epoch: 238\n",
      "training loss: 1.4312804063446756\n",
      "validation loss: 4.802570182681811\n",
      "num epoch no change: 1\n",
      "epoch: 239\n",
      "training loss: 1.4180269562695829\n",
      "validation loss: 4.726903452268504\n",
      "num epoch no change: 0\n",
      "epoch: 240\n",
      "training loss: 1.4062904139427819\n",
      "validation loss: 4.80294184812322\n",
      "num epoch no change: 1\n",
      "epoch: 241\n",
      "training loss: 1.3934925219142524\n",
      "validation loss: 4.739666822699177\n",
      "num epoch no change: 0\n",
      "epoch: 242\n",
      "training loss: 1.3827355096428564\n",
      "validation loss: 4.80564427951216\n",
      "num epoch no change: 1\n",
      "epoch: 243\n",
      "training loss: 1.3703007849941526\n",
      "validation loss: 4.753552314667389\n",
      "num epoch no change: 0\n",
      "epoch: 244\n",
      "training loss: 1.3603934818483445\n",
      "validation loss: 4.810342443986192\n",
      "num epoch no change: 1\n",
      "epoch: 245\n",
      "training loss: 1.3482466133447595\n",
      "validation loss: 4.768352171122339\n",
      "num epoch no change: 0\n",
      "epoch: 246\n",
      "training loss: 1.3390755374820411\n",
      "validation loss: 4.816745193898373\n",
      "num epoch no change: 1\n",
      "epoch: 247\n",
      "training loss: 1.3271564931891076\n",
      "validation loss: 4.783886091733689\n",
      "num epoch no change: 0\n",
      "epoch: 248\n",
      "training loss: 1.3186225091023533\n",
      "validation loss: 4.824599121166445\n",
      "num epoch no change: 1\n",
      "epoch: 249\n",
      "training loss: 1.3068846925844122\n",
      "validation loss: 4.799996862596936\n",
      "num epoch no change: 0\n",
      "epoch: 250\n",
      "training loss: 1.2989011434721913\n",
      "validation loss: 4.833682831536562\n",
      "num epoch no change: 1\n",
      "epoch: 251\n",
      "training loss: 1.2873096705121858\n",
      "validation loss: 4.816546730202413\n",
      "num epoch no change: 0\n",
      "epoch: 252\n",
      "training loss: 1.2798006997558726\n",
      "validation loss: 4.843802227179272\n",
      "num epoch no change: 1\n",
      "epoch: 253\n",
      "training loss: 1.2683308566628555\n",
      "validation loss: 4.833414656012645\n",
      "num epoch no change: 0\n",
      "epoch: 254\n",
      "training loss: 1.2612299169038172\n",
      "validation loss: 4.854787038106035\n",
      "num epoch no change: 1\n",
      "epoch: 255\n",
      "training loss: 1.2498658052860998\n",
      "validation loss: 4.850494407492313\n",
      "num epoch no change: 0\n",
      "epoch: 256\n",
      "training loss: 1.2431143297379674\n",
      "validation loss: 4.866488565308261\n",
      "num epoch no change: 1\n",
      "epoch: 257\n",
      "training loss: 1.2318476763686594\n",
      "validation loss: 4.8676932999334515\n",
      "num epoch no change: 2\n",
      "epoch: 258\n",
      "training loss: 1.2253938891195764\n",
      "validation loss: 4.878778381094829\n",
      "num epoch no change: 3\n",
      "epoch: 259\n",
      "training loss: 1.2142229931693607\n",
      "validation loss: 4.884931319152651\n",
      "num epoch no change: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 260\n",
      "training loss: 1.2080208511610895\n",
      "validation loss: 4.891547602329574\n",
      "num epoch no change: 5\n",
      "epoch: 261\n",
      "training loss: 1.196949648335299\n",
      "validation loss: 4.902140353477648\n",
      "num epoch no change: 6\n",
      "epoch: 262\n",
      "training loss: 1.1909579277321016\n",
      "validation loss: 4.904706340748669\n",
      "num epoch no change: 7\n",
      "epoch: 263\n",
      "training loss: 1.1799951665854655\n",
      "validation loss: 4.919263348824082\n",
      "num epoch no change: 8\n",
      "epoch: 264\n",
      "training loss: 1.1741767231579399\n",
      "validation loss: 4.91818303999282\n",
      "num epoch no change: 0\n",
      "epoch: 265\n",
      "training loss: 1.163335267351324\n",
      "validation loss: 4.936253341046291\n",
      "num epoch no change: 1\n",
      "epoch: 266\n",
      "training loss: 1.1576565098181941\n",
      "validation loss: 4.931923584870131\n",
      "num epoch no change: 0\n",
      "epoch: 267\n",
      "training loss: 1.1469527947943718\n",
      "validation loss: 4.9530724562767245\n",
      "num epoch no change: 1\n",
      "epoch: 268\n",
      "training loss: 1.1413834098685829\n",
      "validation loss: 4.945890241042159\n",
      "num epoch no change: 0\n",
      "epoch: 269\n",
      "training loss: 1.1308370874265117\n",
      "validation loss: 4.969691046630018\n",
      "num epoch no change: 1\n",
      "epoch: 270\n",
      "training loss: 1.1253500458021186\n",
      "validation loss: 4.960060588563543\n",
      "num epoch no change: 0\n",
      "epoch: 271\n",
      "training loss: 1.114983842129328\n",
      "validation loss: 4.986087121083901\n",
      "num epoch no change: 1\n",
      "epoch: 272\n",
      "training loss: 1.1095556977059955\n",
      "validation loss: 4.974426624166689\n",
      "num epoch no change: 0\n",
      "epoch: 273\n",
      "training loss: 1.0993954903592251\n",
      "validation loss: 5.002246155621616\n",
      "num epoch no change: 1\n",
      "epoch: 274\n",
      "training loss: 1.0940069636691343\n",
      "validation loss: 4.988994139691828\n",
      "num epoch no change: 0\n",
      "epoch: 275\n",
      "training loss: 1.0840820549487924\n",
      "validation loss: 5.018161264830891\n",
      "num epoch no change: 1\n",
      "epoch: 276\n",
      "training loss: 1.0787188692314873\n",
      "validation loss: 5.003782374819018\n",
      "num epoch no change: 0\n",
      "epoch: 277\n",
      "training loss: 1.0690624027286608\n",
      "validation loss: 5.03383363156352\n",
      "num epoch no change: 1\n",
      "epoch: 278\n",
      "training loss: 1.0637163192117642\n",
      "validation loss: 5.018823826291237\n",
      "num epoch no change: 0\n",
      "epoch: 279\n",
      "training loss: 1.0543657567351044\n",
      "validation loss: 5.049273044298803\n",
      "num epoch no change: 1\n",
      "epoch: 280\n",
      "training loss: 1.0490357332417894\n",
      "validation loss: 5.0341639903648225\n",
      "num epoch no change: 0\n",
      "epoch: 281\n",
      "training loss: 1.040033280766852\n",
      "validation loss: 5.064498379158883\n",
      "num epoch no change: 1\n",
      "epoch: 282\n",
      "training loss: 1.034726649856962\n",
      "validation loss: 5.0498607178488495\n",
      "num epoch no change: 0\n",
      "epoch: 283\n",
      "training loss: 1.0261194891484304\n",
      "validation loss: 5.0795378610882524\n",
      "num epoch no change: 1\n",
      "epoch: 284\n",
      "training loss: 1.0208530108160563\n",
      "validation loss: 5.065982757875995\n",
      "num epoch no change: 0\n",
      "epoch: 285\n",
      "training loss: 1.0126931507862422\n",
      "validation loss: 5.094428917029672\n",
      "num epoch no change: 1\n",
      "epoch: 286\n",
      "training loss: 1.007493732309228\n",
      "validation loss: 5.082606944165268\n",
      "num epoch no change: 0\n",
      "epoch: 287\n",
      "training loss: 0.9998372347821326\n",
      "validation loss: 5.109217372023764\n",
      "num epoch no change: 1\n",
      "epoch: 288\n",
      "training loss: 0.9947420227130691\n",
      "validation loss: 5.099813335258623\n",
      "num epoch no change: 0\n",
      "epoch: 289\n",
      "training loss: 0.9876472810919924\n",
      "validation loss: 5.123955634769432\n",
      "num epoch no change: 1\n",
      "epoch: 290\n",
      "training loss: 0.9827027232219834\n",
      "validation loss: 5.117677481187045\n",
      "num epoch no change: 0\n",
      "epoch: 291\n",
      "training loss: 0.9762273923442265\n",
      "validation loss: 5.138699396117308\n",
      "num epoch no change: 1\n",
      "epoch: 292\n",
      "training loss: 0.9714867629061907\n",
      "validation loss: 5.136258911996281\n",
      "num epoch no change: 0\n",
      "epoch: 293\n",
      "training loss: 0.9656828869906701\n",
      "validation loss: 5.153502280214896\n",
      "num epoch no change: 1\n",
      "epoch: 294\n",
      "training loss: 0.9612017134618435\n",
      "validation loss: 5.155585034963703\n",
      "num epoch no change: 2\n",
      "epoch: 295\n",
      "training loss: 0.9561086372631336\n",
      "validation loss: 5.168407946945728\n",
      "num epoch no change: 3\n",
      "epoch: 296\n",
      "training loss: 0.9519375422000859\n",
      "validation loss: 5.175630049332902\n",
      "num epoch no change: 4\n",
      "epoch: 297\n",
      "training loss: 0.947572411962129\n",
      "validation loss: 5.183439505523482\n",
      "num epoch no change: 5\n",
      "epoch: 298\n",
      "training loss: 0.9437472051256087\n",
      "validation loss: 5.196289450795576\n",
      "num epoch no change: 6\n",
      "epoch: 299\n",
      "training loss: 0.9400933923288256\n",
      "validation loss: 5.198586975130169\n",
      "num epoch no change: 7\n",
      "epoch: 300\n",
      "training loss: 0.9366229572999709\n",
      "validation loss: 5.217352421046027\n",
      "num epoch no change: 8\n",
      "epoch: 301\n",
      "training loss: 0.9336176907804615\n",
      "validation loss: 5.2137951378007354\n",
      "num epoch no change: 0\n",
      "epoch: 302\n",
      "training loss: 0.9304714238183089\n",
      "validation loss: 5.238477007428476\n",
      "num epoch no change: 1\n",
      "epoch: 303\n",
      "training loss: 0.9279953458885271\n",
      "validation loss: 5.228956558322714\n",
      "num epoch no change: 0\n",
      "epoch: 304\n",
      "training loss: 0.9250936157860037\n",
      "validation loss: 5.259176354369304\n",
      "num epoch no change: 1\n",
      "epoch: 305\n",
      "training loss: 0.9229667411046842\n",
      "validation loss: 5.2439174690800385\n",
      "num epoch no change: 0\n",
      "epoch: 306\n",
      "training loss: 0.9201797434604155\n",
      "validation loss: 5.278827695547529\n",
      "num epoch no change: 1\n",
      "epoch: 307\n",
      "training loss: 0.9181698798618843\n",
      "validation loss: 5.258506452444103\n",
      "num epoch no change: 0\n",
      "epoch: 308\n",
      "training loss: 0.915331533010613\n",
      "validation loss: 5.296717889057141\n",
      "num epoch no change: 1\n",
      "epoch: 309\n",
      "training loss: 0.913181568673823\n",
      "validation loss: 5.272594906918865\n",
      "num epoch no change: 0\n",
      "epoch: 310\n",
      "training loss: 0.91012423195643\n",
      "validation loss: 5.312137455635331\n",
      "num epoch no change: 1\n",
      "epoch: 311\n",
      "training loss: 0.9076022210475887\n",
      "validation loss: 5.286190422427287\n",
      "num epoch no change: 0\n",
      "epoch: 312\n",
      "training loss: 0.9042130223990779\n",
      "validation loss: 5.324525809015931\n",
      "num epoch no change: 1\n",
      "epoch: 313\n",
      "training loss: 0.9011820866434376\n",
      "validation loss: 5.299546167049023\n",
      "num epoch no change: 0\n",
      "epoch: 314\n",
      "training loss: 0.8974712157827146\n",
      "validation loss: 5.333650077725896\n",
      "num epoch no change: 1\n",
      "epoch: 315\n",
      "training loss: 0.8939645759260532\n",
      "validation loss: 5.313242999801226\n",
      "num epoch no change: 0\n",
      "epoch: 316\n",
      "training loss: 0.8901218844266348\n",
      "validation loss: 5.339768611280607\n",
      "num epoch no change: 1\n",
      "epoch: 317\n",
      "training loss: 0.8863948270343689\n",
      "validation loss: 5.3281790238310505\n",
      "num epoch no change: 0\n",
      "epoch: 318\n",
      "training loss: 0.8828008915484391\n",
      "validation loss: 5.34369874122099\n",
      "num epoch no change: 1\n",
      "epoch: 319\n",
      "training loss: 0.879323707646087\n",
      "validation loss: 5.3454064582454155\n",
      "num epoch no change: 2\n",
      "epoch: 320\n",
      "training loss: 0.8764859127684529\n",
      "validation loss: 5.346703562352125\n",
      "num epoch no change: 3\n",
      "epoch: 321\n",
      "training loss: 0.8738492601654275\n",
      "validation loss: 5.365802640700915\n",
      "num epoch no change: 4\n",
      "epoch: 322\n",
      "training loss: 0.8722568874120408\n",
      "validation loss: 5.350164160153594\n",
      "num epoch no change: 0\n",
      "epoch: 323\n",
      "training loss: 0.8709874007923942\n",
      "validation loss: 5.389632409852496\n",
      "num epoch no change: 1\n",
      "epoch: 324\n",
      "training loss: 0.870912414147623\n",
      "validation loss: 5.355106133359091\n",
      "num epoch no change: 0\n",
      "epoch: 325\n",
      "training loss: 0.8712336627368428\n",
      "validation loss: 5.416110945378764\n",
      "num epoch no change: 1\n",
      "epoch: 326\n",
      "training loss: 0.8725302050684705\n",
      "validation loss: 5.361744041527467\n",
      "num epoch no change: 0\n",
      "epoch: 327\n",
      "training loss: 0.8741377331879613\n",
      "validation loss: 5.443091128595251\n",
      "num epoch no change: 1\n",
      "epoch: 328\n",
      "training loss: 0.8761086529926747\n",
      "validation loss: 5.369243826442035\n",
      "num epoch no change: 0\n",
      "epoch: 329\n",
      "training loss: 0.87805250010039\n",
      "validation loss: 5.46700020384227\n",
      "num epoch no change: 1\n",
      "epoch: 330\n",
      "training loss: 0.8794636176900175\n",
      "validation loss: 5.375909652099537\n",
      "num epoch no change: 0\n",
      "epoch: 331\n",
      "training loss: 0.8802581619688001\n",
      "validation loss: 5.483170968851429\n",
      "num epoch no change: 1\n",
      "epoch: 332\n",
      "training loss: 0.8795942237856275\n",
      "validation loss: 5.380019874641648\n",
      "num epoch no change: 0\n",
      "epoch: 333\n",
      "training loss: 0.877700330115606\n",
      "validation loss: 5.4867980068053415\n",
      "num epoch no change: 1\n",
      "epoch: 334\n",
      "training loss: 0.8737425013453521\n",
      "validation loss: 5.381413533919415\n",
      "num epoch no change: 0\n",
      "epoch: 335\n",
      "training loss: 0.8684779747086813\n",
      "validation loss: 5.474897566615852\n",
      "num epoch no change: 1\n",
      "epoch: 336\n",
      "training loss: 0.8611478704804258\n",
      "validation loss: 5.383191564005512\n",
      "num epoch no change: 0\n",
      "epoch: 337\n",
      "training loss: 0.853611622453097\n",
      "validation loss: 5.449344599603888\n",
      "num epoch no change: 1\n",
      "epoch: 338\n",
      "training loss: 0.8446688895278215\n",
      "validation loss: 5.391543315491925\n",
      "num epoch no change: 0\n",
      "epoch: 339\n",
      "training loss: 0.8376715120224889\n",
      "validation loss: 5.418960536175382\n",
      "num epoch no change: 1\n",
      "epoch: 340\n",
      "training loss: 0.8305183164945057\n",
      "validation loss: 5.412361818815402\n",
      "num epoch no change: 0\n",
      "epoch: 341\n",
      "training loss: 0.8272394331470726\n",
      "validation loss: 5.396253225274821\n",
      "num epoch no change: 0\n",
      "epoch: 342\n",
      "training loss: 0.8254514678411674\n",
      "validation loss: 5.447750050751286\n",
      "num epoch no change: 1\n",
      "epoch: 343\n",
      "training loss: 0.8279086525765317\n",
      "validation loss: 5.389379595906648\n",
      "num epoch no change: 0\n",
      "epoch: 344\n",
      "training loss: 0.8332521643795125\n",
      "validation loss: 5.49530712390326\n",
      "num epoch no change: 1\n",
      "epoch: 345\n",
      "training loss: 0.8414038765601037\n",
      "validation loss: 5.397893495982488\n",
      "num epoch no change: 0\n",
      "epoch: 346\n",
      "training loss: 0.8528936467059794\n",
      "validation loss: 5.548214055339223\n",
      "num epoch no change: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 347\n",
      "training loss: 0.8647258593507872\n",
      "validation loss: 5.41528553320357\n",
      "num epoch no change: 0\n",
      "epoch: 348\n",
      "training loss: 0.8791864334979506\n",
      "validation loss: 5.596506917810948\n",
      "num epoch no change: 1\n",
      "epoch: 349\n",
      "training loss: 0.8915289581308985\n",
      "validation loss: 5.4331525376168806\n",
      "num epoch no change: 0\n",
      "epoch: 350\n",
      "training loss: 0.9047217715613636\n",
      "validation loss: 5.62973426617884\n",
      "num epoch no change: 1\n",
      "epoch: 351\n",
      "training loss: 0.914133754693554\n",
      "validation loss: 5.444217878641879\n",
      "num epoch no change: 0\n",
      "epoch: 352\n",
      "training loss: 0.9219888070339861\n",
      "validation loss: 5.639315022213156\n",
      "num epoch no change: 1\n",
      "epoch: 353\n",
      "training loss: 0.9255730741357129\n",
      "validation loss: 5.44494033607239\n",
      "num epoch no change: 0\n",
      "epoch: 354\n",
      "training loss: 0.9257717897192009\n",
      "validation loss: 5.621588202533678\n",
      "num epoch no change: 1\n",
      "epoch: 355\n",
      "training loss: 0.9221031675785114\n",
      "validation loss: 5.437416643690493\n",
      "num epoch no change: 0\n",
      "epoch: 356\n",
      "training loss: 0.9153527315921346\n",
      "validation loss: 5.582734665577643\n",
      "num epoch no change: 1\n",
      "epoch: 357\n",
      "training loss: 0.9053089263022817\n",
      "validation loss: 5.427390882550875\n",
      "num epoch no change: 0\n",
      "epoch: 358\n",
      "training loss: 0.8946516887711581\n",
      "validation loss: 5.539774849003197\n",
      "num epoch no change: 1\n",
      "epoch: 359\n",
      "training loss: 0.8813747251837695\n",
      "validation loss: 5.4187741481340055\n",
      "num epoch no change: 0\n",
      "epoch: 360\n",
      "training loss: 0.8703017923984937\n",
      "validation loss: 5.508963692942527\n",
      "num epoch no change: 1\n",
      "epoch: 361\n",
      "training loss: 0.8574892793202761\n",
      "validation loss: 5.412781857509663\n",
      "num epoch no change: 0\n",
      "epoch: 362\n",
      "training loss: 0.8484245458161618\n",
      "validation loss: 5.4940760047552315\n",
      "num epoch no change: 1\n",
      "epoch: 363\n",
      "training loss: 0.8381080669184162\n",
      "validation loss: 5.410293381131064\n",
      "num epoch no change: 0\n",
      "epoch: 364\n",
      "training loss: 0.831723033738713\n",
      "validation loss: 5.490382029070128\n",
      "num epoch no change: 1\n",
      "epoch: 365\n",
      "training loss: 0.8239841382290771\n",
      "validation loss: 5.411116590790421\n",
      "num epoch no change: 0\n",
      "epoch: 366\n",
      "training loss: 0.819775859502477\n",
      "validation loss: 5.492329285037128\n",
      "num epoch no change: 1\n",
      "epoch: 367\n",
      "training loss: 0.8138728854947068\n",
      "validation loss: 5.413910125541862\n",
      "num epoch no change: 0\n",
      "epoch: 368\n",
      "training loss: 0.8110823210638325\n",
      "validation loss: 5.496146380623132\n",
      "num epoch no change: 1\n",
      "epoch: 369\n",
      "training loss: 0.8062865867958832\n",
      "validation loss: 5.417262623582772\n",
      "num epoch no change: 0\n",
      "epoch: 370\n",
      "training loss: 0.804341414181805\n",
      "validation loss: 5.499897552898549\n",
      "num epoch no change: 1\n",
      "epoch: 371\n",
      "training loss: 0.8001562726309432\n",
      "validation loss: 5.420345447696454\n",
      "num epoch no change: 0\n",
      "epoch: 372\n",
      "training loss: 0.7987036674717906\n",
      "validation loss: 5.5028645660755275\n",
      "num epoch no change: 1\n",
      "epoch: 373\n",
      "training loss: 0.7948281596045492\n",
      "validation loss: 5.422895660944545\n",
      "num epoch no change: 0\n",
      "epoch: 374\n",
      "training loss: 0.79366097818412\n",
      "validation loss: 5.504928066830655\n",
      "num epoch no change: 1\n",
      "epoch: 375\n",
      "training loss: 0.7899222250382708\n",
      "validation loss: 5.424931195682429\n",
      "num epoch no change: 0\n",
      "epoch: 376\n",
      "training loss: 0.7889205818718685\n",
      "validation loss: 5.5061821186128155\n",
      "num epoch no change: 1\n",
      "epoch: 377\n",
      "training loss: 0.7852253353100822\n",
      "validation loss: 5.426550911338955\n",
      "num epoch no change: 0\n",
      "epoch: 378\n",
      "training loss: 0.7843212524536842\n",
      "validation loss: 5.506771490982947\n",
      "num epoch no change: 1\n",
      "epoch: 379\n",
      "training loss: 0.7806246479407094\n",
      "validation loss: 5.427855795328985\n",
      "num epoch no change: 0\n",
      "epoch: 380\n",
      "training loss: 0.7797810161326044\n",
      "validation loss: 5.506837731405187\n",
      "num epoch no change: 1\n",
      "epoch: 381\n",
      "training loss: 0.77606685185277\n",
      "validation loss: 5.428926889441836\n",
      "num epoch no change: 0\n",
      "epoch: 382\n",
      "training loss: 0.7752648717955418\n",
      "validation loss: 5.5065029362177444\n",
      "num epoch no change: 1\n",
      "epoch: 383\n",
      "training loss: 0.7715333228654825\n",
      "validation loss: 5.429822699157441\n",
      "num epoch no change: 0\n",
      "epoch: 384\n",
      "training loss: 0.7707648241153197\n",
      "validation loss: 5.505866774223232\n",
      "num epoch no change: 1\n",
      "epoch: 385\n",
      "training loss: 0.7670246989417374\n",
      "validation loss: 5.430583050425803\n",
      "num epoch no change: 0\n",
      "epoch: 386\n",
      "training loss: 0.7662873078623121\n",
      "validation loss: 5.505008142846333\n",
      "num epoch no change: 1\n",
      "epoch: 387\n",
      "training loss: 0.7625511576266744\n",
      "validation loss: 5.431233958902704\n",
      "num epoch no change: 0\n",
      "epoch: 388\n",
      "training loss: 0.7618452716657133\n",
      "validation loss: 5.50398800985421\n",
      "num epoch no change: 1\n",
      "epoch: 389\n",
      "training loss: 0.7581264073065482\n",
      "validation loss: 5.431791713889276\n",
      "num epoch no change: 0\n",
      "epoch: 390\n",
      "training loss: 0.7574533809927634\n",
      "validation loss: 5.5028525016625\n",
      "num epoch no change: 1\n",
      "epoch: 391\n",
      "training loss: 0.7537641854998076\n",
      "validation loss: 5.432266001618574\n",
      "num epoch no change: 0\n",
      "epoch: 392\n",
      "training loss: 0.7531253334920249\n",
      "validation loss: 5.501635947807423\n",
      "num epoch no change: 1\n",
      "epoch: 393\n",
      "training loss: 0.7494764351381139\n",
      "validation loss: 5.432662225899508\n",
      "num epoch no change: 0\n",
      "epoch: 394\n",
      "training loss: 0.7488725705057292\n",
      "validation loss: 5.500363686912561\n",
      "num epoch no change: 1\n",
      "epoch: 395\n",
      "training loss: 0.7452725625390914\n",
      "validation loss: 5.432983183540939\n",
      "num epoch no change: 0\n",
      "epoch: 396\n",
      "training loss: 0.7447038650588453\n",
      "validation loss: 5.499054486029596\n",
      "num epoch no change: 1\n",
      "epoch: 397\n",
      "training loss: 0.7411593458930845\n",
      "validation loss: 5.433230227392916\n",
      "num epoch no change: 0\n",
      "epoch: 398\n",
      "training loss: 0.740625414214775\n",
      "validation loss: 5.4977224972734415\n",
      "num epoch no change: 1\n",
      "epoch: 399\n",
      "training loss: 0.737141192111816\n",
      "validation loss: 5.433404032382552\n",
      "num epoch no change: 0\n",
      "epoch: 400\n",
      "training loss: 0.7366411816308528\n",
      "validation loss: 5.496378746710207\n",
      "num epoch no change: 1\n",
      "epoch: 401\n",
      "training loss: 0.7332205433215242\n",
      "validation loss: 5.43350506383871\n",
      "num epoch no change: 0\n",
      "epoch: 402\n",
      "training loss: 0.7327533291756946\n",
      "validation loss: 5.49503220361824\n",
      "num epoch no change: 1\n",
      "epoch: 403\n",
      "training loss: 0.7293983134534919\n",
      "validation loss: 5.433533833551189\n",
      "num epoch no change: 0\n",
      "epoch: 404\n",
      "training loss: 0.7289626452755201\n",
      "validation loss: 5.493690507523972\n",
      "num epoch no change: 1\n",
      "epoch: 405\n",
      "training loss: 0.7256742915139269\n",
      "validation loss: 5.4334910144049475\n",
      "num epoch no change: 0\n",
      "epoch: 406\n",
      "training loss: 0.7252689246857055\n",
      "validation loss: 5.492360437715189\n",
      "num epoch no change: 1\n",
      "epoch: 407\n",
      "training loss: 0.722047484690938\n",
      "validation loss: 5.433377468593116\n",
      "num epoch no change: 0\n",
      "epoch: 408\n",
      "training loss: 0.7216712838437813\n",
      "validation loss: 5.491048202658397\n",
      "num epoch no change: 1\n",
      "epoch: 409\n",
      "training loss: 0.7185163960932076\n",
      "validation loss: 5.433194229051244\n",
      "num epoch no change: 0\n",
      "epoch: 410\n",
      "training loss: 0.7181684125460751\n",
      "validation loss: 5.489759612491721\n",
      "num epoch no change: 1\n",
      "epoch: 411\n",
      "training loss: 0.7150792431544745\n",
      "validation loss: 5.432942460463051\n",
      "num epoch no change: 0\n",
      "epoch: 412\n",
      "training loss: 0.7147587706635462\n",
      "validation loss: 5.488500181981778\n",
      "num epoch no change: 1\n",
      "epoch: 413\n",
      "training loss: 0.7117341273870907\n",
      "validation loss: 5.432623415779671\n",
      "num epoch no change: 0\n",
      "epoch: 414\n",
      "training loss: 0.7114407413489917\n",
      "validation loss: 5.487275197110326\n",
      "num epoch no change: 1\n",
      "epoch: 415\n",
      "training loss: 0.7084791670559745\n",
      "validation loss: 5.432238396750768\n",
      "num epoch no change: 0\n",
      "epoch: 416\n",
      "training loss: 0.708212752087692\n",
      "validation loss: 5.4860897670838895\n",
      "num epoch no change: 1\n",
      "epoch: 417\n",
      "training loss: 0.7053126033737454\n",
      "validation loss: 5.431788722114067\n",
      "num epoch no change: 0\n",
      "epoch: 418\n",
      "training loss: 0.7050733735610696\n",
      "validation loss: 5.484948875219114\n",
      "num epoch no change: 1\n",
      "epoch: 419\n",
      "training loss: 0.7022328891572057\n",
      "validation loss: 5.431275704256821\n",
      "num epoch no change: 0\n",
      "epoch: 420\n",
      "training loss: 0.7020214045482349\n",
      "validation loss: 5.483857436477056\n",
      "num epoch no change: 1\n",
      "epoch: 421\n",
      "training loss: 0.699238767185569\n",
      "validation loss: 5.430700633764761\n",
      "num epoch no change: 0\n",
      "epoch: 422\n",
      "training loss: 0.6990559494732368\n",
      "validation loss: 5.482820365844205\n",
      "num epoch no change: 1\n",
      "epoch: 423\n",
      "training loss: 0.6963293440809114\n",
      "validation loss: 5.43006477081595\n",
      "num epoch no change: 0\n",
      "epoch: 424\n",
      "training loss: 0.696176493940045\n",
      "validation loss: 5.481842659737567\n",
      "num epoch no change: 1\n",
      "epoch: 425\n",
      "training loss: 0.6935041645157468\n",
      "validation loss: 5.429369342487832\n",
      "num epoch no change: 0\n",
      "epoch: 426\n",
      "training loss: 0.6933829827566985\n",
      "validation loss: 5.480929491692835\n",
      "num epoch no change: 1\n",
      "epoch: 427\n",
      "training loss: 0.6907632899652243\n",
      "validation loss: 5.428615545474237\n",
      "num epoch no change: 0\n",
      "epoch: 428\n",
      "training loss: 0.6906759045363342\n",
      "validation loss: 5.480086323439816\n",
      "num epoch no change: 1\n",
      "epoch: 429\n",
      "training loss: 0.6881073860446182\n",
      "validation loss: 5.427804554304293\n",
      "num epoch no change: 0\n",
      "epoch: 430\n",
      "training loss: 0.6880563869531395\n",
      "validation loss: 5.479319032849539\n",
      "num epoch no change: 1\n",
      "epoch: 431\n",
      "training loss: 0.6855378226829922\n",
      "validation loss: 5.426937535843847\n",
      "num epoch no change: 0\n",
      "epoch: 432\n",
      "training loss: 0.6855263071069727\n",
      "validation loss: 5.478634061014709\n",
      "num epoch no change: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 433\n",
      "training loss: 0.6830567919730306\n",
      "validation loss: 5.426015671626947\n",
      "num epoch no change: 0\n",
      "epoch: 434\n",
      "training loss: 0.6830884222139707\n",
      "validation loss: 5.478038581836805\n",
      "num epoch no change: 1\n",
      "epoch: 435\n",
      "training loss: 0.6806674495251389\n",
      "validation loss: 5.425040190440391\n",
      "num epoch no change: 0\n",
      "epoch: 436\n",
      "training loss: 0.6807465270273224\n",
      "validation loss: 5.477540698937058\n",
      "num epoch no change: 1\n",
      "epoch: 437\n",
      "training loss: 0.6783740865999195\n",
      "validation loss: 5.424012414636934\n",
      "num epoch no change: 0\n",
      "epoch: 438\n",
      "training loss: 0.6785056460809199\n",
      "validation loss: 5.477149676539316\n",
      "num epoch no change: 1\n",
      "epoch: 439\n",
      "training loss: 0.6761823423054786\n",
      "validation loss: 5.422933824991455\n",
      "num epoch no change: 0\n",
      "epoch: 440\n",
      "training loss: 0.6763722711728177\n",
      "validation loss: 5.476876213299878\n",
      "num epoch no change: 1\n",
      "epoch: 441\n",
      "training loss: 0.6740994678979365\n",
      "validation loss: 5.421806150694401\n",
      "num epoch no change: 0\n",
      "epoch: 442\n",
      "training loss: 0.6743546576726958\n",
      "validation loss: 5.47673277105652\n",
      "num epoch no change: 1\n",
      "epoch: 443\n",
      "training loss: 0.6721346589754965\n",
      "validation loss: 5.420631493520999\n",
      "num epoch no change: 0\n",
      "epoch: 444\n",
      "training loss: 0.6724631975556918\n",
      "validation loss: 5.476733974392595\n",
      "num epoch no change: 1\n",
      "epoch: 445\n",
      "training loss: 0.670299476490974\n",
      "validation loss: 5.419412498639318\n",
      "num epoch no change: 0\n",
      "epoch: 446\n",
      "training loss: 0.6707108929841337\n",
      "validation loss: 5.4768971021273085\n",
      "num epoch no change: 1\n",
      "epoch: 447\n",
      "training loss: 0.6686083845824085\n",
      "validation loss: 5.418152589386623\n",
      "num epoch no change: 0\n",
      "epoch: 448\n",
      "training loss: 0.6691139624345371\n",
      "validation loss: 5.477242698874907\n",
      "num epoch no change: 1\n",
      "epoch: 449\n",
      "training loss: 0.6670794430508833\n",
      "validation loss: 5.416856290331091\n",
      "num epoch no change: 0\n",
      "epoch: 450\n",
      "training loss: 0.6676926227595674\n",
      "validation loss: 5.477795344413537\n",
      "num epoch no change: 1\n",
      "epoch: 451\n",
      "training loss: 0.66573520609634\n",
      "validation loss: 5.415529673063694\n",
      "num epoch no change: 0\n",
      "epoch: 452\n",
      "training loss: 0.6664721065977025\n",
      "validation loss: 5.478584631853074\n",
      "num epoch no change: 1\n",
      "epoch: 453\n",
      "training loss: 0.6646038984317417\n",
      "validation loss: 5.414180973976158\n",
      "num epoch no change: 0\n",
      "epoch: 454\n",
      "training loss: 0.6654839973008608\n",
      "validation loss: 5.479646424067745\n",
      "num epoch no change: 1\n",
      "epoch: 455\n",
      "training loss: 0.6637209677923368\n",
      "validation loss: 5.412821455148192\n",
      "num epoch no change: 0\n",
      "epoch: 456\n",
      "training loss: 0.6647679962019248\n",
      "validation loss: 5.481024483879848\n",
      "num epoch no change: 1\n",
      "epoch: 457\n",
      "training loss: 0.6631311531629149\n",
      "validation loss: 5.4114666120731085\n",
      "num epoch no change: 0\n",
      "epoch: 458\n",
      "training loss: 0.664374284383986\n",
      "validation loss: 5.482772610466046\n",
      "num epoch no change: 1\n",
      "epoch: 459\n",
      "training loss: 0.6628912669120474\n",
      "validation loss: 5.410137881081396\n",
      "num epoch no change: 0\n",
      "epoch: 460\n",
      "training loss: 0.6643667104887272\n",
      "validation loss: 5.48495746749704\n",
      "num epoch no change: 1\n",
      "epoch: 461\n",
      "training loss: 0.6630739759481977\n",
      "validation loss: 5.408865074166157\n",
      "num epoch no change: 0\n",
      "epoch: 462\n",
      "training loss: 0.6648271388830838\n",
      "validation loss: 5.487662365214\n",
      "num epoch no change: 1\n",
      "epoch: 463\n",
      "training loss: 0.6637729968166538\n",
      "validation loss: 5.407689884221065\n",
      "num epoch no change: 0\n",
      "epoch: 464\n",
      "training loss: 0.665861446443554\n",
      "validation loss: 5.490992370354609\n",
      "num epoch no change: 1\n",
      "epoch: 465\n",
      "training loss: 0.6651103156582512\n",
      "validation loss: 5.406670983383548\n",
      "num epoch no change: 0\n",
      "epoch: 466\n",
      "training loss: 0.6676078892367144\n",
      "validation loss: 5.49508128149294\n",
      "num epoch no change: 1\n",
      "epoch: 467\n",
      "training loss: 0.6672463431103481\n",
      "validation loss: 5.405891520340879\n",
      "num epoch no change: 0\n",
      "epoch: 468\n",
      "training loss: 0.6702489165928753\n",
      "validation loss: 5.500101247847324\n",
      "num epoch no change: 1\n",
      "epoch: 469\n",
      "training loss: 0.6703943753621183\n",
      "validation loss: 5.405470273485063\n",
      "num epoch no change: 0\n",
      "epoch: 470\n",
      "training loss: 0.6740280592197161\n",
      "validation loss: 5.506276162526998\n",
      "num epoch no change: 1\n",
      "epoch: 471\n",
      "training loss: 0.6748414491558321\n",
      "validation loss: 5.405578441955159\n",
      "num epoch no change: 0\n",
      "epoch: 472\n",
      "training loss: 0.6792743694398355\n",
      "validation loss: 5.513900474322756\n",
      "num epoch no change: 1\n",
      "epoch: 473\n",
      "training loss: 0.6809787975225756\n",
      "validation loss: 5.4064652305312615\n",
      "num epoch no change: 0\n",
      "epoch: 474\n",
      "training loss: 0.6864382129874353\n",
      "validation loss: 5.5233657906460225\n",
      "num epoch no change: 1\n",
      "epoch: 475\n",
      "training loss: 0.6893468588850395\n",
      "validation loss: 5.408497289248076\n",
      "num epoch no change: 0\n",
      "epoch: 476\n",
      "training loss: 0.6961442464873714\n",
      "validation loss: 5.5351986240536695\n",
      "num epoch no change: 1\n",
      "epoch: 477\n",
      "training loss: 0.700702484565756\n",
      "validation loss: 5.4122201413816535\n",
      "num epoch no change: 0\n",
      "epoch: 478\n",
      "training loss: 0.7092704718226023\n",
      "validation loss: 5.550113791559664\n",
      "num epoch no change: 1\n",
      "epoch: 479\n",
      "training loss: 0.7161200076238663\n",
      "validation loss: 5.41845458333651\n",
      "num epoch no change: 0\n",
      "epoch: 480\n",
      "training loss: 0.727066581807178\n",
      "validation loss: 5.5690888530787745\n",
      "num epoch no change: 1\n",
      "epoch: 481\n",
      "training loss: 0.7371433633439046\n",
      "validation loss: 5.428448282297477\n",
      "num epoch no change: 0\n",
      "epoch: 482\n",
      "training loss: 0.7513300343068339\n",
      "validation loss: 5.593463980299082\n",
      "num epoch no change: 1\n",
      "epoch: 483\n",
      "training loss: 0.7660124914693553\n",
      "validation loss: 5.44411217267331\n",
      "num epoch no change: 0\n",
      "epoch: 484\n",
      "training loss: 0.7846616149089066\n",
      "validation loss: 5.625064074228165\n",
      "num epoch no change: 1\n",
      "epoch: 485\n",
      "training loss: 0.8059883972745493\n",
      "validation loss: 5.468378366710712\n",
      "num epoch no change: 0\n",
      "epoch: 486\n",
      "training loss: 0.8308129773308229\n",
      "validation loss: 5.666313156503409\n",
      "num epoch no change: 1\n",
      "epoch: 487\n",
      "training loss: 0.8617781497070258\n",
      "validation loss: 5.505702250514466\n",
      "num epoch no change: 0\n",
      "epoch: 488\n",
      "training loss: 0.8950833992021519\n",
      "validation loss: 5.720234239596909\n",
      "num epoch no change: 1\n",
      "epoch: 489\n",
      "training loss: 0.9399552564874797\n",
      "validation loss: 5.5626338928378845\n",
      "num epoch no change: 0\n",
      "epoch: 490\n",
      "training loss: 0.984531677942809\n",
      "validation loss: 5.790037506674173\n",
      "num epoch no change: 1\n",
      "epoch: 491\n",
      "training loss: 1.0489311040674905\n",
      "validation loss: 5.648032137463265\n",
      "num epoch no change: 0\n",
      "epoch: 492\n",
      "training loss: 1.1072448794971683\n",
      "validation loss: 5.877612938379583\n",
      "num epoch no change: 1\n",
      "epoch: 493\n",
      "training loss: 1.1971650104474323\n",
      "validation loss: 5.771538511426445\n",
      "num epoch no change: 0\n",
      "epoch: 494\n",
      "training loss: 1.2688052988430123\n",
      "validation loss: 5.979756661839249\n",
      "num epoch no change: 1\n",
      "epoch: 495\n",
      "training loss: 1.3867431852522594\n",
      "validation loss: 5.937129641582531\n",
      "num epoch no change: 0\n",
      "epoch: 496\n",
      "training loss: 1.4628933250209075\n",
      "validation loss: 6.081376835117955\n",
      "num epoch no change: 1\n",
      "epoch: 497\n",
      "training loss: 1.598983068013665\n",
      "validation loss: 6.127824528641584\n",
      "num epoch no change: 2\n",
      "epoch: 498\n",
      "training loss: 1.655345957539421\n",
      "validation loss: 6.148902215259135\n",
      "num epoch no change: 3\n",
      "epoch: 499\n",
      "training loss: 1.7769397232412518\n",
      "validation loss: 6.2862489521709515\n",
      "num epoch no change: 4\n",
      "epoch: 500\n",
      "training loss: 1.7750021540226972\n",
      "validation loss: 6.135113914128149\n",
      "num epoch no change: 0\n",
      "epoch: 501\n",
      "training loss: 1.8332439458116518\n",
      "validation loss: 6.320855923763675\n",
      "num epoch no change: 1\n",
      "epoch: 502\n",
      "training loss: 1.744556784121151\n",
      "validation loss: 6.007063627709972\n",
      "num epoch no change: 0\n",
      "epoch: 503\n",
      "training loss: 1.7135451711185654\n",
      "validation loss: 6.171569547109842\n",
      "num epoch no change: 1\n",
      "epoch: 504\n",
      "training loss: 1.5549201412817073\n",
      "validation loss: 5.785330144539676\n",
      "num epoch no change: 0\n",
      "epoch: 505\n",
      "training loss: 1.4629963496579437\n",
      "validation loss: 5.88580854046729\n",
      "num epoch no change: 1\n",
      "epoch: 506\n",
      "training loss: 1.2915698577964947\n",
      "validation loss: 5.546464095992763\n",
      "num epoch no change: 0\n",
      "epoch: 507\n",
      "training loss: 1.1922688754572408\n",
      "validation loss: 5.589614738402399\n",
      "num epoch no change: 1\n",
      "epoch: 508\n",
      "training loss: 1.0554366929369101\n",
      "validation loss: 5.363689703169982\n",
      "num epoch no change: 0\n",
      "epoch: 509\n",
      "training loss: 0.9803497921994584\n",
      "validation loss: 5.375108131958697\n",
      "num epoch no change: 1\n",
      "epoch: 510\n",
      "training loss: 0.8888730102214625\n",
      "validation loss: 5.2567028217550105\n",
      "num epoch no change: 0\n",
      "epoch: 511\n",
      "training loss: 0.8409994551640858\n",
      "validation loss: 5.253592235787689\n",
      "num epoch no change: 0\n",
      "epoch: 512\n",
      "training loss: 0.784226771265767\n",
      "validation loss: 5.205937750512789\n",
      "num epoch no change: 0\n",
      "epoch: 513\n",
      "training loss: 0.7554752990510986\n",
      "validation loss: 5.1958890902189685\n",
      "num epoch no change: 0\n",
      "epoch: 514\n",
      "training loss: 0.7204211188240572\n",
      "validation loss: 5.186975919377459\n",
      "num epoch no change: 0\n",
      "epoch: 515\n",
      "training loss: 0.7030648670126122\n",
      "validation loss: 5.173403270306464\n",
      "num epoch no change: 0\n",
      "epoch: 516\n",
      "training loss: 0.6807685079611494\n",
      "validation loss: 5.184192794387064\n",
      "num epoch no change: 1\n",
      "epoch: 517\n",
      "training loss: 0.6698846451495869\n",
      "validation loss: 5.16885512295341\n",
      "num epoch no change: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 518\n",
      "training loss: 0.6550965794530405\n",
      "validation loss: 5.189510584422389\n",
      "num epoch no change: 1\n",
      "epoch: 519\n",
      "training loss: 0.6478981495399674\n",
      "validation loss: 5.17336200134245\n",
      "num epoch no change: 0\n",
      "epoch: 520\n",
      "training loss: 0.6376589821471463\n",
      "validation loss: 5.198918275442526\n",
      "num epoch no change: 1\n",
      "epoch: 521\n",
      "training loss: 0.6326051189587295\n",
      "validation loss: 5.18249365383381\n",
      "num epoch no change: 0\n",
      "epoch: 522\n",
      "training loss: 0.6252267330926891\n",
      "validation loss: 5.210352260994561\n",
      "num epoch no change: 1\n",
      "epoch: 523\n",
      "training loss: 0.6214558518841443\n",
      "validation loss: 5.193957586384416\n",
      "num epoch no change: 0\n",
      "epoch: 524\n",
      "training loss: 0.6159456494661267\n",
      "validation loss: 5.222687438124484\n",
      "num epoch no change: 1\n",
      "epoch: 525\n",
      "training loss: 0.6129650598189408\n",
      "validation loss: 5.2064904918647406\n",
      "num epoch no change: 0\n",
      "epoch: 526\n",
      "training loss: 0.6087182582502657\n",
      "validation loss: 5.235271743029296\n",
      "num epoch no change: 1\n",
      "epoch: 527\n",
      "training loss: 0.6062390307781638\n",
      "validation loss: 5.219351155246307\n",
      "num epoch no change: 0\n",
      "epoch: 528\n",
      "training loss: 0.6028737740566537\n",
      "validation loss: 5.247705705972111\n",
      "num epoch no change: 1\n",
      "epoch: 529\n",
      "training loss: 0.600722124889316\n",
      "validation loss: 5.232084050974312\n",
      "num epoch no change: 0\n",
      "epoch: 530\n",
      "training loss: 0.5979891563085018\n",
      "validation loss: 5.259736656050424\n",
      "num epoch no change: 1\n",
      "epoch: 531\n",
      "training loss: 0.5960579832452936\n",
      "validation loss: 5.244404061229841\n",
      "num epoch no change: 0\n",
      "epoch: 532\n",
      "training loss: 0.5937896397749753\n",
      "validation loss: 5.27120591843998\n",
      "num epoch no change: 1\n",
      "epoch: 533\n",
      "training loss: 0.5920114044840068\n",
      "validation loss: 5.256135654598608\n",
      "num epoch no change: 0\n",
      "epoch: 534\n",
      "training loss: 0.5900918462258672\n",
      "validation loss: 5.282019158100454\n",
      "num epoch no change: 1\n",
      "epoch: 535\n",
      "training loss: 0.5884230279916113\n",
      "validation loss: 5.26717703728573\n",
      "num epoch no change: 0\n",
      "epoch: 536\n",
      "training loss: 0.586770289960038\n",
      "validation loss: 5.292127207441415\n",
      "num epoch no change: 1\n",
      "epoch: 537\n",
      "training loss: 0.5851822609909577\n",
      "validation loss: 5.277476914985345\n",
      "num epoch no change: 0\n",
      "epoch: 538\n",
      "training loss: 0.5837371022886273\n",
      "validation loss: 5.301512644784544\n",
      "num epoch no change: 1\n",
      "epoch: 539\n",
      "training loss: 0.582210653469\n",
      "validation loss: 5.287018611406015\n",
      "num epoch no change: 0\n",
      "epoch: 540\n",
      "training loss: 0.5809294382906743\n",
      "validation loss: 5.310180124459118\n",
      "num epoch no change: 1\n",
      "epoch: 541\n",
      "training loss: 0.5794514278761546\n",
      "validation loss: 5.295808946040476\n",
      "num epoch no change: 0\n",
      "epoch: 542\n",
      "training loss: 0.5783014666788875\n",
      "validation loss: 5.318149343666725\n",
      "num epoch no change: 1\n",
      "epoch: 543\n",
      "training loss: 0.5768627298935546\n",
      "validation loss: 5.303870358952383\n",
      "num epoch no change: 0\n",
      "epoch: 544\n",
      "training loss: 0.5758191608126914\n",
      "validation loss: 5.32544991872063\n",
      "num epoch no change: 1\n",
      "epoch: 545\n",
      "training loss: 0.5744131831161782\n",
      "validation loss: 5.311235313267799\n",
      "num epoch no change: 0\n",
      "epoch: 546\n",
      "training loss: 0.573456840715268\n",
      "validation loss: 5.332117664255314\n",
      "num epoch no change: 1\n",
      "epoch: 547\n",
      "training loss: 0.5720789020312131\n",
      "validation loss: 5.317942319955276\n",
      "num epoch no change: 0\n",
      "epoch: 548\n",
      "training loss: 0.5711948328832281\n",
      "validation loss: 5.338191907961563\n",
      "num epoch no change: 1\n",
      "epoch: 549\n",
      "training loss: 0.5698414471908165\n",
      "validation loss: 5.324033126440903\n",
      "num epoch no change: 0\n",
      "epoch: 550\n",
      "training loss: 0.569017857814473\n",
      "validation loss: 5.343713568769899\n",
      "num epoch no change: 1\n",
      "epoch: 551\n",
      "training loss: 0.567686400905004\n",
      "validation loss: 5.329550743013235\n",
      "num epoch no change: 0\n",
      "epoch: 552\n",
      "training loss: 0.5669139000970944\n",
      "validation loss: 5.348723796892236\n",
      "num epoch no change: 1\n",
      "epoch: 553\n",
      "training loss: 0.5656023589845952\n",
      "validation loss: 5.334538073715578\n",
      "num epoch no change: 0\n",
      "epoch: 554\n",
      "training loss: 0.5648734040677614\n",
      "validation loss: 5.353263027082067\n",
      "num epoch no change: 1\n",
      "epoch: 555\n",
      "training loss: 0.5635802061582839\n",
      "validation loss: 5.33903698417467\n",
      "num epoch no change: 0\n",
      "epoch: 556\n",
      "training loss: 0.5628886927265387\n",
      "validation loss: 5.357370335719278\n",
      "num epoch no change: 1\n",
      "epoch: 557\n",
      "training loss: 0.561612587977443\n",
      "validation loss: 5.343087685485545\n",
      "num epoch no change: 0\n",
      "epoch: 558\n",
      "training loss: 0.5609535421174211\n",
      "validation loss: 5.361083021038233\n",
      "num epoch no change: 1\n",
      "epoch: 559\n",
      "training loss: 0.5596935208505126\n",
      "validation loss: 5.346728346480195\n",
      "num epoch no change: 0\n",
      "epoch: 560\n",
      "training loss: 0.5590628655498657\n",
      "validation loss: 5.36443634677339\n",
      "num epoch no change: 1\n",
      "epoch: 561\n",
      "training loss: 0.5578181005462385\n",
      "validation loss: 5.349994870476359\n",
      "num epoch no change: 0\n",
      "epoch: 562\n",
      "training loss: 0.5572124764972204\n",
      "validation loss: 5.367463404854936\n",
      "num epoch no change: 1\n",
      "epoch: 563\n",
      "training loss: 0.5559822818225977\n",
      "validation loss: 5.352920789741619\n",
      "num epoch no change: 0\n",
      "epoch: 564\n",
      "training loss: 0.5553989085852155\n",
      "validation loss: 5.370195064109144\n",
      "num epoch no change: 1\n",
      "epoch: 565\n",
      "training loss: 0.5541827100734936\n",
      "validation loss: 5.35553724335471\n",
      "num epoch no change: 0\n",
      "epoch: 566\n",
      "training loss: 0.553619277518221\n",
      "validation loss: 5.372659980314119\n",
      "num epoch no change: 1\n",
      "epoch: 567\n",
      "training loss: 0.5524165914686285\n",
      "validation loss: 5.357873013244488\n",
      "num epoch no change: 0\n",
      "epoch: 568\n",
      "training loss: 0.5518711741732637\n",
      "validation loss: 5.374884649219204\n",
      "num epoch no change: 1\n",
      "epoch: 569\n",
      "training loss: 0.5506815918976513\n",
      "validation loss: 5.359954599873463\n",
      "num epoch no change: 0\n",
      "epoch: 570\n",
      "training loss: 0.550152581115143\n",
      "validation loss: 5.376893488820832\n",
      "num epoch no change: 1\n",
      "epoch: 571\n",
      "training loss: 0.5489757576978945\n",
      "validation loss: 5.36180632396849\n",
      "num epoch no change: 0\n",
      "epoch: 572\n",
      "training loss: 0.5484618068975001\n",
      "validation loss: 5.378708940704678\n",
      "num epoch no change: 1\n",
      "epoch: 573\n",
      "training loss: 0.5472974530231204\n",
      "validation loss: 5.363450444356024\n",
      "num epoch no change: 0\n",
      "epoch: 574\n",
      "training loss: 0.5467974340065708\n",
      "validation loss: 5.380351582910893\n",
      "num epoch no change: 1\n",
      "epoch: 575\n",
      "training loss: 0.5456453100475362\n",
      "validation loss: 5.364907284671553\n",
      "num epoch no change: 0\n",
      "epoch: 576\n",
      "training loss: 0.5451582773700948\n",
      "validation loss: 5.3818402487733445\n",
      "num epoch no change: 1\n",
      "epoch: 577\n",
      "training loss: 0.5440181891609609\n",
      "validation loss: 5.366195363728633\n",
      "num epoch no change: 0\n",
      "epoch: 578\n",
      "training loss: 0.5435433511231107\n",
      "validation loss: 5.3831921476874784\n",
      "num epoch no change: 1\n",
      "epoch: 579\n",
      "training loss: 0.5424151470096918\n",
      "validation loss: 5.367331525831738\n",
      "num epoch no change: 0\n",
      "epoch: 580\n",
      "training loss: 0.5419518418830741\n",
      "validation loss: 5.384422984894736\n",
      "num epoch no change: 1\n",
      "epoch: 581\n",
      "training loss: 0.5408354107499637\n",
      "validation loss: 5.368331068431527\n",
      "num epoch no change: 0\n",
      "epoch: 582\n",
      "training loss: 0.5403830871992323\n",
      "validation loss: 5.385547078224845\n",
      "num epoch no change: 1\n",
      "epoch: 583\n",
      "training loss: 0.5392783572599567\n",
      "validation loss: 5.369207865348544\n",
      "num epoch no change: 0\n",
      "epoch: 584\n",
      "training loss: 0.5388365581472054\n",
      "validation loss: 5.3865774703792795\n",
      "num epoch no change: 1\n",
      "epoch: 585\n",
      "training loss: 0.5377434963390063\n",
      "validation loss: 5.369974484404584\n",
      "num epoch no change: 0\n",
      "epoch: 586\n",
      "training loss: 0.5373118452685813\n",
      "validation loss: 5.38752603581966\n",
      "num epoch no change: 1\n",
      "epoch: 587\n",
      "training loss: 0.536230457135063\n",
      "validation loss: 5.370642298753519\n",
      "num epoch no change: 0\n",
      "epoch: 588\n",
      "training loss: 0.535808647227634\n",
      "validation loss: 5.388403581683957\n",
      "num epoch no change: 1\n",
      "epoch: 589\n",
      "training loss: 0.53473897720206\n",
      "validation loss: 5.371221591536028\n",
      "num epoch no change: 0\n",
      "epoch: 590\n",
      "training loss: 0.5343267616877805\n",
      "validation loss: 5.389219942418954\n",
      "num epoch no change: 1\n",
      "epoch: 591\n",
      "training loss: 0.5332688937109282\n",
      "validation loss: 5.371721653724365\n",
      "num epoch no change: 0\n",
      "epoch: 592\n",
      "training loss: 0.5328660780096725\n",
      "validation loss: 5.389984068012276\n",
      "num epoch no change: 1\n",
      "epoch: 593\n",
      "training loss: 0.5318201364311357\n",
      "validation loss: 5.372150875197564\n",
      "num epoch no change: 0\n",
      "epoch: 594\n",
      "training loss: 0.5314265714485342\n",
      "validation loss: 5.39070410584814\n",
      "num epoch no change: 1\n",
      "epoch: 595\n",
      "training loss: 0.5303927221707683\n",
      "validation loss: 5.372516829210322\n",
      "num epoch no change: 0\n",
      "epoch: 596\n",
      "training loss: 0.5300082985860373\n",
      "validation loss: 5.391387476310183\n",
      "num epoch no change: 1\n",
      "epoch: 597\n",
      "training loss: 0.5289867504174295\n",
      "validation loss: 5.372826350503038\n",
      "num epoch no change: 0\n",
      "epoch: 598\n",
      "training loss: 0.528611393775794\n",
      "validation loss: 5.392040942322178\n",
      "num epoch no change: 1\n",
      "epoch: 599\n",
      "training loss: 0.527602399963324\n",
      "validation loss: 5.373085607355655\n",
      "num epoch no change: 0\n",
      "epoch: 600\n",
      "training loss: 0.5272360664143788\n",
      "validation loss: 5.392670673060807\n",
      "num epoch no change: 1\n",
      "epoch: 601\n",
      "training loss: 0.5262399263285731\n",
      "validation loss: 5.373300167921197\n",
      "num epoch no change: 0\n",
      "epoch: 602\n",
      "training loss: 0.5258825988739044\n",
      "validation loss: 5.393282302098836\n",
      "num epoch no change: 1\n",
      "epoch: 603\n",
      "training loss: 0.5248996598191263\n",
      "validation loss: 5.373475061191252\n",
      "num epoch no change: 0\n",
      "epoch: 604\n",
      "training loss: 0.524551344949172\n",
      "validation loss: 5.393880980247314\n",
      "num epoch no change: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 605\n",
      "training loss: 0.5235820040710725\n",
      "validation loss: 5.373614832949665\n",
      "num epoch no change: 0\n",
      "epoch: 606\n",
      "training loss: 0.5232427286835378\n",
      "validation loss: 5.394471423364223\n",
      "num epoch no change: 1\n",
      "epoch: 607\n",
      "training loss: 0.5222874349428174\n",
      "validation loss: 5.3737235970652195\n",
      "num epoch no change: 0\n",
      "epoch: 608\n",
      "training loss: 0.5219572434437112\n",
      "validation loss: 5.395057955387716\n",
      "num epoch no change: 1\n",
      "epoch: 609\n",
      "training loss: 0.5210164996213307\n",
      "validation loss: 5.3738050824609775\n",
      "num epoch no change: 0\n",
      "epoch: 610\n",
      "training loss: 0.5206954511153976\n",
      "validation loss: 5.395644546836067\n",
      "num epoch no change: 1\n",
      "epoch: 611\n",
      "training loss: 0.5197698158090259\n",
      "validation loss: 5.373862676079781\n",
      "num epoch no change: 0\n",
      "epoch: 612\n",
      "training loss: 0.5194579812895336\n",
      "validation loss: 5.396234848995773\n",
      "num epoch no change: 1\n",
      "epoch: 613\n",
      "training loss: 0.5185480708542999\n",
      "validation loss: 5.3738994621428215\n",
      "num epoch no change: 0\n",
      "epoch: 614\n",
      "training loss: 0.5182455303031033\n",
      "validation loss: 5.396832223994956\n",
      "num epoch no change: 1\n",
      "epoch: 615\n",
      "training loss: 0.5173520206816522\n",
      "validation loss: 5.373918257972159\n",
      "num epoch no change: 0\n",
      "epoch: 616\n",
      "training loss: 0.5170588599895634\n",
      "validation loss: 5.397439770932252\n",
      "num epoch no change: 1\n",
      "epoch: 617\n",
      "training loss: 0.5161824883669031\n",
      "validation loss: 5.373921646619781\n",
      "num epoch no change: 0\n",
      "epoch: 618\n",
      "training loss: 0.5158987959818915\n",
      "validation loss: 5.398060348203001\n",
      "num epoch no change: 1\n",
      "epoch: 619\n",
      "training loss: 0.5150403621895617\n",
      "validation loss: 5.373912006515298\n",
      "num epoch no change: 0\n",
      "epoch: 620\n",
      "training loss: 0.5147662253964964\n",
      "validation loss: 5.398696592135175\n",
      "num epoch no change: 1\n",
      "epoch: 621\n",
      "training loss: 0.5139265929781556\n",
      "validation loss: 5.373891538312098\n",
      "num epoch no change: 0\n",
      "epoch: 622\n",
      "training loss: 0.5136620937089715\n",
      "validation loss: 5.39935093201816\n",
      "num epoch no change: 1\n",
      "epoch: 623\n",
      "training loss: 0.5128421905455887\n",
      "validation loss: 5.373862289078724\n",
      "num epoch no change: 0\n",
      "epoch: 624\n",
      "training loss: 0.5125874006132175\n",
      "validation loss: 5.400025601578946\n",
      "num epoch no change: 1\n",
      "epoch: 625\n",
      "training loss: 0.5117882189907713\n",
      "validation loss: 5.373826173947506\n",
      "num epoch no change: 0\n",
      "epoch: 626\n",
      "training loss: 0.5115431946343841\n",
      "validation loss: 5.400722646933276\n",
      "num epoch no change: 1\n",
      "epoch: 627\n",
      "training loss: 0.5107657906203824\n",
      "validation loss: 5.373784995297866\n",
      "num epoch no change: 0\n",
      "epoch: 628\n",
      "training loss: 0.5105305662438699\n",
      "validation loss: 5.401443931015149\n",
      "num epoch no change: 1\n",
      "epoch: 629\n",
      "training loss: 0.5097760582214107\n",
      "validation loss: 5.373740459516232\n",
      "num epoch no change: 0\n",
      "epoch: 630\n",
      "training loss: 0.5095506392022395\n",
      "validation loss: 5.402191134467683\n",
      "num epoch no change: 1\n",
      "epoch: 631\n",
      "training loss: 0.508820205392058\n",
      "validation loss: 5.373694191339854\n",
      "num epoch no change: 0\n",
      "epoch: 632\n",
      "training loss: 0.5086045598344308\n",
      "validation loss: 5.402965752963071\n",
      "num epoch no change: 1\n",
      "epoch: 633\n",
      "training loss: 0.5078994346169565\n",
      "validation loss: 5.373647745758106\n",
      "num epoch no change: 0\n",
      "epoch: 634\n",
      "training loss: 0.5076934839224728\n",
      "validation loss: 5.403769090911373\n",
      "num epoch no change: 1\n",
      "epoch: 635\n",
      "training loss: 0.5070149527540807\n",
      "validation loss: 5.373602617412846\n",
      "num epoch no change: 0\n",
      "epoch: 636\n",
      "training loss: 0.5068185608860448\n",
      "validation loss: 5.404602251518474\n",
      "num epoch no change: 1\n",
      "epoch: 637\n",
      "training loss: 0.5061679535874086\n",
      "validation loss: 5.373560247411367\n",
      "num epoch no change: 0\n",
      "epoch: 638\n",
      "training loss: 0.5059809149128515\n",
      "validation loss: 5.405466123165497\n",
      "num epoch no change: 1\n",
      "epoch: 639\n",
      "training loss: 0.5053595970938548\n",
      "validation loss: 5.373522027441648\n",
      "num epoch no change: 0\n",
      "epoch: 640\n",
      "training loss: 0.5051816227018934\n",
      "validation loss: 5.406361362107702\n",
      "num epoch no change: 1\n",
      "epoch: 641\n",
      "training loss: 0.5045909850785085\n",
      "validation loss: 5.373489301063348\n",
      "num epoch no change: 0\n",
      "epoch: 642\n",
      "training loss: 0.5044216874966618\n",
      "validation loss: 5.4072883715333555\n",
      "num epoch no change: 1\n",
      "epoch: 643\n",
      "training loss: 0.5038631328525646\n",
      "validation loss: 5.37346336204062\n",
      "num epoch no change: 0\n",
      "epoch: 644\n",
      "training loss: 0.5037020091161968\n",
      "validation loss: 5.4082472770853425\n",
      "num epoch no change: 1\n",
      "epoch: 645\n",
      "training loss: 0.5031769366679514\n",
      "validation loss: 5.373445449588337\n",
      "num epoch no change: 0\n",
      "epoch: 646\n",
      "training loss: 0.5030233497443184\n",
      "validation loss: 5.409237899033613\n",
      "num epoch no change: 1\n",
      "epoch: 647\n",
      "training loss: 0.5025331366865383\n",
      "validation loss: 5.3734367404241015\n",
      "num epoch no change: 0\n",
      "epoch: 648\n",
      "training loss: 0.5023862953163637\n",
      "validation loss: 5.410259721398379\n",
      "num epoch no change: 1\n",
      "epoch: 649\n",
      "training loss: 0.5019322753553689\n",
      "validation loss: 5.373438337559141\n",
      "num epoch no change: 0\n",
      "epoch: 650\n",
      "training loss: 0.5017912124537333\n",
      "validation loss: 5.411311858464337\n",
      "num epoch no change: 1\n",
      "epoch: 651\n",
      "training loss: 0.5013746511883064\n",
      "validation loss: 5.373451255824857\n",
      "num epoch no change: 0\n",
      "epoch: 652\n",
      "training loss: 0.5012382010449161\n",
      "validation loss: 5.41239301929807\n",
      "num epoch no change: 1\n",
      "epoch: 653\n",
      "training loss: 0.5008602681242736\n",
      "validation loss: 5.373476404223289\n",
      "num epoch no change: 0\n",
      "epoch: 654\n",
      "training loss: 0.5007270427624254\n",
      "validation loss: 5.4135014710840546\n",
      "num epoch no change: 1\n",
      "epoch: 655\n",
      "training loss: 0.5003887808478696\n",
      "validation loss: 5.373514565311512\n",
      "num epoch no change: 0\n",
      "epoch: 656\n",
      "training loss: 0.5002571460421955\n",
      "validation loss: 5.414635002328902\n",
      "num epoch no change: 1\n",
      "epoch: 657\n",
      "training loss: 0.4999594367230734\n",
      "validation loss: 5.373566371985462\n",
      "num epoch no change: 0\n",
      "epoch: 658\n",
      "training loss: 0.4998274883376809\n",
      "validation loss: 5.415790887244254\n",
      "num epoch no change: 1\n",
      "epoch: 659\n",
      "training loss: 0.4995710153063755\n",
      "validation loss: 5.373632282218156\n",
      "num epoch no change: 0\n",
      "epoch: 660\n",
      "training loss: 0.4994365567946488\n",
      "validation loss: 5.416965852899314\n",
      "num epoch no change: 1\n",
      "epoch: 661\n",
      "training loss: 0.49922176677002034\n",
      "validation loss: 5.373712552529437\n",
      "num epoch no change: 0\n",
      "epoch: 662\n",
      "training loss: 0.499082288869959\n",
      "validation loss: 5.418156051022888\n",
      "num epoch no change: 1\n",
      "epoch: 663\n",
      "training loss: 0.49890935097262223\n",
      "validation loss: 5.3738072112144275\n",
      "num epoch no change: 0\n",
      "epoch: 664\n",
      "training loss: 0.49876201482893745\n",
      "validation loss: 5.419357036614675\n",
      "num epoch no change: 1\n",
      "epoch: 665\n",
      "training loss: 0.4986307793507999\n",
      "validation loss: 5.373916032626451\n",
      "num epoch no change: 0\n",
      "epoch: 666\n",
      "training loss: 0.49847240448526653\n",
      "validation loss: 5.420563755775316\n",
      "num epoch no change: 1\n",
      "epoch: 667\n",
      "training loss: 0.4983823622521319\n",
      "validation loss: 5.374038514082599\n",
      "num epoch no change: 0\n",
      "epoch: 668\n",
      "training loss: 0.4982094209710594\n",
      "validation loss: 5.421770545355367\n",
      "num epoch no change: 1\n",
      "epoch: 669\n",
      "training loss: 0.49815966475890083\n",
      "validation loss: 5.374173857216201\n",
      "num epoch no change: 0\n",
      "epoch: 670\n",
      "training loss: 0.4979682847112544\n",
      "validation loss: 5.422971147121902\n",
      "num epoch no change: 1\n",
      "epoch: 671\n",
      "training loss: 0.49795747442725896\n",
      "validation loss: 5.374320955812952\n",
      "num epoch no change: 0\n",
      "epoch: 672\n",
      "training loss: 0.4977434510855516\n",
      "validation loss: 5.42415873911054\n",
      "num epoch no change: 1\n",
      "epoch: 673\n",
      "training loss: 0.49776978464280974\n",
      "validation loss: 5.374478392303891\n",
      "num epoch no change: 0\n",
      "epoch: 674\n",
      "training loss: 0.49752860544541316\n",
      "validation loss: 5.425325986631051\n",
      "num epoch no change: 1\n",
      "epoch: 675\n",
      "training loss: 0.4975897974192711\n",
      "validation loss: 5.374644445111888\n",
      "num epoch no change: 0\n",
      "epoch: 676\n",
      "training loss: 0.4973166791607716\n",
      "validation loss: 5.426465114989066\n",
      "num epoch no change: 1\n",
      "epoch: 677\n",
      "training loss: 0.4974099493863877\n",
      "validation loss: 5.374817108919799\n",
      "num epoch no change: 0\n",
      "epoch: 678\n",
      "training loss: 0.49709989014752093\n",
      "validation loss: 5.427568005345065\n",
      "num epoch no change: 1\n",
      "epoch: 679\n",
      "training loss: 0.4972219643719336\n",
      "validation loss: 5.3749941296122214\n",
      "num epoch no change: 0\n",
      "epoch: 680\n",
      "training loss: 0.4968698108236842\n",
      "validation loss: 5.428626314237322\n",
      "num epoch no change: 1\n",
      "epoch: 681\n",
      "training loss: 0.4970169353335717\n",
      "validation loss: 5.375173055109983\n",
      "num epoch no change: 0\n",
      "epoch: 682\n",
      "training loss: 0.49661746562244474\n",
      "validation loss: 5.429631616149965\n",
      "num epoch no change: 1\n",
      "epoch: 683\n",
      "training loss: 0.4967854374084619\n",
      "validation loss: 5.375351302553933\n",
      "num epoch no change: 0\n",
      "epoch: 684\n",
      "training loss: 0.49633345903728093\n",
      "validation loss: 5.430575567139869\n",
      "num epoch no change: 1\n",
      "epoch: 685\n",
      "training loss: 0.4965176725156283\n",
      "validation loss: 5.375526241309593\n",
      "num epoch no change: 0\n",
      "epoch: 686\n",
      "training loss: 0.4960081337007743\n",
      "validation loss: 5.431450086005742\n",
      "num epoch no change: 1\n",
      "epoch: 687\n",
      "training loss: 0.4962036442957585\n",
      "validation loss: 5.375695290092228\n",
      "num epoch no change: 0\n",
      "epoch: 688\n",
      "training loss: 0.4956317562531171\n",
      "validation loss: 5.432247547883056\n",
      "num epoch no change: 1\n",
      "epoch: 689\n",
      "training loss: 0.49583336027324254\n",
      "validation loss: 5.375856025220323\n",
      "num epoch no change: 0\n",
      "epoch: 690\n",
      "training loss: 0.4951947268290721\n",
      "validation loss: 5.432960983603773\n",
      "num epoch no change: 1\n",
      "epoch: 691\n",
      "training loss: 0.4953970560875757\n",
      "validation loss: 5.376006295693455\n",
      "num epoch no change: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 692\n",
      "training loss: 0.49468780601452017\n",
      "validation loss: 5.433584276819682\n",
      "num epoch no change: 1\n",
      "epoch: 693\n",
      "training loss: 0.4948854346185132\n",
      "validation loss: 5.37614433958583\n",
      "num epoch no change: 0\n",
      "epoch: 694\n",
      "training loss: 0.49410235126212615\n",
      "validation loss: 5.43411234991374\n",
      "num epoch no change: 1\n",
      "epoch: 695\n",
      "training loss: 0.4942899110061998\n",
      "validation loss: 5.376268895293642\n",
      "num epoch no change: 0\n",
      "epoch: 696\n",
      "training loss: 0.4934305531984448\n",
      "validation loss: 5.434541329268462\n",
      "num epoch no change: 1\n",
      "epoch: 697\n",
      "training loss: 0.4936028531434979\n",
      "validation loss: 5.376379300618543\n",
      "num epoch no change: 0\n",
      "epoch: 698\n",
      "training loss: 0.4926656611925516\n",
      "validation loss: 5.434868680651068\n",
      "num epoch no change: 1\n",
      "epoch: 699\n",
      "training loss: 0.4928178063847015\n",
      "validation loss: 5.376475572637202\n",
      "num epoch no change: 0\n",
      "epoch: 700\n",
      "training loss: 0.4918021871570131\n",
      "validation loss: 5.435093306385477\n",
      "num epoch no change: 1\n",
      "epoch: 701\n",
      "training loss: 0.4919296911293952\n",
      "validation loss: 5.376558461881942\n",
      "num epoch no change: 0\n",
      "epoch: 702\n",
      "training loss: 0.49083607693535625\n",
      "validation loss: 5.435215597616753\n",
      "num epoch no change: 1\n",
      "epoch: 703\n",
      "training loss: 0.4909349626978875\n",
      "validation loss: 5.376629475562848\n",
      "num epoch no change: 0\n",
      "epoch: 704\n",
      "training loss: 0.48976483984367786\n",
      "validation loss: 5.435237437257838\n",
      "num epoch no change: 1\n",
      "epoch: 705\n",
      "training loss: 0.48983172452751356\n",
      "validation loss: 5.376690866344662\n",
      "num epoch no change: 0\n",
      "epoch: 706\n",
      "training loss: 0.4885876289376904\n",
      "validation loss: 5.435162151982323\n",
      "num epoch no change: 1\n",
      "epoch: 707\n",
      "training loss: 0.4886197881047504\n",
      "validation loss: 5.3767455854226425\n",
      "num epoch no change: 0\n",
      "epoch: 708\n",
      "training loss: 0.4873052672385\n",
      "validation loss: 5.434994414663883\n",
      "num epoch no change: 1\n",
      "epoch: 709\n",
      "training loss: 0.4873006760308909\n",
      "validation loss: 5.376797201122149\n",
      "num epoch no change: 0\n",
      "epoch: 710\n",
      "training loss: 0.48592021825687026\n",
      "validation loss: 5.434740101689065\n",
      "num epoch no change: 1\n",
      "epoch: 711\n",
      "training loss: 0.48587756794673626\n",
      "validation loss: 5.376849786734231\n",
      "num epoch no change: 0\n",
      "epoch: 712\n",
      "training loss: 0.4844365024337772\n",
      "validation loss: 5.434406112302891\n",
      "num epoch no change: 1\n",
      "epoch: 713\n",
      "training loss: 0.4843551924149345\n",
      "validation loss: 5.376907783536813\n",
      "num epoch no change: 0\n",
      "epoch: 714\n",
      "training loss: 0.48285956426662674\n",
      "validation loss: 5.434000159328092\n",
      "num epoch no change: 1\n",
      "epoch: 715\n",
      "training loss: 0.4827396709685943\n",
      "validation loss: 5.376975846704598\n",
      "num epoch no change: 0\n",
      "epoch: 716\n",
      "training loss: 0.4811960976305797\n",
      "validation loss: 5.433530542032629\n",
      "num epoch no change: 1\n",
      "epoch: 717\n",
      "training loss: 0.48103832310410366\n",
      "validation loss: 5.3770586829018905\n",
      "num epoch no change: 0\n",
      "epoch: 718\n",
      "training loss: 0.4794538388981778\n",
      "validation loss: 5.433005912495924\n",
      "num epoch no change: 1\n",
      "epoch: 719\n",
      "training loss: 0.479259442813663\n",
      "validation loss: 5.377160888684503\n",
      "num epoch no change: 0\n",
      "epoch: 720\n",
      "training loss: 0.4776413387514382\n",
      "validation loss: 5.432435046529746\n",
      "num epoch no change: 1\n",
      "epoch: 721\n",
      "training loss: 0.47741205819867133\n",
      "validation loss: 5.3772867984049775\n",
      "num epoch no change: 0\n",
      "epoch: 722\n",
      "training loss: 0.4757677240071122\n",
      "validation loss: 5.431826629127224\n",
      "num epoch no change: 1\n",
      "epoch: 723\n",
      "training loss: 0.4755056857592402\n",
      "validation loss: 5.377440349203851\n",
      "num epoch no change: 0\n",
      "epoch: 724\n",
      "training loss: 0.4738424603713147\n",
      "validation loss: 5.431189062703745\n",
      "num epoch no change: 1\n",
      "epoch: 725\n",
      "training loss: 0.4735500901929853\n",
      "validation loss: 5.37762496903464\n",
      "num epoch no change: 0\n",
      "epoch: 726\n",
      "training loss: 0.47187512592063563\n",
      "validation loss: 5.430530304266378\n",
      "num epoch no change: 1\n",
      "epoch: 727\n",
      "training loss: 0.47155505910930784\n",
      "validation loss: 5.377843491712343\n",
      "num epoch no change: 0\n",
      "epoch: 728\n",
      "training loss: 0.46987520344859657\n",
      "validation loss: 5.429857735335033\n",
      "num epoch no change: 1\n",
      "epoch: 729\n",
      "training loss: 0.46953020017380376\n",
      "validation loss: 5.378098100910076\n",
      "num epoch no change: 0\n",
      "epoch: 730\n",
      "training loss: 0.4678518978255352\n",
      "validation loss: 5.429178066157408\n",
      "num epoch no change: 1\n",
      "epoch: 731\n",
      "training loss: 0.4674847660597144\n",
      "validation loss: 5.378390303055377\n",
      "num epoch no change: 0\n",
      "epoch: 732\n",
      "training loss: 0.46581398240542127\n",
      "validation loss: 5.428497273694842\n",
      "num epoch no change: 1\n",
      "epoch: 733\n",
      "training loss: 0.46542751040845537\n",
      "validation loss: 5.378720927359924\n",
      "num epoch no change: 0\n",
      "epoch: 734\n",
      "training loss: 0.46376967646167117\n",
      "validation loss: 5.427820571141241\n",
      "num epoch no change: 1\n",
      "epoch: 735\n",
      "training loss: 0.46336657596610836\n",
      "validation loss: 5.379090149864478\n",
      "num epoch no change: 0\n",
      "epoch: 736\n",
      "training loss: 0.4617265537937997\n",
      "validation loss: 5.427152405448574\n",
      "num epoch no change: 1\n",
      "epoch: 737\n",
      "training loss: 0.46130941429918726\n",
      "validation loss: 5.379497537450477\n",
      "num epoch no change: 0\n",
      "epoch: 738\n",
      "training loss: 0.4596914811184693\n",
      "validation loss: 5.426496478492303\n",
      "num epoch no change: 1\n",
      "epoch: 739\n",
      "training loss: 0.4592627350821417\n",
      "validation loss: 5.379942107264741\n",
      "num epoch no change: 0\n",
      "epoch: 740\n",
      "training loss: 0.45767058369459573\n",
      "validation loss: 5.425855787096369\n",
      "num epoch no change: 1\n",
      "epoch: 741\n",
      "training loss: 0.4572324819239099\n",
      "validation loss: 5.380422396886896\n",
      "num epoch no change: 0\n",
      "epoch: 742\n",
      "training loss: 0.4556692348420968\n",
      "validation loss: 5.425232677092836\n",
      "num epoch no change: 1\n",
      "epoch: 743\n",
      "training loss: 0.45522383105388287\n",
      "validation loss: 5.380936540773962\n",
      "num epoch no change: 0\n",
      "epoch: 744\n",
      "training loss: 0.45369206557319397\n",
      "validation loss: 5.424628906842126\n",
      "num epoch no change: 1\n",
      "epoch: 745\n",
      "training loss: 0.453241208881116\n",
      "validation loss: 5.381482348963088\n",
      "num epoch no change: 0\n",
      "epoch: 746\n",
      "training loss: 0.4517429904162111\n",
      "validation loss: 5.424045716101413\n",
      "num epoch no change: 1\n",
      "epoch: 747\n",
      "training loss: 0.45128832441797245\n",
      "validation loss: 5.3820573846166235\n",
      "num epoch no change: 0\n",
      "epoch: 748\n",
      "training loss: 0.4498252456141596\n",
      "validation loss: 5.423483896722875\n",
      "num epoch no change: 1\n",
      "epoch: 749\n",
      "training loss: 0.449368212755402\n",
      "validation loss: 5.382659037677453\n",
      "num epoch no change: 0\n",
      "epoch: 750\n",
      "training loss: 0.4479414361600365\n",
      "validation loss: 5.42294386231767\n",
      "num epoch no change: 1\n",
      "epoch: 751\n",
      "training loss: 0.4474832861262927\n",
      "validation loss: 5.383284592599823\n",
      "num epoch no change: 0\n",
      "epoch: 752\n",
      "training loss: 0.44609358852659614\n",
      "validation loss: 5.4224257146799975\n",
      "num epoch no change: 1\n",
      "epoch: 753\n",
      "training loss: 0.4456353895359964\n",
      "validation loss: 5.383931288782693\n",
      "num epoch no change: 0\n",
      "epoch: 754\n",
      "training loss: 0.44428320640714275\n",
      "validation loss: 5.42192930538483\n",
      "num epoch no change: 1\n",
      "epoch: 755\n",
      "training loss: 0.44382585842476796\n",
      "validation loss: 5.3845963729238004\n",
      "num epoch no change: 0\n",
      "epoch: 756\n",
      "training loss: 0.4425113272621951\n",
      "validation loss: 5.4214542915254285\n",
      "num epoch no change: 1\n",
      "epoch: 757\n",
      "training loss: 0.4420555763158177\n",
      "validation loss: 5.385277143012897\n",
      "num epoch no change: 0\n",
      "epoch: 758\n",
      "training loss: 0.44077857793206576\n",
      "validation loss: 5.421000185026453\n",
      "num epoch no change: 1\n",
      "epoch: 759\n",
      "training loss: 0.4403250308662525\n",
      "validation loss: 5.3859709840839445\n",
      "num epoch no change: 0\n",
      "epoch: 760\n",
      "training loss: 0.43908522800488897\n",
      "validation loss: 5.420566395350053\n",
      "num epoch no change: 1\n",
      "epoch: 761\n",
      "training loss: 0.4386343671575065\n",
      "validation loss: 5.386675396149624\n",
      "num epoch no change: 0\n",
      "epoch: 762\n",
      "training loss: 0.4374312400096973\n",
      "validation loss: 5.420152265707612\n",
      "num epoch no change: 1\n",
      "epoch: 763\n",
      "training loss: 0.4369834374264332\n",
      "validation loss: 5.3873880149540705\n",
      "num epoch no change: 0\n",
      "epoch: 764\n",
      "training loss: 0.4358163158281758\n",
      "validation loss: 5.41975710310558\n",
      "num epoch no change: 1\n",
      "epoch: 765\n",
      "training loss: 0.43537184674407964\n",
      "validation loss: 5.388106626313862\n",
      "num epoch no change: 0\n",
      "epoch: 766\n",
      "training loss: 0.43423993898552893\n",
      "validation loss: 5.419380202700662\n",
      "num epoch no change: 1\n",
      "epoch: 767\n",
      "training loss: 0.433798994396994\n",
      "validation loss: 5.388829174884993\n",
      "num epoch no change: 0\n",
      "epoch: 768\n",
      "training loss: 0.43270141269304274\n",
      "validation loss: 5.419020867028263\n",
      "num epoch no change: 1\n",
      "epoch: 769\n",
      "training loss: 0.4322641109197853\n",
      "validation loss: 5.389553768209321\n",
      "num epoch no change: 0\n",
      "epoch: 770\n",
      "training loss: 0.431199893677428\n",
      "validation loss: 5.418678420710187\n",
      "num epoch no change: 1\n",
      "epoch: 771\n",
      "training loss: 0.43076629087336193\n",
      "validation loss: 5.390278676870276\n",
      "num epoch no change: 0\n",
      "epoch: 772\n",
      "training loss: 0.42973442195115885\n",
      "validation loss: 5.418352221254386\n",
      "num epoch no change: 1\n",
      "epoch: 773\n",
      "training loss: 0.4293045215676709\n",
      "validation loss: 5.391002331536172\n",
      "num epoch no change: 0\n",
      "epoch: 774\n",
      "training loss: 0.4283039467605568\n",
      "validation loss: 5.418041666539758\n",
      "num epoch no change: 1\n",
      "epoch: 775\n",
      "training loss: 0.42787770799773095\n",
      "validation loss: 5.391723317599679\n",
      "num epoch no change: 0\n",
      "epoch: 776\n",
      "training loss: 0.42690734900094446\n",
      "validation loss: 5.417746199541717\n",
      "num epoch no change: 1\n",
      "epoch: 777\n",
      "training loss: 0.42648469430402514\n",
      "validation loss: 5.392440368042249\n",
      "num epoch no change: 0\n",
      "epoch: 778\n",
      "training loss: 0.42554346041698066\n",
      "validation loss: 5.417465310805473\n",
      "num epoch no change: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 779\n",
      "training loss: 0.42512428208881303\n",
      "validation loss: 5.393152355068439\n",
      "num epoch no change: 0\n",
      "epoch: 780\n",
      "training loss: 0.4242110799168016\n",
      "validation loss: 5.417198539119324\n",
      "num epoch no change: 1\n",
      "epoch: 781\n",
      "training loss: 0.4237952459240221\n",
      "validation loss: 5.393858280971864\n",
      "num epoch no change: 0\n",
      "epoch: 782\n",
      "training loss: 0.42290898732545806\n",
      "validation loss: 5.4169454707837055\n",
      "num epoch no change: 1\n",
      "epoch: 783\n",
      "training loss: 0.4224963463783933\n",
      "validation loss: 5.3945572686150856\n",
      "num epoch no change: 0\n",
      "epoch: 784\n",
      "training loss: 0.4216359548903664\n",
      "validation loss: 5.416705737815981\n",
      "num epoch no change: 1\n",
      "epoch: 785\n",
      "training loss: 0.42122634087526056\n",
      "validation loss: 5.395248551832592\n",
      "num epoch no change: 0\n",
      "epoch: 786\n",
      "training loss: 0.4203907568321362\n",
      "validation loss: 5.416479015378331\n",
      "num epoch no change: 1\n",
      "epoch: 787\n",
      "training loss: 0.4199839926705527\n",
      "validation loss: 5.395931465999634\n",
      "num epoch no change: 0\n",
      "epoch: 788\n",
      "training loss: 0.4191721772107865\n",
      "validation loss: 5.416265018667481\n",
      "num epoch no change: 1\n",
      "epoch: 789\n",
      "training loss: 0.41876807821567313\n",
      "validation loss: 5.396605438951614\n",
      "num epoch no change: 0\n",
      "epoch: 790\n",
      "training loss: 0.4179790163518937\n",
      "validation loss: 5.416063499461371\n",
      "num epoch no change: 1\n",
      "epoch: 791\n",
      "training loss: 0.41757739314350406\n",
      "validation loss: 5.39726998238828\n",
      "num epoch no change: 0\n",
      "epoch: 792\n",
      "training loss: 0.41681009605106056\n",
      "validation loss: 5.415874242479456\n",
      "num epoch no change: 1\n",
      "epoch: 793\n",
      "training loss: 0.41641075708922753\n",
      "validation loss: 5.397924683854093\n",
      "num epoch no change: 0\n",
      "epoch: 794\n",
      "training loss: 0.4156642637493088\n",
      "validation loss: 5.415697061679996\n",
      "num epoch no change: 1\n",
      "epoch: 795\n",
      "training loss: 0.41526701753180584\n",
      "validation loss: 5.398569199350538\n",
      "num epoch no change: 0\n",
      "epoch: 796\n",
      "training loss: 0.414540395847321\n",
      "validation loss: 5.415531796589305\n",
      "num epoch no change: 1\n",
      "epoch: 797\n",
      "training loss: 0.4141450528174832\n",
      "validation loss: 5.399203246607004\n",
      "num epoch no change: 0\n",
      "epoch: 798\n",
      "training loss: 0.4134374003033026\n",
      "validation loss: 5.415378308734131\n",
      "num epoch no change: 1\n",
      "epoch: 799\n",
      "training loss: 0.4130437745039358\n",
      "validation loss: 5.399826599013259\n",
      "num epoch no change: 0\n",
      "epoch: 800\n",
      "training loss: 0.4123542186379777\n",
      "validation loss: 5.415236478228699\n",
      "num epoch no change: 1\n",
      "epoch: 801\n",
      "training loss: 0.4119621291428971\n",
      "validation loss: 5.400439080198423\n",
      "num epoch no change: 0\n",
      "epoch: 802\n",
      "training loss: 0.4112898274509438\n",
      "validation loss: 5.415106200551938\n",
      "num epoch no change: 1\n",
      "epoch: 803\n",
      "training loss: 0.4108990996003992\n",
      "validation loss: 5.401040559227263\n",
      "num epoch no change: 0\n",
      "epoch: 804\n",
      "training loss: 0.41024323953538466\n",
      "validation loss: 5.414987383537578\n",
      "num epoch no change: 1\n",
      "epoch: 805\n",
      "training loss: 0.4098537059971253\n",
      "validation loss: 5.401630946374448\n",
      "num epoch no change: 0\n",
      "epoch: 806\n",
      "training loss: 0.4092135046629203\n",
      "validation loss: 5.4148799445898295\n",
      "num epoch no change: 1\n",
      "epoch: 807\n",
      "training loss: 0.4088250063367449\n",
      "validation loss: 5.402210189430381\n",
      "num epoch no change: 0\n",
      "epoch: 808\n",
      "training loss: 0.4081997100971213\n",
      "validation loss: 5.414783808129609\n",
      "num epoch no change: 1\n",
      "epoch: 809\n",
      "training loss: 0.40781209687744957\n",
      "validation loss: 5.402778270487838\n",
      "num epoch no change: 0\n",
      "epoch: 810\n",
      "training loss: 0.4072009808827597\n",
      "validation loss: 5.414698903270519\n",
      "num epoch no change: 1\n",
      "epoch: 811\n",
      "training loss: 0.40681411229098996\n",
      "validation loss: 5.403335203156293\n",
      "num epoch no change: 0\n",
      "epoch: 812\n",
      "training loss: 0.4062164799481588\n",
      "validation loss: 5.414625161719636\n",
      "num epoch no change: 1\n",
      "epoch: 813\n",
      "training loss: 0.40583022564434607\n",
      "validation loss: 5.40388103015046\n",
      "num epoch no change: 0\n",
      "epoch: 814\n",
      "training loss: 0.40524540804983933\n",
      "validation loss: 5.414562515895289\n",
      "num epoch no change: 1\n",
      "epoch: 815\n",
      "training loss: 0.4048596482314548\n",
      "validation loss: 5.404415821200409\n",
      "num epoch no change: 0\n",
      "epoch: 816\n",
      "training loss: 0.40428700358192415\n",
      "validation loss: 5.414510897252246\n",
      "num epoch no change: 1\n",
      "epoch: 817\n",
      "training loss: 0.40390162927613843\n",
      "validation loss: 5.404939671232651\n",
      "num epoch no change: 0\n",
      "epoch: 818\n",
      "training loss: 0.4033405422673368\n",
      "validation loss: 5.41447023480365\n",
      "num epoch no change: 1\n",
      "epoch: 819\n",
      "training loss: 0.4029554555223067\n",
      "validation loss: 5.405452698774609\n",
      "num epoch no change: 0\n",
      "epoch: 820\n",
      "training loss: 0.4024053367434897\n",
      "validation loss: 5.414440453828708\n",
      "num epoch no change: 1\n",
      "epoch: 821\n",
      "training loss: 0.40202045072353126\n",
      "validation loss: 5.405955044538207\n",
      "num epoch no change: 0\n",
      "epoch: 822\n",
      "training loss: 0.40148073605190615\n",
      "validation loss: 5.414421474755188\n",
      "num epoch no change: 1\n",
      "epoch: 823\n",
      "training loss: 0.4010959750411\n",
      "validation loss: 5.406446870142483\n",
      "num epoch no change: 0\n",
      "epoch: 824\n",
      "training loss: 0.4005661250387561\n",
      "validation loss: 5.414413212206189\n",
      "num epoch no change: 1\n",
      "epoch: 825\n",
      "training loss: 0.40018142435745185\n",
      "validation loss: 5.406928356939315\n",
      "num epoch no change: 0\n",
      "epoch: 826\n",
      "training loss: 0.3996609236716554\n",
      "validation loss: 5.414415574201167\n",
      "num epoch no change: 1\n",
      "epoch: 827\n",
      "training loss: 0.39927622951044234\n",
      "validation loss: 5.407399704910762\n",
      "num epoch no change: 0\n",
      "epoch: 828\n",
      "training loss: 0.39876458627702155\n",
      "validation loss: 5.414428461501977\n",
      "num epoch no change: 1\n",
      "epoch: 829\n",
      "training loss: 0.39837985545298615\n",
      "validation loss: 5.407861131611088\n",
      "num epoch no change: 0\n",
      "epoch: 830\n",
      "training loss: 0.39787660070177655\n",
      "validation loss: 5.414451767095411\n",
      "num epoch no change: 1\n",
      "epoch: 831\n",
      "training loss: 0.39749180034221704\n",
      "validation loss: 5.408312871130812\n",
      "num epoch no change: 0\n",
      "epoch: 832\n",
      "training loss: 0.3969964874030942\n",
      "validation loss: 5.414485375804354\n",
      "num epoch no change: 1\n",
      "epoch: 833\n",
      "training loss: 0.3966115945622892\n",
      "validation loss: 5.408755173064627\n",
      "num epoch no change: 0\n",
      "epoch: 834\n",
      "training loss: 0.39612379847011536\n",
      "validation loss: 5.414529164020451\n",
      "num epoch no change: 1\n",
      "epoch: 835\n",
      "training loss: 0.39573879968517833\n",
      "validation loss: 5.409188301468891\n",
      "num epoch no change: 0\n",
      "epoch: 836\n",
      "training loss: 0.39525811658201754\n",
      "validation loss: 5.4145829995515955\n",
      "num epoch no change: 1\n",
      "epoch: 837\n",
      "training loss: 0.3948730073743097\n",
      "validation loss: 5.409612533798413\n",
      "num epoch no change: 0\n",
      "epoch: 838\n",
      "training loss: 0.3943990539074321\n",
      "validation loss: 5.4146467415780855\n",
      "num epoch no change: 1\n",
      "epoch: 839\n",
      "training loss: 0.39401383823641484\n",
      "validation loss: 5.410028159815739\n",
      "num epoch no change: 0\n",
      "epoch: 840\n",
      "training loss: 0.39354625095090323\n",
      "validation loss: 5.4147202407115245\n",
      "num epoch no change: 1\n",
      "epoch: 841\n",
      "training loss: 0.3931609406276398\n",
      "validation loss: 5.41043548046925\n",
      "num epoch no change: 0\n",
      "epoch: 842\n",
      "training loss: 0.3926993753527864\n",
      "validation loss: 5.414803339150768\n",
      "num epoch no change: 1\n",
      "epoch: 843\n",
      "training loss: 0.392313989420569\n",
      "validation loss: 5.410834806739442\n",
      "num epoch no change: 0\n",
      "epoch: 844\n",
      "training loss: 0.3918581206496564\n",
      "validation loss: 5.414895870929199\n",
      "num epoch no change: 1\n",
      "epoch: 845\n",
      "training loss: 0.39147268473940056\n",
      "validation loss: 5.411226458455023\n",
      "num epoch no change: 0\n",
      "epoch: 846\n",
      "training loss: 0.3910222050028955\n",
      "validation loss: 5.414997662247538\n",
      "num epoch no change: 1\n",
      "epoch: 847\n",
      "training loss: 0.39063675067099396\n",
      "validation loss: 5.411610763082724\n",
      "num epoch no change: 0\n",
      "epoch: 848\n",
      "training loss: 0.3901913699036047\n",
      "validation loss: 5.415108531886292\n",
      "num epoch no change: 1\n",
      "epoch: 849\n",
      "training loss: 0.38980593395988133\n",
      "validation loss: 5.411988054496353\n",
      "num epoch no change: 0\n",
      "epoch: 850\n",
      "training loss: 0.38936537886232464\n",
      "validation loss: 5.4152282916916015\n",
      "num epoch no change: 1\n",
      "epoch: 851\n",
      "training loss: 0.3889800026955516\n",
      "validation loss: 5.41235867173205\n",
      "num epoch no change: 0\n",
      "epoch: 852\n",
      "training loss: 0.3885440160922334\n",
      "validation loss: 5.415356747127905\n",
      "num epoch no change: 1\n",
      "epoch: 853\n",
      "training loss: 0.38815874500040215\n",
      "validation loss: 5.412722957737654\n",
      "num epoch no change: 0\n",
      "epoch: 854\n",
      "training loss: 0.38772708519450894\n",
      "validation loss: 5.415493697890593\n",
      "num epoch no change: 1\n",
      "epoch: 855\n",
      "training loss: 0.3873419677266421\n",
      "validation loss: 5.4130812581248176\n",
      "num epoch no change: 0\n",
      "epoch: 856\n",
      "training loss: 0.3869144078543973\n",
      "validation loss: 5.415638938571258\n",
      "num epoch no change: 1\n",
      "epoch: 857\n",
      "training loss: 0.3865294951702222\n",
      "validation loss: 5.413433919932896\n",
      "num epoch no change: 0\n",
      "epoch: 858\n",
      "training loss: 0.3861058225562213\n",
      "validation loss: 5.415792259368045\n",
      "num epoch no change: 1\n",
      "epoch: 859\n",
      "training loss: 0.38572116780944454\n",
      "validation loss: 5.413781290413625\n",
      "num epoch no change: 0\n",
      "epoch: 860\n",
      "training loss: 0.38530118332511376\n",
      "validation loss: 5.415953446832984\n",
      "num epoch no change: 1\n",
      "epoch: 861\n",
      "training loss: 0.3849168410754115\n",
      "validation loss: 5.414123715845649\n",
      "num epoch no change: 0\n",
      "epoch: 862\n",
      "training loss: 0.38450035850268255\n",
      "validation loss: 5.416122284648199\n",
      "num epoch no change: 1\n",
      "epoch: 863\n",
      "training loss: 0.3841163841608202\n",
      "validation loss: 5.4144615403873555\n",
      "num epoch no change: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 864\n",
      "training loss: 0.38370322956310493\n",
      "validation loss: 5.416298554422444\n",
      "num epoch no change: 1\n",
      "epoch: 865\n",
      "training loss: 0.3833196788728924\n",
      "validation loss: 5.414795104976169\n",
      "num epoch no change: 0\n",
      "epoch: 866\n",
      "training loss: 0.3829096899753887\n",
      "validation loss: 5.416482036499543\n",
      "num epoch no change: 1\n",
      "epoch: 867\n",
      "training loss: 0.3825266185354192\n",
      "validation loss: 5.415124746281577\n",
      "num epoch no change: 0\n",
      "epoch: 868\n",
      "training loss: 0.3821196441166815\n",
      "validation loss: 5.416672510770077\n",
      "num epoch no change: 1\n",
      "epoch: 869\n",
      "training loss: 0.38173710694406127\n",
      "validation loss: 5.415450795718478\n",
      "num epoch no change: 0\n",
      "epoch: 870\n",
      "training loss: 0.3813330062406222\n",
      "validation loss: 5.416869757477993\n",
      "num epoch no change: 1\n",
      "epoch: 871\n",
      "training loss: 0.3809510573781673\n",
      "validation loss: 5.4157735785264585\n",
      "num epoch no change: 0\n",
      "epoch: 872\n",
      "training loss: 0.3805496995038385\n",
      "validation loss: 5.417073558013861\n",
      "num epoch no change: 1\n",
      "epoch: 873\n",
      "training loss: 0.3801683916715022\n",
      "validation loss: 5.416093412919775\n",
      "num epoch no change: 0\n",
      "epoch: 874\n",
      "training loss: 0.3797696550527892\n",
      "validation loss: 5.417283695686898\n",
      "num epoch no change: 1\n",
      "epoch: 875\n",
      "training loss: 0.37938903934342283\n",
      "validation loss: 5.416410609311709\n",
      "num epoch no change: 0\n",
      "epoch: 876\n",
      "training loss: 0.37899281117228817\n",
      "validation loss: 5.417499956468353\n",
      "num epoch no change: 1\n",
      "epoch: 877\n",
      "training loss: 0.3786129367912176\n",
      "validation loss: 5.416725469616087\n",
      "num epoch no change: 0\n",
      "epoch: 878\n",
      "training loss: 0.37821911249622225\n",
      "validation loss: 5.4177221296993805\n",
      "num epoch no change: 1\n",
      "epoch: 879\n",
      "training loss: 0.37784002654356585\n",
      "validation loss: 5.417038286627751\n",
      "num epoch no change: 0\n",
      "epoch: 880\n",
      "training loss: 0.3774485092802078\n",
      "validation loss: 5.417950008757079\n",
      "num epoch no change: 1\n",
      "epoch: 881\n",
      "training loss: 0.37707025657437127\n",
      "validation loss: 5.417349343482849\n",
      "num epoch no change: 0\n",
      "epoch: 882\n",
      "training loss: 0.3766809567352435\n",
      "validation loss: 5.418183391673214\n",
      "num epoch no change: 1\n",
      "epoch: 883\n",
      "training loss: 0.37630357967560135\n",
      "validation loss: 5.417658913198829\n",
      "num epoch no change: 0\n",
      "epoch: 884\n",
      "training loss: 0.3759164144207964\n",
      "validation loss: 5.418422081700858\n",
      "num epoch no change: 1\n",
      "epoch: 885\n",
      "training loss: 0.37553995288722397\n",
      "validation loss: 5.417967258293434\n",
      "num epoch no change: 0\n",
      "epoch: 886\n",
      "training loss: 0.375154845695237\n",
      "validation loss: 5.418665887825034\n",
      "num epoch no change: 1\n",
      "epoch: 887\n",
      "training loss: 0.374779336981876\n",
      "validation loss: 5.41827463048095\n",
      "num epoch no change: 0\n",
      "epoch: 888\n",
      "training loss: 0.37439621722109695\n",
      "validation loss: 5.41891462521424\n",
      "num epoch no change: 1\n",
      "epoch: 889\n",
      "training loss: 0.3740216960015312\n",
      "validation loss: 5.418581270443404\n",
      "num epoch no change: 0\n",
      "epoch: 890\n",
      "training loss: 0.3736404985222747\n",
      "validation loss: 5.4191681156106934\n",
      "num epoch no change: 1\n",
      "epoch: 891\n",
      "training loss: 0.37326699684315323\n",
      "validation loss: 5.418887407673926\n",
      "num epoch no change: 0\n",
      "epoch: 892\n",
      "training loss: 0.3728876615900413\n",
      "validation loss: 5.419426187657982\n",
      "num epoch no change: 1\n",
      "epoch: 893\n",
      "training loss: 0.37251520889011386\n",
      "validation loss: 5.419193260388643\n",
      "num epoch no change: 0\n",
      "epoch: 894\n",
      "training loss: 0.3721376805345323\n",
      "validation loss: 5.419688677165599\n",
      "num epoch no change: 1\n",
      "epoch: 895\n",
      "training loss: 0.3717663036860384\n",
      "validation loss: 5.419499035503393\n",
      "num epoch no change: 0\n",
      "epoch: 896\n",
      "training loss: 0.3713905312782843\n",
      "validation loss: 5.419955427310727\n",
      "num epoch no change: 1\n",
      "epoch: 897\n",
      "training loss: 0.371020254647681\n",
      "validation loss: 5.419804928670858\n",
      "num epoch no change: 0\n",
      "epoch: 898\n",
      "training loss: 0.3706461912883554\n",
      "validation loss: 5.420226288778359\n",
      "num epoch no change: 1\n",
      "epoch: 899\n",
      "training loss: 0.370277036813439\n",
      "validation loss: 5.420111124373649\n",
      "num epoch no change: 0\n",
      "epoch: 900\n",
      "training loss: 0.36990463934357476\n",
      "validation loss: 5.4205011198415685\n",
      "num epoch no change: 1\n",
      "epoch: 901\n",
      "training loss: 0.36953662662418085\n",
      "validation loss: 5.420417796068557\n",
      "num epoch no change: 2\n",
      "epoch: 902\n",
      "training loss: 0.369165855333549\n",
      "validation loss: 5.420779786384353\n",
      "num epoch no change: 3\n",
      "epoch: 903\n",
      "training loss: 0.36879900173316355\n",
      "validation loss: 5.420725106377041\n",
      "num epoch no change: 4\n",
      "epoch: 904\n",
      "training loss: 0.36842982008617736\n",
      "validation loss: 5.421062161870155\n",
      "num epoch no change: 5\n",
      "epoch: 905\n",
      "training loss: 0.36806414084196026\n",
      "validation loss: 5.4210332073170004\n",
      "num epoch no change: 6\n",
      "epoch: 906\n",
      "training loss: 0.3676965152205581\n",
      "validation loss: 5.421348127259363\n",
      "num epoch no change: 7\n",
      "epoch: 907\n",
      "training loss: 0.36733202355948924\n",
      "validation loss: 5.421342240570769\n",
      "num epoch no change: 8\n",
      "epoch: 908\n",
      "training loss: 0.36696592302237235\n",
      "validation loss: 5.4216375708798905\n",
      "num epoch no change: 9\n",
      "epoch: 909\n",
      "training loss: 0.36660263028142726\n",
      "validation loss: 5.421652337784455\n",
      "num epoch no change: 10\n",
      "epoch: 910\n",
      "training loss: 0.3662380263390167\n",
      "validation loss: 5.421930388254858\n",
      "num epoch no change: 11\n"
     ]
    }
   ],
   "source": [
    "nodes = [100, 50, 100] # use to specify a number of hidden nodes per layer\n",
    "activations = [] # use if you want a diff activationFn per layer\n",
    "\n",
    "nn = NeuralNetwork(layers=3, nnodes=100, batchSize=50, \n",
    "                   activationFn=\"tanh\", lr=.001, lr_type=\"annealing\", \n",
    "                   max_epoch=2000, momentum=0.9, early_stopping=True)\n",
    "nn.fit(X_std, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error of Housing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: $809.69\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y, nn.predict(X_std))\n",
    "print('Mean absolute error: $%0.2f'%(mae*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these to results to those in nn_tuning_example.ipynb.  Goal: Get MAE Under $1000 with our NN.  Then, we know our NN is working well and can use it on the dataset for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR:\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        # create vector of ones...\n",
    "        ones = np.ones(shape=len(X_train))[..., None]\n",
    "        #...and add to feature matrix\n",
    "        X = np.concatenate((ones, X_train), 1)\n",
    "        #calculate coefficients using closed-form solution\n",
    "        self.coeffs = np.linalg.inv(X.transpose().dot(X)).dot(X.transpose()).dot(y_train)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        ones = np.ones(shape=len(X_test))[..., None]\n",
    "        X_test = np.concatenate((ones, X_test), 1)\n",
    "        y_hat = X_test.dot(self.coeffs)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: $17885.89\n"
     ]
    }
   ],
   "source": [
    "lr = LR()\n",
    "lr.fit(X, y)\n",
    "mae = mean_absolute_error(y, lr.predict(X_std))\n",
    "print('Mean absolute error: $%0.2f'%(mae*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
